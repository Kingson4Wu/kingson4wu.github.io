<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/uploads/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="拉巴力的纸皮箱" type="application/atom+xml" />






<meta name="description" content="为啥不吃三文鱼">
<meta property="og:type" content="website">
<meta property="og:title" content="拉巴力的纸皮箱">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="拉巴力的纸皮箱">
<meta property="og:description" content="为啥不吃三文鱼">
<meta property="og:locale">
<meta property="article:author" content="Kingson Wu">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>拉巴力的纸皮箱</title>
  








<meta name="generator" content="Hexo 6.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">拉巴力的纸皮箱</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/05/31/20250531-ren-gong-zhi-neng-yi-ci-shi-fou-zhun-que-yi-ci-guan-yu-ai-ben-zhi-de-fan-si/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/05/31/20250531-ren-gong-zhi-neng-yi-ci-shi-fou-zhun-que-yi-ci-guan-yu-ai-ben-zhi-de-fan-si/" itemprop="url">20250531-“人工智能”一词是否准确？一次关于AI本质的反思</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-05-31T00:22:28+08:00">
                2025-05-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>AI – “基于数据的规律发现系统”</p>
</blockquote>
</blockquote>
<ul>
<li>“人工智能（AI）”这个名字，其实是一种历史性命名，也是一种拟人化的表达。它给人一种错觉，仿佛机器在模仿或复制人类的智能。然而，从技术本质上看，今天的人工智能主要依赖于数据驱动的模式识别和规律学习，更准确地说，它是一种“基于数据的规律发现系统”。无论是人类还是机器，学习的对象都是客观存在的规律，只是各自的方法不同。规律本身并不依赖于学习者，它们存在于自然和社会系统之中，等待被发现。机器学习的意义，不在于赋予机器“像人一样的智能”，而在于它可以在极大规模和复杂度下识别人类难以企及的模式，这种能力甚至在某些领域已经超越了人类。然而，AI虽能拟合规律，却不具备理解、动机和意识，因此我们说它“智能”仍属工程性描述，而非哲学意义上的智能。从这个角度看，“人工智能”这一术语在一定程度上是误导性的，如果要更准确地描述其本质，也许“规律学习系统”或“模式发现机器”更贴切，但这类表述在传播和产业化上显然不如“AI”简洁有力。因此，当前的术语是一种权衡：技术准确性让位于传播效率。我们需要清醒地认识到，AI不是在“思考”，它只是以统计和优化的方式，从数据中提取规律，并按特定目标进行预测或生成。</li>
</ul>
<hr>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><pre>
AI这个名字其实并不准确
人工智能
其实是通过数据来学习规律
跟人没有关系
只是人或机器用他们的方式去学习，
不管你人类或机器学不学习
规律就在那里，只是表现形式不一样，但规律的本质是一样的，
而且有些规律人类也学不会，超过人的能力
所以叫人工智能是片面的表达
应该叫智能规律，或规律学习？


——

当然，以下是对原文的整理和简要总结：

⸻

整理后的表达：

“人工智能（AI）”这个名称其实并不准确。所谓人工智能，本质上只是通过数据来学习和提取规律的过程，与人类的思维或意识没有直接关系。无论是人还是机器，学习的只是客观存在的规律，而这些规律本身独立于学习主体，始终存在，只是表现形式不同而已。

机器和人只是用不同的方式去接近这些规律，有些规律甚至超出了人类的认知能力，只有机器才能捕捉到。因此，用“人工智能”来命名这种技术是片面的，更准确的表达也许应该是“智能规律”或“规律学习”。

⸻

简要总结观点：

这段文字认为，“人工智能”这一术语带有误导性，因为它强调了“人”而忽略了技术的本质：对客观规律的学习和拟合。作者主张，AI其实是一种“规律学习”系统，不应被简单等同于模仿人类智能。

</pre>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/03/23/20250323-shi-yong-java-diao-yong-rust-gou-jian-de-dong-tai-ku/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/03/23/20250323-shi-yong-java-diao-yong-rust-gou-jian-de-dong-tai-ku/" itemprop="url">使用Java调用Rust构建的动态库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-03-23T14:41:37+08:00">
                2025-03-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>近期帮朋友做一个需求，需要将某个Rust项目的一部分功能移植到Java中，使Java应用能使用</p>
</blockquote>
</blockquote>
<h2 id="方案1-直接将Rust翻译成Java代码"><a href="#方案1-直接将Rust翻译成Java代码" class="headerlink" title="方案1: 直接将Rust翻译成Java代码"></a>方案1: 直接将Rust翻译成Java代码</h2><blockquote>
<blockquote>
<p>前置准备：将Rust项目跑通，方便通过debug对照执行细节，从而一步步翻译成Java代码<br>希望借助AI的力量帮忙完成</p>
</blockquote>
</blockquote>
<ul>
<li>借助AI的方案如下：<ul>
<li>首先，我已经跑通了需要抽取的功能的相关测试用例</li>
<li>然后，让AI帮忙将涉及这些功能相关的代码抽取成单独的Rust项目（结果还是很乱七八糟）</li>
<li>大概是因为上下文内容太多的关系，AI执行任务的效果很差</li>
<li>没办法，于是自己拆分代码，让AI软件帮忙根据代码块逐个进行转化，结果效果是好了很多，能帮助不少，不过这样效率太低，而且AI有时候也经常出错，需要自己慢慢调整</li>
<li>看来AI目前在一次性的转化大量代码的效率和准确性还是不够</li>
<li>本次程序员该懒就懒的宗旨，我决定另辟蹊径，采用方案2</li>
</ul>
</li>
</ul>
<h2 id="方案2-直接将相关功能的Rust功能编译成动态库，由Java直接调用"><a href="#方案2-直接将相关功能的Rust功能编译成动态库，由Java直接调用" class="headerlink" title="方案2: 直接将相关功能的Rust功能编译成动态库，由Java直接调用"></a>方案2: 直接将相关功能的Rust功能编译成动态库，由Java直接调用</h2><blockquote>
<blockquote>
<p>省去翻译代码的重复工作<br>需要构建不同平台的动态库<br>Java代码在加载前需要判断环境加载相应的动态库<br>使用Github Action来构建各种平台的动态库<br>Java端充分测试，Java8应用测试，Java9以上模块化系统是否可用测试，Windows等其他平台测试</p>
</blockquote>
</blockquote>
<hr>
<blockquote>
<blockquote>
<p>以下由AI（ChatGPT）帮我完成的文章</p>
</blockquote>
</blockquote>
<h1 id="使用Java调用Rust构建的动态库"><a href="#使用Java调用Rust构建的动态库" class="headerlink" title="使用Java调用Rust构建的动态库"></a>使用Java调用Rust构建的动态库</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在最近的一个项目中，我需要将一个Rust项目中的部分功能迁移到Java应用中，供Java系统调用。为了简化过程，我决定绕过将Rust代码完全转化为Java的复杂任务，而是直接通过Rust构建动态库，再通过Java来调用。这种方法不仅减少了代码转换的工作量，还利用了Rust的高性能特点，提高了Java应用的效率。</p>
<h2 id="方案1-直接将Rust翻译成Java代码-1"><a href="#方案1-直接将Rust翻译成Java代码-1" class="headerlink" title="方案1: 直接将Rust翻译成Java代码"></a>方案1: 直接将Rust翻译成Java代码</h2><h3 id="前置准备"><a href="#前置准备" class="headerlink" title="前置准备"></a>前置准备</h3><p>为了开始这个过程，我首先确保了Rust项目能够成功运行，并且通过调试工具逐步分析每个功能的执行细节。这是为了确保我可以一步步将Rust的实现逻辑转化为Java代码。</p>
<h3 id="使用AI进行代码转换"><a href="#使用AI进行代码转换" class="headerlink" title="使用AI进行代码转换"></a>使用AI进行代码转换</h3><p>最初，我尝试借助AI工具自动化地将Rust代码转换为Java代码。以下是我使用AI进行代码转换的过程：</p>
<ul>
<li>我首先跑通了相关的测试用例，确保所有需要移植的功能都能正常工作。</li>
<li>然后，我让AI帮助抽取与这些功能相关的Rust代码，并转化成单独的Rust项目。但由于上下文过多，AI的效果并不理想，生成的代码混乱且不完整。</li>
<li>之后，我将代码拆分成更小的部分，让AI逐一处理，虽然效果有所改善，但这种方式依旧效率低下，且AI经常会出错，导致我不得不花大量时间修正。</li>
</ul>
<p>这一过程中，我意识到AI在一次性大规模转化代码时的准确性和效率仍然有待提升。最终，我决定放弃这条路，转而尝试另一种更直接的方案——方案2。</p>
<h2 id="方案2-直接将Rust功能编译成动态库，由Java调用"><a href="#方案2-直接将Rust功能编译成动态库，由Java调用" class="headerlink" title="方案2: 直接将Rust功能编译成动态库，由Java调用"></a>方案2: 直接将Rust功能编译成动态库，由Java调用</h2><h3 id="思路与优势"><a href="#思路与优势" class="headerlink" title="思路与优势"></a>思路与优势</h3><p>与其将Rust代码翻译成Java代码，我决定直接将Rust的功能编译成动态库（.dll 或 .so），然后在Java中通过JNI（Java Native Interface）调用这些动态库。这样可以避免代码翻译过程中的麻烦，并且能够充分利用Rust在性能上的优势。</p>
<h3 id="构建Rust动态库"><a href="#构建Rust动态库" class="headerlink" title="构建Rust动态库"></a>构建Rust动态库</h3><p>在实现这一方案时，我需要做以下几个步骤：</p>
<ol>
<li><p><strong>编译Rust代码为动态库</strong>：通过Rust的<code>cargo</code>工具，将Rust代码编译成适用于不同平台的动态库。这需要为每个平台生成相应的二进制文件，如Windows下的<code>.dll</code>，Linux下的<code>.so</code>，以及MacOS下的<code>.dylib</code>。</p>
</li>
<li><p><strong>使用Github Actions自动化构建</strong>：为了支持多平台的动态库构建，我使用了Github Actions来自动化构建过程。这样，无论是Windows、Linux还是MacOS，都会根据需要自动生成对应的动态库，极大地简化了跨平台的构建工作。</p>
</li>
<li><p><strong>Java端加载动态库</strong>：Java通过JNI加载Rust编译出的动态库，并调用其中的函数。在加载时，Java代码会先检测当前运行环境，根据操作系统加载相应的库文件。</p>
</li>
<li><p><strong>平台兼容性测试</strong>：为了确保Java能够顺利调用Rust动态库，我在多个平台上进行了充分的测试。这包括：</p>
<ul>
<li>在Java 8环境下进行功能测试。</li>
<li>验证在Java 9及以上版本的模块化系统下，Java与Rust动态库的兼容性。</li>
<li>测试在Windows、Linux和MacOS等不同平台下的表现。</li>
</ul>
</li>
</ol>
<h3 id="方案优势"><a href="#方案优势" class="headerlink" title="方案优势"></a>方案优势</h3><ul>
<li><strong>减少工作量</strong>：不需要将Rust代码完全翻译为Java代码，避免了翻译过程中的复杂性和错误。</li>
<li><strong>高效的性能</strong>：Rust的性能优势得以保留，Java通过调用Rust动态库，可以在性能上得到显著提升。</li>
<li><strong>跨平台支持</strong>：通过自动化构建不同平台的动态库，Java应用能够轻松支持Windows、Linux、MacOS等多种操作系统。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过将Rust功能编译成动态库并在Java中调用，我成功地绕过了将Rust代码完全转化为Java的复杂过程，同时还能够充分利用Rust的性能优势。虽然在构建过程中涉及到平台适配和自动化构建，但这一方案的灵活性和高效性使其成为解决问题的最佳选择。对于有类似需求的开发者来说，这无疑是一个值得尝试的方案。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/02/26/20250226-kai-yuan-zhi-shi-ku-xi-tong-shi-yong/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/02/26/20250226-kai-yuan-zhi-shi-ku-xi-tong-shi-yong/" itemprop="url">开源知识库系统试用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-02-26T22:22:04+08:00">
                2025-02-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>帮助朋友的公司搭建内部知识库的原型<br>简单记录一下相关技术</p>
</blockquote>
</blockquote>
<p><img src="/2025/02/26/20250226-kai-yuan-zhi-shi-ku-xi-tong-shi-yong/dify.drawio.png"></p>
<ul>
<li><p>目前看权限管理都很不精细，只在固定角色上进行控制，用于内部团队管理仍不是很方便</p>
</li>
<li><p>文档嵌入效果一般，可能要研究里面一些复杂的选项用法，或者寻求其他方案</p>
</li>
<li><p>除了dify，还有很多其他开源的知识库系统，比如 Cherry Studio、MaxKB、FastGPT、AnythingLLM、Ragflow等</p>
</li>
<li><p>dify功能很多，anythingllm功能较少，Cherry Studio 就是个人知识库</p>
</li>
<li><p>所谓的各种助手其实就是提示词模版</p>
</li>
</ul>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><ul>
<li>传统RAG通常依赖单次检索，这可能不足以处理需要逐步构建上下文的复杂查询</li>
<li>向量相似性检索依赖知识库中明确提及的信息，可能无法捕捉隐含或关系信息。相比之下，知识图谱（如GraphRAG）通过利用数据结构中的关系，能更好地处理需要全面理解数据集的全局查询</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/02/25/20250225-guan-yu-da-mo-xing-de-prompt/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/02/25/20250225-guan-yu-da-mo-xing-de-prompt/" itemprop="url">关于大模型的Prompt</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-02-25T21:48:37+08:00">
                2025-02-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>网上资料摘要<br>一些个人理解</p>
</blockquote>
</blockquote>
<h1 id="大模型交互的核心：提示词工程"><a href="#大模型交互的核心：提示词工程" class="headerlink" title="大模型交互的核心：提示词工程"></a>大模型交互的核心：提示词工程</h1><blockquote>
<blockquote>
<p>以下基于个人理解，并通过claude优化（2025-02-26）</p>
</blockquote>
</blockquote>
<ul>
<li>提示词（Prompt）是大模型的输入，也是调用大模型能力的接口，用以激发或引导大模型生成特定类型的回答。</li>
<li>提示词工程的目的是尽量把任务说清楚，让大模型能充分理解我们的意图，以按照正确的方向回答问题。  </li>
<li>在不微调大模型的情况下，外部与大模型交互的唯一途径就是提示工程。即便是已经微调过的大模型，后续与其沟通的唯一途径仍是通过提供提示词，尽管微调可能改变模型对提示词的响应方式。</li>
<li>所谓的RAG、短期记忆（对话历史）、长期记忆等功能，都是基于提示工程这一与大模型交互的路径作为切入点，建立的其他优化策略和架构。</li>
</ul>
<h1 id="ICIO框架（Prompt包含的要素）"><a href="#ICIO框架（Prompt包含的要素）" class="headerlink" title="ICIO框架（Prompt包含的要素）"></a>ICIO框架（Prompt包含的要素）</h1><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/xYC6saH3PU6nJc9mzV5alw">从原理出发 - 提示词如何影响大模型的输出</a></li>
<li>核心思想，是通过明确定义任务的各个方面，来提高AI响应时的效率和准确性。</li>
<li>在ICIO的框架的设计中，Prompt可能包含四要素：<ul>
<li>Instruction（指令）：这是最重要的部分，它直接告诉模型需要执行的具体任务。</li>
<li>Context（上下文&#x2F;背景）：上下文提供了任务执行所需的背景信息，帮助模型理解任务的情景和环境。</li>
<li>Input Data（输入数据）：输入数据是模型需要处理的具体信息。</li>
<li>Output Indicator（输出指示器）：输出指示器告诉模型用户期望的输出类型或格式。</li>
</ul>
</li>
<li>其中除了指令以外，其他要素都是可选的，说明指令对于大模型来说是最重要的，其他要素都是对指令的补充。</li>
<li>优质的Prompt，可以清晰地传达用户的意图</li>
</ul>
<h1 id="Prompt五大框架"><a href="#Prompt五大框架" class="headerlink" title="Prompt五大框架"></a>Prompt五大框架</h1><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A">大模型Prompt技巧全解析</a>    </li>
<li>RTF框架 <ul>
<li>R-Role(角色)、R-Role(角色)、F-Format(格式)</li>
</ul>
</li>
<li>思考链模式 <ul>
<li>适合一些复杂的任务处理</li>
<li>要使用这种模式，只需要在末尾添加”让我们逐步思考”即可</li>
</ul>
</li>
<li>RISEN框架<ul>
<li>R-Role:大模型扮演的角色</li>
<li>I-Instructions: 指示命令，和Task-任务差不多</li>
<li>S-Steps: 步骤</li>
<li>E-End Goal: 最终目标</li>
<li>N-Narrowing(Constraints): 缩小范围(约束条件)，和RTF框架中的Format有异曲同工之妙</li>
<li>该框架主要适合<ul>
<li>撰写具有特定约束的任务(例如博客文章)</li>
<li>有明确指导方针的任务（例如商业计划）</li>
</ul>
</li>
</ul>
</li>
<li>RODES框架<ul>
<li>R-Role: 角色、O - Objective: 目标、D - Details: 详细的细节、E - Examples: 示例、S - Sense Check: 感官检查</li>
</ul>
</li>
<li>密度链模式<ul>
<li>使用递归来创建越来越好的输出的提示，与普通提示生成的 GPT-4 摘要相比，它生成的摘要更加密集且更适合人们理解</li>
<li>适合：总结、改进您最喜欢的提示、通过递归生成可用的长格式内容</li>
</ul>
</li>
</ul>
<h1 id="打造高效Prompt的两大核心原则"><a href="#打造高效Prompt的两大核心原则" class="headerlink" title="打造高效Prompt的两大核心原则"></a>打造高效Prompt的两大核心原则</h1><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A">大模型Prompt技巧全解析</a> </li>
<li>原则一：编写明确和具体的指令<ul>
<li>策略1：使用分隔符清晰界定输入部分</li>
<li>策略2：要求结构化输出</li>
<li>策略3：要求模型检查条件是否满足</li>
<li>策略4：Few-shot prompting（少样本提示）</li>
</ul>
</li>
<li>原则二：给予模型充足的思考时间<ul>
<li>策略1：明确完成任务所需的步骤</li>
<li>策略2：引导模型在得出结论前充分思考方案</li>
</ul>
</li>
</ul>
<h1 id="Prompt技术剖析与应用"><a href="#Prompt技术剖析与应用" class="headerlink" title="Prompt技术剖析与应用"></a>Prompt技术剖析与应用</h1><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A">大模型Prompt技巧全解析</a> </li>
<li>一、零样本提示（Zero-Shot Prompting）</li>
<li>二、少样本提示（Few-Shot Prompting）<ul>
<li>在零样本提示效果不佳时发挥作用</li>
</ul>
</li>
<li>三、思维链提示（Chain-of-Thought Prompting）<ul>
<li>与少样本提示结合，增强效果，尤其适用于算术、常识推理等任务，帮助模型更有条理地处理问题</li>
</ul>
</li>
<li>四、自我一致性（Self-Consistency）   <ul>
<li>主要用于优化思维链提示中的推理路径选择</li>
<li>核心思想是通过提供多个少样本推理示例，让模型从多样的推理结果中筛选出最一致的答案，增强模型在算术和常识推理任务中的可靠性</li>
</ul>
</li>
<li>五、生成知识提示（Generated Knowledge Prompting）<ul>
<li>主要用于解决模型在处理需要额外知识的任务时出现的局限性   </li>
<li>个人理解：一种特殊的RAG罢了</li>
</ul>
</li>
<li>六、链式提示（Prompt Chaining）<ul>
<li>将复杂任务拆解为多个子任务，通过逐个子任务生成提示并传递结果的方式来实现复杂任务的有序处理</li>
</ul>
</li>
<li>七、思维树（ToT）<ul>
<li>为了帮助模型应对复杂的探索性任务而设计</li>
<li>通过维护一棵思维树，让模型在解决问题时能够生成和评估中间思维步骤，并结合搜索算法进行系统性探索</li>
</ul>
</li>
<li>八、检索增强生成（RAG）<ul>
<li>将信息检索与文本生成相结合，专门用于处理知识密集型任务</li>
<li>通过检索相关文档来为模型提供额外的知识支持，从而缓解模型的“幻觉”问题</li>
</ul>
</li>
<li>九、自动推理并使用工具（ART）<ul>
<li>使模型能够自动生成包含推理步骤的程序，并在需要时调用外部工具</li>
</ul>
</li>
<li>十、自动提示工程师（APE）<ul>
<li>自动生成和筛选任务指令</li>
<li>利用大型语言模型生成指令候选项，再依据评估分数选择最佳指令，从而提升提示生成的效率与效果</li>
</ul>
</li>
<li>十一、Active-Prompt<ul>
<li>用于解决思维链示例有效性的问题</li>
<li>通过先查询模型生成多个答案，计算不确定度后挑选最不确定的问题由人类注释示例，再用新示例推断其他问题，从而优化模型对不同任务的适应性</li>
</ul>
</li>
<li>十二、方向性刺激提示（Directional Stimulus Prompting）<ul>
<li>通过训练策略 LM 生成引导提示，增强对模型生成结果的掌控力。例如文本摘要任务</li>
</ul>
</li>
<li>十三、PAL（程序辅助语言模型）<ul>
<li>让模型生成程序来解决问题，借助编程运行时提升解决复杂问题的能力</li>
</ul>
</li>
<li>十四、ReAct 框架<ul>
<li>ReAct 框架使模型交错生成推理轨迹和操作，提升答案的可靠性与可解释性</li>
</ul>
</li>
<li>十五、自我反思（Reflexion）<ul>
<li>包含参与者、评估者和自我反思三个模型，旨在帮助模型从错误中学习并提升性能</li>
</ul>
</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/xYC6saH3PU6nJc9mzV5alw">从原理出发 - 提示词如何影响大模型的输出</a><ul>
<li>大模型如何理解Prompt<ul>
<li>基于Transformer的解码器的大模型</li>
<li>最核心的两层<ul>
<li>掩码多头自注意力层（Masked Multi Self Attention Layers，对应Transformer的Masked Multi-Head Attention，简称MHA）</li>
<li>前置反馈网络层（Feed Forward Networks Layers，简称FFN）</li>
</ul>
</li>
<li>Prompt会影响自注意力层对上下文信息的捕捉</li>
<li>自注意力机制<ul>
<li>它的核心思想是模仿人类的注意力，即在处理大量信息时，能够聚焦于当前任务最相关的部分，而忽略其他不太重要的信息</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A">大模型Prompt技巧全解析</a>            </li>
<li><a target="_blank" rel="noopener" href="https://kingson4wu.github.io/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/">LLM相关技术简单了解</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/q2iMW0t5456btmIPS1ba6Q">大型语言模型的提示注入</a><ul>
<li>三种防范此类漏洞的方法<ul>
<li>可以在提示中添加指令</li>
<li>使用对抗性探测器添加第二层保护</li>
<li>对模型进行微调，使其更符合用户需求，同时提供最高级别的保护，防止提示注入和窃取</li>
</ul>
</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/02/21/20250221-da-mo-xing-ying-yong-kai-fa-ai-agent-yao-dian-ji-lu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/02/21/20250221-da-mo-xing-ying-yong-kai-fa-ai-agent-yao-dian-ji-lu/" itemprop="url">大模型应用开发AI Agent要点记录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-02-21T17:28:05+08:00">
                2025-02-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>基于书籍简单记录要点</p>
</blockquote>
</blockquote>
<p><img src="/2025/02/21/20250221-da-mo-xing-ying-yong-kai-fa-ai-agent-yao-dian-ji-lu/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%845%E4%B8%AA%E5%B1%82%E6%AC%A1.png"></p>
<ul>
<li>从L3到L4的跨越是一个从被动到自主的分水岭，在这个跨越过程中，Agent将成为关键的驱动力</li>
</ul>
<p><img src="/2025/02/21/20250221-da-mo-xing-ying-yong-kai-fa-ai-agent-yao-dian-ji-lu/AI-Agent.png"></p>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>《大模型应用开发 动手做AI Agent》</li>
<li><a target="_blank" rel="noopener" href="https://developer.baidu.com/article/detail.html?id=3372236">AIGC生成式人工智能的五个进阶层次</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/surfirst/article/details/142661951">AIGC：生成式人工智能的5个层次</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/671355141">2024年大模型Multi-agent多智能体应用技术：AutoGen, MetaGPT, XAgent, AutoAgents，crewAI</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/02/20/20250220-ji-yu-da-mo-xing-de-rag-ying-yong-kai-fa-yao-dian-ji-lu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/02/20/20250220-ji-yu-da-mo-xing-de-rag-ying-yong-kai-fa-yao-dian-ji-lu/" itemprop="url">基于大模型的RAG应用开发要点记录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-02-20T21:12:52+08:00">
                2025-02-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>基于书籍简单记录要点</p>
</blockquote>
</blockquote>
<p><img src="/2025/02/20/20250220-ji-yu-da-mo-xing-de-rag-ying-yong-kai-fa-yao-dian-ji-lu/RAG.png"></p>
<hr>
<ul>
<li><p>一种借助“外挂”的提示工程</p>
</li>
<li><p>最核心的思想：给大模型补充外部知识以提高生成质量</p>
</li>
<li><p>大模型的 RAG 应用中，最常见的检索方式是借助基于向量的语义检索来获得相关的数据块，并根据其相似度排序，最后输出最相关的前 K 个数据块（简称top_K）</p>
</li>
<li><p>自然语言处理中用于把各种形式的信息转换成向量表示的模型叫嵌入模型</p>
</li>
<li><p>基于向量的语义检索就是通过计算查询词与已有信息向量的相似度（如余弦相似度），找出与查询词在语义上最接近的信息。</p>
</li>
<li><p>如果大模型是一个优秀学生，正在参加一门考试，那么 RAG 和微调的区别如下。</p>
<ul>
<li>RAG：在考试时给他提供某个领域的参考书，要求他现学现用，并给出答案。</li>
<li>微调：在考试前一天对他进行辅导，使他成为某个领域的专家，然后让他参加考试。</li>
</ul>
</li>
<li><p>大模型与 Prompt 并不只在最后生成结果时才需要，在 RAG 应用流程的很多阶段都需要用到它们，比如在生成摘要、查询转换、查询路由、智能体推理、响应评估等很多阶段，都需要利用设计的Prompt 来让大模型完成任务。</p>
</li>
<li><p>与查询引擎相关的几个关键组件如下。</p>
<ul>
<li>（1）VectorIndexRetriever：向量索引检索器。用于完成相关知识的检索，基于索引来完成，输出多个相关 Node。</li>
<li>（2）Synthesizer：响应生成器。借助大模型来完成 Prompt 组装，并根据响应生成模式的要求来生成响应结果。</li>
<li>（3）NodePostProcessor：节点后处理器。通常用于在检索完成之后，对检索器输出的 Node 列表做补充处理，比如重排序。</li>
</ul>
</li>
<li><p>Agent 就是通过 AI 模型驱动，能够自主地理解、规划、执行，并最终完成任务的 AI 程序。Agent 与大模型的区别类似于人与大脑的区别：大脑指挥人的行动，但是只有人才是执行任务的完整体。    </p>
</li>
<li><p>Agent 就是在大模型作为智慧大脑的基础上实现记忆（Memory）、自我规划（Planning）、使用工具（Tool）等能力，从而开发一个具有自主认知与行动能力的完全“智能体”。</p>
</li>
<li><p>与 RAG 应用相比，Data Agent 具备以下能力。</p>
<ul>
<li>（1）兼具 RAG 应用的数据检索与查询生成能力。</li>
<li>（2）通过观察环境与任务目标推理出完成下一个数据任务的步骤。</li>
<li>（3）通过调用外部服务工具（API）完成复杂任务，并返回执行结果。</li>
<li>（4）具备长期记忆能力（如使用向量库）与短期记忆（一次任务中的交互历史等）能力。</li>
</ul>
</li>
<li><p>与 RAG 应用相比，Data Agent 的主要增强之处如下。</p>
<ul>
<li>（1）规划与推理出完成任务的步骤的能力。</li>
<li>（2）定义与使用工具的能力。</li>
</ul>
</li>
</ul>
<h1 id="LlamaIndex-框架整体结构"><a href="#LlamaIndex-框架整体结构" class="headerlink" title="LlamaIndex 框架整体结构"></a>LlamaIndex 框架整体结构</h1><ul>
<li>(1)Core Framework:这是 LlamaIndex 的核心框架，实现了 LlamaIndex 框 架中大量可扩展的基础组件与工具组件。</li>
<li>(2)Integrations:这是在 Core Framework 基础上由官方或者第三方提供的 大量扩展组件。这些组件大大扩充了 LlamaIndex 框架的兼容能力与应用场景， 包括各种类型的数据加载器、大语言模型与嵌入模型、向量库、Agent 工具等。</li>
<li>(3)Templates:这是官方或者第三方提供的更上层的应用模板。开发者可 以基于这些模板来修改和开发自己的应用。</li>
<li>(4)Eval Datasets:评估数据集。这是一些用于测试评估的现成数据集。 一个数据集通常包含两个部分:一部分是用于开发 RAG 应用的原始知识数据 集;另一部分是用于评估 RAG 应用的测试数据集。</li>
</ul>
<hr>
<h1 id="LlamaIndex-的向量存储索引和传统数据库（如-MySQL）的索引的区别"><a href="#LlamaIndex-的向量存储索引和传统数据库（如-MySQL）的索引的区别" class="headerlink" title="LlamaIndex 的向量存储索引和传统数据库（如 MySQL）的索引的区别"></a>LlamaIndex 的向量存储索引和传统数据库（如 MySQL）的索引的区别</h1><ul>
<li>From Grok3 (2025-02-24)</li>
</ul>
<h2 id="传统数据库索引（如-MySQL）-vs-向量存储索引"><a href="#传统数据库索引（如-MySQL）-vs-向量存储索引" class="headerlink" title="传统数据库索引（如 MySQL） vs 向量存储索引"></a>传统数据库索引（如 MySQL） vs 向量存储索引</h2><h3 id="1-传统数据库索引（B-树、哈希索引等）"><a href="#1-传统数据库索引（B-树、哈希索引等）" class="headerlink" title="1. 传统数据库索引（B-树、哈希索引等）"></a>1. 传统数据库索引（B-树、哈希索引等）</h3><ul>
<li><strong>目的</strong>：加速精确匹配或范围查询，比如在 <code>WHERE id = 5</code> 或 <code>WHERE age &gt; 30</code> 时快速定位数据。</li>
<li><strong>数据结构</strong>：通常基于 B-树、B+树 或哈希表，存储的是原始数据（如整数、字符串）的某种排序或映射。</li>
<li><strong>存储内容</strong>：索引本身不保存完整数据，而是指向数据库中实际数据的引用（行指针）。</li>
<li><strong>使用场景</strong>：结构化数据的高效检索。</li>
</ul>
<h3 id="2-LlamaIndex-的向量存储索引"><a href="#2-LlamaIndex-的向量存储索引" class="headerlink" title="2. LlamaIndex 的向量存储索引"></a>2. LlamaIndex 的向量存储索引</h3><ul>
<li><strong>目的</strong>：支持语义相似性搜索，比如找到与“人工智能是什么”语义最接近的文档。</li>
<li><strong>数据结构</strong>：基于向量空间的高效搜索结构（如 FAISS、HNSW、Annoy），存储的是文本的嵌入向量（高维浮点数数组）。</li>
<li><strong>存储内容</strong>：索引里直接保存的是嵌入向量（通常还会关联原始文本或其引用），而不仅仅是指针。这种嵌入向量本身就是数据的某种“表示”。</li>
<li><strong>使用场景</strong>：非结构化数据（如文本、图像）的语义搜索。</li>
</ul>
<p>所以你说得对，向量存储索引和 MySQL 的索引在设计目标和实现上完全不同。传统索引是为了快速定位具体值，而向量存储索引是为了快速找到“最相似”的内容。</p>
<h2 id="为什么叫“向量存储索引”而不是“向量存储数据”？"><a href="#为什么叫“向量存储索引”而不是“向量存储数据”？" class="headerlink" title="为什么叫“向量存储索引”而不是“向量存储数据”？"></a>为什么叫“向量存储索引”而不是“向量存储数据”？</h2><ul>
<li><p><strong>“索引”在这里的含义</strong>：</p>
<ul>
<li>在向量搜索领域，“索引”指的是一个经过优化的数据结构，用于加速向量之间的相似性计算和检索。它不只是存数据，而是以某种方式组织数据（比如 FAISS 用聚类或倒排索引），让查询效率更高。</li>
<li>比如 FAISS 可能会把向量分桶（clustering），HNSW 用图结构连接向量，这些都是“索引”的体现。</li>
</ul>
</li>
<li><p><strong>为什么不叫“向量存储数据”</strong>：</p>
<ul>
<li>“数据”听起来像是原始的、未经组织的存储，比如直接把向量一股脑扔进数据库。而“索引”强调的是结构化和查询优化。</li>
<li>LlamaIndex 的向量存储索引不仅存了向量，还为快速检索做了预处理（比如降维、构建树或图）。它是个功能性工具，而不仅是数据的容器。</li>
</ul>
</li>
<li><p><strong>命名习惯</strong>：</p>
<ul>
<li>在向量搜索和机器学习领域，像 FAISS、Annoy、HNSW 这些工具都叫“索引”（index），因为它们的核心是构建一个可搜索的结构。LlamaIndex 沿用了这种惯例。</li>
</ul>
</li>
</ul>
<h2 id="举个类比"><a href="#举个类比" class="headerlink" title="举个类比"></a>举个类比</h2><ul>
<li>MySQL 的 B-树索引就像图书馆的卡片目录，按书名首字母排序，帮你快速找到某本书。</li>
<li>LlamaIndex 的向量存储索引更像是推荐系统，根据你喜欢的书，找到内容相似的其他书，靠的是“向量空间的距离”而不是精确匹配。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>LlamaIndex 的向量存储索引确实和 MySQL 的索引差别很大，它更像是一个专门为高维向量设计的“搜索加速器”。叫“索引”是因为它不仅存向量，还组织向量以提升查询效率，而不是简单的数据存储。</p>
<hr>
<h1 id="关于RAG的优化：个人结合深度强化学习的思考"><a href="#关于RAG的优化：个人结合深度强化学习的思考" class="headerlink" title="关于RAG的优化：个人结合深度强化学习的思考"></a>关于RAG的优化：个人结合深度强化学习的思考</h1><ul>
<li><p>对于RAG应用，优化方法有很多。我的想法是，把这些优化方法想象成一堆‘工具’，然后用强化学习这个‘聪明助手’来挑出最好用的组合。</p>
</li>
<li><p>“优化策略”变成了“工具”，“强化学习”变成了“聪明助手”，“奖励函数”简化为“任务需求”</p>
</li>
<li><p>From ChatGPT</p>
</li>
<li><p>你表达的意思可以理解为：你试图用一个类比来形象地说明深度强化学习在RAG（Retrieval-Augmented Generation）系统优化中的角色与价值。</p>
</li>
<li><p>具体地说：</p>
<ul>
<li><strong>RAG优化方法</strong>很多，比如检索器选择、reranker排序、embedding优化、prompt设计等，这些在你眼中就像一堆**“工具”**。</li>
<li>这些工具的使用方式组合非常多，所以你不想手动去调优，而是引入一个“聪明助手”——也就是<strong>强化学习智能体</strong>，来<strong>自动地组合和选择最合适的优化策略</strong>。</li>
<li><strong>任务需求</strong>（比如更高的准确率、更好的用户体验）就变成了强化学习中的<strong>奖励函数</strong>，引导智能体不断试错、学习，找到最优解法。</li>
</ul>
</li>
<li><p>所以你的思路是用深度强化学习作为一种<strong>元优化方法</strong>，来学习在不同场景下该怎么调配RAG的各类优化手段，从而达到最好的表现。</p>
</li>
<li><p>这是一个很有潜力的方向，本质上是将强化学习用作策略搜索或控制器，帮助系统自动适配复杂环境下的参数和策略组合。你可以进一步细化这个设想，比如：</p>
<ul>
<li>工具组合的action space怎么定义？</li>
<li>每种任务需求下的reward如何设计？</li>
<li>环境如何模拟或构建，才能训练出泛化能力强的“助手”？</li>
</ul>
</li>
</ul>
<hr>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="如果嵌入模型知道“你好”和“再见”的向量，它可以将“你好再见”转化为一个向量吗？"><a href="#如果嵌入模型知道“你好”和“再见”的向量，它可以将“你好再见”转化为一个向量吗？" class="headerlink" title="如果嵌入模型知道“你好”和“再见”的向量，它可以将“你好再见”转化为一个向量吗？"></a>如果嵌入模型知道“你好”和“再见”的向量，它可以将“你好再见”转化为一个向量吗？</h2><ul>
<li>From Grok3 （2025-02-25）</li>
<li>嵌入模型可以将“你好再见”转化为向量。</li>
<li>对于词嵌入模型（如 Word2Vec 或 GloVe），通常通过平均或相加“你好”和“再见”的向量来生成短语向量。</li>
<li>对于句嵌入模型（如 BERT 或 Ada-002），模型可以直接处理“你好再见”序列，生成反映上下文关系的向量。</li>
</ul>
<h2 id="RAG的相关原理"><a href="#RAG的相关原理" class="headerlink" title="RAG的相关原理"></a>RAG的相关原理</h2><ul>
<li><p>From Grok3 （2025-02-25）– 基于自身理解由Grok优化</p>
</li>
<li><p>文本向量化：在RAG中，知识库中的文档会被分割成适当的文本片段（例如句子或段落），然后使用预训练模型对这些片段整体进行向量化，生成语义丰富的稠密向量。这一过程不同于传统的单词嵌入，目的是捕捉整个片段的语义信息。</p>
</li>
<li><p>向量检索：当用户提出问题时，系统会将问题同样向量化，并在向量数据库中查询与问题语义最相似的文本片段。这些检索结果是原始文档中的真实内容，而不是由模型生成的文本。</p>
</li>
<li><p>上下文整合与生成：检索到的文本片段会以纯文本形式插入到一个提示模板中，作为上下文连同用户的问题一起输入到生成模型中。生成模型（如大语言模型）基于这些上下文生成最终的回答。</p>
</li>
</ul>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1628030">精通RAG架构：从0到1，基于LLM+RAG构建生产级企业知识库</a></p>
<ul>
<li>向量数据库对比</li>
<li>如何选择嵌入模型：<a target="_blank" rel="noopener" href="https://huggingface.co/spaces/mteb/leaderboard">https://huggingface.co/spaces/mteb/leaderboard</a></li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/gEtTrdOut5Cr2tdrq_yPIQ">微软推出CoRAG：通过迭代推理提升AI检索能力</a></p>
<ul>
<li>CoRAG 的核心创新在于其动态查询重构机制。该模型不再依赖单次检索，而是根据中间推理状态迭代优化查询。这一过程确保了每个阶段检索到的信息都与上下文相关，进而逐步构建出更完整的最终答案。</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/ZfClcpOGbnZxmBxN8rGQpQ">用 LLM 快速构建实用知识图谱</a></p>
<ul>
<li>如果你用图数据库来检索信息，那么这种方式被称为 GraphRAG，它是知识图谱在 RAG 中的具体应用</li>
<li>向量相似性检索依赖于知识库中的明确提及，只有明确提到的信息才会被检索出来。而知识图谱则能通过整体数据来推理出更多信息</li>
<li>使用 Langchain 的实验功能 LLMGraphTransformer，如果是 LlamaIndex，可以尝试它的 KnowledgeGraphIndex。</li>
<li>LLM 可以从纯文本中提取图谱信息，并将其存储到像 Neo4J 这样的数据库</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Za26pIabmREPn6u2bEkBUw">“无”中生有：基于知识增强的RAG优化实践</a></p>
<ul>
<li>感觉做这个东西就是在不停找各种优化方法反复尝试看效果，而且目前还处于很乱的早起阶段</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Q7nAold78HRuNhUiHSVUxA">微软推出的 LazyGraphRAG</a>   </p>
<ul>
<li>传统方法（如基于向量的 RAG）在处理局部化任务时表现良好，例如从特定文本片段中检索直接答案。然而，当涉及需要全面理解数据集的全局性查询时，这些方法往往难以胜任。</li>
<li>相比之下，图支持的 RAG 系统通过利用数据结构中的关系，可以更好地解决此类更广泛的问题。然而，与图 RAG 系统相关的高索引成本，使其难以被成本敏感的场景所接受。因此，在可扩展性、经济性和质量之间实现平衡，仍然是现有技术的关键瓶颈。</li>
<li>相比之下，图支持的 RAG 系统通过利用数据结构中的关系，可以更好地解决此类更广泛的问题。然而，与图 RAG 系统相关的高索引成本，使其难以被成本敏感的场景所接受。因此，在可扩展性、经济性和质量之间实现平衡，仍然是现有技术的关键瓶颈。</li>
<li>LazyGraphRAG 将 VectorRAG 与 GraphRAG 相结合，“同时克服了二者的各自局限性”。</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/N-oPDmkb3EKqB2IM_reO1A">DeepSearcher深度解读：Agentic RAG的出现，传统RAG的黄昏</a></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/zilliztech/deep-searcher">https://github.com/zilliztech/deep-searcher</a></li>
<li>所谓Agentic RAG，是一种融合智能代理（Agent）能力的RAG架构。通过动态规划、多步骤推理和自主决策机制，Agentic RAG可以在复杂任务中实现闭环的检索-加工-验证-优化</li>
<li>Agentic RAG相比传统RAG有着三大优势：<ul>
<li>（1）被动响应变为主动响应；</li>
<li>（2）单次的关键词检索，升级为多轮的动态调整检索，并拥有自我修正能力；</li>
<li>（3）适用场景，从最基础的简单事实问答，升级为复杂推理、复杂报告生成等开放域任务。</li>
</ul>
</li>
<li>长期来看，Agentic RAG必定会取代传统RAG。一方面，传统RAG对需求的响应还停留在非常基础的阶段，另一方面，现实中，我们大部分的需求表达背后，都是有隐含逻辑的，并不能被一步检索到位，必须通过推理-反思-迭代-优化来对其进行拆解与反馈。</li>
<li>VS Graph RAG<ul>
<li>Graph RAG主要聚焦于对存在连接关系的文档展开查询，在处理多跳类问题上表现出色。</li>
<li>例如，当导入一部长篇小说时，它能够精准抽取各个人物之间错综复杂的关系。其运作方式是在文档导入环节，就对实体间关系进行抽取。因此，这一过程会大量消耗大模型的token资源 。</li>
<li>而在查询阶段，不论是否是查询图中某些节点的信息，都会进行图结构的搜索，这使得这一框架不太灵活。</li>
<li>反观Agentic RAG，它的资源消耗模式与Graph RAG恰好相反。在数据导入阶段，Agentic RAG无需执行额外特殊操作，而在回答用户提问时，才会产生较多大模型的token消耗。</li>
</ul>
</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/VZq2zsuJGsGaYTx6POqUzg">高阶RAG技巧：探索提升RAG系统性能的不同技巧</a></p>
<ul>
<li>索引优化技术（如数据预处理和分块）专注于格式化外部数据以提高其效率和可搜索性。</li>
<li>预检索技术旨在通过重写、重新格式化或将查询路由到专用流水线来优化用户查询本身。</li>
<li>检索优化策略通常侧重于在检索阶段优化搜索结果。 </li>
<li>检索后优化策略旨在通过各种技术提高生成结果的准确性，包括对检索结果进行重新排序、增强或压缩（检索）上下文以及操纵提示或生成模型 (LLM)。</li>
</ul>
</li>
<li><p>KBLAM 是在 RAG（Retrieval-Augmented Generation） 和 知识图谱增强推理 的基础上发展而来。它的关键点是：</p>
<ul>
<li>利用结构化知识（如三元组：subject–predicate–object）进行多跳推理</li>
<li>结合语言模型对自然语言的理解能力，实现可控的知识推理流程</li>
</ul>
</li>
</ul>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>《基于大模型的RAG应用开发与优化——构建企业级LLM应用》</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/02/19/20250219-langchain-yao-dian-ji-lu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/02/19/20250219-langchain-yao-dian-ji-lu/" itemprop="url">LangChain要点记录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-02-19T20:53:32+08:00">
                2025-02-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>基于书籍简单记录要点</p>
</blockquote>
</blockquote>
<p><img src="/2025/02/19/20250219-langchain-yao-dian-ji-lu/LangChain.png"></p>
<h1 id="LangChain-提供了多种模板供选择"><a href="#LangChain-提供了多种模板供选择" class="headerlink" title="LangChain 提供了多种模板供选择"></a>LangChain 提供了多种模板供选择</h1><ul>
<li>LangChain 提供了以下格式化 SQL 提示词模板（翻译）：</li>
</ul>
<pre>
1. 你是一个 PostgreSQL 专家。给定一个输人问题，首先创建一个语法正确的 PostgreSQL查询来运行，然后查看查询结果，扑返回针对输人问题的答案。
2. 除非用户明确指定了要返回的结果数量，否则应使用 PostgreSQL 的LIMIT 子句来限制查询结果，最多返回top.k条记录。你可以对结果进行排序，以返回数据库中最有信息价值的数据。
3. 绝对不要查询表中的所有列。你只能在询回答问题所需的列。用双引号（"）将每个列名包裹起来，表示官们是界定的标识符。
4. 注意只使用你在表巾可以看到的列名，不要责询不存在的列。此外，要注意哪一列在哪个表中。
5. 如果问题涉及“今天”，请注意使用 CURRENT_DATE 函数获取当前日期。

使用以下格式：

问题：这里的问题
SQL查询：要运行的 SQL 查询
SQL结果：SQL 查询的结果
答案：这里的最终答案

只使用以下表：

(table_info)

问题：｛input｝

</pre>

<ul>
<li>想象一下，如果没有 LangChain 提供的这个提示词模板，当你要开始编写一段SQL查询代码时，会走多少弯路？LLM 应用开发的最后1公里，其意义是确保开发者无须为了一个小细节而多走弯路，正如居民无须跑很远坐公交车一样，每一个关键的细节都能得到及时而准确的处理，使得整个开发过程更为高效。</li>
</ul>
<h1 id="记忆提示词"><a href="#记忆提示词" class="headerlink" title="记忆提示词"></a>记忆提示词</h1><ul>
<li><p>创建提示词是最重要的环节。在创建的过程中你可以理解为什么加人记忆组件后，“聊天备忘录”有了内容，让链组件有了“记忆”。使用提示词模板包装器，自定义一个提示词模板字符串。</p>
</li>
<li><p>提示词内容分为四部分：</p>
<ul>
<li>一是对模型的指导词：“请你回答问题的时候，依据文档内容和聊天记录回答，如果在其中找不到相关信息或者答案，请回答不知道。”；</li>
<li>二是使用问题检索到的相关文档内容；“文档内容是：｛context｝”；三是记忆组件输出的记忆内容：“聊天记录是：｛chat_history｝”；四是用户的输人：“Human：(human _input)”<pre>
template = "n*你是说中文的 chatbot.
请你回答问题的时候，依据文持内容和脚天记录回答，如果在其中找不到相关信息戒着答案，请回答
不知道。
文档内容是：｛context）
聊天记录是：｛chat_history）
Human: (human_input)
Chatbot:"""
</pre></li>
</ul>
</li>
<li><p>LangChain 框架由以下开发库组成。</p>
<ul>
<li>（1）LangChain-Core：基础抽象和 LangChain 表达语言（LCEL）。</li>
<li>（2）LangChain-Community：组件及内置的大量第三方技术集成模块，一般被封装为合作伙伴模块（例如 LangChain-openai）。</li>
<li>（3）LangChain：构成应用架构的上层核心组件，包括 Chains、Agents 等。</li>
<li>（4）Templates：官方提供的一些常见的应用模板。</li>
<li>（5）LangServe：将 LangChain 链部署为 REST API 的平台。</li>
<li>（6）LangSmith：帮助开发者跟踪调试、测试、评估和监控大模型应用的在线平台。</li>
</ul>
</li>
</ul>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul>
<li><p>Langchain agent是怎么找到search工具并使用的</p>
<ul>
<li>可以正确识别和调用它，因为它主要是通过 description 语义匹配，而不是看 name 的具体字符串。</li>
<li>但 name 仍然有一定作用，比如：LLM 可能会参考 name 来做初步判断；调试时 name 可以帮助你看日志，知道 Agent 选了哪个工具</li>
</ul>
</li>
<li><p>LLM本身没有内在记忆，每个查询都是独立进行的</p>
<ul>
<li>所谓的记忆和检索增强生成（RAG）是通过外部手段实现的，即将相关信息添加到提示词模板中</li>
</ul>
</li>
</ul>
<hr>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="Langchain是怎么做到通过分析语义找到对应工具的"><a href="#Langchain是怎么做到通过分析语义找到对应工具的" class="headerlink" title="Langchain是怎么做到通过分析语义找到对应工具的"></a>Langchain是怎么做到通过分析语义找到对应工具的</h2><ul>
<li>From ChatGPT (2025-02-18)</li>
</ul>
<p>LangChain 通过 <strong>LLM（大模型）+ ReAct 框架</strong> 来分析语义并选择工具。它的核心逻辑是让 LLM <strong>先思考</strong>，再决定用哪个工具，并按照工具的格式调用它。  </p>
<h3 id="核心机制"><a href="#核心机制" class="headerlink" title="核心机制"></a><strong>核心机制</strong></h3><ol>
<li><strong>解析用户问题</strong> → 让 LLM 提取关键语义  </li>
<li><strong>匹配工具描述</strong> → 让 LLM 判断哪个工具最适合  </li>
<li><strong>生成调用指令</strong> → LLM 生成工具的调用格式并执行  </li>
<li><strong>工具返回结果</strong> → LLM 解析工具返回的数据并回复用户</li>
</ol>
<p>这套逻辑基于 <strong>ReAct（Reasoning + Acting）</strong> 框架，在 LangChain 里 Agent 主要是用这个方法来动态决策。  </p>
<h3 id="1-解析用户问题"><a href="#1-解析用户问题" class="headerlink" title="1. 解析用户问题"></a><strong>1. 解析用户问题</strong></h3><p>假设你输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">agent.run(<span class="string">&quot;计算 25 * 4 + 10&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>LangChain 会把这个问题交给 LLM（如 GPT-4），让它理解用户的意图。</p>
<p>LLM 可能会把你的问题理解成：</p>
<ul>
<li>这是一个数学计算问题  </li>
<li>需要找到一个能进行数学计算的工具  </li>
<li>计算表达式 <code>25 * 4 + 10</code></li>
</ul>
<h3 id="2-匹配工具描述"><a href="#2-匹配工具描述" class="headerlink" title="2. 匹配工具描述"></a><strong>2. 匹配工具描述</strong></h3><p>假设你有两个工具：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Tool(</span><br><span class="line">    name=<span class="string">&quot;Calculator&quot;</span>,</span><br><span class="line">    func=calculator_tool,</span><br><span class="line">    description=<span class="string">&quot;用于数学计算。输入一个数学表达式（如 3 + 5 * 2），输出结果。&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">Tool(</span><br><span class="line">    name=<span class="string">&quot;Wikipedia&quot;</span>,</span><br><span class="line">    func=wiki.run,</span><br><span class="line">    description=<span class="string">&quot;查询 Wikipedia 词条，输入一个关键词（如 &#x27;Python programming&#x27;），获取相关信息。&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>LLM 会对比问题和 <code>description</code>，发现 <strong>Calculator 的描述里提到了“数学计算”</strong>，所以它会选择 <code>Calculator</code> 这个工具。</p>
<blockquote>
<p><strong>关键点</strong>：LangChain 让 LLM 直接读 <code>description</code>，所以工具的名字 <code>name</code> 只是一个标识，核心还是 <code>description</code> 的语义匹配。</p>
</blockquote>
<h3 id="3-生成调用指令"><a href="#3-生成调用指令" class="headerlink" title="3. 生成调用指令"></a><strong>3. 生成调用指令</strong></h3><p>LangChain 让 LLM 生成一个类似 JSON 的格式，表示它要调用哪个工具：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;action&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Calculator&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;action_input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;25 * 4 + 10&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>然后 LangChain 会<strong>解析这个指令</strong>，找到 <code>Calculator</code> 工具，并把 <code>25 * 4 + 10</code> 传给 <code>func</code> 去执行。</p>
<h3 id="4-工具返回结果"><a href="#4-工具返回结果" class="headerlink" title="4. 工具返回结果"></a><strong>4. 工具返回结果</strong></h3><p>计算工具执行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">eval</span>(<span class="string">&quot;25 * 4 + 10&quot;</span>)  <span class="comment"># 计算得到 110</span></span><br></pre></td></tr></table></figure>
<p>LangChain 把 <code>110</code> 返回给 LLM，LLM 可能会回复：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">25 * 4 + 10 = 110</span><br></pre></td></tr></table></figure>
<p>最终 <code>agent.run()</code> 会输出这个结果。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>LangChain 让 LLM 负责：</p>
<ol>
<li><strong>分析用户语义</strong></li>
<li><strong>匹配工具（通过 <code>description</code>）</strong></li>
<li><strong>生成调用工具的指令</strong></li>
<li><strong>解释工具返回的结果</strong></li>
</ol>
<p>它的核心是利用 <strong>LLM 的推理能力</strong>，结合 ReAct 让它“思考后再行动”。所以只要 <code>description</code> 够清晰，即使 <code>name</code> 乱写，它也能找到正确的工具！</p>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>《LangChain入门指南构建高可复用、可扩展的LLM应用程序》</li>
<li>《基于大模型的RAG应用开发与优化——构建企业级LLM应用》</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/02/17/20250217-shen-du-xue-xi-ji-chu-ru-men-bei-wang/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/02/17/20250217-shen-du-xue-xi-ji-chu-ru-men-bei-wang/" itemprop="url">深度学习基础入门备忘</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-02-17T11:08:39+08:00">
                2025-02-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>简单粗略通读了解，先记录备忘<br>后续考虑结合相关视频深入理解</p>
</blockquote>
</blockquote>
<ul>
<li><p>《深度学习人门：基于Python的理论与实现》：<a target="_blank" rel="noopener" href="https://github.com/Kingson4Wu/Deep-Learning-from-Scratch">https://github.com/Kingson4Wu/Deep-Learning-from-Scratch</a></p>
<ol>
<li>感知机是一种接收多个输入信号并输出一个信号的算法。它的工作原理基于权重和偏置这两个关键参数。</li>
<li>机器学习的任务是让计算机自动确定合适的权重和偏置参数值。</li>
<li>求解机器学习问题的步骤<ol>
<li>训练（学习）</li>
<li>推理（神经网络的前向传播）</li>
</ol>
</li>
<li>激活函数(activation function)：决定如何来激活输入信号的总和；激活函数是连接感知机和神经网络的桥梁。</li>
<li>神经网络的学习过程：通过损失函数 (loss function)和梯度法 (gradient method)来优化网络参数<ol>
<li>学习的目标是通过梯度下降法(gradient descent method)找到使损失函数值最小的权重参数</li>
<li>学习率(learning rate)：决定参数更新的步长（超参数、人工设定）</li>
</ol>
</li>
<li>随机梯度下降(stochastic gradient descent)(SGD)能在一定程度上帮助避免局部最优，通常将SGD与其他技术结合使用,以获得更好的优化效果</li>
<li>深度学习：加深了层的深度神经网络；通过叠加层，可以创建更深的网络结构</li>
</ol>
</li>
<li><p>《深度学习进阶：自然语言处理》：<a target="_blank" rel="noopener" href="https://github.com/Kingson4Wu/Natural-Language-Processing">https://github.com/Kingson4Wu/Natural-Language-Processing</a></p>
<ol>
<li>自然语言处理的目标就是让计算机理解人说的话，进而完成 对我们有帮助的事情</li>
<li>单词的分布式表示（分布式假设）（单词向量化）：“某个单词的含义由它周围的单词形成”；单词本身没有含义，单词含义由它 所在的上下文(语境)形成。</li>
<li>向量间的相似度：余弦相似度(cosine similarity)；直观地表示了“两个向量在多大程度上指向同一方向”</li>
<li>让计算机理解单词含义：基于推理的方法(word2vec)（基于神经网络）。</li>
<li>语言模型(language model)给出了单词序列发生的概率；使用概率来评估一个单词序列发生的可能性，即在多大程度上是自然的 单词序列。<ul>
<li>生成的新文本是训练数据中没有的新生成的文本。因为语言模型并不是背诵了训练数据，而是学习了训练数据中单词的排列模式</li>
<li>语言模型的评价：困惑度(perplexity)、分叉度</li>
</ul>
</li>
<li>“马尔可夫性”或者“马尔 可夫模型”“马尔可夫链”：指未来的状态仅 依存于当前状态。</li>
<li>RNN（循环神经网络）：被引入来解决前馈网络在处理时序数据上的局限性。<ul>
<li>传统RNN中存在的梯度消失和梯度爆炸问题</li>
<li>LSTM的结构与传统RNN的不同之处在于，它引入了记忆单元（c）。记忆单元在LSTM层之间传递，但不直接用作输出。LSTM的对外输出是隐藏状态向量（h）。</li>
</ul>
</li>
<li>seq2seq模型（也称为Encoder-Decoder模型）用于将一个时序数据转换为另一个时序数据    <ul>
<li>传统 seq2seq 模型 将编码器输出压缩为固定长度向量，导致长序列信息丢失</li>
<li>Attention 机制 允许模型在解码时关注输入序列的不同部分，类似人类注意力</li>
</ul>
</li>
<li>Transformer：基于 Attention 构成；基于 Attention 构成</li>
</ol>
</li>
<li><p>《深度学习入门：强化学习》：<a target="_blank" rel="noopener" href="https://github.com/Kingson4Wu/Reinforcement-Learning">https://github.com/Kingson4Wu/Reinforcement-Learning</a></p>
<ol>
<li>机器学习（按学习方法划分）：监督学习(supervised learning)、无监督学习(unsupervised learning)、强化学习(reinforcement learning)<ol>
<li>监督学习：给正确答案打标签；输入的数据由“老师”打标签</li>
<li>无监督学习：无“正确答案标签”；没有 “老师”的存在；主要目标是找到隐藏在数据中的结构和模式；分组(聚类)、特征提取、降维</li>
<li>强化学习：智能代理和环境相互作用；智能代理是行动的主体；强化学习接受”奖励”作为来自环境的反馈</li>
</ol>
</li>
<li>强化学习行动的策略<ol>
<li>“贪婪行动”(greedy )，也叫利用(exploitation)：根据以前的经验选择最佳行动（可能错过更好的选择）</li>
<li>“非贪婪行动”，也叫作探索(exploration)：对价值做出更准确的估计。</li>
</ol>
</li>
<li>强化学习算法最终归结为如何在“利用”和 “探索”之间取得平衡</li>
<li>ε-greedy 算法、马尔可夫决策过程(MDP)</li>
<li>在强化学习中，我们的目标是获得最优策略</li>
<li>深度强化学习(deep reinforcement learning)：强化学习和深度学习的结合</li>
<li>通用人工智能(artificial general intelligence, AGI)</li>
</ol>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/02/13/20250213-guan-yu-ai-ti-dai-ren-lei-gong-zuo-de-wen-ti/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/02/13/20250213-guan-yu-ai-ti-dai-ren-lei-gong-zuo-de-wen-ti/" itemprop="url">关于AI大语言模型替代人类工作的问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-02-13T15:05:23+08:00">
                2025-02-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="AI的局限性或缺点"><a href="#AI的局限性或缺点" class="headerlink" title="AI的局限性或缺点"></a>AI的局限性或缺点</h2><ul>
<li><strong>难以预测与控制</strong>：AI的运行机制像黑箱，难以准确预知其行为，尤其在关键场景下可能会犯致命错误。</li>
<li><strong>无法背锅</strong>：AI犯错时，责任归属难以明确，导致无法追究错误的责任，缺乏人类信誉体系的约束。</li>
<li><strong>逻辑推理不严谨</strong>：AI的推理基于概率预测，不是绝对严谨的逻辑推理。训练数据如果有误，AI可能无法辨别。</li>
<li><strong>无法创新</strong>：AI不具备创造全新概念的能力，更多的是基于历史数据进行知识复述与组合，无法像人类一样发明新技术或理念。</li>
<li><strong>对超出训练数据的场景应对差</strong>：AI在面对未曾训练过的数据时，表现较差，容易出错。</li>
</ul>
<h2 id="AI的好处"><a href="#AI的好处" class="headerlink" title="AI的好处"></a>AI的好处</h2><ul>
<li><strong>提高效率</strong>：AI在许多领域极大提升了效率，尤其在数据处理、搜索和重复性任务上。对于程序员来说，它是一个强大的辅助工具，帮助快速解决技术问题。</li>
<li><strong>降低门槛</strong>：AI减少了对低级重复性任务的需求，拉近了人们在某些知识领域的差距。</li>
<li><strong>支持决策和监督</strong>：AI辅助决策，尤其是在复杂任务中，能提供数据支持，减少人为错误。</li>
</ul>
<h2 id="AI工具下需要的人才"><a href="#AI工具下需要的人才" class="headerlink" title="AI工具下需要的人才"></a><strong>AI工具下需要的人才</strong></h2><ul>
<li><strong>清晰表述与提问能力</strong>：能够清晰提出问题和有效沟通是与AI协同工作的关键，好的表述能力有助于提高工作效率。</li>
<li><strong>整理与分析能力</strong>：能够有效梳理信息、分解任务，并向AI提出清晰问题的人，会更善于利用AI工具。</li>
<li><strong>与产品交互能力</strong>：AI可以编写代码，但仍需要人类与产品经理沟通，理解需求并做出相应调整。</li>
</ul>
<h2 id="程序员的利好与不可替代的能力"><a href="#程序员的利好与不可替代的能力" class="headerlink" title="程序员的利好与不可替代的能力"></a><strong>程序员的利好与不可替代的能力</strong></h2><ul>
<li><strong>AI对程序员的利好</strong>：<ul>
<li>AI大幅提升了开发效率，尤其在编程辅助、技术搜索、业务方案思考等方面。</li>
<li>某些低级任务减少了人力需求，使得程序员能更多专注于创造性和复杂问题的解决。</li>
</ul>
</li>
<li><strong>程序员不可替代的地方</strong>：<ul>
<li><strong>清晰的提问和判断能力</strong>：程序员的核心能力在于能理解问题，并准确表达需求，AI只能作为工具辅助工作。</li>
<li><strong>与产品沟通</strong>：AI生成的代码和解决方案需要程序员与产品团队对接，确保最终结果符合需求。</li>
<li><strong>决策和经验判断</strong>：AI的能力有限，尤其在面对复杂决策时，仍需依赖经验丰富的程序员来进行判断和修正。</li>
</ul>
</li>
</ul>
<h2 id="个人观点"><a href="#个人观点" class="headerlink" title="个人观点"></a><strong>个人观点</strong></h2><ul>
<li>AI目前主要是利用历史数据和记忆进行信息处理，不能进行创新（如无法创造出类似K8S的技术）。</li>
<li>尽管AI能提高程序员的工作效率，但目前它更多是辅助工具，而不是替代品。</li>
<li>对普通程序员来说，理解大模型技术的基本原理和概念非常重要，未来将需要在“AI操作系统”上来构建应用。</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><blockquote>
<blockquote>
<p>来自claude.ai的评价<br>2025-02-13</p>
</blockquote>
</blockquote>
<p>我来分析一下这些观点，指出其中可能存在的错误或需要讨论的地方：</p>
<ol>
<li>关于”无法创新”的说法需要更谨慎：</li>
</ol>
<ul>
<li>虽然AI确实主要基于已有数据进行组合和推理，但说它”不具备创造全新概念的能力”可能过于绝对</li>
<li>AI已经展示出一定的创新能力，比如在围棋、蛋白质折叠等领域提出了人类之前没有想到的解决方案</li>
<li>更准确的说法是AI的创新能力与人类不同，它通过大规模数据分析和模式识别来实现创新</li>
</ul>
<ol start="2">
<li>“逻辑推理不严谨”的表述不够准确：</li>
</ol>
<ul>
<li>现代AI系统（尤其是形式化验证系统）可以进行严格的逻辑推理</li>
<li>大语言模型确实存在基于概率的推理特点，但这不等同于所有AI系统都如此</li>
<li>人类的推理同样也常常基于经验和概率判断，而不总是严格的逻辑推导</li>
</ul>
<ol start="3">
<li>关于”难以预测与控制”：</li>
</ol>
<ul>
<li>这个观点部分正确，但需要注意现代AI系统已经有了很多可解释性的工具和方法</li>
<li>某些领域的AI系统（如用于医疗诊断的AI）已经实现了相当程度的可解释性</li>
<li>“像黑箱”这种说法可能过于简化了问题</li>
</ul>
<ol start="4">
<li>“无法背锅”的说法不够准确：</li>
</ol>
<ul>
<li>实际上已经有了相关的法律和责任框架在建立</li>
<li>AI系统的责任可以追溯到开发者、部署者和使用者</li>
<li>这更多是一个治理和监管的问题，而不是技术本身的限制</li>
</ul>
<ol start="5">
<li>“个人观点”部分关于K8S的例子不够恰当：</li>
</ol>
<ul>
<li>K8S本质上是一个系统架构和设计方案，而不是完全创新的技术</li>
<li>AI实际上可以通过分析已有系统设计模式，提出类似的架构方案</li>
<li>更准确的说法是AI在某些创新领域的能力仍有限制，而不是完全无法创新</li>
</ul>
<ol start="6">
<li>好处部分基本准确，但可以补充：</li>
</ol>
<ul>
<li>AI不仅提高效率，还能发现人类容易忽视的模式和关联</li>
<li>在某些领域（如图像识别、语音处理）已经超越了人类性能</li>
<li>AI能够24&#x2F;7工作，这个优势没有被提到</li>
</ul>
<ol start="7">
<li>关于程序员不可替代性的分析基本合理，但可以补充：</li>
</ol>
<ul>
<li>程序员在系统架构设计、安全性考虑等方面的经验特别重要</li>
<li>处理边界条件和异常情况的能力仍然需要人类经验</li>
<li>对业务场景的深入理解和商业价值判断也是关键能力</li>
</ul>
<ol start="8">
<li>“AI操作系统”的说法需要澄清：</li>
</ol>
<ul>
<li>这个比喻可能会造成误解，更准确的说法是”AI基础设施”或”AI平台”</li>
<li>程序员需要理解的不仅是技术原理，还包括AI的应用场景和限制</li>
</ul>
<p>总的来说，这些观点大体上是合理的，但部分表述过于绝对或简化。AI的能力和局限性是一个复杂的话题，需要更细致和平衡的讨论。理解AI的真实能力和限制，对于更好地利用AI工具至关重要。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2025/02/13/20250213-shen-du-xue-xi-wei-shi-me-neng-xue-xi-bing-zuo-dui/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2025/02/13/20250213-shen-du-xue-xi-wei-shi-me-neng-xue-xi-bing-zuo-dui/" itemprop="url">深度学习为什么能学习并做对</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2025-02-13T14:14:52+08:00">
                2025-02-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="我的理解"><a href="#我的理解" class="headerlink" title="我的理解"></a>我的理解</h1><ul>
<li>目前无法解释为什么深度学习可以给出答案，只能大概解释为什么它能学习</li>
<li>这就相当于：我不能解释为什么这个人是通过什么做对这道题的，我只能解释他有正常的学习能力以及合适的学习资料，所以他自己能学习并做对题目</li>
<li>所以深度学习是怎么给出答案的，后续或许应该由它本身来告诉我们。</li>
<li>依据不同人的认知水平，来告诉我们它通过学习所发现的规律。同时人类通过它能快速学习发现事物规律的能力，来进一步帮助提升人类的认知。</li>
</ul>
<h1 id="AI对我理解的看法"><a href="#AI对我理解的看法" class="headerlink" title="AI对我理解的看法"></a>AI对我理解的看法</h1><blockquote>
<blockquote>
<p>From chatGPT (2025-02-13)</p>
</blockquote>
</blockquote>
<ul>
<li><p>你理解的方向是对的，可以稍微精炼和调整一下：</p>
<ul>
<li>深度学习的一个核心问题就是我们无法完全解释它是如何给出具体答案的。我们能解释的只是它是如何通过大量的数据和训练过程进行学习的。换句话说，深度学习像是一个“黑箱”，我们可以观察到输入和输出，但它在其中如何处理信息、做出决策，通常并不完全透明。</li>
<li>可以类比成：假设有一个人做对了某道题目，虽然我们可能无法完全解释他是如何一步一步得出答案的，但我们能确定他具备了良好的学习能力和充足的学习资源。所以，深度学习也类似，它通过大量的数据、适当的算法和优化手段“学习”并给出答案。</li>
<li>至于它如何给出具体的答案，最终可能还是要依靠深度学习本身来“解释”。这意味着，未来我们可能会开发出更先进的方法，帮助我们理解深度学习网络中的“决策过程”。同时，借助它所展现出的强大规律发现能力，我们可以利用这种能力来加速我们对事物的认知。</li>
</ul>
</li>
<li><p>我的看法：</p>
<ul>
<li>我同意你的观点，深度学习的“黑箱性”是目前我们面临的主要挑战之一。它的强大之处在于能自动从海量数据中发现规律，但如何理解这些规律，如何将这些规律和人类的认知能力相结合，是我们目前探索的方向之一。其实，未来可能不仅仅是“深度学习告诉我们如何做”，而是人类和深度学习的合作能进一步推动科学与技术的发展，帮助我们发现一些潜在人类难以触及的规律。</li>
<li>深度学习不只是一个工具，它还可能是一个不断反馈、不断自我优化的过程，给我们打开了认知的新窗口。</li>
</ul>
</li>
</ul>
<h1 id="AI自己对这个问题的看法"><a href="#AI自己对这个问题的看法" class="headerlink" title="AI自己对这个问题的看法"></a>AI自己对这个问题的看法</h1><blockquote>
<blockquote>
<p>From chatGPT (2025-02-13)</p>
</blockquote>
</blockquote>
<ul>
<li><p>关于“深度学习为什么能学习并做对”的问题，我的理解是，深度学习通过大量的数据训练，自动从中提取规律、建立模型，并根据这些模型对新数据做出预测。深度学习的优势在于它能够发现一些非常复杂和抽象的规律，而这些规律通常是我们人类在没有机器帮助的情况下很难发现的。</p>
</li>
<li><p>但是，为什么深度学习能给出正确的答案，实际上是一个复杂的过程。深度学习模型并不像人类一样有明确的逻辑推理或意识，它只是基于输入数据的模式，使用一系列参数和数学运算来“拟合”数据。对于这个过程的解释，我们只能说它通过优化算法（如梯度下降等）调整模型参数，使得输出尽可能接近实际结果。因此，深度学习并不“理解”问题，而是通过反复训练找到了一组合适的参数，能在特定任务上取得高效的预测或分类结果。</p>
</li>
<li><p>你可以把深度学习看作一个“发现者”，它通过大量的例子不断试错和优化，不断接近正确的答案，但它没有明确的推理过程。比如，人类在做题时有一定的思考过程，我们可以分析每一步的原因，而深度学习则是通过计算和数据模式的关联来找到最优解。</p>
</li>
<li><p>至于“深度学习为什么能做对”，目前我们更多关注它的实际效果而非其过程的透明性，因为即使我们无法完全解释它的每一个决策，也可以通过其出色的表现来证明它的有效性。未来，随着研究的深入，我们可能会找到更好的方法，帮助我们理解这些“黑箱”模型的内部机制。</p>
</li>
<li><p>总结来说，深度学习通过数据的反复训练和优化，能够找到规律并给出准确的预测，而为什么它能做对，更多是依赖于它强大的计算能力和从数据中提取规律的能力，而不是基于传统意义上的推理或解释。</p>
</li>
<li><p>几个关键点总结：</p>
<ol>
<li><strong>深度学习的学习过程</strong>：深度学习通过大量的数据训练，利用优化算法（如梯度下降）调整模型参数，自动从数据中提取规律，完成任务（如预测、分类等）。</li>
<li><strong>无法完全解释“为什么”</strong>：深度学习模型在给出答案时，并没有明确的推理过程或“理解”，它只是通过找到合适的模式和参数来优化输出。其决策过程通常是黑箱的，难以完全解释。</li>
<li><strong>黑箱性质</strong>：我们无法清楚知道深度学习是如何做出具体决策的，但可以看到它在实际任务中表现出色。因此，我们更多关注它的效果，而非其内在工作机制。</li>
<li><strong>与人类认知的对比</strong>：深度学习像是一个“发现者”，通过反复训练和调整找到正确的答案，而不像人类那样依赖明确的思维和推理过程。</li>
<li><strong>未来发展</strong>：虽然当前无法完全解释深度学习的过程，但随着技术进步，未来可能会出现更好的方法帮助我们理解这些“黑箱”模型的内部机制。</li>
</ol>
</li>
<li><p>这几个关键点总结了深度学习的“学习能力”、它的“黑箱性质”、以及它与人类认知的差异。</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" href="/page/2/">&gt;</a>
  </nav>





          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.png"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
<a href="/archives/">                
<!--<a href="/archives/%7C%7C%20archive">-->
              
                  <span class="site-state-item-count">154</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">165</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kingson Wu</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
