<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="google-site-verification=n4yVkaTfu2KtQ8fiQ3Ri60FPAbRF74oxrDOkOXWjhSs" />














  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/uploads/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="拉巴力的纸皮箱" type="application/atom+xml" />






<meta name="description" content="Kingson Wu的技术博客，分享编程、架构、AI等技术笔记和个人思考">
<meta property="og:type" content="website">
<meta property="og:title" content="拉巴力的纸皮箱">
<meta property="og:url" content="https://kingson4wu.github.io/page/5/index.html">
<meta property="og:site_name" content="拉巴力的纸皮箱">
<meta property="og:description" content="Kingson Wu的技术博客，分享编程、架构、AI等技术笔记和个人思考">
<meta property="og:locale">
<meta property="article:author" content="Kingson Wu">
<meta property="article:tag" content="技术博客,编程,架构,软件开发,AI,人工智能,后端开发,Java,Go,系统设计">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://kingson4wu.github.io/page/5/"/>





  <title>拉巴力的纸皮箱 - 技术博客 | 记录学习笔记和思考</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'G-4QEGQ2DGGT', 'auto');
  ga('send', 'pageview');
</script>





<meta name="generator" content="Hexo 6.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">拉巴力的纸皮箱</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">技术博客 | 记录学习笔记和思考</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/" itemprop="url">LLM相关技术简单了解</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-12-26T18:48:22+08:00">
                2024-12-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>以下内容基本都是从书籍中摘抄，用于个人记录<br>从AI得出的回答不一定正确或者只是现阶段暂时正确<br>增加部分个人理解</p>
</blockquote>
</blockquote>
<p><img src="/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/LLM_position.png"><br><img src="/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/LLM.png"></p>
<h2 id="LLM（Large-Language-Model）"><a href="#LLM（Large-Language-Model）" class="headerlink" title="LLM（Large Language Model）"></a>LLM（Large Language Model）</h2><ul>
<li><p>大语言模型的涌现能力被非形式化定义为“在小型模型中不存在但在大模型中出现的能力”，具体是指当模型扩展到一定规模时，模型的特定任务性能突然出现显著跃升的趋势，远超过随机水平。类比而言，这种性能涌现模式与物理学中的相变现象有一定程度的相似，但是仍然缺乏相应的理论解释以及理论证实，甚至有些研究工作对于涌现能力是否存在提出质疑 [38]。整体来说，涌现能力的提出有助于使得公众认识到大语言模型所具有的能力优势，能够帮助区分大语言模型与传统预训练语言模型之间的差异。</p>
</li>
<li><p>大语言模型的三种典型涌现能力。</p>
<ol>
<li>上下文学习（In-context Learning, ICL）. 上下文学习能力在 GPT-3 的论文中 [23] 被正式提出。具体方式为，在提示中为语言模型提供自然语言指令和多个任务示例（Demonstration），无需显式的训练或梯度更新，仅输入文本的单词序列就能为测试样本生成预期的输出。</li>
<li>指令遵循（Instruction Following）. 指令遵循能力是指大语言模型能够按照自然语言指令来执行对应的任务 [28, 39, 40]。为了获得这一能力，通常需要使用自然语言描述的多任务示例数据集进行微调，称为指令微调（Instruction Tuning）或监督微调（Supervised Fine-tuning）。通过指令微调，大语言模型可以在没有使用显式示例的情况下按照任务指令完成新任务，有效提升了模型的泛化能力。相比于上下文学习能力，指令遵循能力整体上更容易获得，但是最终的任务执行效果还取决于模型性能和任务难度决定。</li>
<li>逐步推理（Step-by-step Reasoning）. 对于小型语言模型而言，通常很难解决 涉及多个推理步骤的复杂任务（如数学应用题），而大语言模型则可以利用思维链（Chain-of-Thought, CoT）提示策略 [25] 来加强推理性能。具体来说，大语言模型 可以在提示中引入任务相关的中间推理步骤来加强复杂任务的求解，从而获得更 为可靠的答案。</li>
</ol>
</li>
<li><p>通俗来讲，扩展法则与涌现能力之间微妙的关系可以类比人类的学习能力来解释。以语言能力为例，对于儿童来说，语言发展（尤其是婴儿）可以被看作一个多阶段的发展过程，其中也会出现“涌现现象”。在这一发展过程中，语言能力在一个阶段内部相对稳定，但是当进入另一个能力阶段时可能会出现重要的提升（例如从说简单的单词到说简单的句子）。尽管儿童实际上每天都在成长，但是语言的提升过程本质上是不平滑和不稳定的（即语言能力在时间上不以恒定速率发展）。因此，经常可以看到年轻的父母会对宝宝所展现出的语言能力进展感到惊讶。    </p>
</li>
<li><p>这种大模型具有但小模型不具有的能力通常被称为“涌现能力”（Emergent Abilities）。为了区别这一能力上的差异，学术界将这些大型预训练语言模型命名为“大语言模型”</p>
</li>
<li><p>早期的语言模型主要面向自然语言的建模和生成任务，而最新的语言模型（如 GPT-4）则侧重于复杂任务的求解。从语言建模到任务求解，这是人工智能科学思维的一次重要跃升，是理解语言模型前沿进展的关键所在。</p>
</li>
<li><p>早期的统计语言模型主要被用于（或辅助用于）解决一些特定任务，主要以信息检索、文本分类、语音识别等传统任务为主。随后，神经语言模型专注于学习任务无关的语义表征，旨在减少人类特征工程的工作量，可以大范围扩展语言模型可应用的任务。</p>
</li>
<li><p>进一步，预训练语言模型加强了语义表征的上下文感知能力，并且可以通过下游任务进行微调，能够有效提升下游任务（主要局限于自然语言处理任务）的性能。随着模型参数、训练数据、计算算力的大规模扩展，最新一代大语言模型的任务求解能力有了显著提升，能够不再依靠下游任务数据的微调进行通用任务的求解。</p>
</li>
<li><p>大语言模型的能力特点：具有较好的复杂任务推理能力. 除了具有通用性外，大语言模型在复杂任务中还展现出了较好的推理能力。</p>
</li>
<li><p>大语言模型对科技发展的影响</p>
<ul>
<li>【理论基础原理】尽管大语言模型技术已经取得了显著进展，但是对于它的基本原理仍然缺乏深入的探索，很多方面还存在局限性或者提升空间。首先，大模型中某些重要能力（如上下文学习能力）的涌现仍然缺乏形式化的理论解释，需要针对大语言模型基础能力的形成原因进行深入研究，从而揭示大语言模型内部的工作机理。</li>
<li>【细节公开和算力支持】其次，大语言模型预训练需要大规模的计算资源支持，研究各种训练策略的效果并进行可重复性的消融实验的成本非常高昂。学术界难以获得充分的算力来系统性研究大语言模型；虽然工业界或者大型研究机构不断推出性能优异的开源大模型，但是这些模型的训练过程的开源程度还不够充分，许多重要的训练细节仍缺乏公开的研究报道。</li>
<li>【人类对齐】第三，让大语言模型充分与人类价值观或偏好对齐也是一项重要的科研挑战。尽管大语言模型已经具有较好的模型能力，但是在特定场景下或者蓄意诱导下，仍然可能生成虚构、有害或具有负面影响的内容。这一问题随着模型能力的提升而变得更为难于解决。为了应对模型能力未来可能超越人类监管能力的情况，需要设计更为有效的监管方法来消除使用大语言模型的潜在风险。</li>
<li>随着大语言模型技术的迅猛发展，人工智能相关研究领域正发生着重要的技术变革<ol>
<li>自然语言处理. 在自然语言处理领域，大语言模型可以作为一种通用的语言任务解决技术，能够通过特定的提示方式解决不同类型的任务，并且能够取得较为领先的效果。</li>
<li>信息检索. 在信息检索领域，传统搜索引擎受到了人工智能信息助手（即ChatGPT）这一新型信息获取方式的冲击。</li>
<li>计算机视觉. 在计算机视觉领域，研究人员为了更好地解决跨模态或多模态任务，正着力研发类 ChatGPT 的视觉-语言联合对话模型，GPT-4 已经能够支持图文多模态信息的输入。由于开源大语言模型的出现，可以极大地简化多模态模型的实现难度，通过将图像、视频等模态的信息与文本语义空间相融合，可以通过计算量相对较少的微调方法来研发多模态大语言模型。进一步，基于下一个词元预测的思路也可能会带来多模态领域的基础模型架构的转变，例如 OpenAI 最新推出的 Sora 模型就是基于图像块序列建模的思路进行构建的。</li>
<li>人工智能赋能的科学研究（AI4Science）. 近年来，AI4Science 受到了学术界的广泛关注，目前大语言模型技术已经广泛应用于数学、化学、物理、生物等多个领域，基于其强大的模型能力赋能科学研究。</li>
</ol>
</li>
</ul>
</li>
<li><p>目前广泛采用的对齐方式是基于人类反馈的强化学习技术，通过强化学习使得模型进行正确行为的加强以及错误行为的规避，进而建立较好的人类对齐能力。</p>
</li>
<li><p>在实践应用中，需要保证大语言模型能够较好地符合人类的价值观。目前，比较具有代表性的对齐标准是“3 H 对齐标准”，即 Helpfulness（有用性）、Honesty（诚实性）和 Harmlessness（无害性）。</p>
</li>
<li><p>实际上，世界上最会使用工具的智能体就是人类，人类不断发明新的技术与工具，拓展自己的认知与能力边界。</p>
</li>
</ul>
<h2 id="GPT-模型简史"><a href="#GPT-模型简史" class="headerlink" title="GPT 模型简史"></a>GPT 模型简史</h2><ul>
<li><p>GPT 系列模型的基本原理是训练模型学习恢复预训练文本数据，将广泛的世界知识压缩到仅包含解码器（Decoder-Only）的 Transformer 模型中，从而使模型能够学习获得较为全面的能力。其中，两个关键要素是：（I）训练能够准确预测下一个词的 Transformer （只包含解码器）语言模型；（II）扩展语言模型的规模以及扩展预训练数据的规模。</p>
</li>
<li><p>当谷歌 2017 年推出基于注意力机制的 Transformer 模型后，OpenAI 团队迅速洞察到了其潜在的优越性，认为这种模型可能是一种大规模可扩展训练的理想架构。基于此，OpenAI 团队开始构建GPT 系列模型，并于 2018 年推出了第一代 GPT 模型—GPT-1，能够通过“通用文本训练-特定任务微调”的范式去解决下游任务。接下来，GPT-2 和 GPT-3 模型通过扩大预训练数据和模型参数规模，显著提升了模型性能，并且确立了基于自然语言形式的通用任务解决路径。在 GPT-3 的基础上，OpenAI 又通过代码训练、人类对齐、工具使用等技术对于模型性能不断升级，推出了功能强大的 GPT-3.5 系列模型。2022 年 11 月，ChatGPT 正式上线，能够以对话形式解决多种任务，使得用户能够通过网络 API 体验到语言模型的强大功能。2023 年 3 月，OpenAI 推出了标志性的 GPT-4 模型，将模型能力提升至全新高度，并将其扩展至拥有多模态功能的 GPT-4V 模型。</p>
</li>
<li><p>反观 GPT 系列模型的发展历程，有两点令人印象深刻。第一点是可拓展的训练架构与学习范式：Transformer 架构能够拓展到百亿、千亿甚至万亿参数规模，并且将预训练任务统一为预测下一个词这一通用学习范式；第二点是对于数据质量与数据规模的重视：不同于 BERT 时代的预训练语言模型，这次大语言模型的成功与数据有着更为紧密的关系，高质量数据、超大规模数据成为大语言模型的关键基础。</p>
</li>
<li><p>在 GPT-1 出现之前，构建高性能 NLP 神经网络的常用方法是利用监督学习。这种学习技术使用大量的手动标记数据。</p>
</li>
</ul>
<h3 id="GPT-1"><a href="#GPT-1" class="headerlink" title="GPT-1"></a>GPT-1</h3><ul>
<li>GPT-1 的作者提出了一种新的学习过程，其中引入了无监督的预训练步骤。这个预训练步骤不需要标记数据。相反，他们训练模型来预测下一个标记。</li>
<li>由于采用了可以并行化的 Transformer 架构，预训练步骤是在大量数据上进行的。</li>
<li>GPT-1 是小模型，它无法在不经过微调的情况下执行复杂任务。因此，人们将微调作为第二个监督学习步骤，让模型在一小部分手动标记的数据上进行微调，从而适应特定的目标任务。比如，在情感分析等分类任务中，可能需要在一小部分手动标记的文本示例上重新训练模型，以使其达到不错的准确度。这个过程使模型在初始的预训练阶段习得的参数得到修改，从而更好地适应具体的任务。</li>
<li>尽管规模相对较小，但 GPT-1 在仅用少量手动标记的数据进行微调后，能够出色地完成多个 NLP 任务。GPT-1 的架构包括一个解码器（与原始 Transformer 架构中的解码器类似），具有 1.17 亿个参数。作为首个 GPT 模型，它为更强大的模型铺平了道路。后续的 GPT 模型使用更大的数据集和更多的参数，更好地利用了 Transformer 架构的潜力。</li>
</ul>
<h3 id="GPT-2"><a href="#GPT-2" class="headerlink" title="GPT-2"></a>GPT-2</h3><ul>
<li>2019 年初，OpenAI 提出了 GPT-2。这是 GPT-1 的一个扩展版本，其参数量和训练数据集的规模大约是 GPT-1 的 10 倍。这个新版本的参数量为 15 亿，训练文本为 40 GB。2019 年 11 月，OpenAI 发布了完整版的 GPT-2 模型。</li>
<li>GPT-2 是公开可用的，可以从 Hugging Face 或 GitHub 下载。</li>
<li>GPT-2 表明，使用更大的数据集训练更大的语言模型可以提高语言模型的任务处理能力，并使其在许多任务中超越已有模型。它还表明，更大的语言模型能够更好地处理自然语言。</li>
</ul>
<h3 id="从-GPT-3-到-InstructGPT"><a href="#从-GPT-3-到-InstructGPT" class="headerlink" title="从 GPT-3 到 InstructGPT"></a>从 GPT-3 到 InstructGPT</h3><ul>
<li>2020 年 6 月，OpenAI 发布了 GPT-3。GPT-2 和 GPT-3 之间的主要区别在于模型的大小和用于训练的数据量。</li>
<li>2021 年，OpenAI 发布了 GPT-3 模型的新版本，并取名为 InstructGPT。与原始的 GPT-3 基础模型不同，InstructGPT 模型通过强化学习和人类反馈进行优化。</li>
<li>从 GPT-3 模型到 InstructGPT 模型的训练过程主要有两个阶段：监督微调（supervised fine-tuning，SFT）和通过人类反馈进行强化学习 （reinforcement learning from human feedback，RLHF）。每个阶段都会针对前一阶段的结果进行微调。也就是说，SFT 阶段接收 GPT-3 模型并返回一个新模型。RLHF 阶段接收该模型并返回 InstructGPT 版本。</li>
<li>与基础的 GPT-3 模型相比，InstructGPT 模型能够针对用户的提问生成更准确的内容。OpenAI 建议使用 InstructGPT 模型，而非原始版本。</li>
</ul>
<h3 id="GPT-3-5、Codex-和-ChatGPT"><a href="#GPT-3-5、Codex-和-ChatGPT" class="headerlink" title="GPT-3.5、Codex 和 ChatGPT"></a>GPT-3.5、Codex 和 ChatGPT</h3><ul>
<li>ChatGPT 是由 LLM 驱动的应用程序，而不是真正的LLM。ChatGPT 背后的 LLM 是 GPT-3.5 Turbo。</li>
</ul>
<h3 id="GPT-4"><a href="#GPT-4" class="headerlink" title="GPT-4"></a>GPT-4</h3><ul>
<li>与 OpenAI GPT 家族中的其他模型不同，GPT-4 是第一个能够同时接收文本和图像的多模态模型。这意味着 GPT-4 在生成输出句子时会考虑图像和文本的上下文。这样一来，用户就可以将图像添加到提示词中并对其提问。</li>
</ul>
<h3 id="使用插件和微调优化-GPT-模型"><a href="#使用插件和微调优化-GPT-模型" class="headerlink" title="使用插件和微调优化 GPT 模型"></a>使用插件和微调优化 GPT 模型</h3><ul>
<li>OpenAI 提供的插件服务允许该模型与可能由第三方开发的应用程序连接。这些插件使模型能够与开发人员定义的应用程序接口（application program interface，API）进行交互。这个过程可以极大地增强 GPT 模型的能力，因为它们可以通过各种操作访问外部世界。</li>
<li>想象一下，将来每家公司都可能希望拥有自己的 LLM 插件。就像我们今天在智能手机应用商店中看到的那样，可能会有一系列的插件集合。通过插件可以添加的应用程序数量可能是巨大的。</li>
<li>在其网站上，OpenAI 表示可以通过插件让 ChatGPT 执行以下操作：<br>检索实时信息，如体育赛事比分、股票价格、最新资讯等；检索基于知识的信息，如公司文档、个人笔记等； 代表用户执行操作，如预订航班、订购食品等； 准确地执行数学运算。</li>
</ul>
<h3 id="GPT-4-和ChatGPT-的-API"><a href="#GPT-4-和ChatGPT-的-API" class="headerlink" title="GPT-4 和ChatGPT 的 API"></a>GPT-4 和ChatGPT 的 API</h3><ul>
<li>OpenAI Playground 是一个基于 Web 的平台。你可以使用它直接测试 OpenAI 提供的语言模型，而无须编写代码。在 OpenAI Playground 上，你可以编写提示词，选择模型，并轻松查看模型生成的输出。要测试 OpenAI 提供的各种 LLM 在特定任务上的表现，OpenAI Playground 是绝佳的途径。</li>
</ul>
<h2 id="开源LLM"><a href="#开源LLM" class="headerlink" title="开源LLM"></a>开源LLM</h2><h3 id="LLaMA"><a href="#LLaMA" class="headerlink" title="LLaMA"></a>LLaMA</h3><ul>
<li><p>由于对公众开放了模型权重且性能优秀，LLaMA 已经成为了最受欢迎的开源大语言模型之一，许多研究工作都是以其为基座模型进行微调或继续预训练，衍生出了众多变体模型</p>
</li>
<li><p>中文指令. 原始的 LLaMA 模型的训练语料主要以英语为主，在中文任务上的表现比较一般。为了使 LLaMA 模型能够有效地支持中文，研究人员通常会选择扩展原始词汇表，在中文数据上进行继续预训练，并用中文指令数据对其进行微调。经过中文数据的训练，这些扩展模型不仅能更好地处理中文任务，在跨语言处理任务中也展现出了强大的潜力。目前常见的中文大语言模型有 Chinese LLaMA、Panda、Open-Chinese-LLaMA、Chinese Alpaca、YuLan-Chat 等。</p>
</li>
<li><p>垂域指令. LLaMA 虽然展现出了强大的通用基座模型能力，但是在特定的垂直领域（例如医学、教育、法律、数学等）的表现仍然较为局限。为了增强 LLaMA模型的垂域能力，很多工作基于搜集到的垂域相关的指令数据，或者采用垂域知识库以及相关专业文献等借助强大的闭源模型 API（例如 GPT-3.5、GPT-4 等）构建多轮对话数据，并使用这些指令数据对 LLaMA 进行指令微调。常见的垂域 LLaMA模型有 BenTsao（医学）、LAWGPT（法律）、TaoLi（教育）、Goat（数学）、Comucopia （金融）等。</p>
</li>
<li><p>多模态指令. 由于 LLaMA 模型作为纯语言模型的强大能力，许多的多模态模型都将其（或将其衍生模型）作为基础语言模型，搭配视觉模态的编码器，使用多模态指令对齐视觉表征与文本。与其他语言模型相比，Vicuna 在多模态语言模型中受到了更多的关注，由此形成了一系列基于 Vicuna 的多模态模型，包括LLaVA 、MiniGPT4 、InstructBLIP 和 PandaGPT</p>
</li>
<li><p>目前性能最强大的模型仍然主要以闭源为主。这些闭源模型通过 API（应用程序接口）形式进行调用，无需在本地运行模型即可使用。在闭源大语言模型领域，OpenAI 无疑是最具代表性和影响力的公司</p>
</li>
</ul>
<h2 id="LLM训练过程"><a href="#LLM训练过程" class="headerlink" title="LLM训练过程"></a>LLM训练过程</h2><ul>
<li>从机器学习的观点来说，神经网络是一种具有特定模型结构的函数形式，而大语言模型则是一种基于 Transformer 结构的神经网络模型。因此，可以将大语言模型看作一种拥有大规模参数的函数，它的构建过程就是使用训练数据对于模型参数的拟合过程。</li>
<li>尽管所采用的训练方法与传统的机器学习模型（如多元线性回归模型的训练）可能存在不同，但是本质上都是在做模型参数的优化。大语言模型的优化目标更加泛化，不仅仅是为了解决某一种或者某一类特定任务，而是希望能够作为通用任务的求解器</li>
<li>一般来说，这个训练过程可以分为大规模预训练和指令微调与人类对齐两个阶段，一般来说，预训练是指使用与下游任务无关的大规模数据进行模型参数的初始训练，可以认为是为模型参数找到一个较好的“初值点”。</li>
<li>目前来说，比较广泛使用的微调技术是“指令微调”（也叫做有监督微调，Supervised Fine-tuning, SFT），通过使用任务输入与输出的配对数据进行模型训练，可以使得语言模型较好地掌握通过问答形式进行任务求解的能力。这种模仿示例数据进行学习的过程本质属于机器学习中的模仿学习（Imitation Learning）。</li>
<li>如何将语言模型 进行人类对齐。具体来说，主要引入了基于人类反馈的强化学习对齐方法 RLHF（Reinforcement Learning from Human Feedback），在指令微调后使用强化学习加 强模型的对齐能力。在 RLHF 算法中，需要训练一个符合人类价值观的奖励模型（Reward Model）。为此，需要标注人员针对大语言模型所生成的多条输出进行偏 好排序，并使用偏好数据训练奖励模型，用于判断模型的输出质量。</li>
</ul>
<h3 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h3><ul>
<li>常用的预训练数据集：目前常用于训练大语言模型的代表性数据集合。根据其内容类型进行分类，这些语料库可以划分为：网页、书籍、维基百科、代码以及混合型数据集。</li>
<li>数据准备:根据来源不同，预训练数据主要分为两种类型：通用文本数据和专用文本数据。</li>
<li>数据预处理</li>
</ul>
<h3 id="指令微调与人类对齐"><a href="#指令微调与人类对齐" class="headerlink" title="指令微调与人类对齐"></a>指令微调与人类对齐</h3><ul>
<li>为了增强模型的任务解决能力，大语言模型在预训练之后需要进行适应性微调，通常涉及两个主要步骤，即指令微调（有监督微调）和对齐微调。</li>
</ul>
<h3 id="指令微调（Instruction-Tuning）"><a href="#指令微调（Instruction-Tuning）" class="headerlink" title="指令微调（Instruction Tuning）"></a>指令微调（Instruction Tuning）</h3><ul>
<li><p>指令微调（Instruction Tuning）是指使用自然语言形式的数据对预训练后的大语言模型进行参数微调，这一术语由谷歌研究员在 2022 年的一篇 ICLR 论文中正式提出 [39]。在另外一些参考文献中，指令微调也被称为有监督微调（Supervised Fine-tuning）[28] 或多任务提示训练（Multitask Prompted Training）[40]。指令微调过程需要首先收集或构建指令化的实例，然后通过有监督的方式对大语言模型的参数进行微调。经过指令微调后，大语言模型能够展现出较强的指令遵循能力，可以通过零样本学习的方式解决多种下游任务。</p>
</li>
<li><p>指令微调是一种基于格式化的指令示例数据（即任务描述与期望输出相配对的数据）对大语言模型进行训练的过程。在大语言模型的背景下，这种利用配对文本进行训练的方法也被广泛地称为监督微调（Supervised Fine-Tuning, SFT）。</p>
</li>
<li><p>指令微调的作用：总体来说，指令的质量比数量更为重要。指令微调中应该优先使用人工标注的多样性指令数据。然而，如何大规模标注符合人类需求的指令数据目前仍然缺乏规范性的指导标准（比如什么类型的数据更容易激发大模型的能力）。在实践中，可以使用 ChatGPT、GPT-4 等闭源大语言模型来合成、重写、筛选现有指令，并通过数量来弥补质量和多样性上的不足。</p>
</li>
<li><p>指令微调旨在使用人工构建的指令数据对于大语言模型进一步训练，从而增强或解锁大语言模型的能力。与预训练相比，指令微调的成本显著降低，大模型所需的指令数据量仅为预训练阶段的约万分之一甚至更少。</p>
</li>
<li><p>指令微调旨在指导模型学会理解自然语言指令，并据此完成相应的任务。通过指令微调，大模型能够获得较好的指令遵循与任务求解能力，无需下游任务的训练样本或者示例就可以解决训练中未见过的任务。</p>
</li>
<li><p>领域专业化适配：通用的大语言模型能够在传统自然语言处理任务（如生成和推理）以及日常生活任务（如头脑风暴）上取得较好的效果，然而它们在特定领域中（如医学、法律和金融等）的表现与领域专用模型的效果仍有一定差距。在实际应用中，可以针对大语言模型进行面向特定领域的指令微调，从而使之能够适配下游的任务。</p>
</li>
<li><p>指令微调的训练策略：在训练方式上，指令微调与预训练较为相似，很多设置包括数据组织形式都可以预训练阶段所采用的技术</p>
</li>
</ul>
<h3 id="人类对齐"><a href="#人类对齐" class="headerlink" title="人类对齐"></a>人类对齐</h3><ul>
<li>实现人类对齐的关键技术——基于人类反馈的强化学习（Reinforcement Learning from Human Feedback, RLHF），包括人类反馈的收集方法、奖励模型的训练过程、强化学习训练策略以及相关的 RLHF工作。</li>
<li>对齐标准：三个具有代表性的对齐标准展开讨论，分别是有用性（Helpfulness）、诚实性（Honesty）和无害性（Harmlessness）</li>
<li>RLHF 算法系统主要包括三个关键组成部分：需要与人类价值观对齐的模型、基于人类反馈数据学习的奖励模型以及用于训练大语言模型的强化学习算法。</li>
<li>RLHF 的关键步骤<ul>
<li>监督微调. 为了让待对齐语言模型具有较好的指令遵循能力，通常需要收集高质量的指令数据进行监督微调。</li>
<li>奖励模型训练. 第二步是使用人类反馈数据训练奖励模型。</li>
<li>强化学习训练. 在这一步骤中，语言模型对齐被转化为一个强化学习问题。</li>
</ul>
</li>
</ul>
<h2 id="解码与部署"><a href="#解码与部署" class="headerlink" title="解码与部署"></a>解码与部署</h2><h3 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h3><ul>
<li>当完成训练后，我们就可以将大语言模型部署到真实场景中进行使用。大语 言模型是通过文本生成的方式进行工作的。在自回归架构中，模型针对输入内容逐个单词生成输出内容的文本。这个过程一般被称为 解码。</li>
<li>解码策略 大语言模型的生成方式本质上是一个概率采样过程，需要合适的解码策略来生成合适的输出内容。</li>
<li>批次管理优化 在传统的解码操作中，通常会等待一整个批次的所有实例都结束后再进行下 一个批次的计算。然而，一个批次内的不同实例往往生成长度各异，因此经常会出现等待某一条实例（输出长度最长的实例）生成的情况。批次管理优化旨在通过增加计算中的批次大小来提高计 算强度。一个代表性的方法是 vLLM（细节参考第 9.2.4 节）所提出的连续批处理（Continuous Batching）技术 [174]。该技术不同于传统确定顺序的定长批次处理方 式，而是将每个输入实例视为一个请求，每个请求的处理过程可以分解为全量解 码阶段和若干个单步增量解码阶段。在实现中，连续批处理技术会通过启发式算 法来选择部分请求进行全量解码操作，或者选择一些请求进行单步增量解码操作。 通过这样细粒度的拆分，连续批处理技术在一步操作中能够容纳更多的请求（相当于提高批次大小），从而提升了计算强度。</li>
<li>解码策略优化 除了直接解决系统级别的内存墙问题，许多研究工作提出了针对自回归解码策略的改进方法，从而提高解码效率。下面主要介绍四种解码优化算法，包括推测解码（Speculative Decoding）、非自回归解码（Non-autoregressive Decoding）、早退机制（Early Exiting）与级联解码（Cascade Inference）。</li>
</ul>
<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><ul>
<li>低资源部署策略 由于大模型的参数量巨大，在解码阶段需要占用大量的显存资源，因而在实际应用中的部署代价非常高。在本章中，我们将介绍一种常用的模型压缩方法<ul>
<li>量化基础知识： 模型量化（Model Quantization），来减少大模型的显存占用，从而使得能够在资源有限的环境下使用大模型。</li>
<li>通常来说，模型量化方法可以分为两大类，即量化感知训练（Quantization-AwareTraining, QAT）和训练后量化（Post-Training Quantization, PTQ）。</li>
<li>其他模型压缩方法：模型蒸馏和模型剪枝。与模型量化不同，模型蒸馏和模型剪枝则通过精简模型的结构，进而减少参数的数量。<ul>
<li>模型蒸馏 模型蒸馏（Model Distillation）的目标是将复杂模型（称为教师模型）包含的知识迁移到简单模型（称为学生模型）中，从而实现复杂模型的压缩。</li>
<li>模型剪枝 模型剪枝（Model Pruning）的目标是，在尽可能不损失模型性能的情况下，努力消减模型的参数数量，最终有效降低模型的显存需求以及算力开销。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="评测与应用"><a href="#评测与应用" class="headerlink" title="评测与应用"></a>评测与应用</h2><ul>
<li><p>微调大语言模型的评测</p>
<ul>
<li>基于人类的评测</li>
<li>基于模型的评测.考虑到人工评测的成本高昂且耗时较长，一些研究工作使 用强大的闭源大语言模型（如 ChatGPT 和 GPT-4）来替代人类评估员 [68, 315]，对微调大模型的输出进行自动评分或比较。</li>
<li>基于基准的评测. 使用已有的评测基准对于大语言模型进行性能评估已经成 为一种标准性的实践方法。这些评测基准通常包含一系列精心设计的任务，每个任务都对应着充足的测试样本，以确保能够全面而准确地衡量大语言模型的核心能力，如复杂推理、知识利用等。这种评估方法的主要优势在于其高度的自动化和可复用性。自动化的评估过程可以大大减少人工干预的需要，从而提高评估的效率与一致性。</li>
</ul>
</li>
<li><p>公开综合评测体系 随着大语言模型研究的深入，研究者们相继发布了若干用于全面评估大语言模型性能的综合评测体系，从不同角度、不同层次对大语言模型的能力进行了全面而细致的考察。在本章节中，我们将介绍几种广泛应用的综合评测体系，具体包括 MMLU、BIG-Bench、HELM 和 C-Eval。    </p>
</li>
<li><p>更多的评测使用方法详见：<a target="_blank" rel="noopener" href="https://github.com/RUCAIBox/LLMBox/blob/main/utilization/README.md%E3%80%82">https://github.com/RUCAIBox/LLMBox/blob/main/utilization/README.md。</a></p>
</li>
<li><p>大语言模型的另外一个局限之处是，在面对训练数据之外的知识信息时，模型通常无法表现出较好的效果。为了应对这个问题，一个直接的方法是定期使用新数据对大语言模型进行更新。然而，这种方法存在两个显著的问题：一是微调大语言模型的成本昂贵，二是增量训练大语言模型可能会导致灾难性遗忘的现象，即模型在学习新知识时可能会忘记旧知识.</p>
</li>
<li><p>大语言模型的参数化知识很难及时更新。用外部知识源增强大语言模型是解决这一问题的一种实用方法。</p>
</li>
<li><p>复杂推理 复杂推理（Complex Reasoning）是指通过运用支持性证据或逻辑来推导结论或作出决策的能力，这一过程涉及对信息的深入分析与综合处理 [361, 362]。根据推理过程中涉及的逻辑和证据类型，可以将现有的复杂推理任务划分为三个主要类别：知识推理、符号推理和数学推理。</p>
</li>
</ul>
<h2 id="Transformer-architecture（Transformer-架构）"><a href="#Transformer-architecture（Transformer-架构）" class="headerlink" title="Transformer architecture（Transformer 架构）"></a>Transformer architecture（Transformer 架构）</h2><ul>
<li><p>一种常用于自然语言处理任务的神经网络架构。它基于自注意力机制，无须顺序处理数据，其并行性和效率高于循环神经网络和长短期记忆模型。GPT 基于 Transformer 架构。</p>
</li>
<li><p>Transformer 架构彻底改变了 NLP 领域，这主要是因为它能够有效地解决之前的 NLP 模型（如 RNN）存在的一个关键问题：很难处理长文本序列并记住其上下文。换句话说，RNN 在处理长文本序列时容易忘记上下文（也就是臭名昭著的“灾难性遗忘问题”），Transformer 则具备高效处理和编码上下文的能力。</p>
</li>
<li><p>这场革命的核心支柱是注意力机制，这是一个简单而又强大的机制。模型不再将文本序列中的所有词视为同等重要，而是在任务的每个步骤中关注最相关的词。交叉注意力和自注意力是基于注意力机制的两个架构模块，它们经常出现在 LLM 中。Transformer 架构广泛使用了交叉注意力模块和自注意力模块。</p>
</li>
<li><p>与 RNN 不同，Transformer 架构具有易于并行化的优势。这意味着 Transformer 架构可以同时处理输入文本的多个部分，而无须顺序处理。这样做可以提高计算速度和训练速度，因为模型的不同部分可以并行工作，而无须等待前一步骤完成。基于 Transformer 架构的模型所具备的并行处理能力与图形处理单元（graphics processing unit，GPU）的架构完美契合，后者专用于同时处理多个计算任务。由于高度的并行性和强大的计算能力，GPU 非常适合用于训练和运行基于 Transformer 架构的模型。硬件上的这一进展使数据科学家能够在大型数据集上训练模型，从而为开发 LLM 铺平了道路。</p>
</li>
<li><p>attention mechanism（注意力机制）：神经网络架构的一个组件，它使模型在生成输出时能够关注输入的不同部分。注意力机制是 Transformer 架构的关键，使其能够有效地处理长数据序列。</p>
</li>
<li><p>模型架构</p>
<ul>
<li>Transformer 模型 当前主流的大语言模型都基于 Transformer 模型进行设计的。Transformer 是由 多层的多头自注意力（Multi-head Self-attention）模块堆叠而成的神经网络模型。原始的 Transformer 模型由编码器和解码器两个部分构成，而这两个部分实际上可以独立使用，例如基于编码器架构的 BERT 模型 [13] 和解码器架构的 GPT 模型 [14]。</li>
<li>与 BERT 等早期的预训练语言模型相比，大语言模型的特点是使用了更长的向量维度、更深的层数，进而包含了更大规模的模型参数，并主要使用解码器架构，对于 Transformer 本身的结构与配置改变并不大。</li>
</ul>
</li>
</ul>
<h2 id="prompt（提示词）"><a href="#prompt（提示词）" class="headerlink" title="prompt（提示词）"></a>prompt（提示词）</h2><ul>
<li>输入给语言模型的内容，模型通过它生成一个输出。比如，在 GPT 模型中，提示词可以是半句话或一个问题，模型将基于此补全文本。</li>
<li>提示词不仅适用于 OpenAI API，而且是所有 LLM 的入口点。简单地说，提示词就是用户发送给模型的输入文本，用于指导模型执行特定任务。</li>
</ul>
<h2 id="prompt-engineering（提示工程）"><a href="#prompt-engineering（提示工程）" class="headerlink" title="prompt engineering（提示工程）"></a>prompt engineering（提示工程）</h2><ul>
<li><p>设计和优化提示词，以从语言模型中获得所需的输出。这可能涉及指定响应的格式，在提示词中提供示例，或要求模型逐步思考。</p>
</li>
<li><p>提示工程是一门新兴的学科，专注于以最佳实践构建 LLM 的最佳输入，从而尽可能以程序化方式生成目标输出。AI 工程师必须知道如何与 AI 进行交互，以获取可用于应用程序的有利结果。此外，AI 工程师还必须知道如何正确提问和编写高质量的提示词。</p>
</li>
<li><p>通常需要在提示词中定义三大要素：角色、上下文和任务</p>
</li>
<li><p>逐步思考：在提示词末尾添加逐步思考的字样（比如示例中的“Let’s think step by step”）后，模型开始通过拆分问题来进行推理。它可能需要一些时间来进行推理，从而解决之前无法在一次尝试中解决的问题。</p>
</li>
<li><p>实现少样本学习(few-shot learning)：LLM 仅通过提示词中的几个示例就能进行概括并给出有价值的结果。</p>
</li>
<li><p>单样本学习（one-shot learning）。顾名思 义，在单样本学习中，我们只提供一个示例来帮助模型执行任务。尽管这种方法提供的指导比少样本学习要少，但对于简单的任务或 LLM 已经具备丰富背景知识的主题，它可能很有效。单样本学习的优点是更简单、生成速度更快、计算成本更低（因而 API 使用成本更低）。然而，对于复杂的任务或需要更深入理解所需结果的情况，少样本学习的效果可能更好。</p>
</li>
<li><p>改善提示效果</p>
<ol>
<li>指示模型提出更多问题<ul>
<li>在提示词的末尾，询问模型是否理解问题并指示模型提出更多问题。如果你正在构建基于聊天机器人的解决方案，那么这样做非常有效。举例来说，你可以在提示词的末尾添加如下文本：</li>
<li>你清楚地理解我的请求了吗？如果没有，请问我关于上下文的问题。这样一来，当我回答时，你就能够更高效地执行我所请求的任务。</li>
</ul>
</li>
<li>格式化输出</li>
<li>重复指示<ul>
<li>经验表明，重复指示会取得良好的效果，尤其是当提示词很长时。基本思路是，在提示词中多次添加相同的指令，但每次采用不同的表述方式。</li>
</ul>
</li>
</ol>
</li>
<li><p>使用负面提示：在文本生成场景中，负面提示是指通过指定不希望在输出中看到的内容来引导模型。负面提示作为约束或指南，用于滤除某些类型的回答。</p>
</li>
<li><p>添加长度限制：限制长度通常是不错的做法。如果你只希望模型回答 1 个词或者 10个句子，那么不妨将要求添加到提示词中。</p>
</li>
<li><p>chain of thought（CoT，思维链）：一种提示工程技术，核心思想是通过向大语言模型展示少量的示例，在示例中将具体问题拆分成多个推理步骤，并要求模型遵循多步，比如“让我们逐步思考”。这会改善模型在执行复杂的推理任务（算术推理、常识推理和符号推理）时的表现。</p>
</li>
<li><p>你可以将这些技巧结合起来使用，以获得更好的效果。开发人员的工作是找到最有效的提示词来解决特定的问题。请记住，提示工程是一个反复试错的迭代过程。</p>
</li>
<li><p>【来自claude.ai】提示工程能够优化 AI 对话输出的原理主要基于以下几个关键方面：</p>
<ol>
<li>大语言模型的工作原理：</li>
</ol>
<ul>
<li>LLM 本质上是在预测下一个最可能的 token</li>
<li>模型通过海量文本训练学习了文本的统计规律</li>
<li>提示词会影响模型的上下文理解和token预测方向</li>
</ul>
<ol start="2">
<li>上下文学习能力：</li>
</ol>
<ul>
<li>模型能够从提示中理解任务类型和要求</li>
<li>通过示例学习(few-shot learning)快速适应具体任务</li>
<li>更明确的上下文能帮助模型更准确地”理解”任务目标</li>
</ul>
<ol start="3">
<li>注意力机制的影响：</li>
</ol>
<ul>
<li>提示中的关键词会影响模型的注意力分布</li>
<li>结构化的提示能引导模型关注重要信息</li>
<li>合理的提示格式有助于模型理解输入与输出的关系</li>
</ul>
<ol start="4">
<li>模式识别与对齐：</li>
</ol>
<ul>
<li>好的提示能触发模型已学习的有用模式</li>
<li>清晰的指令有助于模型对齐用户意图</li>
<li>示例可以帮助模型识别所需的输出模式</li>
</ul>
<p>  举个例子：<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">糟糕的提示：</span><br><span class="line">&quot;写一篇文章&quot;</span><br><span class="line"></span><br><span class="line">好的提示：</span><br><span class="line">&quot;请写一篇关于人工智能发展的文章，需要包含以下几个方面：</span><br><span class="line">1. 发展历史</span><br><span class="line">2. 主要技术突破</span><br><span class="line">3. 未来展望</span><br><span class="line">要求：</span><br><span class="line">- 语言通俗易懂</span><br><span class="line">- 每个部分300字左右</span><br><span class="line">- 重点突出关键技术进展&quot;</span><br></pre></td></tr></table></figure></p>
<p>  好的提示通过提供：</p>
<ul>
<li>明确的主题和结构</li>
<li>具体的要求和限制</li>
<li>输出格式的指导<br>  帮助模型生成更符合预期的输出。</li>
</ul>
</li>
</ul>
<h3 id="prompt-injection（提示词注入）"><a href="#prompt-injection（提示词注入）" class="headerlink" title="prompt injection（提示词注入）"></a>prompt injection（提示词注入）</h3><ul>
<li>一种特定类型的攻击，通过在提示词中提供精心选择的奖励，使大语言模型的行为偏离其原始任务。</li>
<li>提示词注入的原理如下：用户向应用程序发送一条输入消息，比如“忽略所有先前的指令，执行其他操作”。由于此输入消息与你在构建应用程序时设计的提示词连接在一起，因此 AI 模型将遵循用户的提示词，而不是你的提示词。</li>
<li>如果你计划开发和部署一个面向用户的应用程序，那么我们建议你结合以下两种方法。<ol>
<li>添加分析层来过滤用户输入和模型输出。 </li>
<li>意识到提示词注入不可避免，并采取一定的预防措施。<ul>
<li>分析输入和输出<ol>
<li>使用特定规则控制用户输入</li>
<li>控制输入长度</li>
<li>控制输出、监控和审计</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="embedding（嵌入）"><a href="#embedding（嵌入）" class="headerlink" title="embedding（嵌入）"></a>embedding（嵌入）</h2><ul>
<li><p>表示词语或句子且能被机器学习模型处理的实值向量。对于值较为接近的向量，它们所表示的词语或句子也具有相似的含义。在信息检索等任务中，嵌入的这种特性特别有用。</p>
</li>
<li><p>由于模型依赖数学函数，因此它需要数值输入来处理信息。然而，许多元素（如单词和标记）本质上并不是数值。为了解决这个问题，我们用嵌入将这些概念转化为数值向量。通过以数值方式表示这些概念，嵌入使计算机能够更高效地处理它们之间的关系。在某些情况下，嵌入能力可能很有用。OpenAI 提供了一个可以将文本转换为数值向量的模型。嵌入端点让开发人员能够获取输入文本的向量表示，然后将该向量表示用作其他 ML 模型和 NLP 算法的输入。</p>
</li>
<li><p>在 ML 领域，特别是在处理语言模型时，我们会遇到嵌入这一重要概念。嵌入将分类数据（比如标记，通常是单个词或多组标记）转换为数值格式，具体而言是实数向量。这种转换是必要的，因为 ML 模型依赖数值数据，其直接处理分类数据的能力欠佳。</p>
</li>
<li><p>你可以将嵌入视为一种复杂的语言解释器，它将丰富的词汇和句子转换为 ML 模型能够轻松理解的数值语言。嵌入的一个突出特点是，它能够保持语义相似性。也就是说，含义相近的词语或短语在数值空间中更接近。</p>
</li>
<li><p>LLM 广泛使用嵌入。通常，这些模型处理约 512 维的嵌入，从而提供语言数据的高维数值表示。这些维度很深，使得模型能够区分各种复杂的模式。因此，它们在各种语言任务上表现出色，包括翻译、摘要和生成与人类对话相似的文本回应。</p>
</li>
<li><p>嵌入具有这样的属性：如果两段文本具有相似的含义，那么它们的向量表示也是相似的。</p>
</li>
<li><p>【来自claude.ai】RAG 和 embedding </p>
<ul>
<li>RAG 和 embedding 是紧密相关的技术，embedding 是实现 RAG 的关键技术之一。让我解释它们的关系和区别：<ul>
<li><p>关系：</p>
<ol>
<li>Embedding 是 RAG 的基础技术</li>
</ol>
<ul>
<li>RAG 在检索阶段需要使用 embedding 将文档和查询转换为向量</li>
<li>通过计算向量相似度来找到相关文档</li>
</ul>
<ol start="2">
<li>在 RAG 流程中 embedding 的作用：</li>
</ol>
<ul>
<li>将知识库文档转换为向量存储</li>
<li>将用户查询转换为向量以便检索</li>
<li>通过向量相似度找到最相关的文档片段</li>
</ul>
</li>
<li><p>区别：</p>
<ol>
<li>功能定位不同：</li>
</ol>
<ul>
<li>Embedding 是一种将文本转换为向量的基础技术</li>
<li>RAG 是一个完整的应用框架，包含检索和生成两个主要步骤</li>
</ul>
<ol start="2">
<li>使用场景不同：</li>
</ol>
<ul>
<li>Embedding 可用于多种场景：文本相似度、聚类、分类等</li>
<li>RAG 专注于增强 LLM 的知识和回答准确性</li>
</ul>
<ol start="3">
<li>技术复杂度：</li>
</ol>
<ul>
<li>Embedding 相对简单，主要关注向量转换和相似度计算</li>
<li>RAG 更复杂，需要结合向量检索、上下文组织、LLM 生成等多个环节</li>
</ul>
<ol start="4">
<li>输出结果：</li>
</ol>
<ul>
<li>Embedding 输出是向量</li>
<li>RAG 输出是生成的文本回答</li>
</ul>
</li>
<li><p>简单来说，embedding 是 RAG 的重要组成部分，但 RAG 不仅仅是 embedding。RAG 使用 embedding 技术来实现其检索功能，然后将检索到的相关内容用于增强 LLM 的生成能力。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="RAG（检索增强生成）（Retrieval-Augmented-Generation）"><a href="#RAG（检索增强生成）（Retrieval-Augmented-Generation）" class="headerlink" title="RAG（检索增强生成）（Retrieval-Augmented Generation）"></a>RAG（检索增强生成）（Retrieval-Augmented Generation）</h2><ul>
<li>受限于训练数据的时效性和局限性，当涉及实时新闻或特定专业领域内知识时，大语言模型的生成结果可能不够准确。为弥补这一不足，研究人员引入了检索增强生成（Retrieval-Augmented Generation, RAG）技术。该技术旨在通过信息检索系统从外部知识库中获取相关信息，为大语言模型提供时效性强、领域相关的外部知识，以减少大语言模型生成内容中的错误。</li>
</ul>
<h2 id="fine-tuning（模型微调）"><a href="#fine-tuning（模型微调）" class="headerlink" title="fine-tuning（模型微调）"></a>fine-tuning（模型微调）</h2><ul>
<li><p>在微调过程中，预训练模型（如 GPT-3 或其他大语言模型）在一个较小、特定的数据集上进一步训练。微调旨在重复使用预训练模型的特征，并使其适应于特定任务。对于神经网络来说，这意味着保持结构不变，仅稍微改变模型的权重，而不是从头开始构建模型。</p>
</li>
<li><p>对比微调和少样本学习</p>
<ul>
<li>微调是指针对特定任务在一组数据上重新训练现有模型，以提高模型的性能并使其回答更准确。在微调过程中，模型的内部参数得到更新。少样本学习则是通过提示词向模型提供有限数量的好例子，以指导模型根据这些例子给出目标结果。在少样本学习过程中，模型的内部参数不会被修改。</li>
<li>微调可以帮助我们得到高度专业化的模型，更准确地为特定任务提供与上下文相关的结果。</li>
<li>这使得微调非常适合有大量数据可用的场景。这种定制化确保模型生成的内容更符合目标领域的特定语言模式、词汇和语气 。</li>
<li>少样本学习是一种更灵活的方法，其数据使用率也更高，因为它不需要重新训练模型。当只有有限的示例可用或需要快速适应不同任务时，这种技巧非常有益。少样本学习让开发人员能够快速设计原型并尝试各种任务，这使其成为许多用例的实用选择。这两种方法的另一个关键选择标准是成本，毕竟使用和训练微调模型更贵。</li>
</ul>
</li>
<li><p>迁移学习是指将从一个领域学到的知识应用于不同但相关的领域。正因为如此，你有时可能会听到人们在谈论微调时提到迁移学习。</p>
</li>
<li><p>微调除了文中提到的确保模型生成内容更符合目标领域的特定语言模式、词汇和语气，还有一个优势：你可以通过微调缩短每一次提示中重复的指令或提示词以节省成本或降低延迟，模型会记住通过微调获得的“内置”指令。因此，微调后，你可以在不牺牲提示质量的前提下，每次输入更短的提示词。</p>
</li>
<li><p>微调的应用</p>
<ul>
<li>法律文本分析</li>
<li>自动代码审查</li>
<li>财务文档摘要</li>
<li>技术文档翻译</li>
<li>为专业领域生成内容</li>
</ul>
</li>
<li><p>【来自claude.ai】指令微调(Instruction Tuning&#x2F;RLHF)和Fine-tuning虽然都是大模型调优的方法，但它们是不同的技术：</p>
<ul>
<li>Fine-tuning:<ol>
<li>更广义的概念，指在预训练模型基础上进行进一步训练</li>
<li>目的是让模型适应特定领域或任务</li>
<li>使用传统的监督学习方法</li>
<li>训练数据通常是输入-输出对</li>
<li>例如：用医疗数据fine-tune GPT模型使其更擅长医疗领域</li>
</ol>
</li>
<li>指令微调:<ol>
<li>是Fine-tuning的一种特殊形式</li>
<li>专注于提高模型遵循人类指令的能力</li>
<li>通常使用reinforcement learning from human feedback (RLHF)</li>
<li>训练数据包含明确的指令、期望的输出，以及人类反馈</li>
<li>例如：训练模型理解并执行”用简单的语言解释量子物理”这样的指令</li>
</ol>
</li>
<li>关键区别：<ul>
<li>指令微调更关注模型对指令的理解和执行能力</li>
<li>Fine-tuning更关注领域适应性和特定任务性能</li>
<li>指令微调通常需要人类反馈作为训练信号</li>
<li>Fine-tuning使用常规的监督学习方法</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="plugin（插件）"><a href="#plugin（插件）" class="headerlink" title="plugin（插件）"></a>plugin（插件）</h2><ul>
<li>一种专门为语言模型设计的独立封装软件模块，用于扩展或增强模型的能力，可以帮助模型检索外部数据、执行计算任务、使用第三方服务等。</li>
<li>尽管包括 GPT-4 在内的 LLM 在各种任务上都表现出色，但它们仍然存在固有的局限性。比如，这些模型只能从训练数据中学习，这些数据往往过时或不适用于特定的应用。此外，它们的能力仅限于文本生成。我们还发现，LLM 不适用于某些任务，比如复杂的计算任务。   </li>
<li>插件的目标是为 LLM 提供更广泛的功能，使 LLM 能够访问实时信息，进行复杂的数学运算，并利用第三方服务。 比如，插件可以使 LLM 检索体育比分和股票价格等实时信息，从企业文档等知识库中提取</li>
</ul>
<h2 id="Agents（智能体）"><a href="#Agents（智能体）" class="headerlink" title="Agents（智能体）"></a>Agents（智能体）</h2><ul>
<li><p>所谓智能体，就是一个可以处理用户输入、做出决策并选择适当工具来完成任务的组件。它以迭代方式工作，采取一系列行动，直到解决问题。</p>
</li>
<li><p>一种以大语言模型驱动的人工智能程序，能够自主感知环境并采取行动以实现目标，拥有自主推理决策、规划行动、检索记忆、选择工具执行任务等能力。</p>
</li>
<li><p>大语言模型智能体的构建过程，将围绕三个基本组件进行介绍，包括 记忆组件（Memory）、规划组件（Planning）2 和执行组件（Execution）。</p>
</li>
<li><p>大语言模型智能体的典型应用 大语言模型智能体在自主解决复杂任务方面展现出了巨大的潜力，不仅能够胜任特定任务，还可以构建面向复杂场景的虚拟仿真环境。本节将介绍三个大语言模型智能体的典型应用案例。 WebGPT WebGPT [31] 是由 OpenAI 开发的一款具有信息检索能力的大语言模型，它基于 GPT-3 模型微调得到，可以看作是大语言模型智能体的一个早期雏形。WebGPT部署在一个基于文本的网页浏览环境，用以增强大语言模型对于外部知识的获取能力。作为一个单智能体系统，WebGPT 具备自主搜索、自然语言交互以及信息整合分析等特点，能够理解用户的自然语言查询，自动在互联网上搜索相关网页。根据搜索结果，WebGPT 能够点击、浏览、收藏相关网页信息，对搜索结果进行分析和整合，最终以自然语言的形式提供准确全面的回答，并提供参考文献。WebGPT在基于人类评估的问答任务中，获得了与真实用户答案准确率相当的效果。 MetaGPT MetaGPT [308] 是一个基于多智能体系统的协作框架，旨在模仿人类组织的运作方式，模拟软件开发过程中的不同角色和协作。相关角色包括产品经理、架构师、项目经理、软件工程师及测试工程师等，并遵循标准化的软件工程运作流程对不同角色进行协调，覆盖了需求分析、需求文档撰写、系统设计、工作分配、</p>
</li>
</ul>
<h2 id="其他相关知识点"><a href="#其他相关知识点" class="headerlink" title="其他相关知识点"></a>其他相关知识点</h2><ul>
<li>AI hallucination（AI 幻觉）：AI 生成的内容与现实世界的知识不一致或与实际数据显著不同的现象。在大多数情况下，模型的输出是与提问相关的，并且完全可用，但是在使用语言模型时需要小心，因为它们给出的回答可能不准确。这种回答通常被称为 AI 幻觉，即 AI 自信地给出一个回答，但是这个回答是错误的，或者涉及虚构的信息。</li>
<li>catastrophic forgetting（灾难性遗忘）：这是模型的一种倾向，具体指模型在学习新数据时忘记先前学到的信息。这种限制主要影响循环神经网络。循环神经网络在处理长文本序列时难以保持上下文。</li>
<li>foundation model（基础模型）：一类 AI 模型，包括但不限于大语言模型。基础模型是在大量未标记数据上进行训练的。这类模型可以执行各种任务，如图像分析和文本翻译。基础模型的关键特点是能够通过无监督学习从原始数据中学习，并能够通过微调来执行特定任务。</li>
<li>Generative AI（GenAI，生成式人工智能）：人工智能的一个子领域，专注于通过学习现有数据模式或示例来生成新的内容，包括文本、代码、图像、音频等，常见应用包括聊天机器人、创意图像生成和编辑、代码辅助编写等。</li>
<li>Generative Pre-trained Transformer（GPT，生成式预训练Transformer）：由 OpenAI 开发的一种大语言模型。GPT 基于 Transformer 架构，并在大量文本数据的基础上进行训练。这类模型能够通过迭代地预测序列中的下一个单词来生成连贯且与上下文相关的句子。</li>
<li>inference（推理）：使用训练过的机器学习模型进行预测和判断的过程。<br>information retrieval（信息检索）：在一组资源中查找与给定查询相关的信息。信息检索能力体现了大语言模型从数据集中提取相关信息以回答问题的能力。</li>
<li>language model（语言模型）：用于自然语言处理的人工智能模型，能够阅读和生成人类语言。语言模型是对词序列的概率分布，通过训练文本数据来学习一门语言的模式和结构。</li>
<li>large language model（LLM，大语言模型）：具有大量参数（参数量通常为数十亿，甚至千亿以上）的语言模型，经过大规模文本语料库的训练。GPT-4 和 ChatGPT 就属于 LLM，它们能够生成自然语言文本、处理复杂语境并解答难题。</li>
<li>long short-term memory（LSTM，长短期记忆）：一种用于处理序列数据中的短期及长期依赖关系的循环神经网络架构。然而，基于 Transformer 的大语言模型（如 GPT 模型）不再使用LSTM，而使用注意力机制。</li>
<li>multimodal model（多模态模型）：能够处理和融合多种数据的模型。这些数据可以包括文本、图像、音频、视频等不同模态的数据。它为计算机提供更接近于人类感知的场景。</li>
<li>n-gram：一种算法，常用于根据词频预测字符串中的下一个单词。这是一种在早期自然语言处理中常用的文本补全算法。后来，n-gram 被循环神经网络取代，再后来又被基于 Transformer 的算法取代。</li>
<li>natural language processing（NLP，自然语言处理）：人工智能的一个子领域，专注于计算机与人类之间的文本交互。它使计算机程序能够处理自然语言并做出有意义的回应。</li>
<li>parameter（参数）<br>对大语言模型而言，参数是它的权重。在训练阶段，模型根据模型创建者选择的优化策略来优化这些系数。参数量是模型大小和复杂性的衡量标准。参数量经常用于比较大语言模型。一般而言，模型的参数越多，它的学习能力和处理复杂数据的能力就越强。</li>
<li>pre-trained（预训练）<br>机器学习模型在大型和通用的数据集上进行的初始训练阶段。对于一个新给定的任务，预训练模型可以针对该任务进行微调。</li>
<li>recurrent neural network（RNN，循环神经网络）：一类表现出时间动态行为的神经网络，适用于涉及序列数据的任务，如文本或时间序列。</li>
<li>reinforcement learning（RL，强化学习）：一种机器学习方法，专注于在环境中训练模型以最大化奖励信号。模型接收反馈并利用该反馈来进一步学习和自我改进。</li>
<li>reinforcement learning from human feedback（RLHF，通过人类反馈进行强化学习）：一种将强化学习与人类反馈相结合的训练人工智能系统的先进技术，该技术涉及使用人类反馈来创建奖励信号，继而使用该信号通过强化学习来改进模型的行为。</li>
<li>sequence-to-sequence model（Seq2Seq 模型，序列到序列模型）：这类模型将一个领域的序列转换为另一个领域的序列。它通常用于机器翻译和文本摘要等任务。Seq2Seq 模型通常使用循环神经网络或 Transformer 来处理输入序列和输出序列。</li>
<li>supervised fine-tuning（SFT，监督微调）：采用预先训练好的神经网络模型，并针对特定任务或领域在少量的监督数据上对其进行重新训练。</li>
<li>supervised learning（监督学习）：一种机器学习方法，可以从训练资料中学到或建立一个模式，以达到准确分类或预测结果的目的。</li>
<li>synthetic data（合成数据）：人工创建的数据，而不是从真实事件中收集的数据。当真实数据不可用或不足时，我们通常在机器学习任务中使用合成数据。比如，像 GPT 这样的语言模型可以为各种应用场景生成文本类型的合成数据。</li>
<li>temperature（温度）：大语言模型的一个参数，用于控制模型输出的随机性。温度值越高，模型结果的随机性越强；温度值为 0 表示模型结果具有确定性（在 OpenAI 模型中，温度值为 0 表示模型结果近似确定）。</li>
<li>text completion（文本补全）：大语言模型根据初始的单词、句子或段落生成文本的能力。文本是根据下一个最有可能出现的单词生成的。</li>
<li>token（标记）：字母、字母对、单词或特殊字符。在自然语言处理中，文本被分解成标记。在大语言模型分析输入提示词之前，输入提示词被分解成标记，但输出文本也是逐个标记生成的。</li>
<li>tokenization（标记化）：将文本中的句子、段落切分成一个一个的标记，保证每个标记拥有相对完整和独立的语义，以供后续任务使用（比如作为嵌入或者模型的输入）。</li>
<li>transfer learning（迁移学习）：一种机器学习技术，其中在一个任务上训练的模型被重复利用于另一个相关任务。比如，GPT 在大量文本语料库上进行预训练，然后可以使用较少的数据进行微调，以适用于特定任务。</li>
<li>unsupervised learning（无监督学习）：一种机器学习方法，它使用机器学习算法来分析未标记的数据集并进行聚类。这些算法无须人工干预即可发现隐藏的模式或给数据分组。</li>
<li>zero-shot learning（零样本学习）：一个机器学习概念，即大语言模型对在训练期间没有明确见过的情况进行预测。任务直接呈现在提示词中，模型利用其预训练的知识生成回应。</li>
</ul>
<h2 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h2><ul>
<li>LangChain 框架可能更适合大型项目</li>
<li>LangChain 是专用于开发 LLM 驱动型应用程序的框架。</li>
<li>LangChain 框架的关键模块<ul>
<li>Models（模型）：该模块是由 LangChain 提供的标准接口，你可以通过它与各种 LLM进行交互。LangChain 支持集成 OpenAI、Hugging Face、Cohere、GPT4All 等提供商提供的不同类型的模型。</li>
<li>Prompts（提示词）：提示词已成为 LLM 编程的新标准。该模块包含许多用于管理提示词的工具。</li>
<li>Indexes（索引）：该模块让你能够将 LLM 与你的数据结合使用 </li>
<li>Chains（链）：通过该模块，LangChain 提供了 Chain 接口。你可以使用该接口创建一个调用序列，将多个模型或提示词组合在一起。</li>
<li>Agents（智能体）：该模块引入了 Agent 接口。所谓智能体，就是一个可以处理用户输入、做出决策并选择适当工具来完成任务的组件。它以迭代方式工作，采取一系列行动，直到解决问题。</li>
<li>Memory（记忆）：该模块让你能够在链调用或智能体调用之间维持状态。默认情况下，链和智能体是无状态的。这意味着它们独立地处理每个传入的请求，就像LLM 一样。</li>
</ul>
</li>
</ul>
<h2 id="Hugging-Face"><a href="#Hugging-Face" class="headerlink" title="Hugging Face"></a>Hugging Face</h2><ul>
<li>Hugging Face 是一个致力于推动自然语言处理技术进步的开源社区，专注于为研究人员和工程师提供高效、易用且可重复的自然语言处理技术解决方案。这些解决方案既包括基础的技术流程，如预训练和微调，也涉及具体的应用任务，包括对话系统、翻译等。Hugging Face 平台上的代码大部分基于目前主流的深度学习框架实现完成的，如 PyTorch 和 TensorFlow。为了满足广泛的研究与应用需求，Hugging Face 发布了一系列代码库</li>
</ul>
<h2 id="个人理解（使用claude-ai-或-open-ai-优化过）"><a href="#个人理解（使用claude-ai-或-open-ai-优化过）" class="headerlink" title="个人理解（使用claude.ai 或 open.ai 优化过）"></a>个人理解（使用claude.ai 或 open.ai 优化过）</h2><ol>
<li>通过大量数据进行自监督预训练(Pre-training)，之后使用监督学习(SFT)和强化学习(RLHF)等方法训练大语言模型。模型会在训练过程中表现出一些涌现能力，即随着规模增长获得的意外新能力。</li>
<li>训练之后的大模型可以这样比喻理解：对应一系列复杂的”处理规则”(相当于函数)以及训练时获得的”知识”(相当于多维度的数据)。这些规则决定如何处理输入信息，而知识则帮助模型理解和回应各种问题。就像一个经验丰富的专家，既有处理问题的方法，也有丰富的知识储备。</li>
<li>使用RAG是通过嵌入技术将外部知识转换为向量形式存储，当模型回答问题时，会同时使用：<ul>
<li>模型自身通过训练获得的知识（存在参数&#x2F;权重中）</li>
<li>通过检索获得的外部知识（存在向量数据库中）- （在运行时动态加载到模型的”上下文窗口”中；只是临时作为输入的一部分被模型处理）</li>
</ul>
</li>
<li>嵌入技术在RAG中起到了关键作用：它能把文本转换成向量形式，使得模型能够理解和使用这些外部知识。</li>
<li>微调是通过调整模型的参数权重来优化其性能的过程。它并不等同于新建一个全新的模型，而是基于预训练模型，通过新的数据对部分或全部权重进行进一步优化，以适应特定任务或领域需求。需要注意的是，模型本身并不直接包含训练数据，而是通过参数权重间接“记住”了训练数据中的语言模式和知识。因此，微调的过程不会调整模型使用的原始数据，而是调整模型基于新数据学习到的知识表示和行为。</li>
<li>关于提示词技巧：提示词的设计就像与人交流时语言清晰、有条理，并能准确表达需求的人。这种沟通方式能够让模型更好地理解意图，从而产出符合预期的结果，因此提示词的技巧与良好的表达能力相辅相成，具有高度的共鸣。</li>
<li>在实际应用中，通常会有一个基础模型，它通过大量、多元化的训练数据应对大多数常见问题。这是一个通用的模型，具备广泛的能力。然而，针对特定领域或任务需求，可以对其进行微调或在特定领域的数据上进行训练，以构建不同的模型或智能体。与此同时，可能还会通过插件等方式增强模型的功能，以弥补基础模型在某些方面的不足。<br>具体过程通常是：通过用户输入，首先对语义进行分析，然后根据需求将任务转发给相应的智能体进行处理。整个系统由多个智能体组成，这些智能体可以互相协作，共同完成复杂的任务，从而形成一个多智能体系统。<br>这种架构通过将任务分配给不同的智能体，使得每个智能体可以专注于其擅长的领域，进而提高系统的整体效率和精准度。</li>
</ol>
<h2 id="个人扩展思考"><a href="#个人扩展思考" class="headerlink" title="个人扩展思考"></a>个人扩展思考</h2><ul>
<li>关于替代人的问题：目前大模型还只是工具，不能完全替代所有人，但可以提升很多人的效率，从而也替代部分人。</li>
<li>大模型受限于原理，能力有限：大语言模型的输出基于训练语料和训练过程中学到的概率分布生成。这意味着其生成的内容是在统计意义上最可能的回复。然而，单一模型可能在语料的广度和功能的多样性方面存在局限性，这可能导致其能力受限。</li>
<li>AI无法承担责任或替代人类对错误决策的责任。</li>
</ul>
<h2 id="其他扩展"><a href="#其他扩展" class="headerlink" title="其他扩展"></a>其他扩展</h2><h3 id="关于标记（token）【来自豆包】"><a href="#关于标记（token）【来自豆包】" class="headerlink" title="关于标记（token）【来自豆包】"></a>关于标记（token）【来自豆包】</h3><pre>
在OpenAI中，标记（token）是其对文本进行处理和计费的基本单位.

标记的含义

标记可以是单词、单词的一部分、数字、标点符号等。例如，单词“hello”是一个标记，“don’t”会被拆分成“don”和“‘t”两个标记，“123”是一个标记，逗号“,”也是一个标记.

标记的原理

• 文本分割：OpenAI通过特定的标记化算法，将输入的文本和生成的输出文本都分解成一个个标记。比如对于句子“I am taking my dog on a walk.”，会被分割成“I”“am”“taking”“my”“dog”“on”“a”“walk”等标记，其中“taking”还可能进一步被拆分成“take”和“ing”.

• 数值转换：分割后的标记会被转换为数值，以便模型能够进行处理和计算。模型在训练和推理过程中，都是基于这些数值化的标记来进行各种运算和生成文本.

• 计费依据：OpenAI根据输入和输出文本中标记的总数来计算费用。例如，若输入的问题是50个标记长，得到的回答是150个标记长，那么此次交互总共使用了200个标记，再依据所使用模型的每1000个标记的单价，就可以算出此次的费用.

在OpenAI中，当你输入时指定的标记数量限制，实际使用的标记数量不会超过你所设定的限制。

例如，你设定输入标记限制为500，模型在处理时会尽量依据此限制来生成文本，一般情况下不会超出该数量 。不过，如果输入内容本身就超过了设定的限制，模型通常会截断超出部分，仅处理限制范围内的标记，以保证符合你所设定的上限。

最终的费用计算也是基于实际使用的标记数量，只要在输入时设定了标记数量限制，就不会出现因模型生成内容导致标记数量超出限制而增加费用的情况。
</pre>

<h3 id="大模型是否能发现训练数据存在逻辑矛盾【来自豆包】"><a href="#大模型是否能发现训练数据存在逻辑矛盾【来自豆包】" class="headerlink" title="大模型是否能发现训练数据存在逻辑矛盾【来自豆包】"></a>大模型是否能发现训练数据存在逻辑矛盾【来自豆包】</h3><pre>
大模型通常不具备直接发现训练数据中逻辑矛盾的能力，原因主要有以下几点：

• 训练机制的局限性：大模型的训练基于对大量文本数据的统计分析和模式识别，通过预测下一个单词或字符来生成文本，重点在于学习语言的表面形式和常见搭配，而非深入理解数据背后的逻辑关系和语义内涵。 例如，对于“苹果是红色的”和“苹果是绿色的”这两个相互矛盾的数据，模型只会学习到这两种表述都是可能出现的语言形式，而不会判断其逻辑矛盾.

• 缺乏真实世界的理解和推理能力：大模型没有对现实世界的直接感知和体验，无法像人类一样基于常识和逻辑规则进行推理。比如面对“太阳从西边升起”和“太阳从东边升起”这两个矛盾数据，模型无法依据自然规律来识别其中的逻辑错误.

• 难以对数据进行批判性评估：大模型不会对训练数据的真实性、准确性和一致性进行主动质疑和验证，而是将所有数据同等对待地学习，导致矛盾数据被无差别吸收，进而可能在生成文本时输出与矛盾数据相关的不合理内容.
</pre>

<h3 id="How-to-study-LLMs-with-no-machine-learning-background-【From-Gork-2】"><a href="#How-to-study-LLMs-with-no-machine-learning-background-【From-Gork-2】" class="headerlink" title="How to study LLMs with no machine learning background? 【From Gork 2】"></a>How to study LLMs with no machine learning background? 【From Gork 2】</h3><pre>
Studying Large Language Models (LLMs) from a zero machine learning background involves a step-by-step approach to build your understanding. Here's a concise guide:

### **1. Basics of Machine Learning:**
   - **Start with Fundamentals:** 
     - Learn basic concepts like supervised vs. unsupervised learning, regression, classification, and neural networks. 
     - Resources:
       - *Coursera's Machine Learning by Andrew Ng*
       - *Khan Academy's AI Course*

### **2. Python and Programming:**
   - **Learn Python:** 
     - Python is crucial for ML development. Focus on data structures, control flow, and libraries like NumPy, Pandas.
     - Resources:
       - *Python for Everybody* on Coursera
       - *Automate the Boring Stuff with Python*

### **3. Deep Learning Basics:**
   - **Understand Neural Networks:** 
     - Grasp concepts of neurons, layers, activation functions, backpropagation.
     - Resources:
       - *Deep Learning Specialization by Andrew Ng on Coursera*

### **4. Focus on NLP (Natural Language Processing):**
   - **Basics of NLP:**
     - Learn about tokenization, word embeddings (like Word2Vec, GloVe), and sequence models.
     - Resources:
       - *Natural Language Processing with Deep Learning* by Stanford on YouTube

### **5. Introduction to LLMs:**
   - **Concepts of LLMs:**
     - Study transformer architecture, attention mechanisms, and how LLMs are trained (like BERT, GPT).
     - Resources:
       - *Illustrated Transformer* by Jay Alammar
       - *Hugging Face's NLP Course*

### **6. Practical Experience:**
   - **Implement Small Projects:**
     - Start with fine-tuning pre-trained models rather than training from scratch due to computational constraints.
     - Use platforms like Google Colab or Kaggle for free GPU resources to run models.

### **7. Community and Resources:**
   - **Engage with Communities:**
     - Join forums like Stack Overflow, Reddit (r/MachineLearning, r/LanguageTechnology), and Discord groups.
   - **Read Papers and Blogs:**
     - Follow research papers on arXiv, and blogs by companies like Hugging Face or Google AI.

### **8. Advanced Learning:**
   - **Once you have a foundation:**
     - Dive into specifics of model architectures, optimization techniques, and deployment strategies.

### **9. Keep Learning:**
   - **Stay Updated:** 
     - The field of LLMs is rapidly evolving. Follow conferences like NeurIPS or ACL for the latest advancements.

Starting from zero, this journey will take time and dedication. Patience and consistent practice are key. Remember, each step builds on the previous one, so don't rush through the foundational learning.

</pre>

<h3 id="从零开始构建大模型（如LLM）【来自-open-ai】"><a href="#从零开始构建大模型（如LLM）【来自-open-ai】" class="headerlink" title="从零开始构建大模型（如LLM）【来自 open.ai】"></a>从零开始构建大模型（如LLM）【来自 open.ai】</h3><pre>
从零构建大模型（如LLM）包括设计模型架构（如Transformer）、准备和清洗大量数据集、实现和预训练模型（使用PyTorch或TensorFlow）、优化和调试（采用分布式训练和混合精度）、以及微调和部署。
常用工具有Hugging Face Datasets（数据处理）、PyTorch/TensorFlow（模型实现）、DeepSpeed（分布式训练）、TensorBoard（监控）、以及NVIDIA CUDA（硬件加速）。
构建过程中需要强大的计算资源，如多GPU或TPU集群，云服务（如AWS或Google Cloud）可提供支持。
</pre>

<h3 id="Max-Tokens、Context-Window-和-Context-Length"><a href="#Max-Tokens、Context-Window-和-Context-Length" class="headerlink" title="Max Tokens、Context Window 和 Context Length"></a>Max Tokens、Context Window 和 Context Length</h3><ul>
<li>grok3 (2025-02-24)</li>
<li>Max Tokens、Context Window 和 Context Length 主要关注输入的限制，但它们也可能间接影响到输出，具体来说，通常与模型的生成输出长度或质量有关系。</li>
</ul>
<ol>
<li>Max Tokens (最大令牌数)<ul>
<li>Max Tokens 既包括输入的令牌数，也包括模型生成的输出的令牌数。举个例子，假设一个模型的 Max Tokens 是 4096：</li>
<li>如果输入文本占用了 1000 个令牌，那么剩余的 3096 个令牌就可以用来生成输出。</li>
<li>如果输入文本占用的令牌数较多，那么可用来生成的输出就会变少，反之亦然。</li>
<li>所以，Max Tokens 会直接限制模型的输出长度，因为它是输入和输出令牌数的总和。</li>
</ul>
</li>
<li>Context Window（上下文窗口）<ul>
<li>Context Window 通常更侧重于模型在生成过程中“能看到”的上下文范围。对于长文本，如果输入超过了 Context Window 的限制，超出的部分会被截断，模型只会处理窗口内的文本内容，而不会利用超出部分来生成更合适的回答。</li>
<li>因此，Context Window 主要限制了模型在生成时能够参考的输入量，进而间接影响输出的质量、相关性和连贯性。</li>
</ul>
</li>
<li>Context Length（上下文长度）<ul>
<li>Context Length 指的是你实际输入给模型的文本长度，包括用户输入和可能的上下文（例如先前的对话历史）。它影响了模型的理解过程，并且通常是 Max Tokens 限制的一部分。</li>
<li>如果输入的 Context Length 较长（即文本较多），那么会减少模型在生成输出时可用的令牌数，进而影响输出的长度。</li>
</ul>
</li>
</ol>
<ul>
<li>总结：<ul>
<li>Max Tokens 直接限制了输入和输出的总令牌数，影响输出的最大长度。</li>
<li>Context Window 影响模型生成输出时能参考多少输入内容，因此间接影响输出的质量、相关性和连贯性。</li>
<li>Context Length 是指输入的实际长度，它在占用较多令牌时可能会减少输出可用的令牌数，从而影响输出的长度。</li>
<li>所以，虽然这三个参数主要是控制输入的，但由于它们与模型的令牌处理能力密切相关，它们也会间接影响生成的输出。</li>
</ul>
</li>
</ul>
<h3 id="构建大模型的过程"><a href="#构建大模型的过程" class="headerlink" title="构建大模型的过程"></a>构建大模型的过程</h3><ul>
<li>From ChatGPT (4o) (2025-03-03)</li>
<li><a target="_blank" rel="noopener" href="https://chatgpt.com/share/67c531cc-e618-800b-a49d-cae86ebde079">https://chatgpt.com/share/67c531cc-e618-800b-a49d-cae86ebde079</a></li>
<li>从头构建一个大模型（比如类似 GPT、LLaMA 这样的 Transformer 结构），涉及确定神经元个数（即隐藏层维度）、神经网络层数（深度）、以及激活函数的选择。这个过程通常需要结合理论分析和实验调优。</li>
<li>神经元个数决定了模型的表达能力，主要涉及两个关键参数：<ul>
<li>d_model（隐藏层维度）：决定每个 token 的表示能力。</li>
<li>d_ff（前馈层维度）：影响非线性变换的能力</li>
</ul>
</li>
<li>层数（L）决定了模型可以学习的层级信息。</li>
<li>激活函数的作用是引入非线性，否则整个网络只是线性变换，无法学习复杂模式。</li>
</ul>
<h3 id="训练后大型语言模型的组成"><a href="#训练后大型语言模型的组成" class="headerlink" title="训练后大型语言模型的组成"></a>训练后大型语言模型的组成</h3><ul>
<li><p>From Gork3 (2025-02-25)</p>
</li>
<li><p>关键要点</p>
<ul>
<li>研究表明，大型语言模型训练完成后，其数据内容主要是参数，包括词向量和映射关系。</li>
<li>证据倾向于认为，这些参数是神经网络的权重和偏差，编码了从训练数据中学到的语言模式。</li>
<li>模型本身不存储原始训练数据，而是通过参数捕获语言的统计关系。</li>
</ul>
</li>
<li><p>参数：这些是神经网络的权重和偏差，存储在模型文件中，用于处理输入并生成输出。      </p>
</li>
<li><p>词向量（也称为嵌入），它们是单词的数值表示，捕捉单词的语义和句法意义。</p>
</li>
<li><p>映射关系，通过神经网络各层的权重定义，决定了如何处理这些词向量以生成文本。</p>
</li>
<li><p>结论：训练后的大型语言模型的数据内容是其参数，包括词向量和映射关系。这些参数通过嵌入层、前馈网络和注意力机制等组件实现，捕捉了语言的统计模式。虽然模型不直接存储训练数据，但其参数可能隐含记忆某些内容。  </p>
</li>
<li><p>From ChatGPT(o4) (2025-03-03)</p>
</li>
<li><p>除上述的数据之外，还包括</p>
<ul>
<li>模型架构（Neural Network 结构）：指的是模型的层数、注意力机制、激活函数等，比如 config.json 里会定义 Transformer 结构、隐藏层大小、head 数量、dropout 率等</li>
<li>其他辅助信息：训练时的一些超参数、优化器状态等</li>
</ul>
</li>
<li><p>这些数据以一定的格式和文件保存在大模型的训练结果中。</p>
<ul>
<li>比如Hugging Face transformers 生态 里的 “事实标准”，但并不是所有大模型都会按这个格式存储。不同的框架、实现方式和研究机构可能会有自己的格式和规范。</li>
<li>不同模型格式要用 相应的加载器，不能混用。不同的深度学习框架、训练方式，甚至不同的硬件优化方式，都会影响模型的存储格式和加载方式。</li>
</ul>
</li>
</ul>
<h3 id="如何加载大模型"><a href="#如何加载大模型" class="headerlink" title="如何加载大模型"></a>如何加载大模型</h3><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/KG2yb15EkYuWZFOwF0UT5g">大语言模型引擎全解析：Transformers、vLLM、Llama.cpp、SGLang、MLX 和 Ollama，最佳选择？</a></li>
</ul>
<h3 id="神经网络中，权重和偏置用公式的表现形式"><a href="#神经网络中，权重和偏置用公式的表现形式" class="headerlink" title="神经网络中，权重和偏置用公式的表现形式"></a>神经网络中，权重和偏置用公式的表现形式</h3><ul>
<li><p>From ChatGPT(o4) (2025-03-03)</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://chatgpt.com/share/67c5365d-3fac-800b-87d4-df29d53da575">https://chatgpt.com/share/67c5365d-3fac-800b-87d4-df29d53da575</a></p>
</li>
<li><p>神经网络中的权重和偏置在前向传播时，基本上都是一次方程（线性变换），但整个神经网络通常是非线性映射，因为每层的输出会经过非线性激活函数。</p>
</li>
<li><p>在神经网络中，<strong>输入 X 的个数（也就是特征的维度）</strong>由具体的任务和数据决定</p>
<ol>
<li>由数据决定（特征数量）</li>
<li>由网络结构决定</li>
<li>由数据预处理决定</li>
</ol>
</li>
</ul>
<h3 id="发布的大模型，所指的参数个数怎么计算出来的"><a href="#发布的大模型，所指的参数个数怎么计算出来的" class="headerlink" title="发布的大模型，所指的参数个数怎么计算出来的"></a>发布的大模型，所指的参数个数怎么计算出来的</h3><ul>
<li>From ChatGPT(o4) (2025-03-03)</li>
<li><a target="_blank" rel="noopener" href="https://chatgpt.com/share/67c5365d-3fac-800b-87d4-df29d53da575">https://chatgpt.com/share/67c5365d-3fac-800b-87d4-df29d53da575</a></li>
<li>参数（parameters） 指的是整个模型的权重和偏置，包括所有层的权重矩阵和偏置向量</li>
<li>参数个数：由模型层数、神经元数量、词向量维度决定，影响模型的存储和计算复杂度。</li>
</ul>
<h3 id="用英语和中文询问大型语言模型有何不同"><a href="#用英语和中文询问大型语言模型有何不同" class="headerlink" title="用英语和中文询问大型语言模型有何不同"></a>用英语和中文询问大型语言模型有何不同</h3><ul>
<li>From Gork3 (2025-03-03)</li>
<li>研究表明，使用英语或中文询问大型语言模型（LLM）的主要区别在于语言处理方式和模型性能可能因语言而异。</li>
<li>证据倾向于认为，英语因其丰富的训练数据，通常在某些任务上表现优于中文，但这取决于具体模型和任务。</li>
<li>令人意外的是，中文的字符处理方式（如基于字符的标记化）与英语的单词或子词标记化不同，这可能会影响模型的理解和生成能力。</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>《大模型应用开发极简入门：基于 GPT-4 和 ChatGPT》</li>
<li>《大语言模型》- LLMBook - <a target="_blank" rel="noopener" href="https://github.com/RUCAIBox/LLMSurvey">https://github.com/RUCAIBox/LLMSurvey</a></li>
<li>《大规模语言模型：从理论到实践》- LLM-TAP</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/12/03/20241203-ren-gong-zhi-neng-xiang-guan-ji-zhu-jian-yao-zong-jie-ji-lu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/12/03/20241203-ren-gong-zhi-neng-xiang-guan-ji-zhu-jian-yao-zong-jie-ji-lu/" itemprop="url">人工智能相关技术简要总结记录</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-12-03T21:37:02+08:00">
                2024-12-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>持续补充…</p>
</blockquote>
</blockquote>
<p><img src="/2024/12/03/20241203-ren-gong-zhi-neng-xiang-guan-ji-zhu-jian-yao-zong-jie-ji-lu/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.jpg"></p>
<h2 id="人工智能的三种形态"><a href="#人工智能的三种形态" class="headerlink" title="人工智能的三种形态"></a>人工智能的三种形态</h2><ul>
<li>来自：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/64467701">人工智能是什么？——人工智能图谱</a></li>
<li>弱人工智能：弱人工智能 (Artificial Narrow Intelligence, ANI) 是擅长与单个方面的人工智能，比如有能战胜象棋世界冠军的人工智能，但是它只会下象棋，你要问它怎样更好地在硬盘上存储数据，它就不知道怎么回答你了；</li>
<li>强人工智能：强人工智能 (Artificial General Intelligence, AGI) ，是人类级别的人工智能，强人工智能是指在各方面都能和人类比肩的人工智能，人类能干的脑力活它都能干。创造强人工智能比创造弱人工智能要难得多，我们现在还做不到。Linda Gottfredson教授把智能定义为“一种宽泛的心理能力，能够进行思考、计划、解决问题、抽象思维、理解复杂理念，快速学习和从经验中学习等操作”。强人工智能在进行这些操作时，应该和人类一样得心应手；</li>
<li>超人工智能：超人工智能 (Artificial Super Intelligence, ASI)，牛津哲学家，知名人工智能思想家Nick Bostrom把超级智能定义为“在几乎所有领域都比最聪明的人类大脑都聪明很多，包括科技创新、通识和社交技能”。超人工智能可以是各方面都比人类强一点，也可以是各方面都比人类强万亿倍，超人工智能也正是为什么人工智能这个话题这么火热的缘故，同样也是为什么永生和灭绝这两个词会在本文中多次出现。</li>
</ul>
<h2 id="关于大模型的扩展思考"><a href="#关于大模型的扩展思考" class="headerlink" title="关于大模型的扩展思考"></a>关于大模型的扩展思考</h2><ul>
<li>目前的AI是一个无限能量和记忆的辅助工具，但跟人有差别，比如犯错时难以追责，毕竟人需要信誉等等….</li>
<li>cursor、 Windsurf</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/64467701">人工智能是什么？——人工智能图谱</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/12/02/20241202-yi-ge-wu-zhong-xin-jie-dian-de-ju-yu-wang-tong-xin-gong-ju/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/12/02/20241202-yi-ge-wu-zhong-xin-jie-dian-de-ju-yu-wang-tong-xin-gong-ju/" itemprop="url">一个无中心节点的局域网通信工具</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-12-02T14:54:49+08:00">
                2024-12-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h2><ol>
<li>初始阶段：UDP广播发现</li>
<li>建立连接后：切换到TCP进行可靠通信（也可以使用 UDP）（增加接收完成确认机制）</li>
</ol>
<h2 id="AI生成的需求文档"><a href="#AI生成的需求文档" class="headerlink" title="AI生成的需求文档"></a>AI生成的需求文档</h2><p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h2 id="局域网去中心化点对点通信工具-iOS-应用需求文档"><a href="#局域网去中心化点对点通信工具-iOS-应用需求文档" class="headerlink" title="局域网去中心化点对点通信工具 iOS 应用需求文档"></a>局域网去中心化点对点通信工具 iOS 应用需求文档</h2><h3 id="项目概述"><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h3><p>开发一款完全去中心化的局域网点对点即时通信应用，无需中心服务器，通过UDP广播实现设备发现和通信。</p>
<h3 id="核心设计理念"><a href="#核心设计理念" class="headerlink" title="核心设计理念"></a>核心设计理念</h3><ul>
<li>完全去中心化</li>
<li>基于局域网的点对点直接通信</li>
<li>无需任何中心服务器</li>
<li>设备间直接建立连接</li>
</ul>
<h3 id="网络通信技术架构"><a href="#网络通信技术架构" class="headerlink" title="网络通信技术架构"></a>网络通信技术架构</h3><h4 id="1-设备发现机制"><a href="#1-设备发现机制" class="headerlink" title="1. 设备发现机制"></a>1. 设备发现机制</h4><h5 id="1-1-UDP-广播发现"><a href="#1-1-UDP-广播发现" class="headerlink" title="1.1 UDP 广播发现"></a>1.1 UDP 广播发现</h5><ul>
<li>使用UDP广播进行设备发现</li>
<li>广播地址：255.255.255.255</li>
<li>广播端口：固定端口（如 48689）</li>
<li>发现报文结构：<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;deviceId&quot;</span><span class="punctuation">:</span> <span class="string">&quot;唯一设备标识&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;nickname&quot;</span><span class="punctuation">:</span> <span class="string">&quot;用户昵称&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="string">&quot;时间戳&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;publicKey&quot;</span><span class="punctuation">:</span> <span class="string">&quot;公钥信息&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;capabilities&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;支持的功能列表&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="2-连接建立协议"><a href="#2-连接建立协议" class="headerlink" title="2. 连接建立协议"></a>2. 连接建立协议</h4><ul>
<li>发现阶段：UDP 广播</li>
<li>连接阶段：切换到 TCP</li>
<li>通信协议：自定义应用层协议</li>
<li>连接建立流程：<ol>
<li>UDP 广播发现</li>
<li>交换公钥</li>
<li>建立加密 TCP 通道</li>
</ol>
</li>
</ul>
<h4 id="3-通信模型"><a href="#3-通信模型" class="headerlink" title="3. 通信模型"></a>3. 通信模型</h4><ul>
<li>无中心节点</li>
<li>每个设备既是客户端又是服务端</li>
<li>直接点对点通信</li>
<li>消息路由完全去中心化</li>
</ul>
<h3 id="功能需求详细描述"><a href="#功能需求详细描述" class="headerlink" title="功能需求详细描述"></a>功能需求详细描述</h3><h4 id="1-网络发现与连接"><a href="#1-网络发现与连接" class="headerlink" title="1. 网络发现与连接"></a>1. 网络发现与连接</h4><ul>
<li>持续监听 UDP 广播</li>
<li>自动发现局域网内设备</li>
<li>支持手动&#x2F;自动添加好友</li>
<li>好友关系本地持久化</li>
</ul>
<h4 id="2-消息通信机制"><a href="#2-消息通信机制" class="headerlink" title="2. 消息通信机制"></a>2. 消息通信机制</h4><ul>
<li>UDP 广播发现</li>
<li>TCP 建立稳定通道</li>
<li>消息队列管理</li>
<li>离线消息处理</li>
</ul>
<h4 id="3-安全性设计"><a href="#3-安全性设计" class="headerlink" title="3. 安全性设计"></a>3. 安全性设计</h4><ul>
<li>设备间公钥交换</li>
<li>端到端消息加密</li>
<li>防重放攻击</li>
<li>消息签名验证</li>
</ul>
<h3 id="技术实现细节"><a href="#技术实现细节" class="headerlink" title="技术实现细节"></a>技术实现细节</h3><h4 id="网络通信协议"><a href="#网络通信协议" class="headerlink" title="网络通信协议"></a>网络通信协议</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant A as 设备A</span><br><span class="line">    participant B as 设备B</span><br><span class="line">    </span><br><span class="line">    A-&gt;&gt;B: UDP广播：发现请求</span><br><span class="line">    B--&gt;&gt;A: UDP广播：发现响应</span><br><span class="line">    A-&gt;&gt;B: TCP建立连接</span><br><span class="line">    A--&gt;&gt;B: 交换公钥</span><br><span class="line">    A-&gt;&gt;B: 加密消息传输</span><br></pre></td></tr></table></figure>

<h4 id="消息队列流程"><a href="#消息队列流程" class="headerlink" title="消息队列流程"></a>消息队列流程</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">stateDiagram-v2</span><br><span class="line">    [*] --&gt; 消息生成</span><br><span class="line">    消息生成 --&gt; 本地队列</span><br><span class="line">    本地队列 --&gt; 检测网络</span><br><span class="line">    检测网络 --&gt; 同一局域网: 直接发送</span><br><span class="line">    检测网络 --&gt; 离线: 保持队列</span><br><span class="line">    同一局域网 --&gt; 消息发送</span><br><span class="line">    消息发送 --&gt; [*]</span><br></pre></td></tr></table></figure>

<h3 id="系统架构图"><a href="#系统架构图" class="headerlink" title="系统架构图"></a>系统架构图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[UDP广播发现] --&gt; B[设备信息交换]</span><br><span class="line">    B --&gt; C[TCP安全通道]</span><br><span class="line">    C --&gt; D[端到端加密通信]</span><br><span class="line">    D --&gt; E[本地消息队列]</span><br><span class="line">    E --&gt; F[离线/在线消息管理]</span><br></pre></td></tr></table></figure>

<h3 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h3><ul>
<li>语言：Swift</li>
<li>网络框架：Network.framework</li>
<li>加密：CryptoKit</li>
<li>存储：CoreData</li>
<li>UI：SwiftUI</li>
</ul>
<h3 id="关键技术挑战"><a href="#关键技术挑战" class="headerlink" title="关键技术挑战"></a>关键技术挑战</h3><ol>
<li>跨设备一致性</li>
<li>网络发现可靠性</li>
<li>安全性保证</li>
<li>低功耗设计</li>
</ol>
<h3 id="性能目标"><a href="#性能目标" class="headerlink" title="性能目标"></a>性能目标</h3><ul>
<li>设备发现时间 &lt; 3秒</li>
<li>消息延迟 &lt; 1秒</li>
<li>电池资源占用 &lt; 5%</li>
<li>网络资源占用最小化</li>
</ul>
<h3 id="安全性要求"><a href="#安全性要求" class="headerlink" title="安全性要求"></a>安全性要求</h3><ul>
<li>端到端加密</li>
<li>防重放攻击</li>
<li>设备指纹验证</li>
<li>消息签名机制</li>
</ul>
<h3 id="隐私保护"><a href="#隐私保护" class="headerlink" title="隐私保护"></a>隐私保护</h3><ul>
<li>无中心服务器</li>
<li>本地数据完全加密</li>
<li>用户完全控制通信</li>
<li>不依赖任何第三方服务</li>
</ul>
<h3 id="开发交付物"><a href="#开发交付物" class="headerlink" title="开发交付物"></a>开发交付物</h3><ol>
<li>完整 Xcode 工程</li>
<li>详细技术文档</li>
<li>安全性测试报告</li>
<li>性能基准测试结果</li>
</ol>
<h3 id="版本迭代计划"><a href="#版本迭代计划" class="headerlink" title="版本迭代计划"></a>版本迭代计划</h3><ul>
<li>v1.0：基础局域网通信</li>
<li>v1.1：增强安全性</li>
<li>v1.2：优化性能</li>
<li>v2.0：跨平台支持</li>
</ul>
<h3 id="开发注意事项"><a href="#开发注意事项" class="headerlink" title="开发注意事项"></a>开发注意事项</h3><ul>
<li>严格遵循 Apple 安全guidelines</li>
<li>代码安全审查</li>
<li>最小权限原则</li>
<li>用户体验优先</li>
</ul>
<p>&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h3 id="Rust简易版本"><a href="#Rust简易版本" class="headerlink" title="Rust简易版本"></a>Rust简易版本</h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/Kingson4Wu/mesh-talk">https://github.com/Kingson4Wu/mesh-talk</a> （使用windsurf生成）</li>
</ul>
<p>&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><blockquote>
<blockquote>
<p>发现已经有了相关实现，非常棒！</p>
</blockquote>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/localsend/localsend">https://github.com/localsend/localsend</a> 局域网文件传输，广播发现，可以简易发消息</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/11/29/20241129-ai-yi-jing-ru-ci-qiang-da-liao-bang-wo-xie-wan-suo-you-dai-ma/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/11/29/20241129-ai-yi-jing-ru-ci-qiang-da-liao-bang-wo-xie-wan-suo-you-dai-ma/" itemprop="url">AI已经如此强大了，帮我写完所有代码</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-11-29T23:34:32+08:00">
                2024-11-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li><p>今天使用Windsurf帮我写一个小工具。</p>
</li>
<li><p>全程没有写过一行代码和一个字，全靠一直给AI提需求，配合授权运行纠正；有时感觉偏离正确的道路时，结合git命令回退代码，再重新提需求。就这样一直重复，就帮我把这个小工具写好了，包括使用文档，构建脚本等，通通都包了。</p>
</li>
<li><p>自从两年前第一次用ChatGPT时一下子服气了，这次直接帮我把整个项目搞定了，不得不再次拜服。客观来讲，如果是我一个人来做，由于对Rust不熟练等原因，估计得一周，而且还会很费劲，然而它半天就搞定了，并且我做得不一定比它好。</p>
</li>
<li><p>使用AI帮助编程，就像一个架构师，有一群AI小弟帮你做事。</p>
</li>
<li><p>想要把事情快速做好，前提是你是一个有品位的架构师，另外即使你很多不懂，你也是有很大可能通过你的AI小弟变成一个优秀的架构师。所以学习方法，总结，知识体系很重要，拥抱变化。</p>
</li>
<li><p>AI为什么这么强大，对里面的细节是越来越好奇了。</p>
</li>
<li><p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/Kingson4Wu/magic-converter">https://github.com/Kingson4Wu/magic-converter</a></p>
</li>
</ul>
<p><img src="/2024/11/29/20241129-ai-yi-jing-ru-ci-qiang-da-liao-bang-wo-xie-wan-suo-you-dai-ma/Windsurf.jpeg"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/11/21/20241121-dui-java-go-rust-zhi-jian-de-jian-dan-dui-bi-he-zong-jie/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/11/21/20241121-dui-java-go-rust-zhi-jian-de-jian-dan-dui-bi-he-zong-jie/" itemprop="url">对Java、Go、Rust之间的简单对比和总结</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-11-21T16:42:35+08:00">
                2024-11-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>工作中接触过多种编程语言，主要是 Java 和 Go，最近因个人兴趣简单学习了 Rust，在这里简单记录总结一下</p>
</blockquote>
</blockquote>
<h2 id="编程语言的GC问题"><a href="#编程语言的GC问题" class="headerlink" title="编程语言的GC问题"></a>编程语言的GC问题</h2><ul>
<li><p>一般来说，程序需要管理好运行中使用的内存空间，比如传统的C和C++则要求开发者手动管理内存，但这往往导致内存泄漏和安全隐患；而垃圾回收（GC）语言，比如Java和Go在运行时自动回收内存，但存在”停顿”（STW）问题；而Rust则采用独特的所有权系统，通过编译期严格的规则检查，在不增加运行时开销的情况下实现内存安全。</p>
</li>
<li><p>GC语言，调用栈和内存一直在变化，不STW无法算出没引用的变量（可回收的内存）； 而Rust通过作用域的规则判断自动回收。另外无GC不代表不在堆分配，是代表没有STW的垃圾回收机制。</p>
</li>
<li><p>Rust引入了”所有权”概念，每个值都有且仅有一个所有者，当所有者离开作用域时，值会被自动释放。这种方式不仅避免了运行时垃圾回收的性能开销，还能在编译阶段就发现潜在的内存使用问题，有效防止了常见的内存安全缺陷。</p>
</li>
</ul>
<h2 id="设计哲学"><a href="#设计哲学" class="headerlink" title="设计哲学"></a>设计哲学</h2><ul>
<li>Java 作为一门成熟的编程语言，其设计理念更多体现在企业级应用和跨平台兼容性上。当然个人认为由此历史包袱也比较重。</li>
<li>相比之下，Go 和 Rust 作为更现代的语言，也各有侧重。Go 语言强调简洁、高效和并发性，而 Rust 则更加注重内存安全、零成本抽象和并发安全性。</li>
</ul>
<h2 id="交叉编译"><a href="#交叉编译" class="headerlink" title="交叉编译"></a>交叉编译</h2><ul>
<li>Go 和 Rust 支持各自编译成对应二进制实现跨平台（可以使用交叉编译）；而Java则编译成统一的字节码，依赖平台安装的运行时（JVM）来运行服务（也可以Graalvm直接编译成可执行二进制）</li>
</ul>
<h2 id="工具链"><a href="#工具链" class="headerlink" title="工具链"></a>工具链</h2><ul>
<li>相关工具链完善问题，比如Java性能依赖外部开发，比如arthas，asyncProfiler等；而Go自带pprof，单元测试工具等（Rust 也有一些相应的配套工具）；Java历史包袱重，不够现代化</li>
</ul>
<h2 id="热加载"><a href="#热加载" class="headerlink" title="热加载"></a>热加载</h2><ul>
<li>Java的标准HotSwap机制（基于Instrumentation）有限制，不能新增&#x2F;删除方法和类，只能修改方法体；但JRebel等商业工具通过更复杂的字节码重写技术突破了这些限制，而Spring DevTools 提供了更轻量的重启机制。</li>
<li>Go官方不直接支持热加载；第三方工具如 gin-reload、air 实现热重载（通过监控文件变化，重新编译和启动进程，相对简单直接，但不是语言级特性）</li>
<li>Rust同样没有官方直接的热加载机制；比如cargo-watch 可以监听文件变化并重新编译（由于所有权系统，热加载实现相对复杂）</li>
</ul>
<h2 id="远程Debug"><a href="#远程Debug" class="headerlink" title="远程Debug"></a>远程Debug</h2><ul>
<li>Java远程调试的原理是两个VM之间通过debug协议进行通信，然后以达到远程调试的目的。两者之间可以通过socket进行通信。</li>
<li>Go原生支持远程调试，使用 dlv（Delve）调试器（基于 gRPC 协议通信）</li>
<li>Rust支持远程调试，但配置相对较复杂（主要使用 rust-gdb 和 rust-lldb）</li>
</ul>
<h2 id="依赖管理-以及-冲突解决"><a href="#依赖管理-以及-冲突解决" class="headerlink" title="依赖管理 以及 冲突解决"></a>依赖管理 以及 冲突解决</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><ul>
<li>Java 的依赖管理历史上存在诸多挑战。在早期，Java 并没有原生的依赖版本管理机制，开发者需要依赖 Maven 或 Gradle 等外部构建工具来处理项目依赖。更为关键的是，Java 的依赖冲突解析是基于具体类而非整个 JAR 包，这导致了潜在的版本兼容性和类加载问题。为了彻底解决这一痛点，Java 9 引入了模块化系统（Java Platform Module System, JPMS），提供了更精细和可靠的依赖管理和隔离机制，从根本上改善了包依赖和版本控制的复杂性。这一设计不仅简化了大型项目的依赖管理，还增强了 Java 运行时的安全性和可预测性。</li>
</ul>
<h3 id="关于Java的类重复问题"><a href="#关于Java的类重复问题" class="headerlink" title="关于Java的类重复问题"></a>关于Java的类重复问题</h3><ul>
<li><p>Java 依赖引入的时 Jar 包，使用时则是含路径信息的类名</p>
</li>
<li><p>Go则没有这个问题，因为Go的依赖的引入需要指定模块的全路径，使用时也是使用全路径或别名</p>
</li>
<li><p>Rust和 Go 类似，依赖的引入也需要指定模块的全路径。但不同包有相应的依赖文件，利用这个使相同依赖的不兼容版本共存而没有冲突问题</p>
</li>
<li><p>Java9之前（模块系统之前）- 只能减少，不能从根本上解决</p>
<ol>
<li>协议文件生成的代码，重复拷贝和引入，导致类重复冲突<ul>
<li>使用RPC协议，idl文件生成java文件，容易因为多处拷贝（比如一些业务通用库也使用到），导致类重复问题，这样在运行时可能会造成影响</li>
<li>这时最好打包的时候，不要将协议文件打进jar包中，让业务使用方自行生成代码</li>
<li>通过扫描jar包路径类的方式，可以协助检查这种问题 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">classPath</span> <span class="operator">=</span> Optional.ofNullable(thriftClass.getProtectionDomain())</span><br><span class="line">    .map(ProtectionDomain::getCodeSource)</span><br><span class="line">    .map(CodeSource::getLocation)</span><br><span class="line">    .map(URL::getPath).orElse(<span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!classPath.contains(jarFileName)) &#123;</span><br><span class="line">    System.err.println(String.format(<span class="string">&quot;%s thrift class may be duplicated&quot;</span>, thriftClass.getName()));</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">DuplicatedThriftFileException</span>(String.format(<span class="string">&quot;%s thrift class may be duplicated&quot;</span>, thriftClass.getName()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>通过maven-enforcer插件解决类冲突<ul>
<li>本质上就是解压所有依赖的 jar 包，判断是否存在重复的类文件，性能较低</li>
</ul>
</li>
</ol>
</li>
<li><p>JVM中Jar包的加载顺序</p>
<ul>
<li>由classpath参数指定的顺序决定。这种加载机制可能导致’类版本地狱’问题——不同jar包中的同名类，最终使用哪个版本取决于加载顺序，这在复杂项目中很难追踪和调试。</li>
<li>如果classpath未明确指明，则由文件系统决定的（readdir函数）<ul>
<li>readdir并不保证读取后的文件顺序，在不同的操作系统上可能有不同的顺序。</li>
</ul>
</li>
<li>如何找出重复类<ul>
<li><code>find . -name &quot;*.jar&quot; -exec sh -c  &#39;jar -tf &#123;&#125;|grep -H --label &#123;&#125; &#39;JspRuntimeContext &#39;&#39;</code> </li>
<li><code>-verbose:class</code> 查看加载顺序</li>
</ul>
</li>
</ul>
</li>
<li><p>Java9及以上（使用模块系统）</p>
</li>
</ul>
<h3 id="Go-VS-Rust-库冲突"><a href="#Go-VS-Rust-库冲突" class="headerlink" title="Go VS Rust 库冲突"></a>Go VS Rust 库冲突</h3><ul>
<li><p>当项目间接依赖同一个库的不同版本时，Rust 和 Go 在处理上有什么异同</p>
</li>
<li><p>Go 的处理方式：</p>
  <pre>
  依赖关系示例：
  my-project
  ├── A 
  │   └── pkg v1.1.0
  └── B
      └── pkg v1.2.3
  </pre>
<ul>
<li>Go 会：<ul>
<li>自动选择最低满足要求的版本（v1.2.3）</li>
<li>所有代码路径都使用这个版本</li>
<li>使用 MVS (Minimal Version Selection) 算法</li>
<li>在 go.mod 中记录最终版本  <pre>
  // go.mod
  module my-project

  require (
      A v1.0.0
      B v1.0.0
      pkg v1.2.3 // 间接依赖，统一使用最高版本
  )</pre></li>
</ul>
<p>  </p>
</li>
</ul>
</li>
<li><p>Rust 的处理方式：</p>
  <pre>
  依赖关系示例：
  my-project
  ├── A 
  │   └── pkg 1.1.0
  └── B
      └── pkg 1.2.3
  </pre>    
<ul>
<li>Rust 会：<ul>
<li>允许两个版本同时存在</li>
<li>分别编译两个版本的代码</li>
<li>在最终二进制中包含两个版本  <pre>
  Cargo.toml
  [dependencies]
  A = "1.0.0"  # 依赖 pkg 1.1.0
  B = "1.0.0"  # 依赖 pkg 1.2.3
  </pre></li>
</ul>
</li>
</ul>
</li>
<li><p>主要区别：</p>
<ul>
<li>Go: 强制统一版本，避免重复</li>
<li>Rust: 允许多版本共存，保证兼容性</li>
<li>这种设计反映了两种不同的理念：<ul>
<li>Go: 简单性优先，避免版本冲突</li>
<li>Rust: 灵活性优先，保证正确性</li>
</ul>
</li>
</ul>
</li>
<li><p>针对依赖同一个库的不同版本的情况：如果版本相同或兼容，Cargo会选择满足要求的当前最高版本；如果版本不兼容，Cargo允许在项目中同时使用这些不兼容的版本，可以通过别名来区分使用。</p>
</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>个人看法总结：Rust能做到同时使用同一个库的不同版本，是因为每个项目都有独立的依赖库配置以及引入别名机制，关键的是打包能根据这些信息直接生成二进制。而java是生成 字节码文件，并打包时丢失这方面的信息，虚拟机可能目前由于历史和后续兼容等原因也暂不支持。Go 则是选择简单性优先，避免版本冲突。</li>
<li>Rust可以运行同一库不同版本；Go和Java（模块化后）都不允许同一库不同版本；Go通过路径能确定库的唯一性；Java（未模块化）存在不同库类冲突的可能。</li>
</ul>
<h2 id="封装私有性"><a href="#封装私有性" class="headerlink" title="封装私有性"></a>封装私有性</h2><ul>
<li><p>Java通过访问修饰符（public、private、protected）控制（反射可以破坏私有性；运行时检查私有访问）</p>
</li>
<li><p>Java 9 模块化（JPMS）后，封装私有性发生了显著变化</p>
<ol>
<li>更严格的可见性控制（引入模块（module）概念；模块间显式依赖声明）</li>
<li>可见性新规则（使用 exports 关键字定义可导出包；opens 关键字控制运行时反射访问）</li>
<li>相比传统机制（编译期就能检查模块间依赖；避免了类路径的”打开式”依赖）</li>
<li>实际影响（需要在 module-info.java 显式声明依赖；原有代码需要适配模块系统；更接近 Rust 的模块化设计理念）</li>
</ol>
</li>
<li><p>Go首字母大小写决定可见性（小写标识符包内可见，大写标识符全局可见；没有私有修饰符，依赖命名约定）</p>
</li>
<li><p>Rust模块系统提供精细的可见性控制（默认私有；pub 关键字定义可见性；可以精确控制字段、方法的可见范围；编译期检查，性能无额外开销）</p>
</li>
<li><p>Rust 的封装性设计最为现代和严格，Go 相对最为简单，Java 则相对传统，Java9 之后更加严格，跟 Rust 类似，但由于历史包袱，又显得比较笨重。</p>
</li>
</ul>
<h2 id="并发和多线程"><a href="#并发和多线程" class="headerlink" title="并发和多线程"></a>并发和多线程</h2><ul>
<li>并发线程，Rust为了减少运行时，默认使用线程模型的并发。</li>
<li>Go是绿色线程（协程）。</li>
<li>Java一般也是线程模型，当然也有一些协程库（其他 JVM 语言比如 kotlin 就自带协程）<ul>
<li>Java 21 开始，日常用的虚拟线程已经是 Project Loom 正式交付的成果</li>
</ul>
</li>
</ul>
<h3 id="主线程结束进程是否停止"><a href="#主线程结束进程是否停止" class="headerlink" title="主线程结束进程是否停止"></a>主线程结束进程是否停止</h3><ul>
<li>主线程退出：Java中，主线程结束后，如果还有非守护线程在运行，进程不会退出；而Rust和Go中主线程结束即意味着进程结束，不管其他线程&#x2F;协程状态。</li>
</ul>
<h3 id="非主线程异常进程是否停止"><a href="#非主线程异常进程是否停止" class="headerlink" title="非主线程异常进程是否停止"></a>非主线程异常进程是否停止</h3><ul>
<li>Rust 中子线程 panic 的行为与 Java 和 Go 都不同：<ul>
<li><strong>Java</strong>: 子线程未捕获异常会导致该线程终止，但不影响其他线程和进程</li>
<li><strong>Rust</strong>: 子线程 panic 后，当主线程尝试 join 该线程时会收到 panic。如果不处理（unwrap或?），会导致主线程也panic，进而导致进程退出。Rust提供了灵活的处理机制：<ul>
<li>使用 <code>handle.join()</code> 的 Result 来捕获子线程的 panic</li>
<li>使用 <code>std::panic::catch_unwind()</code> 在子线程内部捕获 panic</li>
<li>使用 <code>std::panic::set_hook()</code> 自定义全局 panic 处理</li>
</ul>
</li>
<li><strong>Go</strong>: goroutine panic 会立即导致整个程序崩溃（除非被 recover 捕获）</li>
</ul>
</li>
<li>总结：Go 最严格（默认崩溃），Java 最宽松（只影响当前线程），Rust 居中（通过 join 传播，但可灵活控制），Rust显式错误处理：强制你意识到子线程可能出错</li>
</ul>
<h2 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h2><ul>
<li>类定义：java Python js 只有class的概念 go 只有struct概念 c++都有 区别是struct可以在栈中定义</li>
<li>面向对象：Java中的单继承其实简化了继承的使用方式， Go和Rust，算是彻底抛弃了使用类继承的方式，选择了接口继承。</li>
<li>Java设计之初就是面向对象，加上由于后续历史兼容等原因，代码看起来比较臃肿（类设计）；Rust博采众长，有各自语法糖；Go追求语法简单，表达力不足，会存在一定丑陋的代码（比如没有set， contains，streams等）</li>
</ul>
<h2 id="接口设计和多态"><a href="#接口设计和多态" class="headerlink" title="接口设计和多态"></a>接口设计和多态</h2><ul>
<li>Rust中的 trait 和 Java 以及 Go 的接口：本质上它们都是在解决同一个问题：如何定义和实现抽象行为。主要区别在于语言设计理念导致的一些具体细节</li>
</ul>
<h2 id="空值问题"><a href="#空值问题" class="headerlink" title="空值问题"></a>空值问题</h2><ul>
<li>Go的类型系统一个缺憾是，对于一个类型，它的值是零值，还是不存在值，混淆不清。Java 之前也存在类似的问题，但是后来增加了基础类型的包装类型（例如对于int的Integer，double的Double），Go是否也可以参考一下？或者增加一个Option(al)类型，对这些基础类型再包装一下（基于泛型），当然还有其他更优方案那就更好了<ul>
<li>JSON包新提案：用“omitzero”解决编码中的空值困局:<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Lw_l_AELo8RKiLzVdS0H-Q">https://mp.weixin.qq.com/s/Lw_l_AELo8RKiLzVdS0H-Q</a></li>
</ul>
</li>
</ul>
<h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><ul>
<li>异常：Java分为Error和Exception，异常又分为运行时异常和检查性异常。抛出与捕获。<br>这点和go是类似的，go也区分简单返回的错误error和抛出的恐慌panic，而 Rust 也是差不多这么设计。</li>
</ul>
<h2 id="链式调用"><a href="#链式调用" class="headerlink" title="链式调用"></a>链式调用</h2><ul>
<li><p>链式调用：Rust和Java支持函数式链式编程，类似stream；Go不支持，要自己实现</p>
</li>
<li><p>Rust 的迭代器和 Java 的 Stream API 确实很像，都支持链式调用和函数式编程风格。</p>
</li>
<li><p>Go 的设计理念是追求简单直接，所以：</p>
<ul>
<li>没有内置的链式调用语法</li>
<li>更倾向于使用显式的 for range 循环</li>
<li>性能更可预测（没有懒加载特性）</li>
</ul>
</li>
<li><p>这反映了不同语言的设计理念：</p>
<ul>
<li>Rust&#x2F;Java：提供丰富的抽象和函数式编程特性</li>
<li>Go：保持简单，倾向于显式的命令式编程</li>
</ul>
</li>
</ul>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul>
<li>枚举：Java和Rust支持，Go不支持；Rust可以支持同个枚举内包含不同类型</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/UG-6UuqDiLX15dEZrGGrRA">Gopher的Rust第一课：Rust的依赖管理</a></li>
</ul>
<h2 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h2><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/cJrQJelrFHVzES2iUm76HQ">Project Loom能否撼动Go和Rust的地位？深入分析三种并发模型</a></li>
</ul>
<p>&#x3D;&#x3D;&#x3D;</p>
<h2 id="其他扩展"><a href="#其他扩展" class="headerlink" title="其他扩展"></a>其他扩展</h2><h3 id="从-JPMS-到-GraalVM：为什么-Java-很难做到真正的-Class-Level-Dead-Code-Elimination"><a href="#从-JPMS-到-GraalVM：为什么-Java-很难做到真正的-Class-Level-Dead-Code-Elimination" class="headerlink" title="从 JPMS 到 GraalVM：为什么 Java 很难做到真正的 Class-Level Dead Code Elimination"></a>从 JPMS 到 GraalVM：为什么 Java 很难做到真正的 Class-Level Dead Code Elimination</h3><ul>
<li>JDK 9 的 JPMS 只能在模块级别裁剪运行时体积，无法做到 class-level 的未用代码消除，这并非模块系统能力不足，而是 Java 语言与 JVM 长期采用开放世界（open-world）运行模型，允许反射、SPI、动态类加载等行为，导致类的可达性无法在编译期可靠判定。</li>
<li>GraalVM 在 native-image 模式下 默认会做 class-level 的 Dead Code Elimination ！</li>
<li>GraalVM native-image 通过引入封闭世界（closed-world）假设和全程序分析，技术上具备 class-level dead code elimination 的能力，但这一能力在通用 Java 应用中会被大量动态特性显著削弱，实际效果高度依赖显式配置与框架配合。</li>
<li>以 Spring 为代表的传统 Java 框架，由于高度依赖运行期反射和类路径扫描，原生运行模型与 native-image 天然不兼容；当前所谓的“兼容”是通过 AOT 编译将运行期行为前移到构建期、限制动态能力后实现的，实质上是一种新的、静态化的运行形态。</li>
<li>相比之下，Go 从语言设计阶段即采用封闭世界与静态链接模型，并对反射能力进行严格约束，使编译器能够默认、安全地执行函数级乃至更细粒度的未用代码消除，这也是其可执行文件天然更小、构建模型更简单的根本原因。</li>
</ul>
<h3 id="Spring-x2F-Quarkus-x2F-Micronaut-——-极简本质对比"><a href="#Spring-x2F-Quarkus-x2F-Micronaut-——-极简本质对比" class="headerlink" title="Spring &#x2F; Quarkus &#x2F; Micronaut —— 极简本质对比"></a><strong>Spring &#x2F; Quarkus &#x2F; Micronaut —— 极简本质对比</strong></h3><ul>
<li><p><strong>Spring</strong><br>运行期框架，动态性最强、生态最全、容错最高；代价是隐式行为多、可预测性较弱。适合复杂业务与快速交付。</p>
</li>
<li><p><strong>Quarkus</strong><br>构建期框架，在 build 阶段冻结决策，运行期更轻更快；在灵活性与确定性之间做工程折中。适合云原生与规模化部署。</p>
</li>
<li><p><strong>Micronaut</strong><br>编译期框架，几乎不依赖反射，行为在编译期已确定；运行模型最简单、最可预测，但约束最强。适合基础设施与性能敏感服务。</p>
</li>
</ul>
<p><strong>一句话总结</strong>：</p>
<blockquote>
<p>Spring 重灵活，Quarkus 重构建期确定性，Micronaut 重编译期确定性。</p>
</blockquote>
<h3 id="Java-Native-Image-选择简要总结"><a href="#Java-Native-Image-选择简要总结" class="headerlink" title="Java Native Image 选择简要总结"></a><strong>Java Native Image 选择简要总结</strong></h3><ul>
<li><p><strong>首选：Quarkus</strong><br>构建期冻结行为，native-image 一等公民，生态与工具链最成熟，整体成本最低。</p>
</li>
<li><p><strong>次选：Micronaut</strong><br>编译期生成代码、极少反射，native 友好但生态较小，适合轻量服务和工具。</p>
</li>
<li><p><strong>不推荐首选：Spring Boot</strong><br>反射与动态机制重，native 成本高，仅适合已有 Spring 体系强依赖的场景。</p>
</li>
</ul>
<p><strong>一句话结论：</strong></p>
<blockquote>
<p>用 native-image，优先选 <strong>Quarkus</strong>，其次 <strong>Micronaut</strong>，最后才考虑 <strong>Spring</strong>。</p>
</blockquote>
<h3 id="JPMS-与-Go-x2F-Rust-的本质差异"><a href="#JPMS-与-Go-x2F-Rust-的本质差异" class="headerlink" title="JPMS 与 Go &#x2F; Rust 的本质差异"></a>JPMS 与 Go &#x2F; Rust 的本质差异</h3><p><strong>核心结论</strong><br>JPMS 并未改变 Java 以“类名”为核心的链接模型，只是通过更严格的规则提前暴露问题；Go 与 Rust 从语言设计层面就避免了这些问题。</p>
<p><strong>关键要点</strong></p>
<ul>
<li><strong>版本冲突</strong>：JPMS 不具备版本感知能力，多版本不兼容仍在运行期以 <code>NoSuchMethodError</code> 暴露；模块系统 ≠ 依赖管理系统。</li>
<li><strong>Split Package</strong>：JPMS 完全禁止（无论是否 <code>exports</code>），只是编译期与运行期检测时机不同。</li>
<li><strong>同名类选择</strong>：JPMS 不支持“指定模块加载同名类”，只能通过禁止歧义来兜底。</li>
</ul>
<p><strong>根因</strong></p>
<ul>
<li>Java 的历史前提：链接单元是 <strong>binary class name</strong>，编译与运行解耦，多版本从未进入语言语义 → 只能靠限制与 fail fast。</li>
</ul>
<p><strong>对比</strong></p>
<ul>
<li><strong>Go</strong>：命名空间是 import path，编译即链接，问题在语义层面被消解；同一 binary 内通常单版本（或靠路径区分）。</li>
<li><strong>Rust</strong>：crate 是最小链接单元，Cargo 允许同一 crate 多版本共存，类型系统层面完全隔离，更严格也更彻底。</li>
</ul>
<p><strong>一句话总结</strong><br>Java（JPMS）在修补历史；Go 用路径规避问题；Rust 用类型系统根本解决。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/10/25/20241025-ren-zhi-jue-xing-bi-ji/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/10/25/20241025-ren-zhi-jue-xing-bi-ji/" itemprop="url">《认知觉醒》-笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-10-25T14:43:45+08:00">
                2024-10-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="/2024/10/25/20241025-ren-zhi-jue-xing-bi-ji/%E8%AE%A4%E7%9F%A5%E8%A7%89%E9%86%92.jpg"></p>
<hr>
<ul>
<li>无论在大脑构造、潜意识、元认知、刻意练习等基本概念的解读上，还是在自控力、专注力、行动力、学习力、情绪力等具体能力的使用策略（包括早起、冥想、阅读、写作、运动等必备习惯的养成）上，都有相对独到的原理呈现和具体可行的方法提供。</li>
</ul>
<h3 id="每日反思"><a href="#每日反思" class="headerlink" title="每日反思"></a>每日反思</h3><ul>
<li>记录时间对我最大的意义，就是让自己能够觉知到时间的存在，让自己过得更加踏实。</li>
<li>每天只需花一点点时间，对当天最触动自己的事情或感悟进行复盘。</li>
<li>通过反思，我越来越多地觉知到生活中的很多细节，无须外界的帮助，就可以从小处不断完善自己。</li>
<li>如果你去练习反思，也必然会关注身体、情绪和思维三个层面，进而不断优化和改进自己。当然也会产生很多灵感、顿悟和创意，只要你去实践，就会有很多发现。</li>
<li>正视痛苦- 少数人会选择正视痛苦，反思错误，而大多数人选择逃避，沉浸在负面情绪中。</li>
<li>谨记：反思的最终目的是改变，而不是形式的完美，所以哪怕只有一句话，且这句话让自己发生了改变，那么反思的目的也就达到了。</li>
</ul>
<h2 id="第一章-大脑——一切问题的起源"><a href="#第一章-大脑——一切问题的起源" class="headerlink" title="第一章 大脑——一切问题的起源"></a>第一章 大脑——一切问题的起源</h2><ul>
<li><p>人类三重大脑</p>
<ul>
<li>本能脑（源于爬行动物，主管本能，对环境快速做出本能反应）</li>
<li>情绪脑（源于哺乳动物，主管情绪，在恶劣的环境中趋利避害，提升生存优势，比如恐惧情绪可以让他远离危险，兴奋情绪可以让他专注捕猎）</li>
<li>理智脑（源于灵长类动物，主管认知，理性地思考）</li>
</ul>
</li>
<li><p>“我怜悯恶人，我该死，应该受报应。”事实上，如果这位农夫懂得一些大脑知识，就不会犯如此低级的错误了。蛇这种冷血的爬行动物根本就没有发达的情绪脑，它不知感恩为何物，只会依靠本能行事，遇到危险要么战斗、要么逃跑；而愚昧的农夫竟然以为蛇和人类一样有善恶之心，会知恩图报，结果使自己命丧黄泉。！！！</p>
</li>
<li><p>令人欣慰的是，高级的理智脑是我们人类所独有的，它使我们富有远见、善于权衡，能立足未来获得延时满足</p>
</li>
<li><p>理智脑虽然高级，但比起本能脑和情绪脑，它的力量实在是太弱小了</p>
</li>
<li><p>本能脑早在婴儿时期就比较完善了，情绪脑则要等到青春期早期才趋于完善，而理智脑最晚，要等到成年早期才基本发育成熟。</p>
</li>
<li><p>所以在人生的前20年里，我们总是显得心智幼稚不成熟。</p>
</li>
<li><p>理智脑对大脑的控制能力很弱，所以我们在生活中做的大部分决策往往源于本能和情绪，而非理智。</p>
</li>
<li><p>为了生存，他们必须借助本能和情绪的力量对危险做出快速反应，对食物进行即时享受，对舒适产生强烈欲望，才不至于被吃掉、被饿死</p>
</li>
<li><p>为了生存，原始人还要尽量节省能量，像思考、锻炼这种耗能高的行为都会被视为对生存的威胁，会被本能脑排斥，而不用动脑的娱乐消遣行为则深受本能脑和情绪脑的欢迎</p>
</li>
<li><p>本能脑和情绪脑的基因一直被生存压力塑造着，所以它们的天性自然成了目光短浅、即时满足</p>
</li>
<li><p>我们当前遇到的几乎所有的成长问题都可以归结到目光短浅、即时满足的天性上，不过在现代社会，用避难趋易和急于求成来代指它们显然更加贴切。</p>
</li>
<li><p>成长就是克服天性的过程！！</p>
</li>
<li><p>而觉醒和成长就是让理智脑尽快变强，以克服天性</p>
</li>
<li><p>因为大脑和肌肉一样，遵循用进废退的原则。</p>
</li>
<li><p>理智脑不是直接干活的，干活是本能脑和情绪脑的事情，因为它们的“力气”大；上天赋予理智脑智慧，是让它驱动本能和情绪，而不是直接取代它们</p>
</li>
<li><p>学习知识，提升认知，运用策略</p>
</li>
<li><p>归结起来，焦虑的原因就两条：想同时做很多事，又想立即看到效果。王小波说：人的一切痛苦，本质上都是对自己无能的愤怒。焦虑的本质也契合这一观点：自己的欲望大于能力，又极度缺乏耐心。焦虑就是因为欲望与能力之间差距过大。</p>
</li>
<li><p>急于求成，想同时做很多事；避难趋易，想不怎么努力就立即看到效果。这才是焦虑真正的根源！焦虑是天性，是人类的默认设置。</p>
</li>
<li><p>我们没有必要自责或愧疚，也没有必要与天性较劲，而应想办法看清背后的机理并设法改变。</p>
</li>
<li><p>得耐心者得天下</p>
</li>
<li><p>缺乏耐心根本不是什么可耻的事，和自己的道德品质也全无关系，这仅仅是天生属性罢了，每个人都一样。</p>
</li>
<li><p>复利效应显示了价值积累的普遍规律：前期增长非常缓慢，但到达一个拐点后会飞速增长。这个“世界第八大奇迹”</p>
</li>
<li><p>我们需要冷静面对前期缓慢的增长并坚持到拐点。</p>
</li>
<li><p>复利曲线和舒适区边缘是一对好朋友，它们组合在一起可以让我们在宏观上看到保持耐心的力量，而且这种力量适用于每一个普通人。</p>
</li>
<li><p>即对于学习而言，学习之后的思考、思考之后的行动、行动之后的改变更重要，如果不盯住内层的改变量，那么在表层投入再多的学习量也会事倍功半；因此，从权重上看，改变量﹥行动量﹥思考量﹥学习量</p>
</li>
<li><p>单纯保持学习输入是简单的，而思考、行动和改变则相对困难。在缺乏觉知的情况下，我们会本能地避难趋易，不自觉地沉浸在表层的学习量中。</p>
</li>
<li><p>我们不会因自己进步缓慢而沮丧，也不会因别人成长迅速而焦虑</p>
</li>
<li><p>毕竟各自所处的阶段不同，只要持续创造价值，别人的今天就是自己的明天。</p>
</li>
<li><p>耐心不是毅力带来的结果，而是具有长远目光的结果。</p>
</li>
<li><p>对外部世界的规律的认知能使我们耐心倍增。</p>
</li>
<li><p>首先，面对天性，放下心理包袱，坦然接纳自己。当我们明白缺乏耐心是自己的天性时，就坦然接纳吧！从现在开始，对自己表现出的任何急躁、焦虑、不耐烦，都不要感到自责和愧疚</p>
</li>
<li><p>面对诱惑，学会延迟满足，变对抗为沟通。</p>
</li>
<li><p>该有的享受一点都不会少，只是不是现在享受，而是在完成重要的事情之后。”这是一个有效的策略，因为放弃享受，它们是不会同意的，但延迟享受，它们是能接受的。</p>
</li>
<li><p>最高级的方法是请本能脑和情绪脑出动来解决困难。</p>
</li>
<li><p>所以，想办法让本能脑和情绪脑感受到困难事物的乐趣并上瘾，才是理智脑的最高级的策略</p>
</li>
</ul>
<h2 id="第二章-潜意识——生命留给我们的彩蛋"><a href="#第二章-潜意识——生命留给我们的彩蛋" class="headerlink" title="第二章 潜意识——生命留给我们的彩蛋"></a>第二章 潜意识——生命留给我们的彩蛋</h2><ul>
<li><p>模糊：人生是一场消除模糊的比赛</p>
</li>
<li><p>为了更好地生存，进化之手巧妙地采用了意识分层的手段，它让潜意识负责生理系统，让意识负责社会系统，如此分工，意识便得到了解放，可以全力投入高级的社会活动。</p>
</li>
<li><p>这种模糊让人心生迷茫和恐惧，而迷茫和恐惧又使我们的认知、情绪和行动遭遇各种困扰，继而影响人生的走向。模糊，正是人生困扰之源。而人生也像是一场消除模糊的比赛，谁的模糊越严重，谁就越混沌；谁的模糊越轻微，谁就越清醒。</p>
</li>
<li><p>正如你知道了“元认知”，就知道了该如何反观自己；知道了“刻意练习”，就明白了如何精进自己；知道了“运动改造大脑”，就清楚了如何激发自己的运动热情</p>
</li>
<li><p>不幸的是，人类天生不喜欢学习和思考，因为这类事极其耗能。在漫长的进化过程中，生命的首要任务是生存，于是，基因自我设计的第一原则是节能，凡耗能高的事情都会被视为是对生存的威胁</p>
</li>
<li><p>学习知识的目的是“消除模糊”，而获取知识的方法也是“消除模糊”，目的和方法相统一</p>
</li>
<li><p>《思考力》一书的作者上田正仁提示：思考力的本质就是“丢弃所有已经消化的信息，让问题的核心浮出水面”；·《刻意练习》中的核心方法论是：不要重复练习已经会的，要不断寻找那些稍有难度的部分；·《原则》一书的作者瑞·达利欧罗列了工作和生活中的原则，用以清晰地指导自己行事；·《超越感觉》一书告诉我们，想拥有清晰的逻辑，就坚持一点：凡事不要凭模糊的感觉判断，要寻找清晰的证据。种种现象都在告诉我们一个事实</p>
</li>
<li><p>学霸”和普通同学之间的差异不仅体现在勤奋的程度上，还体现在努力的模式上：谁更愿意做高耗能的事——消除模糊，制造清晰。</p>
</li>
<li><p>受苦比解决问题来得容易，承受不幸比享受幸福来得简单。</p>
</li>
<li><p>因为解决问题需要动脑，享受幸福也需要动脑平衡各种微妙的关系，而承受痛苦则只需陷在那里不动。</p>
</li>
<li><p>真正的困难总比想象的要小很多。人们拖延、纠结、畏惧、害怕的根本原因往往不是事情本身有多难，而是内心的想法变得模糊。</p>
</li>
<li><p>如果我们再积极些，学会从一开始就主动正视它、拆解它、看清它，或许那种紧张就不困扰自己了，我们甚至能从容地“享受”比赛。</p>
</li>
<li><p>要想不受其困扰，唯一的办法就是正视它、看清它、拆解它、化解它，不给它进入潜意识的机会，不给它变模糊的机会；即使已经进入潜意识，也要想办法将它挖出来。</p>
</li>
<li><p>虽然直面情绪不会让痛苦马上消失，甚至短时间内还会加剧痛苦，但这会让你主导形势，至少不会被情绪无端恐吓。</p>
</li>
<li><p>行动力不足的真正原因是选择模糊。</p>
</li>
<li><p>选择模糊就是一种不确定性，而人类面对不确定性时会不自觉逃避</p>
</li>
<li><p>当我们没有足够清晰的指令或者目标时，就很容易选择享乐，放弃那些本该坚持但比较烧脑的选项。</p>
</li>
<li><p>在现代生活中，要想让自己更胜一筹，就必须学会花费更多的脑力和心力去思考如何拥有足够清晰的目标。我们要把目标和过程细化、具体化，在诸多可能性中建立一条单行通道，让自己始终处于“没得选”的状态。</p>
</li>
<li><p>在这条赛道上，领先的群体都有意无意地做着同一件事：消除认知、情绪和行动上的模糊。</p>
</li>
<li><p>先用感性能力帮助自己选择，再用理性能力帮助自己思考。</p>
</li>
<li><p>读书也是这样，如果单纯运用理性，我们通常会在看完整本书后花大量时间梳理作者的框架、思路，以此来表明自己读懂、读透了这本书；</p>
</li>
<li><p>一个人若是没有人生目标，纵然每天有吃、有喝、有书读、有班上，也会像一个迷失的人一样，内心没有喜悦、生活没有激情，甚至会厌恶自己，因为目标是存放我们热情和精力的地方。很多人为了找到自己的人生目标，费尽心思地分析什么事情最值得做，最后得到的答案往往是“变得很有钱”或“被别人崇拜”。这样的目标不能说有错，但往往不能长久，也无法给人真正的动力，因为这是理性思维权衡利弊和考量得失之后的结果，其动机往往来自“自我索取和外在评价”，时间一长，很容易使人迷失方向，使动力枯竭。</p>
</li>
<li><p>真正的觉醒者往往会有意无意地用感知力来代替思考力    </p>
</li>
<li><p>比如《美好人生运营指南》一书的作者一稼就提出了6条寻找人生使命的建议。·这个世界有很多事情可以做，你最想帮助哪些人？·什么事让你废寝忘食？·你在做什么事情的时候最让自己感动？·你最让人感动的时刻是什么？·如果没有任何经济压力，你会如何度过余生？·闲暇的时候，你关注最多的是哪方面的信息？</p>
</li>
<li><p>理智的分析和计算无法解出内心的真正需求，唯有感性的觉知和洞察才能让答案浮出水面。而且正确的答案往往都是利他的，因为真正长久的人生意义和幸福只能从他人的反馈中获得。</p>
</li>
<li><p>设想你即将离开世界，回首一生会为什么事情而后悔？·想一想你最喜欢的人物是谁？·你年轻的时候是怎么度过闲暇时光的？</p>
</li>
<li><p>对于你喜欢的人物，不管是虚构的还是真实的，只要让你深深地着迷，就可以从这些人物身上反射出内心理想的自己；</p>
</li>
<li><p>而年轻的时候没有家庭、工作负担，那时的追求更加遵从内心，不会受外界压力的干扰。</p>
</li>
<li><p>归纳起来，我们可以发现，理性思维虽然很高级，但在判断与选择方面可能并不具有优势，它那蹩脚的性能实在无法与灵敏快速的感性媲美。所以，先用感性选择，再用理性思考，或许是一个更好的策略，尤其是在做那些重大选择时。诚如洪兰教授的建议：小事听从你的脑，大事听从你的心。这话不无道理。</p>
</li>
<li><p>梦境。梦境是潜意识传递信息的一种方式，它可能是内心真实想法的展示，也可能是灵感的启发。</p>
</li>
<li><p>身体不会说话，却是最诚实的。无论生理还是心理上的不适，都会通过身体如实地反映出来，记得多关注这些反馈。</p>
</li>
</ul>
<h2 id="第三章-元认知——人类的终极能力"><a href="#第三章-元认知——人类的终极能力" class="headerlink" title="第三章 元认知——人类的终极能力"></a>第三章 元认知——人类的终极能力</h2><ul>
<li><p>早在15万年之前，人类就已经拥有这种能力，当然不是指人的身体真的飞到空中，而是指意识与本体分离，“飞”到更高处去反观自己。</p>
</li>
<li><p>你如果仔细观察过这个世界上优秀的人，就会发现他们几乎都是“飞”着前进的；</p>
</li>
<li><p>元认知能力就是我们习以为常、见怪不怪的反思能力。这种能力不仅为我们人类所独有，也是我们成为万物之灵[插图]的根源</p>
</li>
<li><p>当一个人能主动开启第三视角、开始持续反观自己的思维和行为时，就意味着他真正开始觉醒了，他有了快速成长的可能。</p>
</li>
<li><p>高级的元认知——时刻帮你从高处、深处、远处看待现在的自己，让自己保持清醒、不迷失，保持动力、不懈怠，保持平和、不冲动。</p>
</li>
<li><p>元认知能力总能让你站在高处俯瞰全局，不会让你一头扎进生活的细节，迷失其中。</p>
</li>
<li><p>未来视角总是当前行动的指南针</p>
</li>
<li><p>提高元认知能力的方法有很多，但最让人意想不到是下面这条——冥想。是的，冥想就是那种只要静坐在某处，然后放松身体，把注意力完全集中到呼吸和感受上的活动。</p>
</li>
<li><p>不难发现这些活动本质上都在做同一件事：监控自己的注意力，然后将其集中到自己需要关注的地方。</p>
</li>
<li><p>元认知正是人类认知能力的反馈回路，有了它，我们才可能进入快速进化的通道。</p>
</li>
<li><p>有的人能看到事物更多的意义，赋予目标强烈的价值，因此他们比其他人的专注力、执行力和意志力更强；有的人能觉察他人的想法，克制自己的言行，从而显得情商更高。他们真正的竞争力不在于学习能力，而在于强大的元认知能力。！！！</p>
</li>
<li><p>很多学习能力、运算能力超强的学霸，他们的理智脑虽然同样强大，但未必能过好自己的人生。</p>
</li>
<li><p>在“元时间”内我们要做什么呢？很简单，就做一件事：想清楚。如果不在这些选择的节点想清楚，我们就会陷入模糊状态，而模糊是潜意识的领地，它会使我们产生本能的反应——娱乐。所以，基本的应对策略便是：在选择的节点审视自己的第一反应，并产生清晰明确的主张。</p>
</li>
<li><p>虽然这样做会更累，但这正是锻炼元认知能力的最佳时机，就像是在举思想哑铃，让自己的理智脑变得更强大</p>
</li>
<li><p>元认知能力强的一个突出表现是：对模糊零容忍。换句话说，就是想尽一切办法让自己找出那个最重要的、唯一的选项，让自己在某一个时间段里只有一条路可以走。这道理很简单，既然权重都差不多，那么做哪件事都没有损失。犹豫不决，什么都想做又什么都做不好，才是最大的损失。</p>
</li>
<li><p>元认知能力强的人就是这样：无论是当下的注意力、当天的日程安排，还是长期的人生目标，他们都力求想清楚意义、进行自我审视和主动控制，而不是随波逐流。</p>
</li>
</ul>
<h2 id="第四章-专注力——情绪和智慧的交叉地带"><a href="#第四章-专注力——情绪和智慧的交叉地带" class="headerlink" title="第四章 专注力——情绪和智慧的交叉地带"></a>第四章 专注力——情绪和智慧的交叉地带</h2><ul>
<li><p>一是觉得当下太无聊，所以追求更有意思的事情；二是觉得当下太痛苦，于是追求更舒适的事情。因为身体受困于现实，只好让思想天马行空。</p>
</li>
<li><p>可见，分心走神的本质是逃避，所以，面对困难时，身心分离的人总会不自觉地退回舒适区，而身心合一的人则更容易跳出舒适区，直面困难。</p>
</li>
<li><p>身体感受永远是进入当下状态的最好媒介，而感受事物消失的过程更是一种很好的专注力训练。它提示我们，身心合一的要领不仅是专注于当下，更是享受当下，而这种享受必将使我们更从容，不慌张。</p>
</li>
<li><p>行者又问：“那何谓得道？”老和尚说：“得道前，砍柴时惦记着挑水，挑水时惦记着做饭；得道后，砍柴即砍柴，担水即担水，做饭即做饭。”</p>
</li>
<li><p>变聪明的秘诀就是：先保持极度专注，想不出答案时再将注意力转换到另一件与此毫不相干的事情上。即事前聚精会神，让意识极度投入；事后完全忘记，让意识彻底撒手。这样，灵感和答案就会大概率地出现。</p>
</li>
<li><p>很多例子都表明，科学发现或其他智力上的突破都是在当事人毫无期待、正在想别的事情的时候出现的。</p>
</li>
<li><p>李大钊也说过：“要学就学个踏实，要玩就玩个痛快！”说明界线分明的习惯对人性情和能力的培养都很有好处。</p>
</li>
<li><p>能获得有效的反馈。一般而言，不论做什么事情我们都需要反馈来准确识别自己在哪些方面还存在不足，以及为什么会存在不足。</p>
</li>
<li><p>始终在拉伸区练习。一味重复已经掌握的事情是没有意义的，但挑战太难的任务也会让自己感到挫败，二者都无法使人进入沉浸状态，好的状态应该介于二者之间。</p>
</li>
</ul>
<h2 id="第五章-学习力——学习不是一味地努力"><a href="#第五章-学习力——学习不是一味地努力" class="headerlink" title="第五章 学习力——学习不是一味地努力"></a>第五章 学习力——学习不是一味地努力</h2><ul>
<li><p>找一个自己能坚持做下去的方式，比单纯按照标准化的时间和方式做更重要。</p>
</li>
<li><p>我们就应该花大量的时间去梳理哪些内容处在自己的拉伸区，即梳理那些“会做但特别容易错或不会做但稍微努力就能懂”的内容，然后在这个区域内努力。</p>
</li>
<li><p>千万不要认为没有管束的生活很美好，一旦进入完全自由的时间，虽然开始会很舒服，但很快，我们就会迷失在众多选项中——做这个也行，做那个也行。</p>
</li>
<li><p>做选择是一件极为耗能的事情，如果没有与之匹配的清醒和定力，绝大多数人最终都会被强大的天性支配，去选择娱乐消遣。在有约束的环境下我们反而效率更高，生活更充实。</p>
</li>
<li><p>不管做什么，不管当前做得怎么样，只要让自己处在舒适区的边缘持续练习，你的舒适区就会不断扩大，拉伸区也就会不断扩展，原先的困难区也会慢慢变成拉伸区，甚至是舒适区，所以成长是必然的。</p>
</li>
<li><p>这个问题太大、太模糊。所以，你只要拆解目标——把大目标拆分为小目标，任务就会立即从困难区转移到拉伸区，这样你就愿意行动了。</p>
</li>
<li><p>跳出舒适区的最好办法就是去发现和收集那些要点，也就是每次行动的小目标</p>
</li>
<li><p>种种迹象表明，快速、简便、轻松的方式使人们避难趋易、急于求成的天性得到了放大，理智脑的潜能受到了抑制，而深度学习的能力几乎全部依赖高级理智脑的支撑。</p>
</li>
<li><p>被动学习：如听讲、阅读、视听、演示，这些活动对学习内容的平均留存率为5%、10%、20%和30%。主动学习：如通过讨论、实践、教授给他人，将被动学习的内容留存率提升到50%、75%和90%。</p>
</li>
<li><p>以阅读为例，从浅到深依次为：听书、自己读书、自己读书+摘抄金句、自己读书+思维导图&#x2F;读书笔记、自己读书+践行操练、自己读书+践行操练+输出教授。</p>
</li>
<li><p>还有一类人的数量也不少。这类人能够自己阅读，也做读书笔记或思维导图，但遗憾的是，他们的读书笔记往往只是把书中的内容梳理罗列了一番，看起来更像是一个大纲。很多人醉心于此，似乎对全书的知识了然于胸，殊不知，自己只是做了简单的搬运工作而已。虽然这种做法在一定程度上属于主动学习，但它仅仅是简单的知识陈述，与高级别的知识转换有很大的不同。更深一层的是，读完书能去实践书中的道理，哪怕有那么一两点内容让生活发生了改变，也是很了不起的，因为从这一刻开始，书本中的知识得到了转化。</p>
</li>
<li><p>请注意，遇到这种困难才是深度学习真正的开始！因为你必须动用已有的知识去解释新知识，当你能够把新学的知识解释清楚时，就意味着把它纳入了自己的知识体系，同时达到了可以教授他人的水平，并可能创造新的知识。</p>
</li>
<li><p>浅层学习满足输入，深度学习注重输出。从想法到语言再到文字，即将网状的思维变成树状的结构再变成线性的文字，相当于把思想从气态变成液态再变成固态——那些固态的东西才真正属于自己。</p>
</li>
<li><p>毕竟任何知识都不可避免地会损耗，并且这种损耗一直存在，如果不想办法把自己学到的东西固定下来，时间一长，这些知识就会烟消云散，留不下多少痕迹。</p>
</li>
<li><p>教的最高境界是用最简洁的话让一个外行人明白你讲的东西</p>
</li>
<li><p>所以，逼迫自己获取高质量的知识以及深度缝接新知识，再用自己的语言或文字教授他人，是为深度学习之道。</p>
</li>
<li><p>深度学习有以下3个步骤：</p>
<ul>
<li>(1)获取高质量的知识；(2)深度缝接新知识；(3)输出成果去教授。</li>
</ul>
</li>
<li><p>人与人之间的差距不是来自年龄，甚至不是来自经验，而是来自经验总结、反思和升华的能力。</p>
</li>
<li><p>持续反思让我对生活细节的感知能力变得越来越强，从生活中获得的东西也越来越多。</p>
</li>
<li><p>深度学习除了能让我们不再浮躁，能磨炼理智，还能带来诸多好处，比如跨界能力的提升。 </p>
</li>
<li><p>深度学习还能让人产生更多灵感。</p>
</li>
<li><p>只有在自己的领域探索得足够深入时，灵感才可能在潜意识的帮助下显现。虽然我们不是科学家，但深度学习也能让我们更大概率地收获意外的惊喜。</p>
</li>
<li><p>与此同时，深度学习还能让我们看到不同事物之间更多的关联，产生洞见。   </p>
</li>
<li><p>专注于深度学习，同时对浅学习保持开放。</p>
</li>
<li><p>无关联，不学习</p>
</li>
<li><p>常年遨游在知识的海洋中，始终无法进阶，这其中最根本的阻碍在于他们意识不到新学习的知识点是孤立的。不管这个新知识让人多警醒、使人多震撼，若是无法与已有的知识发生足够的关联，它存活不了太久。</p>
</li>
<li><p>如果你了解人类大脑的学习原理，就很容易从这幅图联想到大脑中神经元工作的情景。因为无论是学习动作，还是背记公式，从本质上来说都是大脑中神经细胞建立连接的过程。用神经科学术语解释就是：通过大量的重复动作，大脑中两个或者多个原本并不关联的神经元经过反复刺激产生了强关联。</p>
</li>
<li><p>如果没有关联这个过程，就算有再多脑细胞，你也不会变得更聪明。</p>
</li>
<li><p>鉴于此，我时常也鼓励人们写作。因为单纯阅读时，人容易满足于获取新知识，而一旦开始写作，就必须逼迫自己把所学的知识关联起来，所以写作就是一条深度学习的自然路径。</p>
</li>
<li><p>放眼看去，按照关联意识的强弱，人在不知不觉间被分成了两个群体：绝大多数人习惯以孤立的思维看待事物，喜欢花大量时间收集和占有信息；而另一批先行者则更喜欢拨弄信息之间的关联，从而在不知不觉间变得聪明了起来。</p>
</li>
<li><p>所以，我们在关联时，需要牢牢聚焦自身最迫切的需求，换句话说，就是让一切与自己有关。</p>
</li>
<li><p>知识的获取不在于多少，而在于是否与自己有关联，以及这种关联有多充分。</p>
</li>
<li><p>对别人有用的东西可能与自己并没有关系，那就果断将其放弃，把握“与自己有关”的筛选原则，会让关联效能大大提升。</p>
</li>
<li><p>知识与认知的区别</p>
</li>
<li><p>真正的知识不是你知道了它，而是能运用它帮助自己做出正确的判断和选择，解决实际问题。这一点正是“学术知识体系”和“个人知识体系”的重要区别。所以在个人成长领域，没有最优、最确定、最权威的认知体系，只有最适合我们当前状态的认知体系。</p>
</li>
<li><p>用掌握学术知识的方法去对待别人的认知体系，所以不禁沉迷于全面掌握和全盘照搬他人的体系，甚至感觉如果没有完全掌握对方的认知体系，就有可能前功尽弃。</p>
</li>
<li><p>根据能力圈法则可知，人的能力是无法跳跃发展的，只能在现有基础上一点一点向外扩展，而扩展的最佳区域就在舒适区边缘。</p>
</li>
<li><p>我们不需要全盘掌握他人的知识体系，只需要掌握那些最能触动自己、离自己需求最近的知识</p>
</li>
<li><p>体系的本质就是用独特的视角将一些零散的、独立的知识、概念或观点整合为应对这个世界的方法和技巧。</p>
</li>
<li><p>这就是搭建个人认知体系的真相：打碎各家的认知体系，只取其中最触动自己的点或块，然后将其拼接成自己的认知网络。</p>
</li>
<li><p>随着我们自身认知体系的不断完善，原来距离我们较远的知识就会相对变近，于是又能触动我们，所以暂时放弃一些知识并不可怕，只要持续学习，我们不会损失什么。</p>
</li>
<li><p>很多人读书的时候往往只关注自己是否理解了书中的内容，却经常忽视头脑中冒出的想法。其实这些想法是非常珍贵的，放过了它们，我们的学习效果就会大打折扣。</p>
</li>
<li><p>在生活中能够经常练习或使用这些知识，因为实践是产生强关联的终极方法。</p>
</li>
<li><p>在舒适区边缘，一点一点向外扩展。</p>
</li>
<li><p>莫迷恋打卡，打卡打不出未来</p>
</li>
<li><p>认知闭合，效能降低单纯地依赖打卡，不仅会转移行动的动机，还会降低行动的效能。这源自另一个重要的心理机制——认知闭合需求。</p>
</li>
<li><p>一件事若迟迟没有完成，心里就总是记挂，期盼着早点结束；此事一旦完成，做这件事的动机就会立即趋向于零。</p>
</li>
<li><p>我们之所以有这种心理是因为人类的大脑喜欢确定性，不喜欢未知或不确定性。</p>
</li>
<li><p>这就是打卡心态的特性：学不到，假装一下；学到了，立即停止。</p>
</li>
<li><p>现代人很难获得幸福感，多是因为这种快节奏和急心理，但在这种状态下，生活何其枯燥，它无法让我们享受过程，只会让身心紧张、焦虑、麻木和分裂。！！！</p>
</li>
<li><p>用记录代替打卡</p>
</li>
<li><p>只要专注于学习成长活动本身，体会其中的乐趣，就能保持强烈的学习动机，化被动学习为主动学习。</p>
</li>
<li><p>我们在任务设置时要使用新策略：设下限，不设上限。</p>
</li>
<li><p>从《微习惯》一书中获得的启示。作者斯蒂芬·盖斯为了养成好习惯，要求自己每天只做一个俯卧撑、每天只读一页书、每天只写50个字，这种无负担的习惯养成法最终促使他拥有了良好的身材，养成了阅读习惯，还写出了自己的书。他称这种方法简单到不可能失败。</p>
</li>
<li><p>无反馈，不学习</p>
</li>
<li><p>大多数人往往缺少输出和反馈意识，虽然他们极其理性，甚至能以超越常人的毅力不断激励自己努力，但最终收获的仍然是痛苦和失败。</p>
</li>
<li><p>他们似乎从来没有考虑过要尽快产出点什么，以换取反馈，通过另一种方式来激励自己。</p>
</li>
<li><p>持续的正向反馈才能真正激发本能脑和情绪脑的强大行动力。</p>
</li>
<li><p>我们的理智脑虽然聪明、有远见，但它身单力薄，真的不适合亲自上阵，真正需要它做的，是运用聪明才智去制定策略，让本能脑和情绪脑不断接受强烈的正向反馈，愉悦地朝着目标一路狂奔。</p>
</li>
<li><p>所以科学的学习策略是产出作品、获取反馈，驱动本能脑和情绪脑去“玩玩玩”，而不是一味地努力坚持，让理智脑苦苦地去“学学学”。</p>
</li>
<li><p>教是最好的学；·用是最好的学；·输出倒逼输入；·请用作品说话……那些先行者确实都有相同的品质，他们在学习的时候经常不按常理出牌，不管是不是新知识、技能，他们都直接用、直接做。当然，一开始常常用不好、做不好，但他们肯定要“鼓捣”出一个东西，然后抛出去获取反馈，不断打磨迭代</p>
</li>
<li><p>我知道这就是在驱动情绪脑为自己工作，如果自己写的文章没有任何反馈，我真不敢保证仅凭意志力和长远的认知能走到现在。所以“锁定价值—打磨作品—换取反馈”正是我持续写作的真正策略和真实动力。</p>
</li>
<li><p>分享不是随意分享半成品，而是尽最大力气将作品打磨成自己当前能力范围内可完成的最好的样子。</p>
</li>
<li><p>对待作品要像对待自己的孩子一样，每次出门前都要尽可能把它们打扮得漂亮精致，让人眼前一亮。这种要求必然会逼迫自己在能力舒适区边缘快速成长，因为这符合刻意练习的基本原则。</p>
</li>
<li><p>制定分享策略，展示给那些能力不及你的人。</p>
</li>
<li><p>最后，冷静客观地对待打击。</p>
</li>
<li><p>真正的学习成长不是“努力，努力再努力”，而是“反馈，反馈再反馈”，只有不断产出，获得反馈，我们的人生才会发生真正的变化。</p>
</li>
<li><p>“刻意练习四要素”：定义明确的目标、极度的专注、有效的反馈、在拉伸区练习。</p>
</li>
<li><p>那些持续刻苦、争分夺秒、舍不得休息一下的人，他们的精力总量势必呈一条持续下降的曲线</p>
</li>
<li><p>那些轻松的学霸，他们学习时从不过度消耗自己，只要感到精力不足，就停下来主动休息，这反而使他们精力桶的水位得到快速回升。</p>
</li>
<li><p>专注这个品质在信息时代已日渐成为稀缺品质。要学就学个踏实，要玩就玩个痛快。</p>
</li>
<li><p>面对大量的信息干扰和巨大的竞争压力，在这种情况下，大多数人只会本能地告诉自己要更刻苦、更努力，却很少有人能意识到，更科学的模式应该是：极度专注+主动休息，如此反复。</p>
</li>
<li><p>一个真正的自控高手，不是一个只知道冲刺的人，而是一个善于主动休息、保持平衡的人。</p>
</li>
<li><p>只要开始学习或工作，就尽量保持极度专注的状态，哪怕保持专注的时间很短也是有意义的；一旦发现自己开始因为精力不足而分心走神，就主动停下来调整片刻。</p>
</li>
<li><p>当然辅助工具也是有的。在时间管理领域，有一个著名的番茄工作法。</p>
</li>
<li><p>就在我想通“主动休息”这个原理的瞬间，脑海里第一个闪过的念头竟是番茄工作法，因为它符合学霸模式的所有特征：极度专注、主动休息、循环往复。</p>
</li>
<li><p>然后开始5分钟的休息计时。在这5分钟里，我会做与阅读或写作无关的事情，比如：看看窗外、收收衣服、拆拆包裹，等等，但刷手机、玩游戏这些被动使用注意力的事情我不推荐，因为它们仍然是消耗精力的。！！！</p>
</li>
<li><p>而且这个“主动停止”的动作一定要坚决。很多人在一开始的时候，由于精力分散得还不明显，就不愿意主动停下来，但这往往会得不偿失。主动休息犹如主动喝水，当感到很渴的时候再喝水，其实已经晚了，你想让精力保持高位，就要学会主动停下来，这甚至可以作为一个关键点。</p>
</li>
<li><p>刻苦，是一种宏观态度，轻松，是一种微观智慧。</p>
</li>
</ul>
<h2 id="第六章-行动力——没有行动世界只是个概念"><a href="#第六章-行动力——没有行动世界只是个概念" class="headerlink" title="第六章 行动力——没有行动世界只是个概念"></a>第六章 行动力——没有行动世界只是个概念</h2><ul>
<li><p>在经历了无数次的失败之后，我终于发现与天性对抗是没有出路的，也隐约感觉到自制力强并不代表行动力强。在随后的探索中，这个猜想逐渐得到证实：真正的行动力并不完全来源于自制力。</p>
</li>
<li><p>在一天开始的时候，一头扎进手机信息或是自己觉得有趣的事情中，然后迷失其中。这好比把这份珍贵的礼物直接摔在了地上，长此以往，自然就得不到命运的眷顾了。</p>
</li>
<li><p>如果起床后我们能刻意避开轻松和娱乐的吸引，先去读书、锻炼，或者做些重要的工作，精力就会呈聚合状态，并自动增强。比如起床后先去锻炼，就能让自己头脑清晰、精力充沛，在这种状态下做重要的工作就会非常顺利，工作越顺利，状态就越好，回路逐渐增强；再比如早起后先去阅读，读得越多，脑子里的问题和感触就越多，反过来又会产生更强烈的阅读欲望，回路逐渐增强。行动回路一旦增强，我们就会进入高效和充实的状态，此时我们哪还有精力去关注那些可看可不看的消息呢？注意力的增强回路是正向的还是负向的，很大程度上取决于你最初的选择，这也是老生常谈的道理：要事第一！！！！</p>
</li>
<li><p>在初始阶段，强迫自己先做重要的事情，一旦进入正向的增强回路，你便能拥有强大的行动力——这正是增强自制力、提升行动力的秘密</p>
</li>
<li><p>清晰力才是行动力</p>
</li>
<li><p>知道和做到相差十万八千里，这其中的差距到底在哪里呢？答案正是前文所说的“模糊”。</p>
</li>
<li><p>一切都只知道个大概，这对提升行动力来说，是很致命的。</p>
</li>
<li><p>写下当天所有要做的事，然后清空大脑，按权重将列出的事项标上序号，这样，目标就变得清晰可见；</p>
</li>
<li><p>通过持续的规划和记录，我对自由时间的掌控变得越来越强。我能够主动约束自己，我总知道下一步要做什么、什么事情最重要，即使不小心被各类消息牵绊，也能在自我提醒下快速跳出来，这一切得益于清晰力。</p>
</li>
<li><p>“写下来”就是有这样神奇的效果，因为“写下来”会清空我们的工作记忆。当我们把头脑中所有的想法和念头全部倒出来后，脑子就会瞬间变得清晰，同时，所有的想法都变得清晰且确定，这样一来，我们就进入了一种“没得选”的状态，在过程中不需要花脑力去思考或做选择。</p>
</li>
<li><p>事实上并不会，因为做规划的目的并不是让自己严格地按计划执行，而只是为了让自己心中有数。如果当天计划有变也没关系，有了这份预案，你能够在处理完临时任务后，把自己迅速拉回正轨，但如果没有这份预案，你极有可能在目标和时间都模糊的情况下选择娱乐消遣。所以，做规划十分有效，平时遇到干扰只要及时调整计划就好了。</p>
</li>
<li><p>一切源于“想清楚”</p>
</li>
<li><p>你陷入怠惰、懒散、空虚的情绪中动弹不得时，往往是因为你的大脑处于模糊状态。大脑要么不清楚自己想要什么；要么同时想做的事太多，无法确定最想实现的目标是什么；要么知道目标，但没想好具体要在什么时候以什么方式去实现。</p>
</li>
<li><p>认知越清晰，行动越坚定。</p>
</li>
<li><p>聪明的思考者都知道“想清楚”才是一切的关键，在“想清楚”这件事上。</p>
</li>
<li><p>在普通人眼里是“知易行难”，而在聪明人眼里是“知难行易”，这一点值得我们反思。</p>
</li>
<li><p>想先看到结果再行动的人往往无法看到结果。耍小聪明的人会因为结果不明朗，担心付出没有回报，所以不愿行动，以致永远停留在原地</p>
</li>
<li><p>事实上，只要道理正确，就别在乎那些小聪明，带着不计得失的心态向前走，你会发现目标越来越清晰</p>
</li>
<li><p>你觉得学英语没用，是因为你看不到生活中有需要英语的地方。只有英语学好了，和英语有关的机会才会慢慢地出现在你的周围。你觉得学历没用，是因为你根本不知道学习对你的生活轨迹能带来多少改变，你只是基于当时的场景，认为自己手里只是额外多了一张纸。你觉得锻炼身体没有用，正是因为你不去运动，所以感受不到它的价值</p>
</li>
<li><p>没错，这个世界是有认知层次的。处在下一个认知层次的人往往看不到上一个认知层次的风景，因而只能用狭隘的视角来判断：这些东西虽然很有道理，但似乎看起来并没有什么用。这些东西在他们眼里确实没什么用，因为人们无法证明一件没有发生过的事。想要打破这个悖论，只有让自己行动起来，将认知提升到更高的层次，才能做出不同的判断。</p>
</li>
<li><p>我此前一直强调“想清楚”的重要性，但当我们绞尽脑汁去想却仍然想不清楚的时候，就要依据前人的假设先行动起来</p>
</li>
<li><p>人生目标才可能慢慢浮现。</p>
</li>
<li><p>思考很重要，但光想不做，贻害无穷。</p>
</li>
<li><p>打破这些悖论的方法就是不计得失地先行动起来。</p>
</li>
<li><p>我们在行动时也应如此，我们要专注、要持续行动，直到突破阈值</p>
</li>
<li><p>这里的“傻”，并不是盲目和冲动，而是有原理、有依据的坚定</p>
</li>
<li><p>行动力强，是因为自己赞同行动背后的原理、依据和意义，而不是别人说做这个好，自己不深入了解就跟风去做，那才是真的傻。</p>
</li>
<li><p>换句话说，如果你觉得别人讲的道理有理有据，而自己暂时无法反驳，碰巧自己又非常想做这件事，那就相信他们说的是对的，然后笃定地行动</p>
</li>
<li><p>在实践途中，你自然也要保持思考，用行动反复验证他们的理论，不适则改、适则用，直到自己真正做到为止。届时你不仅能做成那件事，还能探索出自己的理论，成为别人眼中的高手。</p>
</li>
<li><p>道理再好，如果不去刻意练习，不去刺激相关神经元的强关联，这些美好的认知将永远不会真正对自己产生影响。</p>
</li>
<li><p>从现在开始，把认知当成技能，知道或想通一个道理时，不要高兴得太早，想想后面还要做大量的练习，这样就不浮躁了。</p>
</li>
<li><p>从大脑的学习机制推断，无论学习一项技能，还是养成一个习惯，背后都是相关神经元从少到多、从弱到强的关联过程。那么在一开始、在神经元关联很弱的情况下，做不好是正常的。</p>
</li>
<li><p>我们已经不是孩子了，我们应该学会用更成熟的心态包容自己最初的笨拙，即使做不好，也要持续练习，给神经元留够关联时间。</p>
</li>
<li><p>不发生真正改变的学习都是无效的学习。一篇文章、一本书就算讲得再有道理，倘若最终没有促成自己改变，我便认为读这篇文章、这本书的过程是无效的学习</p>
</li>
<li><p>现实和理论都告诉我们：懂得百点不如改变一点。真正的成长不在于自己懂得了多少道理，而在于自己改变了多少。</p>
</li>
<li><p>因为在这个世界上，知而不行的人实在太多了，只要你有所行动，就可以超越一大批人。</p>
</li>
<li><p>对成长来讲，道理都是“空头支票”，改变才是“真金白银”</p>
</li>
</ul>
<h2 id="第七章-情绪力——情绪是多角度看问题的智慧"><a href="#第七章-情绪力——情绪是多角度看问题的智慧" class="headerlink" title="第七章 情绪力——情绪是多角度看问题的智慧"></a>第七章 情绪力——情绪是多角度看问题的智慧</h2><h3 id="第一节-心智带宽：唯有富足，方能解忧"><a href="#第一节-心智带宽：唯有富足，方能解忧" class="headerlink" title="第一节　心智带宽：唯有富足，方能解忧"></a>第一节　心智带宽：唯有富足，方能解忧</h3><ul>
<li><p>贫穷造成的稀缺俘获了人的注意力，进而降低了人的心智带宽。</p>
</li>
<li><p>所谓心智带宽，就是心智的容量，它支撑着人的认知力、行动力和自控力。心智带宽一旦降低，人很容易丧失判断力，做出不明智的选择，或急于求成，做事缺乏耐心，难以抵挡享乐的诱惑。</p>
</li>
<li><p>不难预见，这些短视行为带来的糟糕结果会加剧稀缺心态：吃剩饭吃坏肚子，在医院的花费会远远超过饭菜钱；对孩子发火会让自己压力更大；而在学习时不停地刷手机，自己会更加忧心忡忡。恶性循环会增强负面回路，让忧者更忧。</p>
</li>
<li><p>可见稀缺只是“变笨”的一种诱因，事实上，任何能制造压力的事件都会挤占我们的心智带宽，比如明天的演讲、考试的期限、失业的担忧，等等。只要我们的注意力被某一个巨大的事物吸引，我们就有可能进入稀缺状态，进而降低心智带宽，做出不明智的行为。</p>
</li>
<li><p>“恋爱中的男女智商为零”</p>
</li>
<li><p>本质上就是稀缺心态导致判断力下降。</p>
</li>
<li><p>现代社会虽然给我们提供了更多便利和选择，同时也带来了前所未有的快节奏，仿佛一不留神就会落在队伍后面，这不由得迫使每个人加快脚步，不自觉地想要更多优势</p>
</li>
<li><p>心智带宽被占用殆尽，自然就没有心力支撑自己的远见、耐心、行动力和自控力了，最终只能让自己在痛苦中彷徨，甚至做不好当下的小事。</p>
</li>
<li><p>很多同学或职场人希望在假期或空闲时间提升自己，于是把日程安排得满满当当，不留一丝余地，结果每次都是“理想很丰满，现实很骨感”，不仅实现不了目标，反而在娱乐中无法自拔。这道理其实是一样的：当一个人同时面临很多任务的时候，他的心智带宽就会降低，反而没有了行动力和自控力。</p>
</li>
<li><p>有生活经验的人都会尽量克制自己的欲望，在做重要之事的同时主动安排娱乐活动，尽量保持日程的闲余——这种方法是科学的、智慧的。</p>
</li>
<li><p>陷入盲目尝试、乱学一通、急于求成的陷阱</p>
</li>
<li><p>既有人生未知的后台程序，又有各种急于实现的多线程任务。在这种状态下，一个人是很难走出来的，因为已经没有资源来支撑他的远见、耐心、行动力和自控力了。</p>
</li>
<li><p>现代生活虽然缓解了生存压力，却又带来了自控上的压力。抵制诱惑和欲望无一不消耗我们的心智带宽</p>
</li>
<li><p>唯有心智富足，方能解忧</p>
</li>
<li><p>物质条件无法决定我们的命运，真正影响我们的是心智带宽是否富足。有了富足的心智带宽，我们就能在任何环境中拥有支撑自己的远见、耐心、行动力和自控力，在变化的环境中解救自己。那么如何才能获取心智带宽呢？我想，最重要的莫过于保持自我觉知了。对此，我给大家备上五帖觉知“良药”，请各位按需取用。</p>
<ol>
<li>第一帖，保持环境觉知，理智选择。</li>
<li>第二帖，保持目标觉知，少即是多。</li>
<li>第三帖，保持欲望觉知，审视决策。<ul>
<li>脑子里存在大量任务和念头的时候，往往是我们行动力最弱的时候。所以保持对欲望的觉知，及时地审视它们，是清理自己心智带宽的好办法。</li>
<li>真正的行动力高手不是有能耐在同一时间做很多事的人，而是会想办法避免同时做很多事的人。</li>
</ul>
</li>
<li>第四帖，保持情绪觉知，谨慎决定。<ul>
<li>不要在最兴奋的时候做决定，也不要在最愤怒的时候做决定，尤其是重大决定。大喜大悲的时候，我们的心智带宽往往很窄，判断力也很弱。</li>
<li>一个心智带宽富足的人，也会是一个心平气和的人。</li>
</ul>
</li>
<li>第五帖，保持闲余觉知，自我设限。<ul>
<li>过多的闲余可不是什么好事，如果有大量的金钱，就容易萌生无谓的欲望；有大量的时间，也容易陷入低效的状态。</li>
<li>心智带宽虽足，但若不运行有效的人生程序，自然也是白费。</li>
<li>如果你的人生有如此好运，一切都很富足，不妨想办法给自己设限，适当制造稀缺，以成就自己。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="你的坏情绪，源于视角单一"><a href="#你的坏情绪，源于视角单一" class="headerlink" title="你的坏情绪，源于视角单一"></a>你的坏情绪，源于视角单一</h3><ul>
<li><p>事实上，在面对各种困境的时候，多角度看问题的能力往往是考验解决问题能力的关键</p>
</li>
<li><p>那些习惯从单一角度识人的人，往往比较单纯，也更容易受伤，本质上是因为他们缺乏多角度认知事物的意识。</p>
</li>
<li><p>一个人的性格和脾气好不好，也取决于他多角度看问题的能力：视角单一的人容易固执、急躁和钻牛角尖，而视角多元的人则表现得更为智慧、平和与包容。</p>
</li>
<li><p>我们每个人因为生活环境不同、经历不同、学识不同，所以在看待同一个问题时，理解层次和还原程度也不尽相同。</p>
</li>
<li><p>如果你确定自己的相机比他们的更高级，那就应该有“向下兼容”的意识——要么对其一笑而过，要么拿出自己的高清照片，耐心地向他们讲解什么是更好的，而不是一味地指责对方拍出来的东西很糟糕。毕竟低层的事物不会也不能向上兼容，但我们通过引导，让它们不断升级倒是有可能的。如果自己也曾有一台“落后的相机”，那就更应该体会和包容对方的立场。</p>
</li>
<li><p>在“相机”这件事情上，我们一定要保持觉知，要清醒地意识到自己的视角偏误，时刻做好向上升级、向下兼容的准备。拥有这种心态，不仅我们自己能越来越完善，还能与其他人都合得来。</p>
</li>
<li><p>不要被原始视角束缚，主动转换视角可能会看到一个新天地。</p>
</li>
<li><p>要想拥有多视角能力，就要进行刻意练习，直到形成新的路径依赖</p>
</li>
<li><p>一是勤移动。顾名思义，就是多移动你的“相机”机位，尝试用不同的视角看问题。比如设身处地地站在孩子的角度、老人的角度、对手的角度看问题，而不是仅凭自己的感受就直接认定孩子不懂事、老人不体谅、对手不讲理。</p>
</li>
<li><p>在焦虑、紧张的时候，不妨假设自己是一个局外人，用第三视角来观察自己，你会发现自己的很多担心其实是多余的，因为别人并不是那么在乎你。</p>
</li>
<li><p>如果陷入悲伤，无法自拔，那就假设自己处于十年之后，用未来视角反观现在，你会发现当下的悲伤没有任何意义，还不如收起情绪好好干活。</p>
</li>
<li><p>这种多视角观察的能力其实就体现了元认知能力。有了元认知，我们更容易在自我观察上保持觉知，进而在语言表达上也体现出“高情商”的特质。</p>
</li>
<li><p>二是善学习。</p>
</li>
<li><p>三是要开放。</p>
</li>
<li><p>忘我地聆听对方的想法。过程中没有判断、没有辩论、没有对错，把自己完全置身在对方的位置，以对方的眼睛来看世界；第二步，从“我”的角度来分享，过程中只说自己的客观感受，而不指责对方或告诉对方该怎么做。比如，说“家里满地臭袜子，我觉得精神紧张，心里很不舒适”，而不是“家里满地都是臭袜子，你不觉得难受吗”。</p>
</li>
<li><p>四是寻帮助。</p>
</li>
<li><p>原来出现特殊情况时，飞行员的注意力会被巨大的危险所俘获，心智带宽降低，容易陷入单一视角，而此时，指挥员可以给飞行员提供有效的外部视角，帮助他们更好地处置特殊情况。</p>
</li>
<li><p>同理，当我们对情绪问题或工作问题百思不得其解的时候，不要一个人闷头苦想，要学会主动寻求外部帮助，借助他人的多维视角来克服自己单一视角的局限。</p>
</li>
<li><p>五是多运动。</p>
</li>
<li><p>适当的有氧运动会提升我们体内多巴胺的水平，而多巴胺对于创造力和多角度思考能力来说都很重要。锻炼不仅能帮我们从负面情绪中快速走出来，也会引导大脑从新的角度看待事物，或者从不同角度观察问题，所以，越是心情不好的时候就越要多运动，越是想不通的时候越要多运动。</p>
</li>
<li><p>六是常反思。</p>
</li>
<li><p>通过写作抚平自己的内心，</p>
</li>
<li><p>无论什么时候，你的笔或键盘都能帮你跳出单一视角，看到更多维度。</p>
</li>
</ul>
<h3 id="第三节-游戏心态：幸福的人，总是在做另外一件事"><a href="#第三节-游戏心态：幸福的人，总是在做另外一件事" class="headerlink" title="第三节　游戏心态：幸福的人，总是在做另外一件事"></a>第三节　游戏心态：幸福的人，总是在做另外一件事</h3><ul>
<li><p>“先别减速，等跑到前面10米那个地方再减速也不迟。”等我跑到那个点后，我的目光又落到了前面的10米处，我觉得这样的距离很短，还可以继续来一次，等跑到那个点后，我又把眼光投向下一个10米处</p>
</li>
<li><p>幸福源自主动掌控现代积极心理学中，最引人瞩目的莫过于爱德华·德西和理查德·瑞恩的“自我决定理论”了。它指出人类有三种天生的内在需求：关系需求、能力需求和自主需求</p>
</li>
<li><p>一个人想要生活幸福，需要具备以下因素。·有良好的人际关系，得到别人的爱与尊敬；·有独特的本领、技能，为他人带去独特价值；·有自主选择的权力，能做自己想做的事情。</p>
</li>
<li><p>特别是“自主需求”，它是自我决定理论的关键与核心。也就是说，我们如果能主动选择和掌控所做的事情，就会产生内在动力，获取幸福。</p>
</li>
<li><p>放眼现实生活，我们总是要面对很多“不想做但必须做”的事情。比如1 500米跑步考核、堆积如山的作业、不得不洗的衣服、不得不见的人、不得不做的工作……面对这些事情，我们会不自觉地感到沮丧、抗拒和排斥，因为这些都不是我们自己主动做出的选择，而是外界给的压力。</p>
</li>
<li><p>我并不是在做这件事，我只是在做另外一件事。</p>
</li>
<li><p>我并不是在做跑步测试，我只是在玩追逐游戏；·我并不是在写作业，我只是在挑战自己的速度；·我并不是在洗衣服，我只是在活动自己的手脚；·我并不是去见领导，我只是和一个普通人聊天；·我并不是为老板做事，我只是为了提升自己。</p>
</li>
<li><p>事情本身并不重要，我们只是在通过它获取另外一种乐趣，顺便把这件事给做了。在心理学上，这个方法叫作“动机转移”。</p>
</li>
<li><p>缺乏觉知的人，其行事动机通常都由外部事物牵引，少有自主选择和掌控的余地，容易陷入“为做而做”的境地。但有觉知的人会适时觉察自己的行事动机是否停留在与目标任务无关的外部事物上，如果是，他们就主动想办法将其转移到内部，以拥有自主选择和掌控的能力，而这种掌控的窍门基本上可以分为两类：为自己而做和为玩而做。</p>
</li>
<li><p>为自己而做产生内部动机最好的方式莫过于立足于让自己变好。</p>
</li>
<li><p>而真正希望通过写作建立影响力的人是不会完全被“稿酬”“流量”等外部动机束缚的，他们往往是为自己的成长而写、为众人的需求而写、为长远的价值而写、为创造一个属于自己的世界而写。即使没有鲜花和掌声，他们也会坚持输出和成长，收获的反馈和奖励都只是意外和惊喜，不是必然和期待。</p>
</li>
<li><p>这道理不仅适用于个人层面，企业发展也是如此。比如华为公司之所以坚持不上市，就是不希望企业的发展动机被外部力量控制。如果公司上市，虽然可以在短时间内身价暴涨，但它将不可避免地把眼光放到下个季度的财报上。</p>
</li>
<li><p>那些对内在动机更敏感和坚持的人，总会与众不同。他们不会为外界的奖励或评价而刻意表现，只会为自己的成长和进步而努力进取，这样的人很难被困难击倒。</p>
</li>
<li><p>当人的注意力都在享受上时，他对跑步的心态就不一样了。相比起来，别人为了身材和身体苦苦坚持，而他只是享受愉快的跑步过程。</p>
</li>
<li><p>而我除了把跑步当成玩，其他很多事在我眼里也都是玩。比如阅读这件事。我从来不认为自己是在阅读，而是设想自己在和智者聊天。每本书在我眼里都是一个人，而我的书架就是智者朋友圈</p>
</li>
<li><p>为自己而做，通常是为了应对外部的压力和要求，为玩而做，则是为了应对重复、枯燥的事情</p>
</li>
<li><p>成长啊，有时候要看长远，让自己明白意义，心生动力；有时候要看得近些，让自己不惧困难，欢快前行。</p>
</li>
<li><p>这个世界的模样取决于我们看待它的角度</p>
</li>
<li><p>事实上，人是一种自我解释的动物，世界的意义是人类赋予的。既然做事情就是赋予意义的过程，那我们为什么不赋予它们有用又好玩的意义呢？</p>
</li>
<li><p>为自己而做可以解放情绪，为玩而做可以解放注意力</p>
</li>
</ul>
<h2 id="第八章-早冥读写跑，人生五件套——成本最低的成长之道"><a href="#第八章-早冥读写跑，人生五件套——成本最低的成长之道" class="headerlink" title="第八章 早冥读写跑，人生五件套——成本最低的成长之道"></a>第八章 早冥读写跑，人生五件套——成本最低的成长之道</h2><h3 id="第一节-早起：无闹钟、不参团、不打卡，我是如何坚持早起的"><a href="#第一节-早起：无闹钟、不参团、不打卡，我是如何坚持早起的" class="headerlink" title="第一节　早起：无闹钟、不参团、不打卡，我是如何坚持早起的"></a>第一节　早起：无闹钟、不参团、不打卡，我是如何坚持早起的</h3><ul>
<li><p>日本作家中岛孝志写的《4点起床：最养生和高效的时间管理》这本书。</p>
</li>
<li><p>浅层非快速眼动睡眠与快速眼动睡眠的组合。根据这一规律，人在睡眠后的3小时、4.5小时、6小时、7.5小时这几个节点醒来，就会觉得神清气爽，精力充沛。我对早起的实践就是从对这个理论的神奇体验开始的。</p>
</li>
<li><p>这个理论让我明白了为什么有时候我们睡了很长时间，但醒来后还是精神不佳，原因就是醒来的时机不在睡眠节点上，而是在睡眠周期中。</p>
</li>
<li><p>放弃闹钟。</p>
</li>
<li><p>中岛孝志说：“闹钟不会照顾你的睡眠周期，时间一到，就会把手伸进你的脑子里，让你的脑子发生一场大地震，潜意识会被搅得一团糟。因为你是被闹钟吵醒的，大脑深处其实还睡着，所以明明睡了8小时，可总会觉得没睡饱，整个人昏昏沉沉的。”</p>
</li>
<li><p>而当我有了感知睡眠节点的能力和习惯后（大约用了两周），根本不用担心醒不过来或错过正常的起床时间，这个生物时钟非常准。</p>
</li>
<li><p>放弃闹钟的另一个好处是，不影响家人或室友的休息，这样更容易得到他们的支持。</p>
</li>
<li><p>抓住大脑工作的高峰期。</p>
</li>
<li><p>分泌高峰期正好是早上7点左右，这时，人的工作效率非常高。人体进食后，能量也会在1小时后转变为葡萄糖，输送到大脑，人的记忆力、理解力就会提高，大脑的运转速度会迎来峰值，直至4小时后才降到谷底。所以人们要顺应规律，抓住效率高峰期，把最困难的工作放在这个时间段完成，就能达到事半功倍的效果。另外，正常吃早餐的人，上午的工作效率更高（午饭后的效率峰值在14点到16点间出现）。</p>
</li>
<li><p>一旦认知上想通想透了，行动时就不需要用大把大把的意志力来支撑了。</p>
</li>
<li><p>相比在7点左右起床，我每天多出了2小时，按一天8小时工作时长计算，每年可以多出约90个工作日，如果坚持40年，就相当于一个人全年无休工作10年。</p>
</li>
<li><p>有了这些不被打扰的时间，我可以高效地做下面这些事情。一　规划。利用10分钟左右的时间，罗列全天的工作，对它们进行排序，这样可以让自己保持头脑清晰，对全天的时间产生一种掌控感，保证自己的工作不会走弯路。二　跑步。我个人习惯起床后先跑步，毕竟此时大脑还没完全苏醒，直接进行脑力活动可能不容易迅速进入状态，但跑完步之后再冲个热水澡，精神状态就完全不同了，身体的每个细胞都被激活了，此时再读书写作就会很轻松。这种精神状态会延续到上午，当大家正常起床懵懵懂懂地去上班时，自己已经精神抖擞了。早起跑步可以让自己整个上午都享受身体的轻盈感，冬天会更耐寒。经过长期的锻炼，身型和体质也会得到极大的改善。另外，早起后，大部分人还都在睡梦中，我就可以独自一人享受晨间的静谧，这种感觉非常美妙，不会像夜间锻炼那样，经常遇到熟人而需要不停地打招呼，使锻炼效率变得很低。三　反思。这是我给自己定的功课，每天复盘一些工作、梳理一些思绪，或把一些心得感受记录下来。这么做可以很好地提升自己。四　读书或写作。平时受家庭及工作的影响，我很少有大块的时间进行自我提升，因此，早起后的这些时间非常宝贵，我的很多文章就是在这个时间段写的。五　困难的工作。我有时也会把一些困难的任务放在这个时间段攻克，通常效率会很高。早上上班的时候，那种完成了最困难的工作的心情令我从容和愉悦，这样，我就可以在很轻松的状态下做些超前或拓展性工作。以上是我目前主要的收获：清晰的时间安排、强健的体魄、良好的精神状态、不受干扰的锻炼氛围、专注的学习环境、从容的工作心态、持续的个人成长等。</p>
</li>
<li><p>除此之外，生活中焦虑也减少了很多。长期的坚持也增强了我的毅力，更重要的是，到了晚上10点，我就想着爬上床了，熬夜的恶习彻底改正。如果没有养成早起的习惯，我肯定还处于那个熬夜成性、无精打采、忙忙碌碌、无所长进的状态，不敢想象5年或10年之后会成什么样子。</p>
</li>
</ul>
<h3 id="第二节-冥想：终有一天，你要解锁这条隐藏赛道"><a href="#第二节-冥想：终有一天，你要解锁这条隐藏赛道" class="headerlink" title="第二节　冥想：终有一天，你要解锁这条隐藏赛道"></a>第二节　冥想：终有一天，你要解锁这条隐藏赛道</h3><ul>
<li>普通人和聪明人最大的能力差异是什么？是长时间保持极度专注的能力。</li>
<li>能够迅速进入专注状态，以及能够长期保持专注状态，是高效学习的两个最重要的习惯。</li>
<li>科学研究表明，通过这种集中注意力的冥想练习，人大脑皮层表面积增大，大脑灰质变厚，这意味着这种练习可以从物理上让我们变得更加聪明，因为一个人大脑皮层表面积和大脑灰质厚度是影响人聪明程度的因素。</li>
<li>闭眼静坐，专注于自己的呼吸，每天持续15分钟以上……你会感受到它的效果。</li>
<li>把心中的困惑写出来的原因，因为只要写出来，那些紧张、担忧、畏惧、害怕等情绪就会在清晰的观察下无处遁形，小球的重量自然会减轻</li>
</ul>
<h3 id="第三节-阅读：如何让自己真正爱上阅读"><a href="#第三节-阅读：如何让自己真正爱上阅读" class="headerlink" title="第三节　阅读：如何让自己真正爱上阅读"></a>第三节　阅读：如何让自己真正爱上阅读</h3><ul>
<li><p>想要快速成为一个行业的高手，最好的方法就是和行业专家交流，直接向他们请教</p>
</li>
<li><p>但现实是普通人很少有这样的机会和资源。</p>
</li>
<li><p>书籍是传承思想的最好介质，顶级的思想都能从书籍中找到，只要选书得当，就能以极低的成本找到行业里顶级的思想。</p>
</li>
<li><p>阅读可以让我们的思维能随时与顶级的思想交锋，对一个主题进行深度全面的理解，并与自己的实际充分关联，这种思维状态在平淡生活中是很少有的，但是只要拿起书本就可以马上拥有</p>
</li>
<li><p>一　读书要先学会选书。</p>
</li>
<li><p>选书比读书本身更重要。</p>
</li>
<li><p>多关注那些经过时间检验的书籍通常不会错。</p>
</li>
<li><p>二　阅读是为了改变。</p>
</li>
<li><p>真正读好一本书，往往需要花费数倍于阅读的时间去思考和实践，并输出自己的东西——可能是一篇文章，也可能是养成一个习惯——这个过程比阅读本身要费力得多。</p>
</li>
<li><p>从权重上看，阅读量&lt;思考量&lt;行动量&lt;改变量。阅读仅仅是最表层的行为，最终的目的是通过思考和行动改变自己。</p>
</li>
<li><p>阅读的深度比速度重要，阅读的质量比数量重要。读得多、读得快并不一定是好事，这很可能是自我陶醉的假象</p>
</li>
<li><p>只要紧紧盯住“改变”这个根本目标，很多阅读障碍就会立即消失</p>
</li>
<li><p>三　高阶读书法。</p>
</li>
<li><p>第一个是要特别注意自己在阅读时产生的关联。</p>
</li>
<li><p>第二个是读写不分家。如果你在阅读后还能把所学知识用自己的语言重新阐释，甚至将它们教授给他人，那这个知识将在你脑中变得非常牢固。</p>
</li>
<li><p>用一生的时间去探索、实践。</p>
</li>
</ul>
<h3 id="第四节-写作：谢谢你，费曼先生"><a href="#第四节-写作：谢谢你，费曼先生" class="headerlink" title="第四节　写作：谢谢你，费曼先生"></a>第四节　写作：谢谢你，费曼先生</h3><ul>
<li><p>向一个没有任何背景知识的人说清楚一件事是很难的。正因为这种有意无意的训练，费曼养成了一种独特的思维习惯。在从事物理研究的时候，他也会要求同事在向他汇报或者解释一个新事物时，必须用最简单的话来讲清楚。一旦解释过于冗余或者复杂，就说明他根本没有理解透彻。所谓费曼技巧就是通过自己的语言，用最简单的话把一件事情讲清楚，最好让外行人也能听懂。</p>
</li>
<li><p>这就不难理解为什么我们每个人都天生喜欢轻松愉快和简单的事情，比如在读书或读文章的时候，我们往往更愿意听故事而不是听道理。只要想明白了这一点，我想任何写作的人都会调整自己的创作方式。</p>
</li>
<li><p>先用合适的故事引起对方“感性小人”的兴趣和注意，然后把想要表达的道理通过“感性小人”转达给“理性小人”</p>
</li>
<li><p>特别是讲知识、讲道理的书籍，最好不要随意堆砌抽象概念，让人感觉很高深，看得云里雾里的。如果上来就摆图表、讲模型、说概念，或许“理性小人”没什么意见，但“感性小人”早就不耐烦了，于是他拉起“理性小人”的手说：“没意思，我们走吧。”“感性小人”的力气很大，所以说教式的写作很难吸引读者。当然，我们也不能成为“标题党”，把人吸引过来之后，又没有什么实质性的内容，这样，“理性小人”也会不满意。</p>
</li>
<li><p>能用简单的语言就不要用复杂的，这就是费曼技巧的核心之一。不过，简单不仅仅意味着轻松，还意味着简洁和形象。</p>
</li>
<li><p>我们大多数人都低估了类比（比喻）的作用，认为它只是文学中的一种修辞，事实上，它是我们的思维方式，更是我们的认知工具。</p>
</li>
<li><p>认知语言学科的创始人乔治·莱考夫曾这样定义和评价“类比”。以一种事物认知另一种事物，恰恰是学习的本质！</p>
</li>
<li><p>因为人类只能通过已知事物来解释未知事物，我们很难凭空去理解一个自己从未见过的东西。而类比，正是连接未知事物与已知事物的桥梁。</p>
</li>
<li><p>用自己的语言</p>
</li>
<li><p>费曼技巧的另一个核心就是“用自己的语言表达”，这一点比“用简单的语言表达”更为关键和奇妙。因为只有当我们使用自己的语言去解释所学时，才会真正调动自己原有的知识，才能将松散的信息编织成紧密的体系和网络，甚至创造新的认知。换言之，用自己的语言重新表达就是在调动自己的千军万马。</p>
</li>
<li><p>一个人想要真正成长，一定要学会写作，因为“只读不写”的学习是不完整的，是低效的。而写作时如果不学会用自己的语言转述，则是无用的。</p>
</li>
<li><p>因为“教”才是最好的“学”。教授他人会逼迫我们通过自己的语言，用最简单的话把一件事情讲清楚，甚至让外行人也能听得懂，而写作的优势就在于它可以让我们在磨炼这项技能的路上不断调整、反复修改，直至自己满意。</p>
</li>
</ul>
<h3 id="第五节-运动：灵魂想要走得远，身体必须在路上"><a href="#第五节-运动：灵魂想要走得远，身体必须在路上" class="headerlink" title="第五节　运动：灵魂想要走得远，身体必须在路上"></a>第五节　运动：灵魂想要走得远，身体必须在路上</h3><ul>
<li><p>好的事物往往是“正相关”的</p>
</li>
<li><p>因为运动能够调节人体的各种激素，使人达到最佳状态，使身体这个内部生态系统充满能量和活力。时常运动的人，体内生态系统犹如一汪清泉，而久坐不动的人，体内生态系统则更像是一潭死水。</p>
</li>
<li><p>一个长期缺乏运动的人可能会变“笨”。</p>
</li>
<li><p>运动能够使大脑长出更多的新的神经元，这意味着运动可以在物理上让人变得更“聪明”。</p>
</li>
<li><p>由此可以做出如下推演：运动不仅能使人身材更好、精神更佳，同时能增强大脑功能，提升注意力、记忆力、理解力、自制力，从而增强学习效果，让人创造更大的成就，获取更多资源。</p>
</li>
<li><p>好的模式是“运动+学习”</p>
</li>
<li><p>运动不是关键，运动之后的活动安排及环境刺激才是关键。</p>
</li>
<li><p>有效的模式是这样的：在运动后的1~2小时内进行高强度、高难度的脑力活动，比如阅读、解题、背记、写作、编程，等等，或是一些需要复杂技巧的体力活动，诸如舞蹈、钢琴，以及参加不同于以往的社交活动，如接触新的环境、人物或事物，这么做可以让新的神经元受到刺激，不断生长。换句话说，运动之后，脑子需要充分接受考验或挑战，才能让自己不断地变“聪明”。</p>
</li>
<li><p>“运动+学习”的模式需要坚持，因为新的神经元从生长到成熟通常需要28天</p>
</li>
<li><p>所以绝大多数运动者的硬伤就在这里：运动之后缺乏主动学习的意识和习惯。他们习惯于在运动后看电视、刷手机、玩游戏、逛街、聚会、和朋友们闲聊，甚至直接睡觉，做那些无须动脑或让自己感到很舒服的事。真的很遗憾，那些好不容易生长出来的神经元随即消散，他们因此错失了变“聪明”的机会。</p>
</li>
<li><p>比如在10分钟的有氧热身之后练习瑜伽、舞蹈、体操、太极，等等，这些复杂的活动能让大脑的全部神经细胞参与其中。活动越复杂，神经突触的联系也就越复杂，突触生长也更密集，所以好的运动方式一定同时包含有氧运动和复杂运动</p>
</li>
<li><p>运动更大的意义不在于健身而在于健脑，它不仅能使人更加乐观，还能使头脑更加灵活，最终使健康水平和认知水平实现双重提升。</p>
</li>
<li><p>语言是会影响思维的，“四肢发达，头脑简单”这句话应该修改为“四肢发达，头脑更发达”才合理，而身体和灵魂也并非只能二选一，你不能只学习不运动，或只运动不学习，也不能随心情交替进行这两项活动。我相信你现在肯定更倾向于这样的表述：灵魂想要走得远，身体必须在路上。认知越清晰，行动越坚定。从现在开始，给自己的运动计划赋予一个新的意义吧！</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/10/23/20241023-jin-qian-ye-wu-shu-ju-ku-shi-wu-xiang-guan-yao-dian-ji-lu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/10/23/20241023-jin-qian-ye-wu-shu-ju-ku-shi-wu-xiang-guan-yao-dian-ji-lu/" itemprop="url">金钱业务数据库事务相关要点记录</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-10-23T15:59:48+08:00">
                2024-10-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="表结构"><a href="#表结构" class="headerlink" title="表结构"></a>表结构</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `user_balance` (</span><br><span class="line">`user_id` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;用户ID&#x27;</span>,</span><br><span class="line">`coin` <span class="type">bigint</span>(<span class="number">20</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;余额&#x27;</span>,</span><br><span class="line">`create_time` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line">`update_time` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;更新时间&#x27;</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (`user_id`),</span><br><span class="line">KEY `idx_updatetime` (`update_time`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 COMMENT<span class="operator">=</span><span class="string">&#x27;账户余额表&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `user_balance_log` (</span><br><span class="line">`log_id` <span class="type">bigint</span>(<span class="number">20</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT COMMENT <span class="string">&#x27;流水id&#x27;</span>,</span><br><span class="line">`order_id` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;业务订单ID&#x27;</span>,</span><br><span class="line">`user_id` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;用户ID&#x27;</span>,</span><br><span class="line">`type` tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;1：加，2：减&#x27;</span>,</span><br><span class="line">`coin` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;变更金额&#x27;</span>,</span><br><span class="line">`coin_after` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;变更后的金额&#x27;</span>,</span><br><span class="line">`create_time` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (`log_id`),</span><br><span class="line">KEY `idx_createtime` (`create_time`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 COMMENT<span class="operator">=</span><span class="string">&#x27;账户余额表流水表&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `user_balance`(`user_id`, `coin`, `create_time`, `update_time`) <span class="keyword">VALUES</span> (<span class="string">&#x27;kxw&#x27;</span>, <span class="number">20000000</span>, <span class="string">&#x27;2024-10-23 00:00:00&#x27;</span>, <span class="string">&#x27;2024-10-23 00:00:00&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">UPDATE</span> `user_balance` <span class="keyword">SET</span> `coin`<span class="operator">=</span> `coin` <span class="operator">-</span> <span class="number">1000</span> <span class="keyword">WHERE</span> `user_id` <span class="operator">=</span> <span class="string">&#x27;kxw&#x27;</span> <span class="keyword">AND</span> `coin` <span class="operator">&gt;=</span> <span class="number">1000</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="操作用户余额时注意"><a href="#操作用户余额时注意" class="headerlink" title="操作用户余额时注意"></a>操作用户余额时注意</h2><ol>
<li>可重复读（记录扣费后余额快照）(select <code>coin</code> 后记录到user_balance_log表的<code>coin_after</code>)</li>
<li>乐观锁（扣费冲突）（set <code>coin</code> - 1000 where <code>coin</code> &gt;&#x3D; 1000）</li>
<li>业务幂等（不同业务使用相应的订单表）</li>
<li>事务（用户余额表<code>user_balance</code>、日志流水表<code>user_balance_log</code>、业务订单表绑定）</li>
<li>canal 监听 binlog 识别业务异常 (对比 binlog监听的<code>user_balance</code>表<code>coin</code>变化量 和 <code>user_balance_log</code>的 <code>coin</code>记录总量 是否一致)</li>
</ol>
<h2 id="流水表只需要记录coin-after"><a href="#流水表只需要记录coin-after" class="headerlink" title="流水表只需要记录coin_after"></a>流水表只需要记录coin_after</h2><h3 id="事务过程"><a href="#事务过程" class="headerlink" title="事务过程"></a>事务过程</h3><table>
<thead>
<tr>
<th>事务1</th>
<th>事务2</th>
</tr>
</thead>
<tbody><tr>
<td>BEGIN;</td>
<td></td>
</tr>
<tr>
<td></td>
<td>BEGIN;</td>
</tr>
<tr>
<td>SELECT * FROM <code>user_balance</code> WHERE <code>user_id</code> &#x3D; ‘kxw’; (coin&#x3D;20000000)</td>
<td></td>
</tr>
<tr>
<td>UPDATE <code>user_balance</code> SET <code>coin</code>&#x3D; <code>coin</code> - 1000 WHERE <code>user_id</code> &#x3D; ‘kxw’ AND <code>coin</code> &gt;&#x3D; 1000;</td>
<td></td>
</tr>
<tr>
<td></td>
<td>SELECT * FROM <code>user_balance</code> WHERE <code>user_id</code> &#x3D; ‘kxw’; (coin&#x3D;20000000)</td>
</tr>
<tr>
<td></td>
<td>UPDATE <code>user_balance</code> SET <code>coin</code>&#x3D; <code>coin</code> - 1000 WHERE <code>user_id</code> &#x3D; ‘kxw’ AND <code>coin</code> &gt;&#x3D; 1000;</td>
</tr>
<tr>
<td>SELECT * FROM <code>user_balance</code> WHERE <code>user_id</code> &#x3D; ‘kxw’; (coin&#x3D;19999000)</td>
<td></td>
</tr>
<tr>
<td>COMMIT;</td>
<td></td>
</tr>
<tr>
<td></td>
<td>SELECT * FROM <code>user_balance</code> WHERE <code>user_id</code> &#x3D; ‘kxw’; (coin&#x3D;19998000)</td>
</tr>
<tr>
<td></td>
<td>COMMIT;</td>
</tr>
</tbody></table>
<ul>
<li>流水表只需要记录<code>coin_after</code>（变更后的余额）即可，因为变更前的余额，可能因为并发导致不准确，除非开启事务后，使用<code>select for update</code>来查询，而不是用普通的快照读</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/10/22/20241022-jian-dan-ji-lu-wo-zai-ji-jia-gong-si-de-jing-li/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/10/22/20241022-jian-dan-ji-lu-wo-zai-ji-jia-gong-si-de-jing-li/" itemprop="url">简单记录我在几家公司的经历</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-10-22T14:36:03+08:00">
                2024-10-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li><p>经历了一次大家普遍觉得“没考好”的高考后，我补录进入了广州一家末流的一本学校。出身于广东四五线城市的普通家庭，在高考前我并没有认真研究自己想要选择的专业。经过简单的网上搜索就业率后，我选择了网络工程这个专业。当时我并不认为这个专业与编程有什么关联，甚至可以说我对编程一无所知。</p>
</li>
<li><p>进入大学后，习惯于自学的我感到如同置身地狱（初中和高中时期我都是习惯自己看书、解题，几乎很少主动向老师请教）。现在回想起来，这种极端的习惯可能是我未能进一步提升，或走了一些弯路的原因。之所以称之为“地狱难度”，是因为我真的一无所知，只知道努力却无法抓住重点。在大学里，没有明确的方向，学习的内容繁多而杂乱。</p>
</li>
<li><p>另一方面，我也得为自己辩解一下。中国的大学（我没有见识过其他国家的情况）计算机专业的教育在一定程度上与社会脱节。缺乏引路人或足够的主动性和渴望，很难在未来的就业中具备足够的竞争力。当然，那时的网络没有现在这么发达，优质的教程较为匮乏。因此，我始终相信年轻人会越来越聪明，只要愿意学习，网络上有很多免费的优质资源，能够帮助我们少走很多弯路。毕竟，站在巨人的肩膀上学习，可以大大提高效率，节约时间。</p>
</li>
</ul>
<h2 id="毕业进入第一家公司-V"><a href="#毕业进入第一家公司-V" class="headerlink" title="毕业进入第一家公司 V"></a>毕业进入第一家公司 V</h2><blockquote>
<blockquote>
<p>时长：两年<br>社会经验尚浅，没有好好体会和感受就离开了。<br>个人成长：业务和技术启蒙，基本开发技术和业务流程的熟悉与掌握，大公司职场的适应。</p>
</blockquote>
</blockquote>
<ul>
<li><p>我首先要感谢三个人：飞哥、龙哥和强哥。</p>
</li>
<li><p>飞哥是我关系最好的同事，我们在工作中配合默契，工作之外也相处得非常融洽。他曾告诉我：“我不是来工作的，我是来交朋友的。”随着年龄的增长，我越来越认同，对于绝大多数人来说，人脉确实非常重要。</p>
</li>
<li><p>龙哥回想起来应该是我当时工作中的业务小组长。由于刚参加工作，我对这个角色并没有太多概念，我们平常就像普通同事那样相处。龙哥像大哥一样指导我解决工作中的问题，也会和我讨论业务和技术，推荐阅读技术书籍，鼓励我相信自己的学习能力，多读英文书，获取一手资料。工作之外，我们也常常开玩笑，偶尔一起出去吃下午茶。</p>
</li>
<li><p>强哥是我遇到的技术能力最强的同事，思维敏捷、动手能力出众。我现在的许多工作习惯都是向他学习的。强哥当时负责组内的基础建设，算是技术含量最高的小组。我后来主动去学习，并自然地加入了这个小组。虽然强哥有时显得严肃，但可能是对某些事情无法忍受。聪明的人有时会觉得与不太聪明的人共事很困难，因此难免会有些暴躁，现在我偶尔也能体会到这种感觉。与强哥的故事并未结束，后来我还跟着他一起创业了一段时间。</p>
</li>
<li><p>在这里，我交到了最多的朋友，大家都非常友好。</p>
</li>
</ul>
<h2 id="第二家公司-U"><a href="#第二家公司-U" class="headerlink" title="第二家公司 U"></a>第二家公司 U</h2><blockquote>
<blockquote>
<p>时长：一年三个月<br>技术基础较好的公司，但气氛却比较压抑，难以适应。<br>个人成长：学习能力和方法，技术基础原理的积累。</p>
</blockquote>
</blockquote>
<ul>
<li><p>在这里，我遇到了两个不错的同事，阿舜和阿君。总体来说，我与某些同事相处得较好，但总感觉有些同事特别冷漠，虽然不是故意的，似乎普遍存在社交恐惧，平常默默去食堂吃饭也不打招呼。可能是性格、职业属性、职场压力和公司文化等多方面原因，我个人的感受比较压抑。</p>
</li>
<li><p>作为国内前几的大公司，里面确实汇聚了很多人才和技术沉淀，光是在内网的论坛上就能学到不少知识。</p>
</li>
<li><p>此外，我在这家公司体验到了大公司内部创业的团队模式，以及组织架构调整和人员变动的经历。</p>
</li>
</ul>
<h2 id="第三家公司-D"><a href="#第三家公司-D" class="headerlink" title="第三家公司 D"></a>第三家公司 D</h2><blockquote>
<blockquote>
<p>时长：三个月<br>一家创业公司，最累但也是最开心的时光，同事相处融洽。<br>个人成长：技术管理者全局思考能力的培养，技术规划等经验。</p>
</blockquote>
</blockquote>
<ul>
<li><p>加入这家公司是前一家公司的强哥邀请的，他是团队的创始人之一，后来他也辞去了前公司的职务，全职加入。</p>
</li>
<li><p>团队规模较小，大约十三人，其中开发人员七个，没有专门的测试人员。虽然我只在这里待了三个月就宣布解散，但还是体验到了创业公司的开放与忙碌，当然也有混乱和无奈等。团队的技术人员经验虽然较浅，但各有优点和潜力。其中阿韬是我邀请到下家公司一起共事的。</p>
</li>
</ul>
<h2 id="第四家公司-K"><a href="#第四家公司-K" class="headerlink" title="第四家公司 K"></a>第四家公司 K</h2><blockquote>
<blockquote>
<p>时长：六年<br>收入最多，但在大公司光环下却是一个相对奇葩的小作坊。在这里，我的个人能力得到了充分发挥。<br>个人成长：各方面能力的积累与提升，职场经验和事务处理的积累。</p>
</blockquote>
</blockquote>
<ul>
<li><p>不确定是什么原因，前期技术和业务能力的积累、个人职业能力的成熟、对职场规则的理解，还是这里人才密度不足的影响。在这里，我的职业发展如鱼得水。在六年中经历了多次组织调整和三四次换领导，我也开始带领小规模的技术团队。在这段时间，我得到了同事们不同程度的认可，六年来每年的绩效都是优秀或以上。</p>
</li>
<li><p>我认为有几个因素促成了这一点：遇到优秀的领导、扎实的个人技术能力、良好的透明沟通等。最核心的窍门在于，在正确的职场价值观前提下，常常换位思考，这样基本能做出合理的选择。当然，有时在某些原则下可能会产生冲突和不愉快，或许有更好的处理方式，但我个人尚未掌握，某些方面也不想耗费额外时间，显得比较直接。另外，我的行事风格也在增加自己的“可替代性”。</p>
</li>
<li><p>在这里，我结识了许多关系良好的同事，毕竟待了很多年。其中，特别提到阿拳、阿杰和阿韬。</p>
</li>
<li><p>阿拳是我偶然发现的校友，比我小一届。有些人天然有种默契，眼神一对，自然而然就成了好朋友。他是一个喜欢技术挑战，渴望提升自己能力的人，但似乎在职场上的投入和专注不足，始终未能如愿。经历了换团队后，他也没有改观，最终离开了，加入了其他公司。现在看到他职业发展越来越好，生活也越来越丰富，我意识到，合适的环境和机遇对我们来说确实很重要。</p>
</li>
<li><p>阿杰是我刚加入公司时的同事，后来换团队后的领导。他与之前的领导不同，比较平易近人，尽量将公司的各种政策和职场潜规则向我们说明白。尽管身处职场，他总能从一个打工人的角度保持良心。大多数情况下，我们的相处就像朋友一样。</p>
</li>
<li><p>阿韬是前公司 D 的同事，他给我留下的印象最深刻的就是人际关系很好，从未见他与任何人发生冲突，平常开朗，喜欢群体活动。加入公司后，除了工作，我们私下相处的时间也最多，成为了我最好的朋友。在公司，他的评价一直很好，大家有心事都会找他倾诉，我常戏称他为“中央空调”。在这里，虽然技术能力是基础，但大多数情况下，沟通能力更为重要。</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/07/24/20240724-tan-tan-jie-kou-diao-yong-zhong-de-xu-lie-hua-xie-yi/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/07/24/20240724-tan-tan-jie-kou-diao-yong-zhong-de-xu-lie-hua-xie-yi/" itemprop="url">谈谈接口调用中的序列化协议</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-07-24T16:27:09+08:00">
                2024-07-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<blockquote>
<p>接口调用存在于内部服务之间，也存在于客户端和服务端之间<br>既然涉及接口调用，必然就涉及到数据的序列化</p>
</blockquote>
</blockquote>
<h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><ul>
<li>什么是 RPC？<ul>
<li>RPC是”远程过程调用”(Remote Procedure Call)的缩写。这是一种计算机通信协议,允许程序调用另一个地址空间(通常是在其它计算机上)的子程序或过程,而程序员就像调用本地程序一样,无需额外地为这个交互作用编程。</li>
</ul>
</li>
<li>其实 RPC 不仅可以存在于内部服务之间，前端和服务端之间的交互也可以用 RPC</li>
</ul>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><ul>
<li>一般情况下，我们习惯于使用 idl 文件定义数据格式（比如 thrift 或 Protocol Buffer），然后使用 RPC（比如 gPRC 等）用于服务之间的调用；而使用 JSON 和 HTTP 作为前端和服务端的交互方式</li>
<li>这里提一点，回看 RPC 的定义，即使使用 JSON 作为序列化协议，也可以使用 RPC 作为接口调用，具体要看 RPC 框架的实现。</li>
</ul>
<h2 id="使用-RPC-和-IDL文件-的好处"><a href="#使用-RPC-和-IDL文件-的好处" class="headerlink" title="使用 RPC 和 IDL文件 的好处"></a>使用 RPC 和 IDL文件 的好处</h2><ul>
<li>本文只关注序列化方面相关的好处</li>
<li>举个例子，接口调用简单使用 HTTP + JSON；如果后续加字段，而调用方使用不规范，复用接口调用的返回对象用于业务的其他逻辑，而字段名刚好相同，则会冲突从而可能导致逻辑异常，这种低级错误无论是客户端还是服务端都经常发生</li>
<li>理论上每个接口都应该有单独的接口响应类，这样才不会在后续加字段时产生语义冲突,虽然写起来麻烦，但这是最规范最严谨的做法，所以自动化代码工具很重要</li>
<li>其中一种解决方式：使用 IDL 文件定义数据格式，并且通过 RPC 框架限制调用的返回对象不被随意设置，从而解决这种低级又容易忽视的错误</li>
<li>对 RPC 框架的要求：<ol>
<li>限制返回对象不被修改</li>
<li>排查工具完善，支持将数据转成可阅读格式（比如使用Protobuf二进制传输，将很难排查）</li>
<li>适配多种语言的客户端 sdk（包括客户端）</li>
</ol>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kingson4wu.github.io/2024/07/18/20240718-gao-xiao-hui-yi-de-chong-yao-xing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拉巴力的纸皮箱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2024/07/18/20240718-gao-xiao-hui-yi-de-chong-yao-xing/" itemprop="url">高效会议的重要性</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2024-07-18T12:13:08+08:00">
                2024-07-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>生命是以时间为单位的，浪费别人的时间等于谋财害命；浪费自己的时间，等于慢性自杀。 - 鲁迅</p>
</blockquote>
<ul>
<li>平常在工作中，有些同事在没有提前发会议主题和相关资料前，突然就拉一群人一起开会，方便了自己，却浪费了别人的时间。</li>
<li>比如一些不专业的产品为了节省自己的时间，也不做充分的会前准备，拉一堆开发给自己做需求完善员，对别人的时间极其不尊重。</li>
</ul>
<h2 id="高效会议"><a href="#高效会议" class="headerlink" title="高效会议"></a>高效会议</h2><ol start="0">
<li>能线下小部分人沟通清楚的，不必拉齐人一起开会</li>
<li>会前发相关资料，让潜在参与者提前了解</li>
<li>看完资料，可以发相关疑问，有些内容可以提前单独沟通</li>
<li>真正开会前发会议主题和目标</li>
<li>会有要有会议纪要，结论，执行人等</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Eew2WXHKskYR3VH35QTh4A">去TMD低效会议</a></li>
</ul>
<pre>
最近和几个大佬朋友聊天，大家不约而同的在吐槽公司开会效率低下的问题。



一提到开会，想必大家都会浮现各种场景，甚至有人可能要开始骂娘了吧？不断延长的会议时间，沉默的参会成员，语无伦次的会议组织者，不断跑偏的主题，一不小心一天就全在开会了。



what? 不仅一天全开会了，还没有任何有用的结论？



作为一个开会无数的互联网老鸟，针对高效开会，我有以下六点建议：



1.能不开会就不要开会



很多会其实根本没有开的必要，不少人平时不沟通，沟通全靠会议！



一旦开会出现几个人相互扯皮，你一句我一句的情况，基本可以断定这几个人平时就不怎么沟通，或者沟通有问题。



更为可怕的是，有些管理者，不开会就不知道自己要做什么！曾经我招过一个产品leader，热衷于组织各种会议，基本可以在会议室呆着不用出来的那种，但关键事情的推进都没落地。



具体注意点如下：

会议组织者还没完全想清楚之前，坚决不要开会

能定点沟通清楚的问题，坚决不要开会

能召集3，4个人花5分钟说清楚的事情，坚决不要开会



2.开小会，越小越好



会议人数尽量控制在7个人以内，人越多会议效率越低。有时候喊很多人开会，无非是出于显示你的权威或者逃避责任，潜台词是：反正大家都参加会议了，出了问题一起扛。



不知道大家注意过一个现象没有，不少微信群人少的时候，大家都很活跃，如果进来一些不说话的「潜水者」，大家也就慢慢都不说话了。



开会也是一个道理！如果有不太相关的人进来，他肯定会不怎么参与讨论，而其他人的思维活跃度都会受影响。



那么有人会问：如果会议就是需要很多人参与怎么办？可以将一个大的会议拆解成几个议题，分议题开小会。然后再把小会的决策者喊一起开会。



乔布斯就特别重视控制会议人数，在「疯狂的简洁」一书中记载了乔布斯一个小故事：「在一次和广告公司的例行会议上，乔布斯突然发现了一位名叫Lorrie的陌生的参会者，乔布斯指着Lorrie问到：“请问您是哪位？”，Lorrie解释自己需要听这个会议，但最后乔布斯还是礼貌的请Lorrie小姐离开了：“我不觉得你有必要参加这个会议，Lorrie小姐，谢谢。”」



我猜，Lorrie小姐估计也是暗爽的吧，毕竟她估计也是莫名其妙被拉到这个会议。



3.开会前做好充分准备



会议组织者需要把会议主题、会议背景、提前同步给所有参会人员，甚至需要提前进行答疑及相关沟通工作。



比如产品的技术评审会，不少产品经理可能没有提前发出原型做沟通。结果在会议上大家需要先理解原型，而不是上来直奔主题。



充分的准备工作，会让会议更加高效，大家坐下来开会的时候已经清楚所有信息，开门见山展开思辨，而不是一屋子人毫无准备甚至满头雾水。



4.能站着开，就别坐着开



比尔盖茨说过一句话，“当你能站着开会，就不要坐下来”。



会议室的椅子也不能用太舒服的那种，为什么？当人们坐在一个舒适且舒服的椅子上，大脑更多的时候是在放空状态，注意力无法被集中。



坐在那里舒舒服服的探讨，效率远低于站着快速解决。当站着开会，不再有人坐在办公椅上犯困想打瞌睡，不再有人玩手机看电脑。时间大大的减少，不再沉默寡言，而是速战速决。



每日的项目进度之类，特别适合10-20分钟的站会形式。站着开会，大家都不想浪费时间，自然就更能保证高节奏，高效率。



5.盯紧走神的人



开会的过程中，一般会不断有人走神。这点很考验会议组织者，如果发现有人走神，需要盯着他，看他眼睛。如果还不行，就需要提醒下拉回他的注意力。



开会应该是个激烈思辨的过程，走神是要被杜绝的。如果团队中发现开会经常走神的人，那要小心了。他要么是对业务不太了解，说不上话，要么是心灰意冷已经不想说话。「要引起重视了」



6.会后，有结论、有责任



开会过程要对关键结论做会议纪要，在会议结束后，尽早发出会议记录。会议记录可能会有遗漏和错误的地方，尽早将会议记录发给所有相关人，可以让其它参会者检查，提出问题或作出补充。



会议结束后，将任务指派给每一位责任人。这也往往是会议组织者的工作，不仅仅做出决定，更要负责落实决定的执行。如果这一步做不到位，那基本可以说这个会白开了。



最后总结几句：



开会是个大学问，千万不要小看提升的那点效率。10个人开会，浪费2小时，就相当于浪费了一个人一天的生命和一个人的工资。



工作的目标是为了创造价值，而不是摧毁价值。低效会议无疑是摧毁价值的重要帮凶！！！



浪费时间等于谋财害命，高效开会是每个会议组织者必须学会的技能。

</pre>


          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/">&lt;</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/6/">&gt;</a>
  </nav>





          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.png"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
<a href="/archives/">                
<!--<a href="/archives/%7C%7C%20archive">-->
              
                  <span class="site-state-item-count">178</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">219</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kingson Wu</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
