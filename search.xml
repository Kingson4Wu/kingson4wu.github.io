<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Warriors</title>
    <url>/2019/07/06/20190706-warriors/</url>
    <content><![CDATA[<ul>
<li>Goooooooooooo!<br><img src="/2019/07/06/20190706-warriors/Warriors.jpg"></li>
</ul>
]]></content>
      <tags>
        <tag>LIFE</tag>
      </tags>
  </entry>
  <entry>
    <title>《天下足球》曲目</title>
    <url>/2019/12/28/20191228-tian-xia-zu-qiu-qu-mu/</url>
    <content><![CDATA[<ol>
<li>The Phoenix - Fall Out boy</li>
<li>Love Runs Out - OneRepublic</li>
<li>Empire of Angels</li>
<li>Breath And Lift</li>
<li>If I Could Fly</li>
<li>Electric romeo</li>
<li>Rise - John Dreamer</li>
<li>Victory - Two Steps From Hell</li>
<li>El Dorado - Two Steps From Hell</li>
<li>Journey - Capo Productions</li>
<li>Star Sky - Two Steps From Hell</li>
<li>No Boundaries - Adam Lambert</li>
<li>Attraction - Masazumi Ozawa</li>
<li>Because of You - Kelly Clarkson</li>
<li>Now We Are Free - Hans Zimmer</li>
</ol>
<p><img src="/2019/12/28/20191228-tian-xia-zu-qiu-qu-mu/Cristiano_Ronaldo.jpeg"></p>
]]></content>
      <tags>
        <tag>LIFE</tag>
      </tags>
  </entry>
  <entry>
    <title>电影摘要</title>
    <url>/2020/01/01/20200101-dian-ying-zhai-yao/</url>
    <content><![CDATA[<h2 id="《战争之王》"><a href="#《战争之王》" class="headerlink" title="《战争之王》"></a>《战争之王》</h2><ul>
<li><a href="https://movie.douban.com/review/8808554/">https://movie.douban.com/review/8808554/</a></li>
<li>Let me tell you what’s gonna happen.This way you can prepare yourself.Soon there’s gonna be a knock on that door and you will be called outside. In the hall there will be a man who outranks you.First,he’ll compliment you on the fine job you’ve done, that you’re making the world a safer place,that you’re to receive a commendation and a promotion.And then he’s going to tell you that I am to be released. You’re going to protest.You’ll probably threaten to resign.But in the end I will be released.The reason I’ll be released is the same reason you think I’ll be convicted.I do rub shoulders with some of the most vile,sadistic men calling themselves leaders today.But some of those men are the enemies of your enemies.And while the biggest arms dealer in the world is your boss, the President of the United States, who ships more merchandise in a day than I do in a year,sometimes it’s embarrassing to have his fingerprints on the guns. Sometimes he needs a freelancer like me to supply forces he can’t be seen supplying. So , you call me evil. But unfortunately for you,I’m a necessary evil.<br>　　- 让我告诉你将会发生什么事情，好让你有个心理准备。很快会有人来敲门叫你出去，大厅里有个比你官衔高的人。首先，他会称赞你所做的一切，世界因为你变得更安全，你会获得表扬或晋升。然后他会告诉你，我会被释放。你会反对，也许还威胁要辞职，但最后我还是会被释放。我被释放的理由跟你认为我会被定罪的理由一样，我和世界上称自己为领导人的人打交道。这些人其中有些是你敌人的敌人，世界上最大的军火商是你的老板，美国的总统，他一天卖的比我一年还多，有时候在枪支上找到他的指纹是一件很尴尬的事，有时他需要像我这样的自由工作者供应一些他不方便出面供应的货物。所以，你说我是恶魔，但不幸的是，对你我是一个必须存在的恶魔。</li>
</ul>
<h2 id="《点球成金》"><a href="#《点球成金》" class="headerlink" title="《点球成金》"></a>《点球成金》</h2><ul>
<li>I made one decision in my life based on money. (我为了钱 曾做过一次人生重大的决定)</li>
<li>And I swore I would never do it again. (我发誓我再也不会那么做)</li>
</ul>
<ul>
<li>You’re not doing it for the money. (你那样做不是为了钱)</li>
<li>You’re doing it for what the money says. (你是为这笔钱代表的价值而做)</li>
<li>And it says what it says to any player that makes big money. （每个领高薪的球员也是一样）</li>
<li>That they’re worth it. (他们值得)</li>
</ul>
<ul>
<li><p>拿高薪不是为了钱，是为了证明自己的价值</p>
</li>
<li><p><a href="https://baijiahao.baidu.com/s?id=1597282786381213634">https://baijiahao.baidu.com/s?id=1597282786381213634</a></p>
</li>
<li><p>如果Billy接受这笔钱，就可以一洗之前的“屈辱”，不但个人生活有了保障，还能在新的球队自由发挥，不再被金钱束手束脚。但是Billy没有接受，意料之中又意料之外。离开自己带了几十年的球队不容易，离开自己一直居住的加州不容易，最重要的是离开自己可爱懂事的女儿不容易。当钱的问题终于解决，才发现事情的关键并不是钱，说白了，一个人的成就感并不能用钱来衡量。</p>
</li>
<li><p>如果真要把这部电影当成励志片，它告诉我的并不是“努力就能创造奇迹”，而是人要有勇气作出改变。Billy一直拒绝跟球员亲近，理由是如果投入太多情感，想炒人的时候会下不了手，可却在40几岁的时候，放下了这些防御，主动跟球员沟通，为他们加油打气。在遇到小胖之前，Billy一辈子都在听老一辈人的经验之谈，十八九岁的时候，听了这帮人的游说，放弃了全奖的斯坦福，直接加盟了职业联赛，结果十年也没出成绩，到后来当上经理人，也要听这帮人的建议来买卖队员经营球队，可却在40几岁的时候，选择力排众议，听一个25岁年轻人的建议。如果相信，就要拿出勇气改变。这就是我所学到的。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>LIFE</tag>
      </tags>
  </entry>
  <entry>
    <title>移动端下一种折中的分页方法</title>
    <url>/2020/03/26/20200326-yi-dong-duan-xia-yi-chong-zhe-zhong-fen-ye-fang-fa/</url>
    <content><![CDATA[<p><img src="/2020/03/26/20200326-yi-dong-duan-xia-yi-chong-zhe-zhong-fen-ye-fang-fa/Messi.jpg"></p>
<ul>
<li><p>移动互联网下微服务大行其道，服务之间按业务拆分精细，各司其职，通过服务发现rpc相互调用，实现各自的需求场景。</p>
</li>
<li><p>一个简单的列表，如果不依赖其他服务，只依赖自身的数据库，可以简单的通过sql即可查询出来。</p>
</li>
<li><p>而如果数据来源于其他服务，根据特定的需求场景，可能就需要调用多个服务，获取数据，判断属性，过滤数据，再展示，那么可能未免会出现分页的问题。</p>
</li>
<li><p>以下面的场景为例：</p>
</li>
</ul>
<p><img src="/2020/03/26/20200326-yi-dong-duan-xia-yi-chong-zhe-zhong-fen-ye-fang-fa/page1.png"></p>
<ul>
<li>业务服务依赖两个底层服务的数据进行聚合，导致返回客户端的数据小于请求值10，甚至为空，客户端认为已经没数据了，从而错误提示用户“已经到底了”。</li>
<li>解决方案：客户端不依赖返回数据的数量判断是否还有数据，由服务端返回”hasNext&#x3D;1”来判断是否有数据，控制用户是否可继续滑动查看</li>
</ul>
<p><img src="/2020/03/26/20200326-yi-dong-duan-xia-yi-chong-zhe-zhong-fen-ye-fang-fa/page2.png"></p>
<ul>
<li>方案并不完美，极端情况下可能因为数据被过滤，导致返回前端数据太少设置没数据，影响体验。所以此方案只是不考虑极端场景的折中方案，另外的优化手段是初始请求size控制在一个合适的值，比如size&#x3D;30</li>
</ul>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>分页</tag>
      </tags>
  </entry>
  <entry>
    <title>发版过程的兼容性考虑</title>
    <url>/2020/03/29/20200329-fa-ban-guo-cheng-de-jian-rong-xing-kao-lu/</url>
    <content><![CDATA[<p><img src="/2020/03/29/20200329-fa-ban-guo-cheng-de-jian-rong-xing-kao-lu/Torres.jpg"></p>
<ul>
<li>一般情况下，服务一般不是仅有一台服务器提供服务的，因此服务上线的过程中其实会经历一个灰度过程</li>
</ul>
<p><img src="/2020/03/29/20200329-fa-ban-guo-cheng-de-jian-rong-xing-kao-lu/mermaid-diagram-20200329140016.png"></p>
<p>如上所示，服务器A是新代码，走的是新逻辑，服务器B和C未发版，走的旧逻辑。</p>
<ul>
<li>如果新上线的变更只涉及读逻辑的，那么这样的灰度上线是没问题的。</li>
<li>但如果上线的内容涉及写逻辑的变更，甚至还关联到异步处理的变更。那么这样的上线方式可能是不兼容的，会导致处理异常。</li>
<li>在服务全量发版之后，新的流量可能正常，但发版过程中导致一定的脏数据。</li>
</ul>
<p>(图不画了，自行想象)</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul>
<li>开关！用配置中心开关控制，走新逻辑还是旧逻辑。默认旧逻辑。</li>
<li>代码需要保留两套，通过开关控制走哪个分支。</li>
<li>全量发版之后，此时线上全是新代码了，通过开关灰度(此时是业务灰度而不是机器灰度了)</li>
</ul>
]]></content>
      <tags>
        <tag>业务方案</tag>
      </tags>
  </entry>
  <entry>
    <title>表结构变更是否需要处理历史月表？</title>
    <url>/2020/03/29/20200329-biao-jie-gou-bian-geng-shi-fou-xu-yao-chu-li-li-shi-yue-biao/</url>
    <content><![CDATA[<p><img src="/2020/03/29/20200329-biao-jie-gou-bian-geng-shi-fou-xu-yao-chu-li-li-shi-yue-biao/Henry.jpeg"></p>
<ul>
<li>目前针对历史流水表，历史订单表，采用的以月为维度的方式建表，如以下表结构所示<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t_order_202002` (</span><br><span class="line">`order_id` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;订单id&#x27;</span>,</span><br><span class="line">`coin` <span class="type">decimal</span>(<span class="number">32</span>,<span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0.00&#x27;</span> COMMENT <span class="string">&#x27;支付币数&#x27;</span>,</span><br><span class="line">`user_id` <span class="type">bigint</span>(<span class="number">20</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;用户id&#x27;</span>,</span><br><span class="line">`create_time` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line">`update_time` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;更新时间&#x27;</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (`order_id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 COMMENT<span class="operator">=</span><span class="string">&#x27;订单表&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t_order_202003` (</span><br><span class="line">`order_id` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;订单id&#x27;</span>,</span><br><span class="line">`coin` <span class="type">decimal</span>(<span class="number">32</span>,<span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0.00&#x27;</span> COMMENT <span class="string">&#x27;支付币数&#x27;</span>,</span><br><span class="line">`user_id` <span class="type">bigint</span>(<span class="number">20</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;用户id&#x27;</span>,</span><br><span class="line">`create_time` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line">`update_time` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;更新时间&#x27;</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (`order_id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 COMMENT<span class="operator">=</span><span class="string">&#x27;订单表&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t_order_202004` (</span><br><span class="line">`order_id` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;订单id&#x27;</span>,</span><br><span class="line">`coin` <span class="type">decimal</span>(<span class="number">32</span>,<span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0.00&#x27;</span> COMMENT <span class="string">&#x27;支付币数&#x27;</span>,</span><br><span class="line">`user_id` <span class="type">bigint</span>(<span class="number">20</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;用户id&#x27;</span>,</span><br><span class="line">`create_time` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line">`update_time` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;更新时间&#x27;</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (`order_id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 COMMENT<span class="operator">=</span><span class="string">&#x27;订单表&#x27;</span></span><br></pre></td></tr></table></figure>
现要对表结构增加一个字段 room_id<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> t_order_202003</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">COLUMN</span> `room_id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;动作发生的所在房间ID&#x27;</span>;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> t_order_202004</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">COLUMN</span> `room_id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;动作发生的所在房间ID&#x27;</span>;</span><br></pre></td></tr></table></figure>
那么久的历史表可以不处理吗？</li>
</ul>
<ol>
<li>假如全部的查询语句都是<code>select *</code>,  那么久的历史表可以不处理，但是这样违反了按需查询原则</li>
<li>如果查询语句有指定字段如<code>select order_id, room_id</code>,那么查询到旧的表时会报错</li>
</ol>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><ol>
<li>历史表和当前的表结构保存一致，在进行表结构变更时一并处理，避免后续的坑(没精力折腾的建议这样处理，可以增加一些监控手段)</li>
<li>历史表不处理，在程序代码上兼容。这样会增加代码复杂度，难以维护，如果有必要最好统一sdk中处理。</li>
<li>运维层面，统一处理，统一月表的结构，需要DBA工具支持</li>
</ol>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>历史月表</tag>
      </tags>
  </entry>
  <entry>
    <title>RPC可以和事务绑定吗？</title>
    <url>/2020/07/05/20200705-rpc-ke-yi-he-shi-wu-bang-ding-ma/</url>
    <content><![CDATA[<p><img src="/2020/07/05/20200705-rpc-ke-yi-he-shi-wu-bang-ding-ma/MSN.jpg"></p>
<p>在平常编码的时候，经常会看到很多人喜欢把一次RPC调用和数据库事务绑定在一起，RPC调用成功则提交事务，RPC调用失败或超时，则回滚事务。那么这样做是对的吗？</p>
<h3 id="业务场景描述"><a href="#业务场景描述" class="headerlink" title="业务场景描述"></a>业务场景描述</h3><p>考虑以下一种业务场景：用户加入群聊需要花费200金币。<br>服务架构：服务A(群服务)，服务B(消费服务)，操作都是幂等的。</p>
<pre>
加群请求----------> 服务A
             [1.新增事务]
             [2.RPC进行扣费]------------>服务B
             [3.执行加群操作(DB操作)]
             [4.提交事务]
</pre>

<h3 id="业务场景分析"><a href="#业务场景分析" class="headerlink" title="业务场景分析"></a>业务场景分析</h3><ol>
<li>服务B返回成功，业务无异常</li>
<li>服务B返回失败，事务回滚，业务无异常</li>
<li>服务B超时，或服务A RPC调用之后重启等场景，业务异常！</li>
</ol>
<p>业务异常表现为：用户已经扣费，但是没加群成功(即服务A和服务B数据不一致)</p>
<h3 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h3><ul>
<li><p>服务A通过本地事务表解决。</p>
<ol>
<li>服务A在进行RPC调用之前，需先保存一条订单，订单状态为“待扣费”，扣费成功后，更新订单状态为“已扣费”。</li>
<li>启动定时任务，查询过去某时间范围内（如30分钟前至当前时间1分钟前）的“待扣费”的订单是否已扣费。若已扣费进行加群操作，并更新订单状态；否则，将订单置为无效状态。</li>
<li>订单状态：[1待扣费，2已扣费，3已加群，4无效]</li>
</ol>
</li>
<li><p>加群流程图</p>
<pre>
加群请求----------> 服务A
           [1.新增“待扣费”订单(DB操作)]
           [2.RPC进行扣费]------------>服务B
           [3.更新订单状态为“已扣费”(DB操作)]
           [4.执行加群操作(DB操作)]
           [5.更新订单状态为“已加群”(DB操作)]</pre></li>
</ul>
<p><br>上图的每个操作都是单独的，其中某一步异常都会导致后续中断，因此需要两个定时任务，分别检查“待扣费”和“已扣费”的订单。</p>
<ul>
<li>定时任务1<pre>
定时任务1---------> 服务A
           [1.查询“待扣费”订单]
           [2.RPC查询是否已扣费]------------>服务B
           |(1)已扣费                         |(2)未扣费
           |                                         |</pre></li>
</ul>
<p>[3.更新订单状态为“已扣费”(DB操作)]           [3.更新订单状态为“无效”(DB操作)]<br>[4.执行加群操作(DB操作)]<br>[5.更新订单状态为“已加群”(DB操作)]<br></p>
<ul>
<li>定时任务2<pre>
定时任务2---------> 服务A
           [1.查询“已扣费”订单]    
           [2.执行加群操作(DB操作)]
           [3.更新订单状态为“已加群”(DB操作)]</pre></li>
</ul>
<p><br>当然定时任务1和2可以放在同一个定时任务执行</p>
<ul>
<li>解决了问题之后，我们再回头看看一开始的问题：“RPC调用和数据库事务不能绑定吗？”<ul>
<li>答案是看具体业务情况而定</li>
<li>比如上述的业务场景。操作1显然是不能绑事务的</li>
<li>但是2,3,4,5操作其实是可以绑事务的，因为定时任务可以进行补偿，而且可以因此减少定时任务2</li>
<li>总结：rpc操作后续可补偿重试或查询，那么就是可以绑事务的，因为服务不会“失忆”；相反数据未落地之前，是不能进行绑事务了，因为一旦异常，数据就会回滚而“丢失”。</li>
</ul>
</li>
</ul>
<h3 id="其他解决方式"><a href="#其他解决方式" class="headerlink" title="其他解决方式"></a>其他解决方式</h3><ol>
<li>业务对账，补偿机制。即接入第三方服务进行业务流水对账，发现不一致，进行修正；具体修正方式需根据具体业务场景，是退币，还是使加群成功。</li>
<li>使用其他分布式事务解决方案(tcc，seata等)</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul>
<li>重试是 “写”还是“读”？比如上述扣费操作，超时情况下，服务A重试是查询还是重新执行扣费？<ul>
<li>其实还是取决于业务场景</li>
<li>一般情况下，超时情况下，返回用户是失败，所以使用查询比较合适，不系统自动为用户扣费，这时候应该是“读”</li>
<li>如果需要使用rpc调用进行加群，用户扣费了就必须要加群成功，那么加群RPC重试应该是“写”</li>
<li>对于金钱业务来说，一般情况下，加币操作(充值，活动赠币)是“写”，扣币操作(送礼，用户触发)是“读”；入仓是“写”，出仓是“读”</li>
</ul>
</li>
<li>补偿操作是“正向”还是“逆向”？比如上述扣费操作，超时情况下，服务A重试查询到用户已经扣费成功，这是是应该给用户退币，还是加群成功？<ul>
<li>一样还是取决于业务场景</li>
<li>如果用户只是想加群，那么只需要正向操作就好了，不影响用户利益，只是加群操作有些延迟，这时候应该是“正向”</li>
<li>如果用户扣费之后，可以进行抽奖等，相当于用户的权益是具备实时性的，因为扣费超时(实际成功)导致无法抽奖，那么应该是退币才对的，即“逆向”</li>
</ul>
</li>
<li>“无效”状态的订单应该支持重试，因为无效是因为未扣费，若作为一个基础服务，上次服务可能会使用同一个订单号进行重试，那么不能告诉业务方，操作失败等，应该作为一个全新的请求处理。可以通过增加订单的流水日志解决数据覆盖问题。</li>
<li>上述的处理方式中，余额不足的扣费，会导致比较多的无效订单，因此在扣费之前，可以增加一次RPC查询，判断是余额是否足够</li>
</ul>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>RPC</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>关于服务间一致性和前置校验的思考</title>
    <url>/2020/07/05/20200705-guan-yu-fu-wu-jian-yi-zhi-xing-he-qian-zhi-xiao-yan-de-si-kao/</url>
    <content><![CDATA[<p><img src="/2020/07/05/20200705-guan-yu-fu-wu-jian-yi-zhi-xing-he-qian-zhi-xiao-yan-de-si-kao/Zidane.jpeg"></p>
<p>每个服务都有相应的前置校验，有些前置校验逻辑不统一，就会导致服务间数据的不一致。比如风控拦截，服务A未拦截，而服务B却拦截了，从而导致不一致。</p>
<h3 id="业务描述"><a href="#业务描述" class="headerlink" title="业务描述"></a>业务描述</h3><ul>
<li>下面描述一个仓库送礼的场景<pre>
送礼请求----------> 服务A(送礼服务)
           [1.出仓库礼物]------------>服务B(仓库服务)
           [2.收礼者加分成]------------>服务C(消费服务[含分成服务])</pre></li>
</ul>
<p></p>
<pre>
送礼请求----------> 服务A(送礼服务)
             [1.出仓库礼物]------------>服务B(仓库服务)
             [2.收礼者加分成]------------>服务C(消费服务[含分成服务])
                                [查询是否风险用户]------------>服务D(风控服务)
</pre>
<p>服务C增加查询之后，如果是风险用户，将会拦截加分成的操作。这样就会导致用户仓库礼物出仓了，但是收礼者却无法接收分成</p>
<h3 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h3><p>服务B也要进行风险用户判断，针对资金操作相关的校验，可以统一逻辑，避免相同逻辑维护多个地方</p>
<ol>
<li>服务C增加一个统一判断接口<pre>
送礼请求----> 服务A(送礼服务)
          [1.出仓库礼物]----->服务B(仓库服务)
                        [ 1.1查询用户是否允许资金变动]----->服务C
                                     [1.1.1查询是否风险用户]--->服务D(风控服务)
          [2.收礼者加分成]----->服务C(消费服务[含分成服务])
                            [2.1查询是否风险用户]----->服务D(风控服务)</pre></li>
</ol>
<p><br>若用户是风险用户，操作1就会返回失败，不出仓，也无后续的操作2，这样就避免不一致的问题</p>
<ol start="2">
<li>收敛消费入口，统一资产类的入口<br>方案1的缺点明显，每个服务都要直接或间接的查询一次风控服务，实际上理想情况下，只需要查询一次即可。<pre>
送礼请求----------> 服务A(送礼服务)
          [1.出仓库礼物和加分成]--------->服务C(消费服务)
                                [1.1查询是否风险用户]------------>服务D(风控服务)
                                [1.2出仓库礼物]------------>服务B(仓库服务)
                                [1.3收礼者加分成]</pre></li>
</ol>
<p><br>由消费服务统一对资产进行“出”和“入”</p>
<ol start="3">
<li>网关服务拦截<br>由网关服务统一调风控服务进行判断，并支持业务类型定制(比如资产类接口应该进行哪些判断)</li>
</ol>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>前置校验</tag>
      </tags>
  </entry>
  <entry>
    <title>上线需要做哪些准备？</title>
    <url>/2020/07/06/20200706-shang-xian-xu-yao-zuo-na-xie-zhun-bei/</url>
    <content><![CDATA[<p><img src="/2020/07/06/20200706-shang-xian-xu-yao-zuo-na-xie-zhun-bei/Carlos.jpg"></p>
<p>一般常规的上线，需要做哪些准备，确保不会因为遗漏这种低级错误导致线上问题？</p>
<ol start="0">
<li>开发中遇到问题标注TODO，避免遗漏，单元测试覆盖业务逻辑</li>
<li>准备上线checklist，验收方案</li>
<li>检查上线配置</li>
<li>是否需要配置定时任务</li>
<li>重新检查一遍变更的代码</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ol>
<li>涉及app的，需要考虑旧版本兼容和回归测试（重点回归若干个高流量的旧版本）</li>
<li>若上线后出现问题，先回滚再查问题（适用于大多数场景）</li>
<li>核心业务要重点测试</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>使用ThreadContext缓存RPC结果</title>
    <url>/2020/07/06/20200706-shi-yong-threadcontext-huan-cun-rpc-jie-guo/</url>
    <content><![CDATA[<p><img src="/2020/07/06/20200706-shi-yong-threadcontext-huan-cun-rpc-jie-guo/Gerrard.jpeg"></p>
<p>在业务开发中，经常会使用RPC请求获取数据。有时候在同一条逻辑链路中，会多次使用RPC返回的数据。</p>
<h3 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a>业务场景</h3><pre>
请求----------> 服务A
             [1.methodA]----获取用户数据--->服务B(用户服务)
             [2.mehtodB]----获取用户数据--->服务B(用户服务)
</pre>
<p>上图中，服务A中同一个逻辑链路中包含methodA和mehtodB，两个都会使用到用户数据，因此会导致重复的RPC调用。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol>
<li>将数据实体作为methodB的参数传入<ul>
<li>这种方式可以避免调用多次重复的RPC，但是也有缺点：<br>  a. 如果有mehtodC，methodD等，每个方法都加个参数，不是很优雅<br>  b. 如果除了获取用户信息，还要获取商品信息等，那么方法形参将越来越多，影响阅读</li>
</ul>
</li>
</ol>
<pre>
请求----------> 服务A
             [1.methodA]----获取用户数据--->服务B(用户服务)
             [2.mehtodB(param1: userInfo)]----获取用户数据--->服务B(用户服务)
             [3.mehtodC(param1: userInfo)]----获取用户数据--->服务B(用户服务)
</pre>		
<ol start="2">
<li>使用	ThreadContext 缓存RPC结果<ul>
<li>可以使用拦截器统一处理服务的所有ThreadContext(因为使用完之后需要remove)</li>
<li>将RPC结果保存到ThreadContext和从ThreadContext获取RPC结果的逻辑，封装在RPC调用方法中<pre>
请求----------> 服务A
       [1.methodA]----获取用户数据--->服务B(用户服务)
       ->> 将RPC结果保存在ThreadContext
       [2.mehtodB]----获取用户数据--->从ThreadContext获取
       [3.mehtodC]----获取用户数据--->从ThreadContext获取</pre></li>
</ul>
</li>
</ol>
<p>	</p>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>RPC</tag>
        <tag>ThreadContext</tag>
      </tags>
  </entry>
  <entry>
    <title>唯一ID的基因</title>
    <url>/2020/07/07/20200707-wei-yi-id-de-ji-yin/</url>
    <content><![CDATA[<p><img src="/2020/07/07/20200707-wei-yi-id-de-ji-yin/Zidane_2.jpeg"></p>
<p>在互联网服务中，经常需要使用唯一ID。其中一个常见的应用场景是作为业务中请求的幂等ID。</p>
<h3 id="分布式唯一ID生成方案"><a href="#分布式唯一ID生成方案" class="headerlink" title="分布式唯一ID生成方案"></a>分布式唯一ID生成方案</h3><ol>
<li>uuid</li>
<li>snowflake</li>
<li>包含业务属性的唯一ID，如 timestamp+ uid（10-11位）+ 随机3位数字（或递增）</li>
<li>其他方案</li>
</ol>
<p>优劣不在这里讨论</p>
<h3 id="业务场景分析"><a href="#业务场景分析" class="headerlink" title="业务场景分析"></a>业务场景分析</h3><p>结合目前工作中的现状进行分析</p>
<ol>
<li>唯一ID的存储方式：MySQL－bigint(20)</li>
<li>唯一ID生成方式：snowflake－64位：42位时间戳+5位机器码+5位进程worker标识码+12位自增id（42|5|5|12 &#x3D; 64）</li>
</ol>
<ul>
<li><p>我们把幂等ID作为数据库的唯一键，从而保证幂等；而当数据量越来越大是，我们对数据按月进行分表，提升处理性能。</p>
</li>
<li><p>我们在数据库中除了有幂等ID（orderId）字段之外，还有添加时间字段（addTime）;当请求进来之后，根据addTime找到相应的月表。所以实际上要保证请求处理幂等，依赖的是orderId＋addTime 不变（或addTime保证始终落在同一个月）</p>
</li>
</ul>
<h4 id="为什么要依赖addTime保证幂等？"><a href="#为什么要依赖addTime保证幂等？" class="headerlink" title="为什么要依赖addTime保证幂等？"></a>为什么要依赖addTime保证幂等？</h4><ol>
<li><p>基础组件提供的唯一ID生成服务，对snowflake进行个性化的改造，只能保证ID是唯一的，然而ID的属性并不明显，无法方便的使用唯一ID进行分库（实际上snowflake算法的前n位是时间戳，可以考虑作为分库的属性）</p>
</li>
<li><p>一些常见唯一ID的例子</p>
<pre>
交易单号:4008722001201707283057762612
商户单号:2017072809364399365840049582
订单编号: 60310040822721833
支付宝交易号: 2017092021001001150522558267
大众点评订单号36611441412777832
</pre></li>
</ol>
<p>像“商户单号”和“支付宝交易号”，很明显可以使用日期“基因”来分库，不过这种唯一ID不能使用bigint 存储，因为超过64位了</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>一个好的唯一ID算法生成的ID，应该具备易用的“基因”。像UUID这种就不是很满足。</p>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>唯一ID</tag>
      </tags>
  </entry>
  <entry>
    <title>如何处理RPC返回的错误码？</title>
    <url>/2020/07/07/20200707-ru-he-chu-li-rpc-fan-hui-de-cuo-wu-ma/</url>
    <content><![CDATA[<p><img src="/2020/07/07/20200707-ru-he-chu-li-rpc-fan-hui-de-cuo-wu-ma/Zlatan.jpeg"></p>
<h4 id="RPC调用的返回结果"><a href="#RPC调用的返回结果" class="headerlink" title="RPC调用的返回结果"></a>RPC调用的返回结果</h4><ol>
<li>成功</li>
<li>失败</li>
<li>超时</li>
</ol>
<p>超时情况是不确定的，需要调用方重试或查询等，根据业务情况进行处理</p>
<h4 id="返回结果表示方法"><a href="#返回结果表示方法" class="headerlink" title="返回结果表示方法"></a>返回结果表示方法</h4><ol>
<li>使用http协议的状态码</li>
<li>使用业务错误码（在业务处理中比较常见）<ul>
<li>0表示成功</li>
<li>1表示失败</li>
<li>其他错误码代表具体的失败业务场景</li>
</ul>
</li>
</ol>
<h4 id="失败错误码类型"><a href="#失败错误码类型" class="headerlink" title="失败错误码类型"></a>失败错误码类型</h4><ol>
<li>业务错误（参数错误，或业务场景校验限制，请求已经处理完成）</li>
<li>处理速度慢（msg:”请求处理中”）</li>
<li>限流（msg:”你的操作太快了”）</li>
<li>未知错误</li>
<li>其他</li>
</ol>
<p>针对2或4的场景，很可能提交的RPC实际上已经成功，属于不确定的情况（同超时），业务方不能直接当成失败处理；1的场景中“请求已经处理完成”，实际上已经成功，只是调用方的接口返回不幂等。</p>
<h4 id="错误码处理"><a href="#错误码处理" class="headerlink" title="错误码处理"></a>错误码处理</h4><p>定义RPC请求中，成功，失败，不确定三种结果对应的错误码集合（最好可配置），业务针对不同的结果进行相应处理。</p>
<ol>
<li>成功（错误码：A,B,C ….）</li>
<li>失败（错误码：E,F,G ….）</li>
<li>不确定（错误码：H,I,J …. 和 ”超时“）</li>
</ol>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>RPC</tag>
        <tag>错误码</tag>
      </tags>
  </entry>
  <entry>
    <title>外网请求如何保证幂等</title>
    <url>/2020/07/08/20200708-wai-wang-qing-qiu-ru-he-bao-zheng-mi-deng/</url>
    <content><![CDATA[<p>常见的外网请求，通常来自网页或app。一个不幂等的接口，可能会导致用户只点击一次，却产生多次点击的效果。</p>
<ol>
<li>如果用户的请求只是修改昵称，那么基本没影响</li>
<li>但如果用户的请求是扣费，比如送礼，那就会产生多扣费的资金问题。</li>
</ol>
<h3 id="问题的原因"><a href="#问题的原因" class="headerlink" title="问题的原因"></a>问题的原因</h3><p>在互联网上，无论是内网还是外网，网络经常会有不稳定的情况。为应对这些网络问题，通常会有各种重试策略。</p>
<ol>
<li>内网不稳定的情况，通常会在代理上(如nginx)配置一些超时重试，或50x重试策略</li>
<li>外网不稳定的情况，客户端会在超时时进行重试或切域名重试等</li>
</ol>
<p>这些重试策略，导致了用户端只发出一次请求，实际服务端收到多次请求的情况。</p>
<p>总结：“重试”是产生问题的源头</p>
<h3 id="解决问题的关键"><a href="#解决问题的关键" class="headerlink" title="解决问题的关键"></a>解决问题的关键</h3><p>解决问题的关键其实很简单，就是要让服务端能识别接收到的“多个”请求是否是“同个”请求，从而确保业务只执行一次。</p>
<h4 id="如何标识请求的唯一性"><a href="#如何标识请求的唯一性" class="headerlink" title="如何标识请求的唯一性"></a>如何标识请求的唯一性</h4><p>本质上是请求的参数中，包含由一个或多个参数组合而成的，唯一且不变的标识。</p>
<ol>
<li>像修改用户昵称的请求，业务本身就幂等，因为用户id是唯一且不变的</li>
<li>像用户的扣费请求，那么通常的做法是使用唯一的订单号，以及相应的唯一ID生成策略</li>
</ol>
<h4 id="唯一ID算法需要考虑哪些"><a href="#唯一ID算法需要考虑哪些" class="headerlink" title="唯一ID算法需要考虑哪些"></a>唯一ID算法需要考虑哪些</h4><ol>
<li>有序<ul>
<li>唯一ID作为数据的索引，保持有序有助于数据库性能提升</li>
</ul>
</li>
<li>数据库类型<ul>
<li>以MySQL为例，选择bigint(20)还是varchar，前者只有64位，像”2017072809364399365840049582“这种订单号只能用varchar存储</li>
</ul>
</li>
<li>基因<ul>
<li>分库需求，详见：<a href="https://kingson4wu.github.io/2020/07/07/20200707-%E5%94%AF%E4%B8%80ID%E7%9A%84%E5%9F%BA%E5%9B%A0/">唯一ID的基因</a></li>
</ul>
</li>
<li>性能</li>
</ol>
<h4 id="前端唯一ID生成方案"><a href="#前端唯一ID生成方案" class="headerlink" title="前端唯一ID生成方案"></a>前端唯一ID生成方案</h4><ol>
<li>使用UUID (缺点：无序)</li>
<li>通过后端接口获取唯一ID(缺点：多一次外网的网络请求)</li>
<li>按一定的业务规则生成，如：timestamp+ 用户ID（10-11位）+ 随机3位数字（或递增）(优点：有序且基本保证唯一)</li>
</ol>
<h4 id="后端唯一ID生成方案"><a href="#后端唯一ID生成方案" class="headerlink" title="后端唯一ID生成方案"></a>后端唯一ID生成方案</h4><ol>
<li>使用snowflake算法实现的唯一ID服务</li>
<li>其他业界方案</li>
</ol>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ol>
<li>前端唯一ID使用方案3<ul>
<li>后端服务对前端生成的ID进行规则校验，防止恶意伪造不规范的唯一ID</li>
</ul>
</li>
<li>后端唯一ID</li>
<li>直接使用前端传入的唯一ID</li>
<li>从唯一ID服务获取(和前端唯一ID进行映射)</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><h4 id="不同业务唯一ID冲突问题"><a href="#不同业务唯一ID冲突问题" class="headerlink" title="不同业务唯一ID冲突问题"></a>不同业务唯一ID冲突问题</h4><ul>
<li>若后端作为一个基础服务，对接上层业务，每个业务使用的唯一ID规则不一样。那么如何避免业务之间唯一ID冲突？<ol>
<li>使用业务ID＋业务唯一ID进行订单唯一性区分</li>
<li>统一唯一ID的生成规则(统一从基础服务获取或由该服务提供订单ID申请接口)</li>
</ol>
</li>
</ul>
<h4 id="跨机房的服务幂等问题"><a href="#跨机房的服务幂等问题" class="headerlink" title="跨机房的服务幂等问题"></a>跨机房的服务幂等问题</h4><ul>
<li>若服务部署多个机房（通常每个机房有对应的数据库），如何保证幂等，因为外网请求重试，不一定会到达同一个机房。<ol>
<li>把用户按机房分区</li>
<li>不考虑跨机房幂等问题(主备架构下同个请求落在不同机房概率不高，收益低)</li>
</ol>
</li>
</ul>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>唯一ID</tag>
        <tag>幂等</tag>
      </tags>
  </entry>
  <entry>
    <title>程序异常时能返回50x吗？</title>
    <url>/2020/07/08/20200708-cheng-xu-yi-chang-shi-neng-fan-hui-50x-ma/</url>
    <content><![CDATA[<p><img src="/2020/07/08/20200708-cheng-xu-yi-chang-shi-neng-fan-hui-50x-ma/Gerrard_2.jpeg"></p>
<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ol>
<li>内网nginx配置<pre>
proxy_next_upstream error timeout http_500 http_502 http_503 http_504;
proxy_upstream_tries 5;
</pre>
表示超时或50x(500,502,503,504)，nginx会进行重试，一共5次</li>
<li>服务的程序有bug，报NullPointException，实际逻辑已经执行成功</li>
<li>服务使用springboot，默认异常时返回的HTTP状态是500</li>
<li>nginx收到500之后，进行重试</li>
<li>服务的接口不幂等</li>
</ol>
<h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><ol>
<li>很难保证服务的所有接口都幂等，并且是外网的幂等</li>
<li>服务的统一异常拦截，最好把状态码设置成200，调用方通过业务错误码判断，避免nginx误重试。</li>
</ol>
]]></content>
      <tags>
        <tag>幂等</tag>
      </tags>
  </entry>
  <entry>
    <title>《一只特里独行的猪》摘要</title>
    <url>/2020/07/09/20200709-yi-zhi-te-li-du-xing-de-zhu-zhai-yao/</url>
    <content><![CDATA[<p><img src="/2020/07/09/20200709-yi-zhi-te-li-du-xing-de-zhu-zhai-yao/Shanghai_Beach.png"></p>
<ul>
<li><p>我的看法也许不值得别人重视，但对自己却很重要。这说明我有自己的好恶、爱憎等等。假如没有这些，做人也没什么味道。</p>
</li>
<li><p>我已经四十岁了，除了这只猪，还没见过谁敢于如此无视对生活的设置。相反，我倒见过很多想要设置别人生活的人，还有对被设置的生活安之若素的人。因为这个缘故，我一直怀念这只特立独行的猪。</p>
</li>
<li><p>真正有出息的人是对名人感兴趣的东西感兴趣，并且在那上面做出成就，而不是仅仅对名人感兴趣。</p>
</li>
<li><p>奇怪的是：错得越厉害就越有人信——这都是因为它让人振奋。</p>
</li>
<li><p>整个人类是一个物种，科学是全人类的事业，它的成就不能为民族所专有，所以它是全人类的光荣；这样就能有一些平常心。有了平常心，也就不容易被人骗。</p>
</li>
<li><p>如罗素所言，科学在“不计利害地追求客观真理”。请扪心自问，你所称的科学，是否如此淳朴和善良。尤瑟纳尔女士说：“当我计算或写作时，就超越了性别，甚至超越了人类。”请扪心自问，你所称的科学，是否是如此崇高的事业。</p>
</li>
<li><p>当年文化知识不能成为饭碗，也不能夸耀于人，但有一些青年对它还是有兴趣，这说明学习本身就可成为一种生活方式。学习文史知识目的在于“温故”，有文史修养的人生活在从过去到现代一个漫长的时间段里。学习科学知识目的在于“知新”，有科学知识的人可以预见将来，他生活在从现在到广阔无垠的未来。假如你什么都不学习，那就只能生活在现时现世的一个小圈子里，狭窄得很</p>
</li>
<li><p>人的存在是一种自然现象，而不是某种意志的产物。这种现象的内容就包括：人和人是不一样的，有性别之分、贤愚之分，还有同性恋和异性恋之分，这都是自然的现象。把属于自然的现象叫做“丑恶”，不是一种郑重的态度。这段话的意思说白了就是这样的：有些事原本就是某个样子，不以人的意志为转移。</p>
</li>
<li><p>据我所知，学化学的研究生也未必能学到李先生的理论；他们还有个罪名是“追星族”，鬼迷心窍，连杨振宁、李政道、李四光是谁都不知道。据我所知，这三位先生的学问实在高深，中学生根本不该懂，不知道学问，死记些名字，有何必要？更何况记下这些名字之后屈指一算，多一半都入了美国籍，这是给孩子灌输些什么</p>
</li>
<li><p>那些与命运斗争的人，那些做接近自己限度的斗争的人，却天生地接近这种失败。</p>
<p>一个常常在进行着接近自己限度的斗争的人总是会常常失败的，一个想探索自然奥秘的人也常常会失败，一个想改革社会的人更是会常常失败。只有那些安于自己限度之内的生活的人才总是“胜利”，这种“胜利者”之所以常胜不败，只是因为他的对手是早已降伏的，或者说，他根本没有投入斗争。</p>
<p>在人生的道路上，“失败”这个词还有另外的含义，即是指人失去了继续斗争的信心，放下了手中的武器。人类向限度屈服，这才是真正的失败。而没有放下手中武器，还在继续斗争，继续向限度挑战的人并没有失败。如此看来，老人没有失败。老人从未放下武器，只不过是丧失了武器。老人没有失去信心，因此不应当说他是“失败了的英雄”。</p>
<p>那些永远不肯或不能越出自己限度的人是平庸的人。</p>
</li>
</ul>
<p><img src="/2020/07/09/20200709-yi-zhi-te-li-du-xing-de-zhu-zhai-yao/MSN.jpg"></p>
]]></content>
      <tags>
        <tag>LIFE</tag>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>关于幂等的若干问题</title>
    <url>/2020/07/09/20200709-guan-yu-mi-deng-de-ruo-gan-wen-ti/</url>
    <content><![CDATA[<ol>
<li>请求已经处理成功，当业务调用方重试时，幂等id不变，但其他参数有变化时。<ul>
<li>该返回成功的结果吗？或者说应该对所有的参数进行校验，判断和之前的参数是否一致？</li>
<li>与幂等相关的不可变参数组成签名，并保存到数据库（同时保存当时参与签名的生成规则），后续可依据判断参数是否变化？</li>
<li>个人看法最新更新 - 20240528<ul>
<li>对于入参是否变化不应该归于苛刻，因为后续迭代加字段是很正常的</li>
<li>说明接口对某些入参幂等，比如订单号</li>
<li>根据业务实际情况，根据需要标注幂等时效性（比如同个订单号一年内幂等，后续可能返回订单错误等）</li>
</ul>
</li>
</ul>
</li>
</ol>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>幂等</tag>
      </tags>
  </entry>
  <entry>
    <title>缓存策略简单总结</title>
    <url>/2020/07/10/20200710-huan-cun-ce-lue-jian-dan-zong-jie/</url>
    <content><![CDATA[<h3 id="缓存的三座大山"><a href="#缓存的三座大山" class="headerlink" title="缓存的三座大山"></a>缓存的三座大山</h3><p>以下内容摘自：<a href="https://mp.weixin.qq.com/s/ziJ8OFiLA1it3sQvycN7Mg">翻越缓存的三座大山</a></p>
<ol>
<li>缓存一致性<ul>
<li>缓存一致性是指业务在引入分布式缓存系统后，业务对数据的更新除了要更新存储以外还需要同时更新缓存，对两个系统进行数据更新就要先解决分布式系统中的隔离性和原子性难题。</li>
</ul>
</li>
<li>缓存击穿<ul>
<li>缓存击穿是指查询请求没有在缓存层命中而将查询透传到存储 DB 的问题，当大量的请求发生缓存击穿时，将给存储 DB 带来极大的访问压力，甚至导致 DB 过载拒绝服务。</li>
<li>通过以下方式防止缓存击穿：<ol>
<li>通过 bloomfilter 记录 key 是否存在，从而避免无效 Key 的查询；</li>
<li>在 Redis 缓存不存在的 Key，从而避免无效 Key 的查询；</li>
</ol>
</li>
</ul>
</li>
<li>缓存雪崩	<ul>
<li>缓存雪崩是指由于大量的热数据设置了相同或接近的过期时间，导致缓存在某一时刻密集失效，大量请求全部转发到 DB，或者是某个冷数据瞬间涌入大量访问，这些查询在缓存 MISS 后，并发的将请求透传到 DB，DB 瞬时压力过载从而拒绝服务。目前常见的预防缓存雪崩的解决方案，主要是通过对 key 的 TTL 时间加随机数，打散 key 的淘汰时间来尽量规避，但是不能彻底规避。</li>
</ul>
</li>
</ol>
<p>本文主要讲的是第一个问题：缓存一致性</p>
<h3 id="基本要点"><a href="#基本要点" class="headerlink" title="基本要点"></a>基本要点</h3><ol>
<li>缓存替换方式<ul>
<li>更新缓存VS淘汰缓存</li>
</ul>
</li>
<li>缓存替换和写库顺序<ul>
<li>先替换缓存后写数据库vs先写数据库后替换</li>
</ul>
</li>
<li>更新缓存数据源是主还是从<ul>
<li>主从数据库下（主从延迟），是从还是主读取数据进行缓存替换</li>
</ul>
</li>
<li>从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案</li>
</ol>
<h4 id="Cache-Aside-pattern"><a href="#Cache-Aside-pattern" class="headerlink" title="Cache-Aside pattern"></a>Cache-Aside pattern</h4><p>最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。</p>
<ol>
<li>失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。</li>
<li>命中：应用程序从cache中取数据，取到后返回。</li>
<li>更新：先把数据存到数据库中，成功后，再让缓存失效。</li>
</ol>
<p>大多数业务，使用这样的更新套路即可</p>
<h3 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h3><ol>
<li><p>以下摘自：<a href="https://blog.csdn.net/ZLHZHJ/article/details/80176988">高并发下缓存和数据库一致性问题</a></p>
<ul>
<li>主从一致性，即修改完立马就要读取到最新的数据（本方案不涉及到缓存的同步，如果涉及可以结合全篇思路去设计） 方案如下：<ol>
<li>半同步复制，理应数据库原生的功能，等从库同步完才返回结果，缺点吞吐量下降</li>
<li>强制读主库，部分有一致性要求的，代码中强制读取主库，这个时候一定要结合好缓存，提高读性能</li>
<li>数据库中间件，一般情况数据库中间件把写路由到主，把读路由到从，此处是记录所以写的key，在500ms内读主库，超过500ms后读从库，能保证绝对的一致性，缺点是成本比较高</li>
<li>缓存记录写key法，发生写操作，把此key记录在缓存里过期时间500ms，key存在表示刚更新过，还没完成同步，强制路由到主库，没有则路由到从库</li>
</ol>
</li>
<li>关于强一致的需求，现实是不多的，本身就使用cache了还要求强一致，貌似本末倒置，但是不排除特殊情况的存在，主要是思路和大家分享。</li>
<li>金钱余额业务有这种强一致需求(用户余额表接近6亿，查询QPS晚高峰4~5k )</li>
</ul>
</li>
<li><p>读和写使用分布式锁控制，这样就能保证，先操作（或读或写）数据的先获得结果；写的时候让读流量直接走DB，让更新缓存的操作和写DB的操作串行。</p>
</li>
<li><p>延时双删策略 (延时减少读到脏数据的概率, 可以异步延时)</p>
<pre>
（1）先淘汰缓存
（2）再写数据库（这两步和原来一样）
（3）休眠1秒，再次淘汰缓存
这么做，可以将1秒内所造成的缓存脏数据，再次删除。
</pre>
<p>延迟删只是减少概率</p>
</li>
<li><p>只有在读请求比写请求耗时还长的场景下才能产生，实际上这种情况发生的概率会很小</p>
</li>
<li><p>在读流量走从库的情况下，也有可能会导致缓存不一致。<br>由于更新完主库后，binlog还没有同步到从库，这时候DB读到的是旧的值，同样会导致缓存不一致的场景</p>
</li>
<li><p>缓存更新重试机制：使用MQ或binlog (个人不是很喜欢，除非能很好的抽象成公共组件可以考虑)</p>
</li>
<li><p>热点数据查主库(同1中的第4点)  </p>
<ol>
<li>写，更新db，设置热点数据标志（30s（可配置））</li>
</ol>
</li>
<li><p>读，判断是否是热点数据。是，直接读主库（主库超过一定qps，读从库），写缓存；否，读缓存</p>
</li>
<li><p>根据业务id，实时性高的读主库，实时性低的读从库或者缓存</p>
</li>
</ol>
<ul>
<li><a href="https://mp.weixin.qq.com/s/Y9S89MT0uAobzRKgYVrI9Q">浅谈缓存最终一致性的解决方案</a></li>
<li>总结: 在解决缓存一致性的过程中，有多种途径可以保证缓存的最终一致性，应该根据场景来设计合适的方案，读多写少的场景下，可以选择采用“ Cache-Aside 结合消费数据库日志做补偿”的方案，写多的场景下，可以选择采用“ Write-Through 结合分布式锁”的方案 ，写多的极端场景下，可以选择采用“ Write-Behind ” 的方案。</li>
</ul>
<h3 id="其他个人经验"><a href="#其他个人经验" class="headerlink" title="其他个人经验"></a>其他个人经验</h3><ol>
<li>设置缓存时为了防止穿透,并且具备更新缓存的能力,需要失败时提供默认值,设置较大的过期时间</li>
<li>那么需要设置:正常数据更新时间R、失败默认数据过期时间DR、数据过期时间E;</li>
<li>一般E &gt; R &gt; DR</li>
<li>并且,当缓存已经有数据时, 重新远程获取数据失败时,不应该更新缓存</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/xRVUEtbOhCHZHaBa0YQwTQ">太强了，全面解析缓存应用经典问题</a><ul>
<li>缓存的主要存储模式<ol>
<li>Cache Aside（旁路缓存）</li>
<li>Read&#x2F;Write Through（读写穿透）</li>
<li>Write Behind Caching（异步缓存写入）</li>
</ol>
</li>
<li>缓存7大经典问题的常用解决方案<ol>
<li>缓存集中失效</li>
<li>缓存穿透</li>
<li>缓存雪崩</li>
<li>缓存数据不一致</li>
<li>竞争并发</li>
<li>热点Key问题</li>
<li>大Key问题</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a href="https://blog.csdn.net/ZLHZHJ/article/details/80176988">高并发下缓存和数据库一致性问题（更新淘汰缓存不得不注意的细节）</a></li>
<li><a href="https://www.cnblogs.com/rjzheng/p/9041659.html">分布式之数据库和缓存双写一致性方案解析</a></li>
<li><a href="https://mp.weixin.qq.com/s/ziJ8OFiLA1it3sQvycN7Mg">翻越缓存的三座大山</a></li>
<li><a href="https://juejin.cn/post/7085530088628256776">解析分布式系统的缓存设计</a></li>
</ol>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>财务数据报表的跨天之苦</title>
    <url>/2020/07/09/20200710-cai-wu-shu-ju-bao-biao-de-kua-tian-zhi-ku/</url>
    <content><![CDATA[<p>数据报表，尤其是金钱相关的财务报表，对数据的准确性犹为敏感。而服务系统间的处理时间点的存在差异的客观事实（网络时延，失败重试等原因），导致在以天（或月&#x2F;年）为维度的数据报表中，或对账中，常常出现数据不平的问题。</p>
<h3 id="业务描述"><a href="#业务描述" class="headerlink" title="业务描述"></a>业务描述</h3><p>以用户充值加金币的业务为例</p>
<pre>
充值请求---------------->  充值服务A
                 (支付成功的时间x：2020-07-08 23:59:59)
                 ----------------> 金币服务B
                           (加币成功的时间y：2020-07-09 00:00:01)
</pre>
<p>现在，有以下数据报表的需求：输出每一天支付金额以及对应的加金币数目。</p>
<ul>
<li>从上图可以看出，时间x和时间y不在同一天，在出数据报表的时候，这条充值记录应该归为7月8日还是7月9日呢？<ol>
<li>从用户的角度看，充值成功的行为是一个原子操作，用户不关心服务方底层有区分支付时间和加币时间；</li>
<li>从公司财务的角度看，他们同样不关心1描述的问题，只关心报表是否平帐(支付金币＝加币数目)</li>
</ol>
</li>
</ul>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>要解决以上问题：需要统一充值请求的业务时间</p>
<pre>
充值请求---------------->  充值服务A
(生成当前时间addTime并传入)
                 (支付成功的时间x：2020-07-08 23:59:59)
                 (接收addTime参数)
                 ----------------> 金币服务B
                           (加币成功的时间y：2020-07-09 00:00:01)
                           (接收addTime参数)
</pre>

<ul>
<li>充值请求在发起时就会生成一个当前时间addTime，并一直透传到底层服务，那么统一以addTime作为充值的时间点，就不会出现跨天差异导致的数据不平问题。</li>
</ul>
<h3 id="注意事项和监控重跑"><a href="#注意事项和监控重跑" class="headerlink" title="注意事项和监控重跑"></a>注意事项和监控重跑</h3><ul>
<li>上述的方案有一个问题需要解决：addTime 时间的合法性<ol>
<li>传入的addTime大于当前时间</li>
<li>传入的addTime远远小于当前时间</li>
</ol>
</li>
</ul>
<h4 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h4><ul>
<li>问题1显然是错误的，是不合法的请求，但由于系统间可能存在微小差异，可以在逻辑上拒绝addTime大于当前时间超1分钟的请求</li>
<li>问题2是客观存在的。<ol>
<li>addTime是一开始生成的时间，当传到每个服务之后，理论上服务的当前时间必然大于addTime</li>
<li>由于网络超时，重试等原因，相差的时间可能达到分钟级；而由于链路上下层服务因为故障等原因暂时无法处理，那么相差的时间可能到小时级以上。</li>
<li>一般情况下，一个充值请求正常情况下，一分钟之内就能完成。所以有一个定时任务会在凌晨生成昨天的报表，以供财务人员第二天查看。<br>  如果报表已经生成之后，addTime是昨天的充值记录才重试成功，那么将导致该条数据没被统计到！</li>
</ol>
</li>
</ul>
<h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><p>针对上述问题2导致的数据报表错误</p>
<ol>
<li>（程序阻断）当数据报表已经生成之后，拒绝addTime&lt;&#x3D;昨天的请求，避免充值数据和数据报表不一致。同时增加告警，支持解除限制和重跑报表。</li>
<li>（告警重跑）当数据报表已经生成之后，接收到addTime&lt;&#x3D;昨天的请求，且执行成功时告警，通知相关人员重跑报表。</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>有人可能会问，上述的解决方案始终依赖告警和人工补偿。有没有更加自动化的手段？</p>
<ol>
<li>二八法则：避免将资金、精力和时间花在琐碎的多数问题上。上述的方案其实已经解决了大多数场景的问题，如果要完美的解决，必然需要花费更大的精力(可能花费时间比实现原功能更多)。<br>当然可以想办法解决，如果确实有必要的话。</li>
<li>针对一些不常发生的异常问题：增加限制、增加告警、增加人工补偿，是安全快捷、高效成本低的手段。</li>
</ol>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>金钱相关</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式锁简单总结</title>
    <url>/2020/07/11/20200711-fen-bu-shi-suo-jian-dan-zong-jie/</url>
    <content><![CDATA[<h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><ol>
<li>数据库的行级排它锁（如select * from x for update）；</li>
<li>基于zookeeper的瞬间顺序节点；<ul>
<li>最小节点获得锁</li>
</ul>
</li>
<li>基于 Redis 的 SETNX 命令。<ul>
<li>使用lua脚本保证原子性 （Redisson 有封装实现 ）</li>
<li>RedLock <ul>
<li>红锁并非是一个工具，而是Redis官方提出的一种分布式锁的算法。</li>
<li>RedLock作者指出，之所以要用独立的，是避免了redis异步复制造成的锁丢失，比如：主节点没来的及把刚刚set进来这条数据给从节点，就挂了。</li>
<li>红锁算法认为，只要(N&#x2F;2) + 1个节点加锁成功，那么就认为获取了锁， 解锁时将所有实例解锁。</li>
<li><a href="https://mp.weixin.qq.com/s/6bE5WmDubFCcSIMFuEqxEQ">细说Redis分布式锁</a></li>
<li>Redisson 有封装实现</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>本文要讲的是第3种方式。</p>
<h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><ol>
<li><p>使用setnx创建一个key，如果key不存在，则创建成功返回1，否则返回0。根据是否获得锁决定是否执行业务逻辑，执行完后删除key来实现释放锁。</p>
<ul>
<li><code>SET resource_name my_random_value NX PX 30000</code></li>
</ul>
</li>
<li><p>为了避免客户端挂了导致其他客户端无法获得锁的情况，为lock_key设置一个过期时间lock timeout</p>
<ul>
<li>一旦业务逻辑执行时间过长，租约到期，就会引发并发问题。</li>
<li>lock timeout 设置合适的时间，一般情况10s内</li>
<li>相对而言，ZooKeeper版本的分布式锁没有这个问题<ul>
<li>锁的占用时间限制：redis就有占用时间限制，而ZooKeeper则没有，最主要的原因是redis目前没有办法知道已经获取锁的客户端的状态，是已经挂了呢还是正在执行耗时较长的业务逻辑。而ZooKeeper通过临时节点就能清晰知道，如果临时节点存在说明还在执行业务逻辑，如果临时节点不存在说明已经执行完毕释放锁或者是挂了。</li>
<li>使用ZooKeeper可以主动通知客户端释放锁，Redis则不行</li>
</ul>
</li>
</ul>
</li>
<li><p>设置一个随机字符串my_random_value是很有必要的，它保证了一个客户端释放的锁必须是自己持有的那个锁。</p>
<ul>
<li>释放锁lua脚本 <figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>可重入锁</p>
<ul>
<li><a href="https://juejin.cn/post/6961380552519712798">https://juejin.cn/post/6961380552519712798</a></li>
<li>lua 脚本，需要存储 锁名称lockName、获得该锁的线程id和对应线程的进入次数count</li>
<li>加锁 lock.lua <figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">   <span class="comment">-- 不存在该key时</span></span><br><span class="line"><span class="keyword">if</span> (redis.call(<span class="string">&#x27;exists&#x27;</span>, KEYS[<span class="number">1</span>]) == <span class="number">0</span>) <span class="keyword">then</span> </span><br><span class="line">	<span class="comment">-- 新增该锁并且hash中该线程id对应的count置1</span></span><br><span class="line">	redis.call(<span class="string">&#x27;hincrby&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">2</span>], <span class="number">1</span>); </span><br><span class="line">	<span class="comment">-- 设置过期时间</span></span><br><span class="line">	redis.call(<span class="string">&#x27;pexpire&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">1</span>]); </span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>; </span><br><span class="line"><span class="keyword">end</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 存在该key 并且 hash中线程id的key也存在</span></span><br><span class="line"><span class="keyword">if</span> (redis.call(<span class="string">&#x27;hexists&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">2</span>]) == <span class="number">1</span>) <span class="keyword">then</span> </span><br><span class="line">	<span class="comment">-- 线程重入次数++</span></span><br><span class="line">	redis.call(<span class="string">&#x27;hincrby&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">2</span>], <span class="number">1</span>); </span><br><span class="line">	redis.call(<span class="string">&#x27;pexpire&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">1</span>]); </span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>; </span><br><span class="line"><span class="keyword">end</span>; </span><br><span class="line"><span class="keyword">return</span> redis.call(<span class="string">&#x27;pttl&#x27;</span>, KEYS[<span class="number">1</span>]);</span><br></pre></td></tr></table></figure></li>
<li>解锁 unlock.lua <figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">   <span class="comment">-- 不存在key</span></span><br><span class="line"><span class="keyword">if</span> (redis.call(<span class="string">&#x27;hexists&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">3</span>]) == <span class="number">0</span>) <span class="keyword">then</span> </span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"><span class="comment">-- 计数器 -1</span></span><br><span class="line"><span class="keyword">local</span> counter = redis.call(<span class="string">&#x27;hincrby&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">3</span>], <span class="number">-1</span>); </span><br><span class="line"><span class="keyword">if</span> (counter &gt; <span class="number">0</span>) <span class="keyword">then</span> </span><br><span class="line">	<span class="comment">-- 过期时间重设</span></span><br><span class="line">	redis.call(<span class="string">&#x27;pexpire&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">2</span>]); </span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>; </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">	<span class="comment">-- 删除并发布解锁消息</span></span><br><span class="line">	redis.call(<span class="string">&#x27;del&#x27;</span>, KEYS[<span class="number">1</span>]); </span><br><span class="line">	redis.call(<span class="string">&#x27;publish&#x27;</span>, KEYS[<span class="number">2</span>], ARGV[<span class="number">1</span>]); </span><br><span class="line">	<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span>; </span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>锁续约	</p>
<ul>
<li>延长锁的releaseTime延迟释放锁来直到完成业务期望结果，这种不断延长锁过期时间来保证业务执行完成的操作就是锁续约。</li>
</ul>
</li>
<li><p>基于单Redis节点的分布式锁无法解决的安全问题。</p>
<ul>
<li>假如Redis节点宕机了，那么所有客户端就都无法获得锁了，服务变得不可用。为了提高可用性，我们可以给这个Redis节点挂一个Slave，当Master节点不可用的时候，系统自动切到Slave上（failover）。但由于Redis的主从复制（replication）是异步的，这可能导致在failover过程中丧失锁的安全性。</li>
<li>Redlock算法</li>
</ul>
</li>
<li><p>使用Redisson可以满足以上所有需求。</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/135864820">Redisson 实现分布式锁原理分析</a></li>
<li>Redisson没有设置一个随机值，也可以解决解锁误删的问题。因为Redisson在解决可重入时，已经定义了threadId进行重入计数，通过threadId就可以判断是否是自己之前加的锁。</li>
<li>锁续期：leaseTime 必须是 -1 才会开启 Watch Dog 机制，也就是如果你想开启 Watch Dog 机制必须使用默认的加锁时间为 30s。如果你自己自定义时间，超过这个时间，锁就会自定释放，并不会延长。</li>
<li>锁等待：当锁正在被占用时，等待获取锁的进程并不是通过一个 while(true) 死循环去获取锁，而是利用了 Redis 的发布订阅机制,通过 await 方法阻塞等待锁的进程，有效的解决了无效的锁申请浪费资源的问题。</li>
<li>缺点：Redis Cluster 或者说是 Redis Master-Slave 架构的主从异步复制导致的 Redis 分布式锁的最大缺陷（在 Redis Master 实例宕机的时候，可能导致多个客户端同时完成加锁）</li>
<li>用法：<a href="https://www.jianshu.com/p/cde0700f0128">使用Redisson实现分布式锁</a></li>
</ul>
</li>
</ol>
<ul>
<li>个人看法： 分布式锁并不是绝对可靠，只能尽量保证大多数时候可靠，业务应该自行保证一旦锁失效时的逻辑正确性。</li>
</ul>
<h3 id="Zookeeper和Redis分布式锁的比较"><a href="#Zookeeper和Redis分布式锁的比较" class="headerlink" title="Zookeeper和Redis分布式锁的比较"></a>Zookeeper和Redis分布式锁的比较</h3><ol>
<li>添加和删除，Reids性能较高</li>
<li>Zookeeper有等待锁队列，大大提升抢锁效率；Redis需要考虑超时，原子性，误删等场景，客户端需要自旋等锁。</li>
<li>使用 Redis 实现分布式锁在很多企业中非常常见，而且大部分情况下都不会遇到所谓的“极端复杂场景”。所以使用 Redis 作为分布式锁也不失为一种好的方案，最重要的一点是 Redis 的性能很高，可以支撑高并发的获取、释放锁操作。</li>
<li>ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。<br>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。<br>但是 ZK 也有其缺点：如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul>
<li><p>可以尝试使用Redisson实现分布式锁</p>
</li>
<li><p>Redis的作者antirez给出了一个更好的实现，称为Redlock，算是Redis官方对于实现分布式锁的指导规范。Redlock的算法描述就放在Redis的官网上：<br><a href="https://redis.io/topics/distlock">https://redis.io/topics/distlock</a></p>
</li>
<li><p>举个场景的例子来详细说明：一提到分布式锁问题，大多数人想到的方案是基于Redis的Master-Slave模式来实现。这个实现方案行不行？分布式锁本质是一个CP需求，基于Redis的实现是一个AP需求，乍一看基于Redis的实现是无法满足的。脱离业务场景来谈架构都是耍流氓。<br>从技术战略的需求层面来看，如果分布式锁在极端情况下获取锁的不一致，社交业务场景能够接受，那么基于Redis的实现是完全可行的。如果业务是交易场景，分布式锁在极端情况下获取锁的不一致性无法接受，那么基于Redis的实现方案是不可行的。在锁强一致性的场景下，需要采取基于CP模型的etcd等方案来实现。</p>
</li>
<li><p>redis-cli提供了EVAL与EVALSHA命令执行Lua脚本:</p>
<ol>
<li>EVAL<ul>
<li>EVAL script numkeys key [key …] arg [arg …]</li>
<li>key和arg两类参数用于向脚本传递数据, 他们的值可在脚本中使用KEYS和ARGV两个table访问: KEYS表示要操作的键名, ARGV表示非键名参数(并非强制).</li>
</ul>
</li>
<li>EVALSHA</li>
</ol>
<pre><code>- EVALSHA命令允许通过脚本的SHA1来执行(节省带宽), Redis在执行EVAL/SCRIPT LOAD后会计算脚本SHA1缓存, EVALSHA根据SHA1取出缓存脚本执行.
</code></pre>
</li>
<li><p>redis一般都是单机房部署，如果要控制多个机房只有一个锁，考虑使用Consul来实现分布式锁。 </p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/TEWnB_VqAW12nVrQlNmgNg">Redis 分布式锁的 10 个坑</a></p>
<ol>
<li>非原子操作（setnx + expire）<ul>
<li>如果刚要执行完setnx加锁，正要执行expire设置过期时间时，进程crash或者要重启维护了，那么这个锁就“长生不老”了，别的线程永远获取不到锁了</li>
</ul>
</li>
<li>被别的客户端请求覆盖（ setnx + value为过期时间）<ul>
<li>Getset 命令用于设置指定 key 的值，并返回 key 的旧值。</li>
</ul>
</li>
<li>忘记设置过期时间</li>
<li>业务处理完，忘记释放锁</li>
<li>B的锁被A给释放了<br>- 假设在这样的并发场景下：A、B两个线程来尝试给Redis的keylockKey加锁，A线程先拿到锁（假如锁超时时间是3秒后过期）。如果线程A执行的业务逻辑很耗时，超过了3秒还是没有执行完。这时候，Redis会自动释放lockKey锁。刚好这时，线程B过来了，它就能抢到锁了，开始执行它的业务逻辑，恰好这时，线程A执行完逻辑，去释放锁的时候，它就把B的锁给释放掉了。<br>- 正确的方式应该是，在用set扩展参数加锁时，放多一个这个线程请求的唯一标记，比如requestId，然后释放锁的时候，判断一下是不是刚刚的请求。</li>
<li>释放锁时，不是原子性<ul>
<li>因为判断是不是当前线程加的锁和释放锁不是一个原子操作。如果调用unlock(lockKey)释放锁的时候，锁已经过期，所以这把锁已经可能已经不属于当前客户端，会解除他人加的锁。</li>
<li>判断和删除是两个操作，不是原子的，有一致性问题。释放锁必须保证原子性，可以使用Redis+Lua脚本来完成</li>
</ul>
</li>
<li>锁过期释放，业务没执行完<ul>
<li>是否可以给获得锁的线程，开启一个定时守护线程，每隔一段时间检查锁是否还存在，存在则对锁的过期时间延长，防止锁过期提前释放。</li>
<li>当前开源框架Redisson解决了这个问题: 只要线程一加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果线程一还持有锁，那么就会不断的延长锁key的生存时间。</li>
</ul>
</li>
<li>Redis分布式锁和@transactional一起使用失效<ul>
<li>正确的实现方法,可以在updateDB方法之前就上锁，即还没有开事务之前就加锁，那么就可以保证线程的安全性.</li>
</ul>
</li>
<li>锁可重入<ul>
<li>前面讨论的Redis分布式锁，都是不可重入的。</li>
<li>不可重入的分布式锁的话，是可以满足绝大多数的业务场景。但是有时候一些业务场景，我们还是需要可重入的分布式锁</li>
<li>Redis只要解决这两个问题，就能实现重入锁了：<ul>
<li>怎么保存当前持有的线程</li>
<li>怎么维护加锁次数（即重入了多少次）</li>
</ul>
</li>
<li>实现一个可重入的分布式锁，我们可以参考JDK的ReentrantLock的设计思想。实际上，可以直接使用Redisson框架，它是支持可重入锁的。</li>
</ul>
</li>
<li>Redis主从复制导致的坑<ul>
<li>如果线程一在Redis的master节点上拿到了锁，但是加锁的key还没同步到slave节点。恰好这时，master节点发生故障，一个slave节点就会升级为master节点。线程二就可以获取同个key的锁啦，但线程一也已经拿到锁了，锁的安全性就没了。</li>
<li>为了解决这个问题，Redis作者 antirez提出一种高级的分布式锁算法：Redlock。Redlock核心思想是这样的：<ul>
<li>搞多个Redis master部署，以保证它们不会同时宕掉。并且这些master节点是完全相互独立的，相互之间不存在数据同步。同时，需要确保在这多个master实例上，是与在Redis单实例，使用相同方法来获取和释放锁。</li>
<li>简化下步骤就是：<ol>
<li>按顺序向5个master节点请求加锁</li>
<li>根据设置的超时时间来判断，是不是要跳过该master节点。</li>
<li>如果大于等于3个节点加锁成功，并且使用的时间小于锁的有效期，即可认定加锁成功啦。</li>
<li>如果获取锁失败，解锁！</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li>个人意见:一般情况下(绝大多数),业务不要强依赖于redis做互斥逻辑</li>
</ol>
</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a href="https://yq.aliyun.com/articles/60663">分布式锁的实现</a></li>
<li><a href="https://www.cnblogs.com/gxyandwmm/p/9588383.html">使用Redis作为分布式锁的一些注意点</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzUzMjkwMjg3Mg==&mid=2247484843&amp;idx=1&amp;sn=549ed30972eea76d5e7a0a9e1cfaf321&source=41#wech">如何实现靠谱的分布式锁？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODI5Njc2MA==&mid=2655825455&idx=1&sn=53e7043d76c0a39cf1b0d3be7a384ade&chksm=bd74e3f88a036aee104a1ec6001379d2238db2fde913b889b42138316e84ce9ed5e1ec271a10&mpshare=1&scene=1&srcid=0715ZMUAKOiQLNOSllsVZVKW%23rd">分布式锁用Redis还是Zookeeper？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261514&idx=1&sn=47b1a63f065347943341910dddbb785d&chksm=84479e13b3301705ea29c86f457ad74010eba8a8a5c12a7f54bcf264a4a8c9d6adecbe32ad0b&scene=21#wechat_redirect">基于Redis的分布式锁到底安全吗（上）？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&mid=2247487106&idx=1&sn=dd5f327c46d4274ba643a31cd0f0a77e&chksm=fa497133cd3ef82">80% 人不知道的 Redis 分布式锁的正确实现方式（Java 版）</a></li>
<li><a href="https://mp.weixin.qq.com/s/On55CQezQ5sOw1E-YUpVUw">Redis结合Lua脚本实现高并发原子性操作</a></li>
<li><a href="https://mp.weixin.qq.com/s/6bE5WmDubFCcSIMFuEqxEQ">细说Redis分布式锁</a></li>
<li><a href="https://mp.weixin.qq.com/s/1TsBsaItcZ6fOg-bo2tGww">分布式锁用 Redis 好，还是 ZooKeeper 好？</a></li>
<li><a href="https://www.zhihu.com/question/452803310/answer/1931377239">使用Redis实现分布式锁和ZK实现分布式锁有什么区别，分别有哪些场景?</a></li>
</ol>
]]></content>
      <tags>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式限流简单总结</title>
    <url>/2020/07/11/20200711-fen-bu-shi-xian-liu-jian-dan-zong-jie/</url>
    <content><![CDATA[<h3 id="基本描述"><a href="#基本描述" class="headerlink" title="基本描述"></a>基本描述</h3><ul>
<li><p>限流分类</p>
<ol>
<li>单机限流</li>
<li>分布式限流</li>
</ol>
</li>
<li><p>限流的指标</p>
<ul>
<li>每秒处理的事务数 (TPS)，每秒请求数 (hits per second)</li>
<li>使用 hits per second 作为限流指标</li>
</ul>
</li>
<li><p>限流规则包含三个部分：时间粒度，接口粒度，最大限流值。</p>
</li>
<li><p>选择单机限流还是分布式限流</p>
<ol>
<li>单机限流一般针对服务负载，防止突发流量压垮服务器</li>
<li>分布式限流一般针对在业务侧做细粒度限流</li>
</ol>
</li>
</ul>
<h3 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h3><ol>
<li>固定时间窗口<ul>
<li>首先需要选定一个时间起点，之后每次接口请求到来都累加计数器，如果在当前时间窗口内，根据限流规则（比如每秒钟最大允许 100 次接口请求），累加访问次数超过限流值，则限流熔断拒绝接口请求。当进入下一个时间窗口之后，计数器清零重新计数。</li>
<li>限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量。</li>
</ul>
</li>
<li>滑动时间窗口<ul>
<li>滑动时间窗口限流算法可以保证任意时间窗口内接口请求次数都不会超过最大限流值，但是仍然不能防止在细时间粒度上面访问过于集中的问题</li>
</ul>
</li>
<li>令牌桶算法(Token Bucket)<ul>
<li>接口限制 t 秒内最大访问次数为 n，则每隔 t&#x2F;n 秒会放一个 token 到桶中；桶中最多可以存放 b 个 token</li>
<li>令牌桶大小为 b，所以是可以应对突发流量的</li>
<li>没有提前预热的令牌桶，如果做否决式限流，会导致误杀很多请求</li>
</ul>
</li>
<li>漏桶算法(Leaky Bucket)<ul>
<li>漏桶算法稍微不同与令牌桶算法的一点是：对于取令牌的频率也有限制，要按照 t&#x2F;n 固定的速度来取令牌，所以可以看出漏桶算法对流量的整形效果更加好，流量更加平滑，任何突发流量都会被限流。</li>
</ul>
</li>
</ol>
<h3 id="分布式限流"><a href="#分布式限流" class="headerlink" title="分布式限流"></a>分布式限流</h3><ol>
<li>采用redis+lua的方案做分布式限流 (参考业界实现方案即可，需注意原子性)</li>
<li>由于使用中心存储计数的方式性能较差，在业务允许的情况下可以考虑将限制的数量分摊到每个服务(服务数通过服务发现接口获取)，间接使用单机限流提升性能。</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ol>
<li>Google的Guava包中的RateLimiter<ul>
<li>令牌桶算法的解决方案，假设1S需要限流5次；也就是1S会往桶里面方5个Token;如果在这1S内桶满了则不再加请求，如果空了则表示达到限制的上线了，会阻塞，直到有数据加入再次处理。</li>
</ul>
</li>
<li>[ratelimiter4j] (<a href="https://github.com/wangzheng0822/ratelimiter4j">https://github.com/wangzheng0822/ratelimiter4j</a>)<ul>
<li>分布式限流算法的性能瓶颈主要在中心计数器 Redis，从我们开源的 ratelimiter4j 压测数据来看，在没有做 Redis sharding 的情况下，基于单实例 Redis 的分布式限流算法的性能要远远低于基于内存的单机限流算法，基于我们的压测环境，单机限流算法可以达到 200 万 TPS，而分布式限流算法只能做到 5 万 TPS。所以，在应用分布式限流算法时，一定要考量限流算法的性能是否满足应用场景，如果微服务接口的 TPS 已经超过了限流框架本身的 TPS，则限流功能会成为性能瓶颈影响接口本身的性能。</li>
</ul>
</li>
</ol>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a href="https://mp.weixin.qq.com/s/k9tm-4lBwm69nxnYp9octA">微服务接口限流的设计与思考</a></li>
</ol>
]]></content>
      <tags>
        <tag>限流</tag>
      </tags>
  </entry>
  <entry>
    <title>使用回调机制提高接口安全性</title>
    <url>/2020/07/12/20200712-shi-yong-hui-diao-ji-zhi-ti-gao-jie-kou-an-quan-xing/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><ul>
<li>接口回调在平常的业务开发中并不罕见。做过渠道推广业务，对接过广告平台接口的同学应该比较熟悉。</li>
<li>在业务的作用主要是两个<ol>
<li>异步通知</li>
<li>业务查询</li>
</ol>
</li>
</ul>
<p>本文主要讲的第二种，并通过一个业务例子来展开描述</p>
<h3 id="业务描述"><a href="#业务描述" class="headerlink" title="业务描述"></a>业务描述</h3><p>有以下业务场景，用户通过充值加金币：</p>
<pre>
充值请求----------> 服务A（充值服务）
             [1.验证用户已经支付成功]
             [2.发起加金币请求]------------>服务B（金币服务）
</pre>

<ul>
<li><p>服务B如何验证加金币操作的请求是合法，从而保证资金安全呢？</p>
<ul>
<li>有一种方法是通过分配业务对应的秘钥和服务端签名对比，验证请求的合法性</li>
</ul>
</li>
<li><p>通过秘钥和验签的方式无法避免以下问题</p>
<ol>
<li>其他业务方误用秘钥</li>
<li>因误操作而发加币请求</li>
<li>业务方有bug一次充值多次加币</li>
</ol>
</li>
</ul>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul>
<li>其实以上描述的业务有一个特点：每一次操作都有对应的前置操作，比如<ol>
<li>充值加金币的前置操作是：充值支付成功</li>
<li>活动类加金币的前置操作是：用户达到活动要求</li>
</ol>
</li>
</ul>
<p>那么作为底层的金币服务，可以使用定义一种同样的回查机制，由各业务方实现查询逻辑，金币服务通过回查来检验请求的合法性，从而提高安全性。</p>
<ul>
<li>基础服务（金币服务）接收回调链接地址有两种方式：</li>
</ul>
<ol>
<li>通过后台配置，每个业务配置对应回调链接和相应的参数 （相比可能比较安全可控，但不灵活）</li>
<li>通过参数获取，如callback参数（灵活，但是要设计完善的校验机制保证安全）<ul>
<li>可结合公司的基础服务实现，如可以通过服务发现获取服务对应的地址，只需传uri即可</li>
</ul>
</li>
</ol>
<pre>
充值请求----------> 服务A（充值服务）
             [1.验证用户已经支付成功]
             [2.发起加金币请求]------------>服务B（金币服务）
                                <----------[3.回调验证] [4.加金币] < pre>

<ul>
<li>统一回调接口返回格式</li>
</ul>
<pre>
回调接口返回格式
{
    "code": 0,
    "message": "success"
}
0 代表成功；其他：失败

回调用于查询业务订单是否存在，检验是否非法订单
一般实现逻辑建议业务方直接查主库
</pre>

<ul>
<li>回调无法绝对解决以上提出的问题，只能说一定程度上提升接口的安全性级别。</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul>
<li>使用非对称加密，是不是可以替换回调验证？（客户端使用公钥解密，服务端使用私钥加密，前提是私钥不泄漏）</li>
</ul>
</----------[3.回调验证]></pre>]]></content>
      <tags>
        <tag>接口回调</tag>
      </tags>
  </entry>
  <entry>
    <title>由灾备工作中引发的对“比例”的思考</title>
    <url>/2020/07/13/20200713-you-zai-bei-gong-zuo-zhong-yin-fa-de-dui-bi-li-de-si-kao/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><ul>
<li>关于文章的题目我想了很久，暂时没想到合适的题目，姑且先这样吧</li>
<li>之前在做灾备工作的时候，经常涉及服务的强弱依赖，超时时间，降级，以及业务折中方面的思考，下面将通过一些例子简要进行描述</li>
</ul>
<h3 id="场景描述"><a href="#场景描述" class="headerlink" title="场景描述"></a>场景描述</h3><ul>
<li><p>从服务所依赖的重要程度上来区分有“强依赖”和“弱依赖”。</p>
<ol>
<li>通常上，针对“弱依赖”我们会设置较小的超时时间(比如100ms以内)，并且在失败率较高是进行降级；</li>
<li>而针对“强依赖”我们会设置一个较大的超时时间，当接口失败时返回“服务繁忙“，表示暂不可用(当然可以产品层面进行合适的引导)</li>
</ol>
</li>
<li><p>我们在灾备演练中，通过停其中一个机房，触发以下的问题</p>
<ol>
<li>强依赖超时问题（停机房瞬间）</li>
<li>弱依赖多变长的问题（停机房期间）</li>
</ol>
</li>
<li><p>从而导致停机房瞬间接口失败率高，停机房期间接口时延上涨严重。由此引发我对“比例“问题的思考。</p>
<ol>
<li>强依赖超时时间设长，可以减少失败率，但也有可能导致服务worker线程池被占满而拒绝请求。</li>
<li>弱依赖虽然每个都设置100ms以内，但是当依赖的服务超过10个时(真实业务真的有)，可能导致总时长超过一秒(弱依赖慢但都没熔断，所以没降级；可异步并发的弱依赖的另说)</li>
</ol>
</li>
</ul>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol>
<li>对强依赖，可设置超时时间的比例（比如只有20%的请求可以超过1s，其他的控制在100ms以内），解决停机房瞬间，线程池占满拒绝请求的问题</li>
<li>对弱依赖，可控制多个弱依赖的总超时时间，解决停机房期间跨机房调用导致时延一直上涨的问题<ul>
<li>单个调用超时时间可分级设置比例；多个调用（可熔断）可聚合在一起设置总超时时间比例</li>
<li>降级优先级排序，控制总时间。熔断线程池，控制比例超时。允许一定的时间超时。流量控制。物理隔离。</li>
</ul>
</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ol>
<li>针对<a href="https://kingson4wu.github.io/2020/07/12/20200712-%E4%BD%BF%E7%94%A8%E5%9B%9E%E8%B0%83%E6%9C%BA%E5%88%B6%E6%8F%90%E9%AB%98%E6%8E%A5%E5%8F%A3%E5%AE%89%E5%85%A8%E6%80%A7/">使用回调机制提高接口安全性</a>所讲的，某些网络场景可以考虑针对大金额的请求才回调，减少RPC次数，这其实也是一个“比例”问题。</li>
</ol>
]]></content>
      <tags>
        <tag>容灾</tag>
        <tag>降级</tag>
      </tags>
  </entry>
  <entry>
    <title>业务重构实践总结</title>
    <url>/2020/07/14/20200714-ye-wu-chong-gou-shi-jian-zong-jie/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>业务重构似乎是必然且合理的过程。一个项目刚开始为了快速上线和试错，总会或多或少出现不合理的地方。当项目活下来了，为了寻求下一步的发展，服务的稳定和扩展性提升了优先级，自然就需要有人来重构了，这也是项目历史遗留的技术债务。</p>
</blockquote>
</blockquote>
<h3 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h3><ul>
<li>公司原有的业务几乎都是PHP编写的，并且处于一个很大的项目里维护和运行，可以说是大杂烩。随着业务发展和用户量的提升，渐渐得暴露了很多问题：<ol>
<li>PHP运行效率较低，业务未进行隔离，出问题时相互影响；</li>
<li>PHP 过于灵活的语言特性，导致后期较高的后期维护成本；</li>
<li>基础框架和服务对PHP支持不足；</li>
<li>实现灾备比较困难。</li>
</ol>
</li>
</ul>
<h3 id="重构语言选择"><a href="#重构语言选择" class="headerlink" title="重构语言选择"></a>重构语言选择</h3><ul>
<li>我们选择Java作为开发语言进行重构<ol>
<li>静态类型，多人协作开发和维护更加安全可靠；</li>
<li>内部基础组件的 Java 版生态比较完善；</li>
<li>学习成本低，且开发效率较 PHP 没有明显降低。</li>
</ol>
</li>
</ul>
<h3 id="重构的工作是什么？"><a href="#重构的工作是什么？" class="headerlink" title="重构的工作是什么？"></a>重构的工作是什么？</h3><ol>
<li>最简单直接的主要工作：就是充当PHP到Java语言的翻译，将PHP代码转化成Java代码，并保持逻辑不变，对上层业务是无感知的；</li>
<li>除此之外，对业务逻辑进行优化和简化，提高后续的可维护性和开发效率；对服务架构进行优化，提升服务的稳定性和可靠性。这是重构的主要意义；</li>
<li>重构完成之后，制定完善的验证和上线方案。</li>
</ol>
<h3 id="实施过程"><a href="#实施过程" class="headerlink" title="实施过程"></a>实施过程</h3><ul>
<li>Step 1. 用 Java 重构逻辑<ul>
<li>对外暴露的协议（HTTP 、RPC 接口定义和返回数据）与之前保持一致（保持协议一致很重要，之后迁移依赖方会更方便）</li>
<li>尽量翻译而不是重构优化（至少第一版重构采取这样的策略）</li>
</ul>
</li>
<li>Step 2. 验证新逻辑正确性<ul>
<li>当代码重构完成后，在将流量切换到新逻辑之前，我们会先验证新服务的正确性。</li>
<li>考验对业务的熟悉程度和翻译的准确度（代码太久远，最熟悉的可能只有你自己）</li>
<li>单元测试保证</li>
</ul>
</li>
<li>Step 3. 灰度放量<ul>
<li>当一切验证通过之后，我们会开始按照百分比转发流量。</li>
<li>PHP入口对接底层新逻辑（验证逻辑正确性；之所以不直接从流量入口切换，是为了保证稳定性，在出现问题时可以迅速回滚。）</li>
<li>外网代理切到新接口（保持协议一致，无需前端修改，切换彻底）</li>
</ul>
</li>
</ul>
<h3 id="经验总结"><a href="#经验总结" class="headerlink" title="经验总结"></a>经验总结</h3><ol>
<li>PHP代码太复杂，项目又不容易跑起来怎么办？<ul>
<li>默默睁大眼睛翻译还能怎样。。。</li>
<li>如何验证是否翻译正确？</li>
<li>找个在线PHP执行平台把复杂的代码片断跑起来，按照执行结果编写测试用例</li>
</ul>
</li>
<li>PHP代码太狗血太久远，万一翻译到半死发现这段逻辑根本已经没用了怎么办？<ul>
<li>把你的服务当nginx用，参数不符合条件的转发到旧服务，记录入参和返回结果，打日志和监控观察流量</li>
</ul>
</li>
</ol>
<h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><ol>
<li>不能相信自己</li>
<li>不能相信别人</li>
<li>只能相信自己</li>
<li>乖乖覆盖测试用例</li>
</ol>
]]></content>
      <tags>
        <tag>重构</tag>
      </tags>
  </entry>
  <entry>
    <title>单元测试的工具和技巧</title>
    <url>/2020/07/14/20200714-dan-yuan-ce-shi-de-gong-ju-he-ji-qiao/</url>
    <content><![CDATA[<h3 id="提高单元测试覆盖率"><a href="#提高单元测试覆盖率" class="headerlink" title="提高单元测试覆盖率"></a>提高单元测试覆盖率</h3><ul>
<li><p>提高bean类的覆盖率</p>
<ol>
<li>pojo-tester</li>
<li>lombok [lɒmˈbɒk]</li>
<li>kotlin</li>
</ol>
</li>
<li><p>定义一些过滤规则</p>
</li>
</ul>
<h3 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h3><ul>
<li>mock神器：mockito</li>
<li>sql模拟测试：h2</li>
<li>对测试进行参数化: JUnitParams</li>
<li>Awaitility: 一个小型的Java领域专用语言（DSL），用于对异步的操作进行同步。<br><a href="https://www.ctolib.com/topics-109441.html">https://www.ctolib.com/topics-109441.html</a></li>
<li>WireMock: 用于模拟HTTP服务的工具 （对外部服务打桩） </li>
<li>Selenium：编写UI驱动的端到端测试</li>
</ul>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li><p>使用 集成测试 覆盖若干个完整的核心流程</p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/2tBrkzjeufAP-CNrNcJb9A">测试金字塔（深度好文）</a></p>
</li>
</ul>
]]></content>
      <tags>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title>如何接手一个旧项目</title>
    <url>/2020/07/14/20200714-ru-he-jie-shou-yi-ge-jiu-xiang-mu/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>改变心态，以前会抱怨业务乱，但是业务在发展过程中乱是很正常的，也要有人来主动整理，同时也在考验和锻炼整理人的能力。</p>
</blockquote>
</blockquote>
<ol>
<li>梳理现有业务文档，进行归类(如果有的话？)</li>
<li>拉代码，服务本地跑起来，并跑通单元测试</li>
<li>梳理服务现有的所有监控平台和数据</li>
<li>梳理服务的依赖关系和超时时间</li>
<li>梳理服务的依赖组件（MQ，Redis，DB等）和部署情况</li>
<li>数据库表梳理</li>
<li>了解服务的部署和灾备架构（机器数，机房，流量入口）</li>
<li>代码核心逻辑阅读（核心流量接口）</li>
<li>了解服务的监控情况，常用配置和开关，相关告警配置通知人</li>
<li>待优化任务和遗留问题接手</li>
</ol>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/lJAbzU43RJU-YLFMfiM__w">软件泥潭真体验</a><ul>
<li>“定时炸弹”</li>
</ul>
</li>
</ul>
<pre>
附录1: 交接列表示例（设计与开发）

## 项目管理
    - 项目日程 
    - 会议记录
    - 体制图 
## 项目要件
    - 业务功能清单 
    - 业务流程图 
    - 需求变更记录 
    - 操作说明书/用户手册 
    - 常见问题一览 
## 界面设计
    - UE设计稿
    - 高保真画面设计稿
    - 需求变更一览
## 系统设计
    - 系统架构设计图
    - 部署架构图DB关联图（ER图）和DB详细设计
    - 系统间集成关系图
    - 对接系统一览表和对接系统接口清单
## 开发制作
    - 源代码
    - 代码运行说明
## 测试
    - 系统测试用例与系统测试报告书
    - 性能测试用例与性能测试报告书
    - 用户测试用例
    - 用户测试签字

附录2: 交接列表示例（运维相关）

## 上线相关
    - 上线判定表
    - 上线操作记录
    - 历次上线版本说明
    - 临时对应体制
## 基础设施
    - 硬件资源一览
    - 软件资源一览
    - 服务器/系统账号权限
    - 系统工具 - 付费/免费软件
## 运维体制
    - 运维工作一览表
    - 近半年运维工作应对流程
    - 运维体制
    - 故障对应流程
    - SLA（服务水平协议）
## DEVOPS（开发运维一体化）
    - CI/CD工具与使用
    - 监控工具
    - 备份管理
    - 代码库与分支管理
    - 数据库相关配置与策略

</pre>]]></content>
  </entry>
  <entry>
    <title>canal使用总结</title>
    <url>/2020/07/15/20200715-canal-shi-yong-zong-jie/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文只讲自己在使用canal之后的一些总结，关于canal的基础用法和介绍，不在这里赘述。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><ul>
<li><p>canal的原理是基于mysql binlog技术，所以这里一定需要开启mysql的binlog写入功能，建议配置binlog模式为row</p>
</li>
<li><p>原文：<a href="https://blog.csdn.net/liupeifeng3514/article/details/79687130">https://blog.csdn.net/liupeifeng3514/article/details/79687130</a> </p>
</li>
<li><p>mysql的自带复制技术可分成三步：</p>
<ol>
<li>master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events，可以通过show binlog events进行查看）；</li>
<li>slave将master的binary log events拷贝到它的中继日志(relay log)，这里是I&#x2F;O thread线程；</li>
<li>slave重做中继日志中的事件，将改变反映它自己的数据，这里是SQL thread线程。</li>
</ol>
</li>
<li><p>基于canal&amp;otter的复制技术和mysql复制类似，具有类比性：</p>
<ol>
<li>Canal对应于I&#x2F;O thread，接收Master Binary Log；</li>
<li>Otter对应于SQL thread，通过Canal获取Binary Log数据，执行同步插入数据库；</li>
</ol>
</li>
<li><p>两者的区别在于：</p>
<ol>
<li>otter目前嵌入式依赖canal，部署为同一个jvm，目前设计为不产生Relay Log，数据不落地；</li>
<li>otter目前允许自定义同步逻辑，解决各类需求；<br>  a. ETL转化. 比如Slave上目标表的表名，字段名，字段类型不同，字段个数不同等.<br>  b. 异构数据库. 比如Slave可以是oracle或者其他类型的存储,nosql等.<br>  c. M-M部署，解决数据一致性问题<br>  d. 基于manager部署，方便监控同步状态和管理同步任务.</li>
</ol>
</li>
<li><p>canal的工作原理：</p>
<ul>
<li>canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议</li>
<li>mysql master收到dump请求，开始推送binary log给slave(也就是canal)</li>
<li>canal解析binary log对象(原始为byte流)</li>
</ul>
</li>
</ul>
<h3 id="使用简述"><a href="#使用简述" class="headerlink" title="使用简述"></a>使用简述</h3><ol>
<li>对MySQL给canal-server授权<ul>
<li><code>CREATE USER &#39;canal_server&#39; IDENTIFIED BY &#39;canal_server&#39;;</code></li>
<li><code>GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#39;canal_server&#39;;</code></li>
</ul>
</li>
<li>canal使用ZK来做HA，因为涉及多个client时，消费计算的业务较为复杂的问题，所以目前在使用上只是单点部署，基本能满足需求。</li>
</ol>
<h3 id="使用总结"><a href="#使用总结" class="headerlink" title="使用总结"></a>使用总结</h3><ol>
<li>可以通过指定binlog文件和position来重放binlog数据：</li>
<li>如何查看MySQL位点：<a href="https://blog.csdn.net/c1052981766/article/details/80604083">https://blog.csdn.net/c1052981766/article/details/80604083</a><ul>
<li><code>show master status</code></li>
<li><code>show binary logs</code></li>
<li><code>show binlog events in &#39;binlog.000368&#39; limit 10;</code> &#x2F;&#x2F;pos 就是位点, 重启 canal</li>
<li>如何查到旧记录的位点？<ol>
<li>由canal-server中meta.dat记录</li>
<li>通过 mysqlbinlog 命令分析 mysql-bin.xxx 文件内容，确定增量恢复到的时间点（运维协助）。</li>
</ol>
</li>
</ul>
</li>
<li>除了用pos点的办法进行恢复，也可以通过指定时间区间进行恢复，按时间恢复需要用mysqlbinlog命令读取binlog日志内容，找时间节点。<ul>
<li><a href="https://blog.csdn.net/zyz511919766/article/details/38089393">使用mysqlbinlog工具进行基于位置或时间点的数据恢复</a></li>
</ul>
</li>
<li>重跑。修改instance.properties文件设置重跑起始位点，删除meta.dat文件并重启。注意回放数据时视业务情况，可能要忽略第一个位点对应的数据。</li>
<li>重启之后batchId会变，所以不能使用batchId来做幂等处理</li>
<li>使用mysql主从同步和使用canal同步的区别? 同步数据为什么不直接用主从同步机制？<ol>
<li>mysql版本不一致，不支持主从同步</li>
<li>并不是自己的库，只需要同步几张表，运维不会做这种定制化</li>
<li>完成同步目标后，可方便拆卸和控制</li>
</ol>
</li>
<li>client重启如何对应原来的位点<ul>
<li>canal client和server交互之间的身份标识，目前clientId写死为1001. (目前canal server上的一个instance只能有一个client消费，clientId的设计是为1个instance多client消费模式而预留的，暂时不需要理会)</li>
</ul>
</li>
</ol>
<h3 id="canal和MySQL相关资料"><a href="#canal和MySQL相关资料" class="headerlink" title="canal和MySQL相关资料"></a>canal和MySQL相关资料</h3><ol>
<li>下载：<a href="https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.deployer-1.1.4.tar.gz">https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.deployer-1.1.4.tar.gz</a></li>
<li><code>canal.instance.gtidon</code>   是否启用mysql gtid的订阅模式 <ul>
<li><a href="https://blog.csdn.net/wmq880204/article/details/53160078">Mysql GTID 模式详解</a></li>
</ul>
</li>
<li><a href="https://github.com/alibaba/canal/wiki/QuickStart">https://github.com/alibaba/canal/wiki/QuickStart</a><br><a href="https://github.com/alibaba/canal/wiki/AdminGuide">https://github.com/alibaba/canal/wiki/AdminGuide</a><br><a href="https://github.com/alibaba/canal/wiki/ClientExample">https://github.com/alibaba/canal/wiki/ClientExample</a></li>
<li><a href="https://www.cnblogs.com/sunss/archive/2010/10/05/1844204.html">MySQL数据库的授权原则</a></li>
<li><a href="https://www.jianshu.com/p/0f580647905c">canal 高可用介绍</a></li>
<li><a href="https://www.cnblogs.com/f-zhao/p/7681960.html">canal和otter的高可靠性分析</a></li>
</ol>
]]></content>
      <tags>
        <tag>canal</tag>
      </tags>
  </entry>
  <entry>
    <title>使用“自旋”降低业务失败率</title>
    <url>/2020/07/16/20200716-shi-yong-zi-xuan-jiang-di-ye-wu-shi-bai-lu/</url>
    <content><![CDATA[<h3 id="业务场景描述"><a href="#业务场景描述" class="headerlink" title="业务场景描述"></a>业务场景描述</h3><p>不说废话，直接描述以下两个业务场景</p>
<ol>
<li>使用分布式锁控制并发<pre>
请求----------> 服务A
       [1.尝试获取锁]
       [2.获取锁失败]
       [3.返回失败(提示操作太快)]</pre></li>
</ol>
<p><br>2. 强依赖服务超时或”请求处理中”</p>
<pre>
请求----------> 服务A
          [1.强依赖请求]----------> 服务B
                           [2.执行慢(网络抖动等原因)]
          [3.请求服务B超时]   
          [4.返回失败(提示服务繁忙)]
</pre>

<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ol>
<li>场景1在获取锁失败时直接返回业务失败，可以考虑二次尝试；</li>
<li>场景2因为服务B执行慢，直接返回上层失败。<ul>
<li>服务A重试请求服务B时，可能请求已经执行完，很快就返回成功；或者服务B仍在执行该请求，返回“执行中”错误码。</li>
</ul>
</li>
</ol>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol>
<li>场景1可以使用“自旋”减少失败率：在抢锁失败时，当前线程“自旋”100m以内的随机数，再二次获取锁；</li>
<li>场景2同样可以使用“自旋”减少失败率：服务A在请求超时或收到“执行中”错误码时，同样自旋后再次重试，较大概率得到成功结果。</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul>
<li>自旋同样需要考虑“比例”问题，不然大量自旋会影响服务的吞吐量，具体可参考:<a href="https://kingson4wu.github.io/2020/07/13/20200713-%E7%94%B1%E7%81%BE%E5%A4%87%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%BC%95%E5%8F%91%E7%9A%84%E5%AF%B9%E2%80%9C%E6%AF%94%E4%BE%8B%E2%80%9D%E7%9A%84%E6%80%9D%E8%80%83/">由灾备工作中引发的对“比例”的思考</a></li>
</ul>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>自旋</tag>
      </tags>
  </entry>
  <entry>
    <title>监控告警要留意哪些点？</title>
    <url>/2020/07/16/20200716-jian-kong-gao-jing-yao-liu-yi-na-xie-dian/</url>
    <content><![CDATA[<ol>
<li>告警信息要标明：机器、业务和环境等信息</li>
<li>制定合理的告警规则，梳理告警项，优化项目error日志等；避免大量无用的告警导致麻木</li>
<li>重要的特定业务可以单独配告警</li>
<li>是不是经常遇到临时打开某个开关，最后又忘记修改回来的事情？其实这种可以通过告警来解决，通过配置常规状态的固定值，定时检查告警即可。</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/wnQhovr3651SbA7a8tXr_w">对 Java 意义重大的 7 个性能指标</a></li>
<li><a href="https://mp.weixin.qq.com/s/MWjjOB62QtX4uCWpKVs60A">对业务系统的监控 No.118</a></li>
<li><a href="https://mp.weixin.qq.com/s/3eDrbITbi66e3dzwYJPmeQ">一些好用的开源监控工具汇总</a></li>
</ul>
]]></content>
      <tags>
        <tag>监控告警</tag>
      </tags>
  </entry>
  <entry>
    <title>如何预估开发时间</title>
    <url>/2020/07/19/20200719-ru-he-yu-gu-kai-fa-shi-jian/</url>
    <content><![CDATA[<ol start="0">
<li>大的需求应预留时间方案设计和评审</li>
<li>方案时间( 包括跟相关依赖方确认方案时间)<ul>
<li>确定依赖方工作量和时间点</li>
<li>工作项拆分</li>
</ul>
</li>
<li>需求细节确认预留</li>
<li>开发时间</li>
<li>联调时间</li>
<li>配合测试时间（改bug）</li>
<li>单元测试</li>
<li>产品验收（测试环境）</li>
<li>需求改动预留</li>
<li>代码审核时间</li>
<li>处理其他突发事情预留</li>
<li>上线跟进</li>
<li>记录延期原因（需求变更，需求优先级调整，方案改动等；并同步相关人）</li>
<li>数据需求(可能影响方案实现细节)</li>
</ol>
<h3 id="参考场景"><a href="#参考场景" class="headerlink" title="参考场景"></a>参考场景</h3><ol>
<li>需求方需要一个相对准确的时间点；</li>
<li>给自己一个合理靠谱，相对科学的心理预估，避免坑人坑自己；</li>
<li>紧急情况特事特办。。。</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>职场生存小小总结</title>
    <url>/2020/07/19/20200719-zhi-chang-sheng-cun-xiao-xiao-zong-jie/</url>
    <content><![CDATA[<h3 id="不只局限于做需求本身"><a href="#不只局限于做需求本身" class="headerlink" title="不只局限于做需求本身"></a>不只局限于做需求本身</h3><ol>
<li>可以考虑把原本不合理的东西进行优化（当然要考虑分享和成本以及必要性）;</li>
<li>基于基础通用的角度设计方案；</li>
<li>只做需求本身和想同时做更多的事，时间成本肯定不一样，如何解决两者之间的矛盾：<ol>
<li>透明！把方案抛出来，由团队共同决策选择；</li>
<li>提供短期方案和长期优化方案。</li>
</ol>
</li>
</ol>
<h3 id="及时反馈"><a href="#及时反馈" class="headerlink" title="及时反馈"></a>及时反馈</h3><ol>
<li>发生故障及时反馈，不独自默默处理，避免由小故障变大故障；</li>
<li>工作进度和成果及时反馈，避免无用功；</li>
<li>其实还是要透明。</li>
<li>凡事有交代，件件有着落，事事有回音。</li>
<li>在不确定的场景下，尽量可以在多个假设中做多套方案（代价不会特别大），这样在对方案的时候，才不会导致得先重做才能继续讨论。</li>
</ol>
<h3 id="按流程做事"><a href="#按流程做事" class="headerlink" title="按流程做事"></a>按流程做事</h3><ol>
<li>大公司的流程虽然繁琐，但很多流程其实有其存在的道理，毕竟来源于很多历史教训；保持敬畏，可以减少错误；</li>
<li>当然紧急情况除外，但是要保持透明，和坚持底线；</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li>尽量透明；</li>
<li>站在对方的角度考虑问题；</li>
<li>保持底线；</li>
</ol>
<p>To Be Continued …</p>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><h4 id="寻帮助-《认知觉醒》"><a href="#寻帮助-《认知觉醒》" class="headerlink" title="寻帮助 - 《认知觉醒》"></a>寻帮助 - 《认知觉醒》</h4><ul>
<li>原来出现特殊情况时，飞行员的注意力会被巨大的危险所俘获，心智带宽降低，容易陷入单一视角，而此时，指挥员可以给飞行员提供有效的外部视角，帮助他们更好地处置特殊情况。</li>
<li>同理，当我们对情绪问题或工作问题百思不得其解的时候，不要一个人闷头苦想，要学会主动寻求外部帮助，借助他人的多维视角来克服自己单一视角的局限。</li>
</ul>
]]></content>
      <tags>
        <tag>JOB</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title>打赏类业务货币体系简述</title>
    <url>/2020/08/04/20200804-da-shang-lei-ye-wu-huo-bi-ti-xi-jian-shu/</url>
    <content><![CDATA[<ul>
<li>在打赏类业务中，消费跟分成是紧紧挂钩的。比如在直播间送礼，用户通过花费虚拟货币给对方送礼，而对方则得到相应的分成。</li>
<li>定义：用户花费的是“金币”，接受者得到的是“银币”。</li>
</ul>
<h3 id="设计概要"><a href="#设计概要" class="headerlink" title="设计概要"></a>设计概要</h3><p><img src="/2020/08/04/20200804-da-shang-lei-ye-wu-huo-bi-ti-xi-jian-shu/%E9%87%91%E9%92%B1%E6%9C%8D%E5%8A%A1%E4%BD%93%E7%B3%BB.png"></p>
<h4 id="一、用户货币类型组成"><a href="#一、用户货币类型组成" class="headerlink" title="一、用户货币类型组成"></a>一、用户货币类型组成</h4><ol>
<li>用户通过充值或活动赠币等方式得到“金币(coin)”<ul>
<li>充值行为得到的是“充值金币(money)”</li>
<li>活动赠币等非充值行为得到的是“非充值金币(virtualCoin)”</li>
<li>coin&#x3D;money + virtualCoin</li>
</ul>
</li>
<li>消费行为的接受者（收益方）得到的是“银币(bean)”</li>
</ol>
<h4 id="二、业务情况"><a href="#二、业务情况" class="headerlink" title="二、业务情况"></a>二、业务情况</h4><p>所有的业务场景其实都是对上述几种货币类型的加减，主要分为以下几类：</p>
<ol>
<li>充值业务</li>
<li>消费业务（伴随着分成）</li>
<li>赠币业务（活动获取）</li>
<li>兑换业务（“银币”可以兑换成“金币”进行消费）</li>
<li>结算业务（“银币”可以进行提现）</li>
<li>管理员调整（运营行为，对用户货币进行调整）</li>
</ol>
<h4 id="三、冻结账户设计"><a href="#三、冻结账户设计" class="headerlink" title="三、冻结账户设计"></a>三、冻结账户设计</h4><p>针对消费场景，有两种形式的消费：</p>
<ol>
<li>即时消费(比如送礼)；<ul>
<li>用户消费的同时，收益方立即得到相应的分成</li>
</ul>
</li>
<li>延迟消费(比如申请上麦)<ul>
<li>先对用户的“金币“进行冻结，根据最终的结果，对用户冻结的金币进行结算或退回；用户的消费时间为实际结算的时间（不是冻结时的时间）。</li>
</ul>
</li>
</ol>
<p><img src="/2020/08/04/20200804-da-shang-lei-ye-wu-huo-bi-ti-xi-jian-shu/%E9%87%91%E9%92%B1%E5%86%BB%E7%BB%93%E8%B4%A6%E6%88%B7%E8%AE%BE%E8%AE%A1.png"></p>
<ul>
<li>冻结&amp;结算 和 消费&amp;退款 在技术实现设计上的差异：<ol>
<li>前者两次RPC，后者一次RPC</li>
<li>前者以结算时间作为消费完成时间；后者是以扣币时间作为消费完成时间，且退款会导致营收数据受影响</li>
</ol>
</li>
</ul>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>金钱相关</tag>
        <tag>货币体系</tag>
      </tags>
  </entry>
  <entry>
    <title>关于CDN缓存总结摘要</title>
    <url>/2020/08/20/20200820-guan-yu-cdn-huan-cun/</url>
    <content><![CDATA[<h3 id="CDN缓存的几点总结"><a href="#CDN缓存的几点总结" class="headerlink" title="CDN缓存的几点总结"></a>CDN缓存的几点总结</h3><ol>
<li>CDN资源的标识: url</li>
<li>跟HTTP缓存无关的请求头不影响CDN缓存（亲测）</li>
<li>不仅是静态资源，接口的数据可以做CDN缓存（亲测）</li>
<li>CDN服务一般都有默认的缓存配置（比如一分钟），服务端可以通过设置HTTP缓存相关的Header控制是否适用CDN缓存</li>
<li>HTTP缓存和CDN缓存分别作为客户端缓存和服务端缓存</li>
</ol>
<h3 id="HTTP缓存"><a href="#HTTP缓存" class="headerlink" title="HTTP缓存"></a>HTTP缓存</h3><p>关键字段有Expires，Cache-Control ，Last-Modified ，Etag 四个字段，Expires和Cache-Control用来确定确定缓存的存储时间，Last-Modified 和Etag则用来确定缓存是否要被更新</p>
<h4 id="强制缓存"><a href="#强制缓存" class="headerlink" title="强制缓存"></a>强制缓存</h4><p>控制强制缓存的字段分别是Cache-Control和Expires，其中Cache-Control优先级比Expires高</p>
<ol>
<li>Expires: HTTP1.0的，已废弃</li>
<li>Cache-Control: HTTP1.1中用来控制缓存时间的参数 (Cache-Control:max-age&#x3D;30;xxx;)<pre>
public: 表明响应可以被任何对象（包括：发送请求的客户端，代理服务器，等等）缓存。
private: 表明响应只能被单个用户缓存，不能作为共享缓存（即代理服务器不能缓存它）。
max-age=seconds: 设置缓存存储的最大周期，相对于请求的时间缓存seconds秒，在此时间内，访问资源直接读取本地缓存，不向服务器发出请求。（与expires同时出现时，max-age优先级更高）
s-maxage=seconds: 规则等同max-age，覆盖max-age 或者 Expires 头，但是仅适用于共享缓存(比如各个代理)，并且私有缓存中它被忽略。（与expires或max-age同时出现时，s-maxage优先级更高）
no-store: 不缓存服务器响应的任何内容，每次访问资源都需要服务器完整响应
no-cache: 缓存资源，但立即过期，每次请求都需要跟服务器对比验证资源是否被修改。（等同于max-age=0）
</pre></li>
</ol>
<h4 id="协商缓存"><a href="#协商缓存" class="headerlink" title="协商缓存"></a>协商缓存</h4><p>协商缓存就是强制缓存失效后，浏览器携带缓存标识向服务器发起请求，由服务器根据缓存标识决定是否使用缓存的过程。控制协商缓存的字段分别有：Last-Modified &#x2F; If-Modified-Since和Etag &#x2F; If-None-Match，其中Etag &#x2F; If-None-Match的优先级比Last-Modified &#x2F; If-Modified-Since高。</p>
<ol start="2">
<li>Last-modified: 源头服务器认定的资源做出修改的日期及时间。精确度比Etag低。包含有If-Modified-Since或 If-Unmodified-Since首部的条件请求会使用这个字段。</li>
<li>Etag: HTTP响应头是资源的特定版本的标识符。</li>
</ol>
<h4 id="如何控制不使用缓存"><a href="#如何控制不使用缓存" class="headerlink" title="如何控制不使用缓存"></a>如何控制不使用缓存</h4><ul>
<li>F5刷新：<br>(Cache-Control: max-age&#x3D;0)<br>浏览器会设置max-age&#x3D;0，跳过强缓存判断，会进行协商缓存判断【浏览器直接对本地的缓存文件过期，但是会带上If-Modifed-Since，If-None-Match（如果上一次response带Last-Modified, Etag）这就意味着服务器会对文件检查新鲜度，返回结果可能是304，也有可能是200.】</li>
<li>强制刷新 (command+shift+R)：浏览器不使用缓存，因此发送的请求头部均带有 Cache-control: no-cache(为了兼容，还带了 Pragma: no-cache),服务器直接返回 200 和最新内容。<br>ctrl+F5强制刷新：<br>(Cache-Control: no-cache)<br>跳过强缓存和协商缓存，直接从服务器拉取资源。【浏览器不仅会对本地文件过期，而且不会带上If-Modifed-Since，If-None-Match，相当于之前从来没有请求过，返回结果是200.】</li>
<li>如何不缓存<br>Cache-Control其他字段：<br>no-cache: 虽然字面意义是“不要缓存”。但它实际上的机制是，仍然对资源使用缓存，但每一次在使用缓存之前必须向服务器对缓存资源进行验证。<br>no-store: 不使用任何缓存<br>禁止缓存：<br>Cache-Control: no-cache, no-store, must-revalidate<br>Expires：设为当前时间之前</li>
<li>强缓存存在两种形式：from memory cache 与 from disk cache (浏览器F12查看)</li>
</ul>
<h3 id="CDN缓存"><a href="#CDN缓存" class="headerlink" title="CDN缓存"></a>CDN缓存</h3><ul>
<li>cdn缓存是一种服务端缓存</li>
<li>与http缓存规则不同的是，这个规则并不是规范性的，而是由cdn服务商来制定</li>
<li>回源的意思就是返回源站，何为源站，就是我们自己的服务器;CDN回源，没有资源就去源站读取，有资源就直接发送给用户。</li>
<li>cdn缓存配置，整体来说，建议和http缓存配置保持统一</li>
</ul>
<h4 id="不一致的影响"><a href="#不一致的影响" class="headerlink" title="不一致的影响"></a>不一致的影响</h4><p>cdn的缓存配置会受到http缓存配置的影响，而且各个cdn服务商并不完全一致，以腾讯云为例，在缓存配置的文档中特别有以下说明。<br>这会对我们有什么影响呢？</p>
<ol>
<li>如果我们http缓存设置cache-control: max-age&#x3D;600，即缓存10分钟，但cdn缓存配置中设置文件缓存时间为1小时，那么就会出现如下情况，文件被访问后第12分钟修改并上传到服务器，用户重新访问资源，响应码会是304，对比缓存未修改，资源依然是旧的，一个小时后再次访问才能更新为最新资源</li>
<li>如果不设置cache-control呢，在http缓存中我们说过，如果不设置cache-control，那么会有默认的缓存时间，但在这里，cdn服务商明确会在没有cache-control字段时主动帮我们添加cache-control: max-age&#x3D;600。<br>注：针对问题1，也并非没有办法，当我们必须要在缓存期内修改文件，并且不向想影响用户体验，那么我们可以使用cdn服务商提供的强制更新缓存功能，主要注意的是，这里的强制更新是更新服务端缓存，http缓存依然按照http头部规则进行自己的缓存处理，并不会受到影响。</li>
</ol>
<h4 id="缓存配置"><a href="#缓存配置" class="headerlink" title="缓存配置"></a>缓存配置</h4><ul>
<li>cdn缓存的配置并不复杂， 复杂的情况在于cdn缓存配置会受到http缓存配置的影响，并且不同的cdn运营商对于这种影响的处理也都不一致，实际使用时，建议去对应的cdn服务商文档中找到对应的注意事项。</li>
<li>CDN缓存控制:如果源站设置了 no-cache 、private、 max-age &#x3D; 0 都遵循源站，CDN 是不会进行缓存的。</li>
<li>又拍云为开发者执行缓存刷新提供了主动更新和被动更新两种方式。<ol>
<li>主动更新主要是指同名资源在源服务器更新之后，开发者手动刷新文件。又拍云提供了可视化的操作台供用户执行缓存刷新操作，同时支持 URL 刷新和规则刷新。此外开发者也可通过 API 接口完成刷新操作。</li>
<li>被动刷新则是等文件在 CDN 节点的缓存过期之后，节点回源拉取源服务器上最新的文件。这个过程由 CDN 自动完成，无需手动操作。</li>
</ol>
</li>
</ul>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul>
<li><p><a href="https://www.jianshu.com/p/eb974c412399">动态CDN加速</a></p>
</li>
<li><p>CDN的全称是Content Delivery Network，即内容分发网络</p>
</li>
<li><p>动态CDN加速:非静态数据，通过CDN的加速来起到快速回源的效果的。使用到的就是CDN的快速传输的能力。其实也就是DSA(Dynamic Site Acceleration)</p>
<ul>
<li>传统的DSA有:<ul>
<li>TCP 优化：设计算法来处理网络拥堵和包丢失，加快这些情况下的数据从cdn的恢复以及一些常见的TCP瓶颈</li>
<li>Route optimization：就是优化从源到用户端的请求的线路，以及可靠性，就是不断的测量计算得到更快更可靠的路线</li>
<li>Connection management：就是边缘和源之间，包括CDN之前的线路，采用长连接，而不是每一个请求一个连接</li>
<li>On-the-fly compression：就是数据在刚刚离开源的时候就进行压缩，可以缩短在整个网络之中的流通时间</li>
<li>SSL offload：加速或者说减少一些安全监测，减少原服务器执行这种计算密集型的压力</li>
<li>Pre-fetching：有的服务可以解析HTML文件，并将原始服务器预取缓存对象嵌入到文件中</li>
</ul>
</li>
<li>更可靠的连接(只要负责连接边缘服务器，如果直接走回源线路的话，线路会很长，不可靠)</li>
</ul>
</li>
<li><p><a href="https://www.cnblogs.com/EasonJim/p/8323578.html">使用CDN隐藏服务器真实IP</a></p>
<ul>
<li>隐藏服务器真实IP是解决问题最好和最快的方法，但只针对小流量，大流量同样会扛不住。<br>服务器前端加CDN中转，比如阿里云、百度云加速、360网站卫士、加速乐、安全宝等，如果资金充裕的话，可以购买高防的盾机，用于隐藏服务器真实IP，域名解析使用CDN的IP，所有解析的子域名都使用CDN的IP地址。此外，服务器上部署的其他域名也不能使用真实IP解析，全部都使用CDN来解析。</li>
<li>另外防止服务器对外传送信息泄漏IP，最常见的是，服务器不使用发送邮件功能，如果非要发送邮件，可以通过第三方代理(例如sendcloud)发送，这样对外显示的IP是代理的IP。</li>
</ul>
</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a href="https://www.jianshu.com/p/baf12d367fe7">聊聊 CDN 缓存与浏览器缓存</a></li>
<li><a href="https://blog.csdn.net/weixin_34043301/article/details/87964291">http缓存与cdn缓存配置指南</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/83486624">CDN 基础架构及缓存控制</a></li>
<li><a href="https://segmentfault.com/a/1190000006673084">从HTTP响应头看各家CDN缓存技术</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/58685072">HTTP 缓存机制</a></li>
</ul>
]]></content>
      <tags>
        <tag>CDN</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Redis实现榜单</title>
    <url>/2020/08/31/20200831-shi-yong-redis-shi-xian-bang-dan/</url>
    <content><![CDATA[<h3 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h3><ol>
<li>使用redis实现</li>
<li>基于直播间业务场景</li>
<li>不阐述详细实现细节</li>
</ol>
<h3 id="二、相关Redis数据结构和命令"><a href="#二、相关Redis数据结构和命令" class="headerlink" title="二、相关Redis数据结构和命令"></a>二、相关Redis数据结构和命令</h3><h4 id="Redis-集合-Set"><a href="#Redis-集合-Set" class="headerlink" title="Redis 集合(Set)"></a>Redis 集合(Set)</h4><ol>
<li>Sismember 命令判断成员元素是否是集合的成员。</li>
</ol>
<h4 id="Redis-有序集合-sorted-set"><a href="#Redis-有序集合-sorted-set" class="headerlink" title="Redis 有序集合(sorted set)"></a>Redis 有序集合(sorted set)</h4><ol>
<li>Zrevrank 命令返回有序集中成员的排名。其中有序集成员按分数值递减(从大到小)排序。</li>
<li>Zincrby 命令对有序集合中指定成员的分数加上增量 increment</li>
<li>Zrevrangebyscore 返回有序集中指定分数区间内的所有的成员。有序集成员按分数值递减(从大到小)的次序排列</li>
<li>Zremrangebyrank 命令用于移除有序集中，指定排名(rank)区间内的所有成员。</li>
</ol>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><ol>
<li>查找特定前缀key：scan命令</li>
</ol>
<h3 id="三、如何实现"><a href="#三、如何实现" class="headerlink" title="三、如何实现"></a>三、如何实现</h3><h4 id="榜单保存"><a href="#榜单保存" class="headerlink" title="榜单保存"></a>榜单保存</h4><ol>
<li>使用 Redis 有序集合(sorted set)保存榜单数据</li>
<li>如果是按时间排序的榜单，把时间戳存到score字段；如果是按礼物数量排序，把数量存到score；其他排序场景同理</li>
</ol>
<h4 id="榜单添加数据操作幂等"><a href="#榜单添加数据操作幂等" class="headerlink" title="榜单添加数据操作幂等"></a>榜单添加数据操作幂等</h4><ol>
<li>使用数据库日志表（唯一索引） （最严格可靠）</li>
<li>使用一个set保存所有的消息ID，并使用sismember防止重复处理（并发场景可能不幂等）</li>
</ol>
<h4 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h4><ol>
<li>使用一个set保存现有所有在线的房间榜单；定时任务检查房间是否在播，不在线的进行清理（同时可以监听房间下播时间）</li>
<li>保存一定数量的redis榜单：Zremrangebyrank 命令用于移除有序集中，指定排名(rank)区间内的所有成员</li>
<li>使用scan命令 查找特定前缀key的榜单，同1或2操作进行清理</li>
</ol>
<h3 id="四、扩展"><a href="#四、扩展" class="headerlink" title="四、扩展"></a>四、扩展</h3><ol>
<li>房间榜单的标识是房间id有时可能不够，因为通过榜单有时是和本场开播挂钩的，同一个房间多次开播，可能导致不同场次的数据导致榜单错误。<br>增加房间开播id标识可以解决。</li>
<li>老生常谈的哲学问题:二八定理。花费大量时间来得到较低的收益，实现时要从业务看是否值得。但不代表在做设计方案时不去考虑，这是严谨性的问题。<br>按极端的方式考虑，实际实现按业务需要进行选择折中。</li>
</ol>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>榜单</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>如何解决脑裂问题</title>
    <url>/2020/09/05/20200905-ru-he-jie-jue-nao-lie-wen-ti/</url>
    <content><![CDATA[<p>什么是“Split Brain”(脑裂)问题？</p>
<p>Split Brain 是指在同一时刻有两个认为自己处于 Active 状态的 NameNode。对于HA集群而言，确保同一时刻只有一个NameNode处于active状态是至关重要的。否则，两个NameNode的数据状态就会产生分歧，可能丢失数据，或者产生错误的结果。</p>
<h3 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h3><ul>
<li><p>Consistency (一致性): 副本一致性特指强一致性；</p>
</li>
<li><p>Availiablity(可用性): 指系统在出现异常时已经可以提供服务;</p>
</li>
<li><p>Tolerance to the partition of network (分区容忍): 指系统可以对网络分区这种异常情 况进行容错处理;</p>
</li>
<li><p>CAP理论，对于P（分区容忍性）而言，是实际存在 从而无法避免的。因为，分布系统中的处理不是在本机，而是网络中的许多机器相互通信，故网络分区、网络通信故障问题无法避免。因此，只能尽量地在C 和 A 之间寻求平衡。</p>
</li>
<li><p>对于数据存储而言，为了提高可用性（Availability），采用了副本备份。某数据块所在的机器宕机了，就去该数据块副本所在的机器上读取。但是，当需要修改数据时，就需要更新所有的副本数据，这样才能保证数据的一致性（Consistency）。因此，就需要在 C(Consistency) 和 A(Availability) 之间权衡。</p>
</li>
<li><p>Quorum机制，就是这样的一种权衡机制，一种将“读写转化”的模型。</p>
</li>
</ul>
<h3 id="Quorum机制"><a href="#Quorum机制" class="headerlink" title="Quorum机制"></a>Quorum机制</h3><ol>
<li>Write-all-read-one(简称 WARO).(极端的方案)<ul>
<li>当Client请求向某副本写数据时(更新数据)，只有当所有的副本都更新成功之后，这次写操作才算成功，否则视为失败。</li>
<li>WARO牺牲了更新服务的可用性，最大程度地增强了读服务的可用性。而Quorum就是更新服务和读服务之间进行一个折衷。</li>
</ul>
</li>
<li>Quorum 机制<ul>
<li>将 WARO 的条件进行松弛,从而使得可以在读写服务可用性之间做折中,得出 Quorum 机制。</li>
<li>Quorum机制是“抽屉原理”的一个应用。定义如下：假设有N个副本，更新操作wi 在W个副本中更新成功之后，才认为此次更新操作wi 成功。称成功提交的更新操作对应的数据为：“成功提交的数据”。对于读操作而言，至少需要读R个副本才能读到此次更新的数据。其中，W+R&gt;N ，即W和R有重叠。一般，W+R&#x3D;N+1</li>
<li>仅仅依赖 quorum 机制是无法保证强一致性的。因为仅有 quorum 机制时无法确 定最新已成功提交的版本号,除非将最新已提交的版本号作为元数据由特定的元数据服务器或元数 据集群管理,否则很难确定最新成功提交的版本号。<ul>
<li>1）如何读取最新的数据？—在已经知道最近成功提交的数据版本号的前提下，最多读R个副本就可以读到最新的数据了。</li>
<li>2）如何确定 最高版本号 的数据是一个成功提交的数据？—继续读其他的副本，直到读到的 最高版本号副本 出现了W次。</li>
</ul>
</li>
<li>Quorum 机制的三个系统参数 N、W、R 控制了系统的可用性,也是系统对用户的服务承诺:数 据最多有 N 个副本,但数据更新成功 W 个副本即返回用户成功。对于一致性要求较高的 Quorum 系 统,系统还应该承诺任何时候不读取未成功提交的数据,即读取到的数据都是曾经在 W 个副本上成 功的数据。</li>
</ul>
</li>
</ol>
<h3 id="Lease-机制"><a href="#Lease-机制" class="headerlink" title="Lease 机制"></a>Lease 机制</h3><ul>
<li>Lease 是由颁发者授予的在某一有效期内的承诺。颁发者一旦发出 lease,则无论接受方是否收到,也无论后续接收方处于何种状态,只要 lease 不过期,颁发者一 定严守承诺;另一方面,接收方在 lease 的有效期内可以使用颁发者的承诺,但一旦 lease 过期,接 收方一定不能继续使用颁发者的承诺。</li>
<li>Lease 机制依赖于有效期,这就要求颁发者和接收者的时钟是同步的。对于这种时钟不同步,实践中的通常做法是 将颁发者的有效期设置得比接收者的略大,只需大过时钟误差就可以避免对 lease 的有效性的影响。</li>
</ul>
<h3 id="解决脑裂的关键"><a href="#解决脑裂的关键" class="headerlink" title="解决脑裂的关键"></a>解决脑裂的关键</h3><h4 id="raft是如何解决的？"><a href="#raft是如何解决的？" class="headerlink" title="raft是如何解决的？"></a>raft是如何解决的？</h4><ol start="0">
<li>核心是“大多数成功”机制。Raft就是基于Quorum机制下实现的。</li>
<li>看下以下这篇文章:<a href="https://www.jianshu.com/p/072380e12657">为 Raft 引入 leader lease 机制解决集群脑裂时的 stale read 问题</a><ul>
<li>这种方法牺牲了一定的可用性（在脑裂时部分客户端的可用性）换取了一致性的保证。</li>
<li>多数派的网络分区挂了，岂不是直接不可写了</li>
</ul>
</li>
<li>如何解决多数派的网络分区挂了，服务就不可用的问题？<ul>
<li>我的答案是部署不止两个网络分区，至少三个网络分区；这样任意一个分区挂了，服务都可用，除非三个分区的大多数分区挂了(挂了2个)；</li>
</ul>
</li>
<li>副本控制协议分为两大类:“中心化(centralized)副本控制协议”和“去中心化(decentralized) 副本控制协议”。解决脑裂的其中一个关键点是哪种 “去中心化的协议”，paxos和raft都是。</li>
</ol>
<h4 id="使用非分布式存储的应用如何解决？"><a href="#使用非分布式存储的应用如何解决？" class="headerlink" title="使用非分布式存储的应用如何解决？"></a>使用非分布式存储的应用如何解决？</h4><ol>
<li>上述处理脑裂问题的前提是：服务本身就是一个分布式存储服务，使用raft等一致性协议；那么普通的业务服务，使用MySQL的的情况下，怎么解决脑裂问题？</li>
<li>MySQL主从服务复制，这种存储服务本身就不是去中心的分布式数据库；</li>
<li>解决问题的核心点是：引入第三方组件作为整个业务集群的“选主服务”(比如Consul、Etcd，都是基于Raft协议)；结合MySQL的半同步复制机制：支持配置n个从库ack才响应客户端（类似Quorum机制）和MHA，可以很大程度的避免丢数据导致不一致。</li>
<li>Consul本身就是基于raft协议，可以利用其去中心化的特性，作为选主服务，业务通过Consul识别到哪个集群是主集群之后，可定制进行相应的业务处理。</li>
</ol>
<h4 id="选主服务"><a href="#选主服务" class="headerlink" title="选主服务"></a>选主服务</h4><ol>
<li>Consul、Etcd (Raft)<ul>
<li>在本次案例中是通过判断是否能获得Consul集群中的leader来判断孤岛的（调获取某个node的信息接口，如果没有leader会返回“No cluster leader”）；而不是通过Consul分布式锁的方式选主。</li>
</ul>
</li>
<li>ZooKeeper (ZAB、Paxos )</li>
<li>Chubby 分布式锁；<a href="https://mp.weixin.qq.com/s/R2FCLknar6bCvykJ1m7rJQ">Google的锁，才是分布式锁？</a></li>
</ol>
<h3 id="使用Consul解决脑裂问题"><a href="#使用Consul解决脑裂问题" class="headerlink" title="使用Consul解决脑裂问题"></a>使用Consul解决脑裂问题</h3><ul>
<li><img src="/2020/09/05/20200905-ru-he-jie-jue-nao-lie-wen-ti/Consul_no_leader.png"></li>
</ul>
<h4 id="如何判断“孤岛”？"><a href="#如何判断“孤岛”？" class="headerlink" title="如何判断“孤岛”？"></a>如何判断“孤岛”？</h4><ol>
<li>在三个IDC部署一个Consul集群，该集群会存在一个leader，且每个IDC的service在网络正常的情况下，都能检测到哪个是leader；依赖Consul的raft协议选举判断网络孤岛；(为了后续描述简单，假设每个IDC只部署一个Consul结点)</li>
<li>每个IDC的service只访问当前IDC对应的Consul结点；当访问返回“No cluster leader”时，说明该网络分区已经是”孤岛”；<pre>
curl 'http://consul:8500/v1/health/service/nodeName?passing&wait=1s&index=1&tag=master'
No cluster leader
</pre></li>
<li>通过“No cluster leader”来判断孤岛的前提是，假设Consul是高可用的。因为当有两个Consul结点无法访问或挂掉的时候，也有能误判成没有leader（实际上并未出现网络孤岛，只是Consul集群异常）；</li>
<li>引入双重检查机制，解决Consul集群因为可用性问题导致的误判的可能性；在Consul判断为网络孤岛的情况下，通过ping异地IDC的service的健康检查接口，二次确认；双重检查机制只能解决误判问题，若Consul集群不能高可用，那么判断孤岛的机制将失效。</li>
</ol>
<h4 id="如何处理“孤岛”？"><a href="#如何处理“孤岛”？" class="headerlink" title="如何处理“孤岛”？"></a>如何处理“孤岛”？</h4><ol>
<li>判断为孤岛的网络分区的服务，如果接收到外网请求(因为是孤岛情况下其他IDC内网不通)，可以拒绝服务，也可以返回特殊的业务错误码或HTTP错误码，由上层服务或客户端重试到其他的机房。</li>
</ol>
<h4 id="“孤岛”消失后如何恢复？"><a href="#“孤岛”消失后如何恢复？" class="headerlink" title="“孤岛”消失后如何恢复？"></a>“孤岛”消失后如何恢复？</h4><ol>
<li>手动恢复。”孤岛”的网络分区服务不恢复提供服务，由开发人员确认DB等无异常后再手动恢复；</li>
<li>自动恢复。需做好充分的检测手段才能启用自动恢复：DB是否发生切换、主从DB数据是否一致（如比对脚本）、判断网络是否已经恢复到策略(防止来回切)等。</li>
</ol>
<h3 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h3><h4 id="为什么每个IDC的service只访问当前IDC对应的Consul结点？-前提是Consul高可用性"><a href="#为什么每个IDC的service只访问当前IDC对应的Consul结点？-前提是Consul高可用性" class="headerlink" title="为什么每个IDC的service只访问当前IDC对应的Consul结点？(前提是Consul高可用性)"></a>为什么每个IDC的service只访问当前IDC对应的Consul结点？(前提是Consul高可用性)</h4><ol>
<li>假设IDC-A出现网络孤岛的情况下，IDC-A的service本身就无法访问IDC-B的Consul结点；</li>
<li>假设IDC-B未出现网络孤岛，IDC-A的service只需要访问IDC-A的Consul结点即可判断；</li>
</ol>
<h4 id="选主服务一定要选择基于去中心一致性协议的组件吗？"><a href="#选主服务一定要选择基于去中心一致性协议的组件吗？" class="headerlink" title="选主服务一定要选择基于去中心一致性协议的组件吗？"></a>选主服务一定要选择基于去中心一致性协议的组件吗？</h4><ol>
<li>不一定。使用选主服务只是利用组件高可用性和选举机制解决脑裂问题。Raft等去中心一致性的协议解决的的一致性问题及其leader的选举机制。换句话，只要该组件能高可用且在结点大多数存活（网络互通）的情况下，能选举出一个Leader即可，数据的一致性并不重要（因为没用到组件提供的数据存储功能）。</li>
<li>一般情况下，业务使用MHA-Consul-MySQL作为DB切换的高可用方案；那么解决脑裂问题，也使用Consul组件，也可以减少服务对其他组件的依赖。</li>
</ol>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ol>
<li>Group Replication<ul>
<li>Group Replication由至少3个或更多个节点共同组成一个数据库集群，事务的提交必须经过半数以上节点同意方可提交，在集群中每个节点上都维护一个数据库状态机，保证节点间事务的一致性。Group Replication基于分布式一致性算法Paxos实现，允许部分节点故障，只要保证半数以上节点存活，就不影响对外提供数据库服务，是一个真正可用的高可用数据库集群技术。 Group Replication支持两种模式，单主模式和多主模式。在同一个group内，不允许两种模式同时存在，并且若要切换到不同模式，必须修改配置后重新启动集群。 在单主模式下，只有一个节点可以对外提供读写事务的服务，而其它所有节点只能提供只读事务的服务，这也是官方推荐的Group Replication复制模式。</li>
</ul>
</li>
<li>NewSQL<ul>
<li>关于NewSQL的定义是：这是一类现代关系型的DBMS，旨在为NoSQL的OLTP读写负载提供相同的可扩展性能，同时仍然提供事务的ACID保证。</li>
<li>TiDB。TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适OLAP 场景的混合数据库。</li>
</ul>
</li>
</ol>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li>刘杰：分布式原理介绍</li>
<li><a href="https://www.cnblogs.com/hapjin/p/5626889.html">分布式系统理论之Quorum机制</a></li>
<li><a href="https://kingson4wu.gitee.io/2020/08/31/20200831-%E5%85%B3%E4%BA%8EMHA-Consul-MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88%E7%9A%84%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93%E5%92%8C%E6%80%9D%E8%80%83/">关于MHA_Consul_MySQL高可用方案的简单总结和思考</a></li>
<li><a href="http://mysql.taobao.org/monthly/2017/08/01/">MySQL · 引擎特性 · Group Replication内核解析</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/71073707">我们听到的TiDB到底是什么？</a></li>
</ul>
]]></content>
      <tags>
        <tag>容灾</tag>
        <tag>脑裂</tag>
        <tag>Consul</tag>
        <tag>Quorum</tag>
        <tag>Raft</tag>
      </tags>
  </entry>
  <entry>
    <title>金融业务容灾体系简述</title>
    <url>/2020/09/08/20200908-jin-rong-ye-wu-rong-zai-ti-xi-jian-shu/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li>本文针对金融类(如用户虚拟货币)这类对数据准确性很敏感的业务的容灾架构；</li>
<li>案例中的服务架构为同城主备架构；</li>
<li>内容包括：容灾架构、故障切换、故障恢复、演练方案等；</li>
<li>涉及技术点：MySQL、MHA、Consul等；</li>
<li>本文基于<ol>
<li><a href="https://kingson4wu.gitee.io/2020/08/31/20200831-%E5%85%B3%E4%BA%8EMHA-Consul-MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88%E7%9A%84%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93%E5%92%8C%E6%80%9D%E8%80%83/">关于MHA-Consul-MySQL高可用方案的简单总结和思考</a></li>
<li><a href="https://kingson4wu.gitee.io/2020/09/05/20200905-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98/">如何解决脑裂问题</a></li>
</ol>
</li>
<li>由于某种原因，某些细节不会描述。</li>
<li>关于系统可用性，收藏了一张网图<br><img src="/2020/09/08/20200908-jin-rong-ye-wu-rong-zai-ti-xi-jian-shu/availability.png"></li>
<li>MTTF 是 Mean Time To Failure，平均故障前的时间，即系统平均能够正常运行多长时间才发生一次故障。系统的可靠性越高，MTTF 越长。（注意：从字面上来说，看上去有 Failure 的字样，但其实是正常运行的时间。）</li>
<li>MTTR 是 Mean Time To Recovery，平均修复时间，即从故障出现到故障修复的这段时间，这段时间越短越好。</li>
<li>故障是正常的，而且是常见的。<br>故障是不可预测突发的，而且相当难缠。<br>我们要干的事儿就是想尽一切手段来降低 MTTR——故障的修复时间。<br>– 陈皓</li>
</ul>
<h2 id="容灾架构"><a href="#容灾架构" class="headerlink" title="容灾架构"></a>容灾架构</h2><p><img src="/2020/09/08/20200908-jin-rong-ye-wu-rong-zai-ti-xi-jian-shu/Network_Topology.png"></p>
<p><img src="/2020/09/08/20200908-jin-rong-ye-wu-rong-zai-ti-xi-jian-shu/Architecture.png"></p>
<ol>
<li>红色线条为正常情况下的服务主链路；</li>
<li>同城主备架构： 主－IDC-A；从－IDC-B;</li>
<li>域名灾备：前端通过主域名访问后端接口，当响应超时或者返回50x的时候，前端将切换到备用域名访问后端接口；<ul>
<li>异常情况可能是后端服务异常或者用户所在地区网络不稳定等原因；</li>
<li>针对不幂等的接口，应设置成只切换域名不进行重试；</li>
<li>后端服务可以根据自身服务的异常情况，返回50x，让前端切换到备用域名</li>
</ul>
</li>
<li>主域名为CDN域名，连接北京两个机房，备用域名是非CDN域名，直接连接北京第三个机房；<ul>
<li>使用CDN域名的原因：不把回源点暴露出去，从而把核心机房暴露出去。</li>
</ul>
</li>
<li>使用MHA＋Consul作为DB的切换方案；</li>
<li>每个IDC的gateway配置服务的主权重都是在IDC-A；发生故障切换时，gateway将把服务主权重切换到IDC-B，而通过外网进入IDC-A的流量，服务通过返回50x由前端切换到备用域名。</li>
</ol>
<h2 id="详细描述"><a href="#详细描述" class="headerlink" title="详细描述"></a>详细描述</h2><h3 id="故障切换"><a href="#故障切换" class="headerlink" title="故障切换"></a>故障切换</h3><h4 id="触发故障切换的场景"><a href="#触发故障切换的场景" class="headerlink" title="触发故障切换的场景"></a>触发故障切换的场景</h4><ol>
<li>机房孤岛 (MHA＋Consul出发切换)</li>
<li>网络抖动 (由决策服务通过健康检查手段决策)</li>
<li>服务自身异常或机器问题等 (MHA＋Consul出发切换)</li>
</ol>
<h4 id="1-MHA-Consul切换"><a href="#1-MHA-Consul切换" class="headerlink" title="1) MHA+Consul切换"></a>1) MHA+Consul切换</h4><ul>
<li>触发条件：1或3 (主库不可访问)</li>
<li>MHA＋Consul切换后，决策服务切换gateway的服务权重</li>
</ul>
<h4 id="2-决策服务切换"><a href="#2-决策服务切换" class="headerlink" title="2) 决策服务切换"></a>2) 决策服务切换</h4><ul>
<li>触发条件：2 (网络抖动)</li>
<li>决策服务健康检查异常后，通过MHA+Consul主动切换主库，并切换gateway的服务权重</li>
</ul>
<h3 id="机房容灾场景（单机房故障）"><a href="#机房容灾场景（单机房故障）" class="headerlink" title="机房容灾场景（单机房故障）"></a>机房容灾场景（单机房故障）</h3><h4 id="1-机房内外网不通"><a href="#1-机房内外网不通" class="headerlink" title="1) 机房内外网不通"></a>1) 机房内外网不通</h4><ol>
<li>IDC-A故障<ol>
<li>服务权重通过gateway切换到IDC-B</li>
<li>外网无法进入IDC-A，只能进入IDC-B</li>
<li>CDN域名检测异常后剔除IDC-A的服务节点</li>
<li>故障瞬间由于IDC-A不通，cdn结点会重试到IDC-B或者返回前端50x，前端访问备用域名。</li>
</ol>
</li>
<li>IDC-B故障<ol>
<li>服务权重无需调整</li>
<li>外网无法进入IDC-B，只能进入IDC-A</li>
<li>CDN域名检测异常后剔除IDC-B的服务节点</li>
<li>故障瞬间由于IDC-B不通，cdn结点会重试到IDC-A或者返回前端50x，前端访问备用域名。</li>
</ol>
</li>
</ol>
<h4 id="2-机房孤岛（内网不通，外网通）"><a href="#2-机房孤岛（内网不通，外网通）" class="headerlink" title="2) 机房孤岛（内网不通，外网通）"></a>2) 机房孤岛（内网不通，外网通）</h4><ol>
<li>IDC-A故障<ol>
<li>服务权重通过gateway切换到IDC-B</li>
<li>通过外网进入IDC-A的流量，服务自杀返回50x，前端访问备用域名<ul>
<li>服务自杀参考：<a href="https://kingson4wu.gitee.io/2020/09/05/20200905-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98/">如何解决脑裂问题</a></li>
</ul>
</li>
</ol>
</li>
<li>IDC-B故障<ol>
<li>服务权重无需调整</li>
<li>通过外网进入IDC-B的流量，服务自杀返回50x，前端访问备用域名</li>
</ol>
</li>
</ol>
<h4 id="3-机房网络抖动"><a href="#3-机房网络抖动" class="headerlink" title="3) 机房网络抖动"></a>3) 机房网络抖动</h4><p>机房服务异常（内外网都通，但该机房服务有问题，网络不稳定，丢包率高等，需机房切换）。<br>流量进入服务之后处理同2）只是切换策略不同。</p>
<h3 id="决策服务"><a href="#决策服务" class="headerlink" title="决策服务"></a>决策服务</h3><ol>
<li>通过Consul判断是否孤岛</li>
<li>通过接口调用失败率，apm，监控网络丢包率等指标判断</li>
<li>相关服务同步切</li>
</ol>
<h4 id="单元化"><a href="#单元化" class="headerlink" title="单元化"></a>单元化</h4><ol>
<li>切换需要把相互依赖的服务整体进行切换，尽量避免跨机房调用。</li>
</ol>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><h3 id="gateway如何实现"><a href="#gateway如何实现" class="headerlink" title="gateway如何实现"></a>gateway如何实现</h3><ul>
<li>可以考虑结合服务发现，以localproxy代替nginx代替服务权重配置</li>
</ul>
<h3 id="其他注意事项"><a href="#其他注意事项" class="headerlink" title="其他注意事项"></a>其他注意事项</h3><ol>
<li>定时任务是否要切换</li>
<li>MQ消费或生产是否要切换</li>
<li>服务强依赖要单元化，比如强依赖方主备，自己的服务做双活也没用</li>
<li>MQ类发送异步进行</li>
<li>留意nginx重试机制，如以下配置：<code>proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504;</code>，501是不重试的，超时和其他50x会重试。<ul>
<li><a href="https://blog.csdn.net/mj158518/article/details/49847119">nginx的重试机制</a></li>
</ul>
</li>
</ol>
<h3 id="其他技巧"><a href="#其他技巧" class="headerlink" title="其他技巧"></a>其他技巧</h3><ol>
<li>服务所依赖的外部服务分为强依赖和弱依赖。弱依赖可以继续降级，而强依赖则不可以。</li>
<li>强依赖可以进一步划分成读依赖和写依赖。通常情况下写依赖是几乎不可能优化的，只能依赖其高可用，比如扣费服务。而读依赖则有优化空间，读依赖可以分为实时性依赖和非实时性依赖，后者可以通过缓存来解决强依赖的问题，比如用户的信息。这部分数据通常的强依赖的，但是又可以缓存下来。</li>
<li>强实时性读依赖的，故障情况下，可以考虑降级成非实时性依赖。比如采取先读远端数据，失败时降级成读缓存的策略。</li>
</ol>
<h3 id="演练方式"><a href="#演练方式" class="headerlink" title="演练方式"></a>演练方式</h3><ol start="0">
<li>前期：tcpcpoy线上流量，复制线上服务部署单独一台演练环境，包括应用和db</li>
<li>kill服务，killDB</li>
<li>iptables屏蔽端口<ul>
<li>iptable和kill应用不一样。前者会有readtimeout，后者直接reset peer</li>
<li>kill应用的方式基本是平稳的，使用iptable屏蔽端口的方式，可能会有connectTimeout或readTimeout。</li>
</ul>
</li>
<li>线上停机房<ul>
<li>停专线一定是孤岛，不存在一边内网通，另一边内网不通的情况，是一个内网（看上图的网络拓扑图）。</li>
</ul>
</li>
</ol>
<h3 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h3><ol>
<li>备用机房（IDC-B）正常情况下无流量？<ul>
<li>配置万分之一的流量，确保切换前已经可用。</li>
<li>确保切换之前备机房是可用的，是否可用通过观察日志情况。</li>
<li>备用机房异常应该及时告警。</li>
</ul>
</li>
<li>为什么跨机房同步不使用MySQL主从同步而使用otter？<ul>
<li>一般主从同步只在同机房或者同城进行。</li>
<li>otter是阿里开源的一个分布式数据库同步系统，尤其是在跨机房数据库同步方面，有很强大的功能。 </li>
<li>？？？？</li>
</ul>
</li>
<li>相关服务一同切换是否合理<ol>
<li>机房异常一同切换可行；</li>
<li>如果只是单个服务异常，别的服务也要跟着切库不一定合理。决策服务应该支持业务自行配置切换策略。</li>
</ol>
</li>
</ol>
]]></content>
      <tags>
        <tag>金钱相关</tag>
        <tag>容灾</tag>
      </tags>
  </entry>
  <entry>
    <title>金融业务容灾切换后监控和修正方案</title>
    <url>/2020/09/08/20200908-jin-rong-ye-wu-rong-zai-qie-huan-hou-jian-kong-he-xiu-zheng-fang-an/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul>
<li><p>接<a href="https://kingson4wu.gitee.io/2020/08/31/20200831-%E5%85%B3%E4%BA%8EMHA-Consul-MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88%E7%9A%84%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93%E5%92%8C%E6%80%9D%E8%80%83/">关于MHA_Consul_MySQL高可用方案的简单总结和思考</a><br>中所讲，该方案无法严格保证主从数据一致或者不丢数据，那么对数据准确性非常严格的业务，则需要在业务层面进行相应的对账和修正。</p>
</li>
<li><p>对账的前提当然是要有流水，可以是业务流水(跟余额表事务绑定)或者是binlog的变更流水。</p>
</li>
<li><p>既然是对准确性要求严格的业务，一般都应该会有业务流水。</p>
</li>
</ul>
<h2 id="方案描述"><a href="#方案描述" class="headerlink" title="方案描述"></a>方案描述</h2><ul>
<li>方案以数据库切换事件为线索，描述切库前的事先准备、切库中的止损、切库后的监控和修正。</li>
</ul>
<h3 id="一、切库前"><a href="#一、切库前" class="headerlink" title="一、切库前"></a>一、切库前</h3><ol>
<li>余额写redis缓存（如果有多机房，需要异步多写对应机房的redis，或nsq通知）</li>
</ol>
<h3 id="二、切库中"><a href="#二、切库中" class="headerlink" title="二、切库中"></a>二、切库中</h3><ol>
<li>发生切库事件</li>
<li>（切库之后的一段时间内）若有用户余额变动操作，比对redis和DB余额是否一致，不一致则阻断一段时间。</li>
</ol>
<ul>
<li>缺点：不一致有可能是误伤（redis刚好写失败导致切库前就不一致）</li>
<li>折中：针对一些大额变更才阻断，增加一些更细致的策略</li>
</ul>
<h3 id="三、切库后"><a href="#三、切库后" class="headerlink" title="三、切库后"></a>三、切库后</h3><ol>
<li>指定主库和从库，对比流水日志</li>
<li>修复数据（若有不一致），并关闭冻结开关</li>
<li>无法修复的订单如何处理（用户余额不足）？<ul>
<li>考虑当坏账处理；通过余额调整（邮件审批方式同步团队成员）；再按流水订单重新扣除</li>
</ul>
</li>
</ol>
<h3 id="对比流水和修复大致思路"><a href="#对比流水和修复大致思路" class="headerlink" title="对比流水和修复大致思路"></a>对比流水和修复大致思路</h3><ol>
<li>读旧主库和新主库的余额变更流水日志</li>
<li>对比得到旧主库存在而新主库不存在的余额变更流水日志</li>
<li>获取受影响的用户的余额，重放流水日志模拟分析，得到受影响人数，受影响金额，不可修复订单（比如余额不足）等情况</li>
<li>按照流水日志中的业务类型重新执行相应的业务sql（充值，消费，提现等）</li>
<li>修复完成之后，重建旧主库，并挂为主库</li>
</ol>
]]></content>
      <tags>
        <tag>金钱相关</tag>
        <tag>容灾</tag>
      </tags>
  </entry>
  <entry>
    <title>关于CLOSE_WAIT和HttpClient的使用</title>
    <url>/2020/09/26/20200926-guan-yu-close-wait-he-httpclient-de-shi-yong/</url>
    <content><![CDATA[<p><img src="/2020/09/26/20200926-guan-yu-close-wait-he-httpclient-de-shi-yong/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png"><br><img src="/2020/09/26/20200926-guan-yu-close-wait-he-httpclient-de-shi-yong/tcp_normal_close.png"></p>
<p>ESTABLISHED 表示正在进行网络连接的数量<br>TIME_WAIT 表示表示等待系统主动关闭网络连接的数量<br>CLOSE_WAIT 表示被动等待程序关闭的网络连接数量</p>
<ol start="0">
<li>查看系统TCP状态的命令：<code>netstat -n | awk &#39;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&#39;</code></li>
<li>CLOSE_WAIT 是被动关闭产生的一种状态，当用户程序正常close之后将变成LAST_ACK状态。</li>
<li>TIME_WAIT状态可以通过优化服务器参数得到解决(当然也有可能是程序处理不当产生太多连接)。而CLOSE_WAIT数目过大一般是由于程序被动关闭连接处理不当导致的。</li>
<li>以HttpClient为例<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">resp</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">    <span class="type">HttpResponse</span> <span class="variable">response</span> <span class="operator">=</span> client.execute(get);</span><br><span class="line">    <span class="keyword">if</span> (response.getStatusLine().getStatusCode() != <span class="number">200</span>) &#123;</span><br><span class="line">        get.abort();</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">HttpEntity</span> <span class="variable">entity</span> <span class="operator">=</span> response.getEntity();</span><br><span class="line">    <span class="keyword">if</span> (entity != <span class="literal">null</span>) &#123;</span><br><span class="line">        in = entity.getContent();</span><br><span class="line">        resp = in.xxx;</span><br><span class="line">        <span class="comment">//xxx</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> resp;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    get.abort();</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (in != <span class="literal">null</span>) &#123;</span><br><span class="line">        in.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
在异常时显示调用abort，直接中止本次连接，避免in未赋值导致连接未关闭的问题。</li>
<li>HttpClient连接关闭。一种是主动，一种是被动。在代码API的使用上没进行区分。主动关闭时当调用Close()，发出FIN包由ESTABLISHED进入FIN_WAIT_1 状态；被动关闭时当调用Close()，发出FIN包由CLOSE_WAIT进入LAST_ACK状态。</li>
<li>使用PoolingClientConnectionManager？</li>
</ol>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="httpclient-的timeout参数"><a href="#httpclient-的timeout参数" class="headerlink" title="httpclient 的timeout参数"></a>httpclient 的timeout参数</h3><ul>
<li><a href="https://blog.csdn.net/btlas/article/details/53710854">httpclient SocketTimeout ConnectTimeout ConnectionRequestTimeout</a></li>
<li>ConnectionRequestTimeout<ul>
<li>httpclient使用连接池来管理连接，这个时间就是从连接池获取连接的超时时间，可以想象下数据库连接池；</li>
</ul>
</li>
<li>ConnectTimeout<ul>
<li>连接建立时间，三次握手完成时间；</li>
</ul>
</li>
<li>SocketTimeout<ul>
<li>关于readimeout的含义: Defines a timeout for reading a response from the proxied server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the proxied server does not transmit anything within this time, the connection is closed.</li>
<li>数据传输过程中数据包之间间隔的最大时间；</li>
<li>SocketTimeout的值表示的是“a”、”b”、”c”这三个报文，每两个相邻的报文的间隔时间不能超过SocketTimeout</li>
<li>虽然报文(“abc”)返回总共用了6秒，如果SocketTimeout设置成4秒，实际程序执行的时候是不会抛出java.net.SocketTimeoutException: Read timed out异常的</li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.cnblogs.com/sunxucool/p/3449068.html">服务器TIME_WAIT和CLOSE_WAIT详解和解决办法</a></li>
<li><a href="https://blog.csdn.net/shootyou/article/details/6615051">HttpClient连接池抛出大量ConnectionPoolTimeoutException: Timeout waiting for connection异常排查</a></li>
</ul>
]]></content>
      <tags>
        <tag>TCP</tag>
        <tag>CLOSE_WAIT</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis笔记</title>
    <url>/2020/10/11/20201011-redis-bi-ji/</url>
    <content><![CDATA[<h2 id="脑图"><a href="#脑图" class="headerlink" title="脑图"></a>脑图</h2><p><img src="/2020/10/11/20201011-redis-bi-ji/Redis.png"></p>
<h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><ul>
<li>info memory 可查看Redis使用了jemalloc</li>
<li>Redis Config Get 命令 - 获取指定配置参数的值：<a href="https://www.redis.net.cn/order/3667.html">https://www.redis.net.cn/order/3667.html</a></li>
<li>cluster nodes</li>
</ul>
<h2 id="Redis-客户端"><a href="#Redis-客户端" class="headerlink" title="Redis 客户端"></a>Redis 客户端</h2><ul>
<li><a href="https://redis.io/clients#java">https://redis.io/clients#java</a></li>
<li>Jedis</li>
<li>lettuce</li>
<li>Redisson</li>
</ul>
<h3 id="Jedis"><a href="#Jedis" class="headerlink" title="Jedis"></a>Jedis</h3><h4 id="连接方式"><a href="#连接方式" class="headerlink" title="连接方式"></a>连接方式</h4><ol>
<li>Jedis直连<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Jedis</span> <span class="variable">jedis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Jedis</span>(<span class="string">&quot;127.0.0.1&quot;</span>,<span class="number">6379</span>);</span><br></pre></td></tr></table></figure></li>
<li>Jedis连接池<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">GenericObjectPoolConfig</span> <span class="variable">poolConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GenericObjectPoolConfig</span>();</span><br><span class="line">          <span class="type">JedisPool</span> <span class="variable">jedisPool</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JedisPool</span>(poolConfig, <span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">6379</span>);</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>Jedis是redis的java客户端，JedisCluster则是Jedis根据Redis集群的特性提供的集群客户端。</li>
</ul>
<h3 id="Jedis客户端如何定位到对应的主节点"><a href="#Jedis客户端如何定位到对应的主节点" class="headerlink" title="Jedis客户端如何定位到对应的主节点"></a>Jedis客户端如何定位到对应的主节点</h3><ul>
<li><a href="https://zhuanlan.zhihu.com/p/69800024">你不知道的Redis：RedisCluster与JedisCluster</a></li>
<li>JedisClusterInfoCache：关于缓存数据的获取及更新实际是由JedisClusterInfoCache的discoverClusterNodesAndSlots方法实现， 主要是通过cluster slots 命令获取集群内的槽位分布数据，然后解析该命令的返回结果，为每个主节点初始化一个连接池，然后将节点与连接池、节点负责的所有槽位与连接池的映射关系缓存</li>
<li>初始化主要分为一下几部分：<ol>
<li>连接一个节点执行cluster slots命令，获取槽位分布以及集群节点信息；</li>
<li>为每一个节点都初始化一个连接池，并跟节点建立映射关系缓存；</li>
<li>将每个主节点负责的槽位一一与主节点连接池建立映射缓存。</li>
<li>初始化工作中缓存的映射信息，在JedisCluster的使用过程中起到了至关重要的作用。但也正是因为JedisCluster在本地内存中缓存节点数据并且为每个节点维护一个连接池，在使用节点特别多的庞大集群时，客户端也会消耗更多内存。</li>
</ol>
</li>
</ul>
<h2 id="Redis基本数据类型原理"><a href="#Redis基本数据类型原理" class="headerlink" title="Redis基本数据类型原理"></a>Redis基本数据类型原理</h2><ol>
<li>字符串：redis没有直接使用C语言传统的字符串表示，而是自己实现的叫做简单动态字符串SDS的抽象类型。C语言的字符串不记录自身的长度信息，而SDS则保存了长度信息，这样将获取字符串长度的时间由O(N)降低到了O(1)，同时可以避免缓冲区溢出和减少修改字符串长度时所需的内存重分配次数。</li>
<li>链表linkedlist：redis链表是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使用到了链表来实现，每个链表的节点由一个listNode结构来表示，每个节点都有指向前置节点和后置节点的指针，同时表头节点的前置和后置节点都指向NULL。</li>
<li>字典hashtable：用于保存键值对的抽象数据结构。redis使用hash表作为底层实现，每个字典带有两个hash表，供平时使用和rehash时使用，hash表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对hash表进行扩容或者缩容的时候，为了服务的可用性，rehash的过程不是一次性完成的，而是渐进式的。</li>
<li>跳跃表skiplist：跳跃表是有序集合的底层实现之一，redis中在实现有序集合键和集群节点的内部结构中都是用到了跳跃表。redis跳跃表由zskiplist和zskiplistNode组成，zskiplist用于保存跳跃表信息（表头、表尾节点、长度等），zskiplistNode用于表示表跳跃节点，每个跳跃表的层高都是1-32的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。</li>
<li>整数集合intset：用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。</li>
<li>压缩列表ziplist：压缩列表是为节约内存而开发的顺序性数据结构，他可以包含多个节点，每个节点可以保存一个字节数组或者整数值。</li>
</ol>
<p>基于这些基础的数据结构，redis封装了自己的对象系统，包含字符串对象string、列表对象list、哈希对象hash、集合对象set、有序集合对象zset，每种对象都用到了至少一种基础的数据结构。</p>
<p>redis通过encoding属性设置对象的编码形式来提升灵活性和效率，基于不同的场景redis会自动做出优化。不同对象的编码如下：</p>
<ol>
<li>字符串对象string：int整数、embstr编码的简单动态字符串、raw简单动态字符串</li>
<li>列表对象list：ziplist、linkedlist</li>
<li>哈希对象hash：ziplist、hashtable</li>
<li>集合对象set：intset、hashtable</li>
<li>有序集合对象zset：ziplist、skiplist</li>
</ol>
<h2 id="Redis为什么快"><a href="#Redis为什么快" class="headerlink" title="Redis为什么快"></a>Redis为什么快</h2><p>redis的速度非常的快，单机的redis就可以支撑每秒10几万的并发，相对于mysql来说，性能是mysql的几十倍。速度快的原因主要有几点：</p>
<ol>
<li>完全基于内存操作</li>
<li>C语言实现，优化过的数据结构，基于几种基础的数据结构，redis做了大量的优化，性能极高</li>
<li>使用单线程，无上下文的切换成本</li>
<li>基于非阻塞的IO多路复用机制</li>
</ol>
<h3 id="Redis6-0之后改用多线程"><a href="#Redis6-0之后改用多线程" class="headerlink" title="Redis6.0之后改用多线程"></a>Redis6.0之后改用多线程</h3><ul>
<li>redis使用多线程并非是完全摒弃单线程，redis还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。</li>
<li>这样做的目的是因为redis的性能瓶颈在于网络IO而非CPU，使用多线程能提升IO读写的效率，从而整体提高redis的性能。</li>
</ul>
<h2 id="主从同步的原理"><a href="#主从同步的原理" class="headerlink" title="主从同步的原理"></a>主从同步的原理</h2><ol>
<li>slave发送sync命令到master</li>
<li>master收到sync之后，执行bgsave，生成RDB全量文件</li>
<li>master把slave的写命令记录到缓存</li>
<li>bgsave执行完毕之后，发送RDB文件到slave，slave执行</li>
<li>master发送缓存中的写命令到slave，slave执行</li>
</ol>
<h2 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h2><h3 id="cluster-require-full-coverage"><a href="#cluster-require-full-coverage" class="headerlink" title="cluster-require-full-coverage"></a>cluster-require-full-coverage</h3><h4 id="cluster-require-full-coverage-x3D-yes"><a href="#cluster-require-full-coverage-x3D-yes" class="headerlink" title="cluster-require-full-coverage&#x3D; yes"></a>cluster-require-full-coverage&#x3D; yes</h4><ol>
<li>任一master宕机	集群可用</li>
<li>同一组master和slave宕机	集群不可用</li>
<li>半数及以上master宕机	集群不可用</li>
</ol>
<h4 id="cluster-require-full-coverage-x3D-no"><a href="#cluster-require-full-coverage-x3D-no" class="headerlink" title="cluster-require-full-coverage&#x3D; no"></a>cluster-require-full-coverage&#x3D; no</h4><ol>
<li>同一组master和slave宕机	集群可用</li>
<li>半数及以上master宕机	集群不可用</li>
</ol>
<h2 id="源码系列"><a href="#源码系列" class="headerlink" title="源码系列"></a>源码系列</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/QVxwJb6F99E17ZaGQlhVTQ">全面阐释Redis常见对象类型的底层数据结构</a></li>
</ul>
<h3 id="字符串SDS"><a href="#字符串SDS" class="headerlink" title="字符串SDS"></a>字符串SDS</h3><ul>
<li>扩容策略：长度小于1M时每次扩容加倍；长度大于1M后每次扩容加1M</li>
</ul>
<h3 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h3><ul>
<li>由两个hashtable组成，通常情况下只有一个有值。扩容时搬迁过程中两个都有值；</li>
<li>hashtable第一维是数组，第二维是链表；</li>
<li>渐进式rehash：在后续的hset，hdel等指令逐步搬迁，同时有定时任务进行搬迁(单线程，一次性搬迁太耗时)</li>
</ul>
<h3 id="压缩列表-ziplist"><a href="#压缩列表-ziplist" class="headerlink" title="压缩列表(ziplist)"></a>压缩列表(ziplist)</h3><ul>
<li>zset和hash在元素较少时使用ziplist存储</li>
<li>ziplist是连续的内存空间，元素紧凑存储，支持双向遍历</li>
</ul>
<h3 id="快速列表-quicklist"><a href="#快速列表-quicklist" class="headerlink" title="快速列表(quicklist)"></a>快速列表(quicklist)</h3><h3 id="跳跃列表-skiplist"><a href="#跳跃列表-skiplist" class="headerlink" title="跳跃列表(skiplist)"></a>跳跃列表(skiplist)</h3><h3 id="紧凑列表-listpack"><a href="#紧凑列表-listpack" class="headerlink" title="紧凑列表(listpack)"></a>紧凑列表(listpack)</h3><ul>
<li>Redis 5.0</li>
</ul>
<h3 id="基数树-rax"><a href="#基数树-rax" class="headerlink" title="基数树(rax)"></a>基数树(rax)</h3><h3 id="LFU"><a href="#LFU" class="headerlink" title="LFU"></a>LFU</h3><ul>
<li>Least Frequently Used, 按最近的访问频率进行淘汰，比LRU更精准表示一个key的访问热度</li>
</ul>
<h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><ul>
<li>Redis Memory Analyzer:<a href="https://scalegrid.io/blog/the-top-6-free-redis-memory-analysis-tools/">https://scalegrid.io/blog/the-top-6-free-redis-memory-analysis-tools/</a>, <a href="https://stackoverflow.com/questions/49388547/get-the-redis-key-value-size-in-memory">https://stackoverflow.com/questions/49388547/get-the-redis-key-value-size-in-memory</a></li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>[redis深度历险：核心原理与应用实践]</li>
<li><a href="https://mp.weixin.qq.com/s/M9ImkchlYfB5yc7chJs0uQ">关于Redis，你扛得住这夺命连环11问吗？</a></li>
</ul>
]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>【计算机科学速成课】笔记</title>
    <url>/2020/10/18/20201018-ji-suan-ji-ke-xue-su-cheng-ke-bi-ji/</url>
    <content><![CDATA[<ul>
<li><a href="https://www.bilibili.com/video/BV1EW411u7th?from=search&seid=3492574543463250318">【计算机科学速成课】[40集全&#x2F;精校] - Crash Course Computer Science</a></li>
</ul>
]]></content>
      <tags>
        <tag>Computer</tag>
      </tags>
  </entry>
  <entry>
    <title>重构-改善既有代码的设计-摘要</title>
    <url>/2020/11/01/20201101-chong-gou-gai-shan-ji-you-dai-ma-de-she-ji-zhai-yao/</url>
    <content><![CDATA[<p><img src="/2020/11/01/20201101-chong-gou-gai-shan-ji-you-dai-ma-de-she-ji-zhai-yao/0531.jpg"><br><img src="/2020/11/01/20201101-chong-gou-gai-shan-ji-you-dai-ma-de-she-ji-zhai-yao/06211.jpg"><br><img src="/2020/11/01/20201101-chong-gou-gai-shan-ji-you-dai-ma-de-she-ji-zhai-yao/06212.jpg"><br><img src="/2020/11/01/20201101-chong-gou-gai-shan-ji-you-dai-ma-de-she-ji-zhai-yao/06213.jpg"><br><img src="/2020/11/01/20201101-chong-gou-gai-shan-ji-you-dai-ma-de-she-ji-zhai-yao/0701.jpg"><br><img src="/2020/11/01/20201101-chong-gou-gai-shan-ji-you-dai-ma-de-she-ji-zhai-yao/08061.jpg"><br><img src="/2020/11/01/20201101-chong-gou-gai-shan-ji-you-dai-ma-de-she-ji-zhai-yao/08062.jpg"></p>
]]></content>
      <tags>
        <tag>IT-BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>《半小时漫画经济学》-笔记</title>
    <url>/2020/11/02/20201102-ban-xiao-shi-man-hua-jing-ji-xue-bi-ji/</url>
    <content><![CDATA[<p><img src="/2020/11/02/20201102-ban-xiao-shi-man-hua-jing-ji-xue-bi-ji/Shanghai_Beach_4.png"></p>
<h3 id="一、开篇：我们为什么要读经济学"><a href="#一、开篇：我们为什么要读经济学" class="headerlink" title="一、开篇：我们为什么要读经济学"></a>一、开篇：我们为什么要读经济学</h3><ul>
<li>历史上没有一场仗是因为爱和正义打起来的，所有的流血背后，深层次的原因都是经济</li>
<li>如果我们想搞明白人类是怎么活成这样的、世界是怎么运转起来的，就要先搞明白这个问题：经济是怎么来的？一、经济起源首先，经济是什么？简单地讲，就是资源最优化配置。比如一瓶水，只有到口渴的人手里，价值才能发挥到最大。</li>
<li>这些余粮，就是大家的财产，我们也可以将之理解成经济学里的资源。</li>
<li>农业是骨架，工业填充了血肉，其他行业是各种器官，它们一起组成了经济这副躯体。</li>
</ul>
<h3 id="二、货币的起源：钱打哪儿来的"><a href="#二、货币的起源：钱打哪儿来的" class="headerlink" title="二、货币的起源：钱打哪儿来的"></a>二、货币的起源：钱打哪儿来的</h3><ul>
<li>用金银当货币，就叫——金银本位。用羊当货币就是羊本位，用贝壳当货币就是贝本位，以此类推。</li>
<li>经济越来越好，商品就越来越多，这就需要更多的钱去买。于是有了比金银更方便带、更方便造的纸币。到后来，人们觉得纸币也麻烦，于是有了方便付款的电子货币。</li>
<li>货币随着经济增长一直在变多！</li>
<li>钱源于债务！因为人类学家发现了很多证据，研究了半天，得出个结论：这种物物交换的社会是不存在的！</li>
<li>二狗子拿着鸡要换三胖子的铁锤，三胖子虽然不想要鸡，但他还是把铁锤给了二狗子，大家都熟，打个欠条就行。比如欠条到了老四手里，就相当于二狗子欠老四债。后来，大家也都这么做，用着用着顺手了，欠条就在村里流通了起来，谁还在乎它原先是谁的？为什么大家相信这张欠条呢？原来，二狗子人品好，财产多，不管谁拿着欠条来换铁锤，他都给换。这种有借有还的品质，就是传说中的——信用。人们交换、欠债什么的，其实玩的都是信用，只要有人相信，贝壳、石头、金银，甚至纸，都能当钱花。这就是信用货币理论的一部分。</li>
</ul>
<h3 id="三、那些年缴过的“五险一金”到底是什么"><a href="#三、那些年缴过的“五险一金”到底是什么" class="headerlink" title="三、那些年缴过的“五险一金”到底是什么"></a>三、那些年缴过的“五险一金”到底是什么</h3><ul>
<li>政府、工厂、工人各拿出点钱来存在一起，哪个工人出意外了，就拿钱出来，让他能维持生活，大概是这样：工人们没后顾之忧了，干起活儿来更带劲，德国经济一路雄起。现代社保制度从此诞生了！</li>
<li>如果社保不够年限，那恐怕享受不到福利了。你自己缴的会退给你，不过公司帮你缴的钱，只能和它们说再见了。</li>
</ul>
<h3 id="四、养老金能养老吗"><a href="#四、养老金能养老吗" class="headerlink" title="四、养老金能养老吗"></a>四、养老金能养老吗</h3><ul>
<li>计算养老金时，是以当时的社会平均工资为基础的，所以不用担心钱贬值的问题。</li>
<li>真实情况是，人口正在老龄化，上班族越来越少，退休的大爷大妈越来越多。[插图]这样下去，总有一天，社保基金入不敷出，到时候嘛。。</li>
</ul>
<h3 id="五、医保到底保了个啥"><a href="#五、医保到底保了个啥" class="headerlink" title="五、医保到底保了个啥"></a>五、医保到底保了个啥</h3><h3 id="六、一口气搞懂到底要缴哪些税"><a href="#六、一口气搞懂到底要缴哪些税" class="headerlink" title="六、一口气搞懂到底要缴哪些税"></a>六、一口气搞懂到底要缴哪些税</h3><ul>
<li>从收入里拿出来的这部分钱就叫个人所得税。正确叫法应该是免征额</li>
<li>在商品流通过程中缴的税，就叫流转税。</li>
<li>无论占有哪种财富，都有可能要缴税，这叫财产和资源税。</li>
<li>税很多事和特定行为有关，把它们打包一下收的税，就叫行为税</li>
</ul>
<h3 id="七、买房前必须知道的二三事"><a href="#七、买房前必须知道的二三事" class="headerlink" title="七、买房前必须知道的二三事"></a>七、买房前必须知道的二三事</h3><ul>
<li>宅基地所有权归集体，使用权归农民，不存在什么年限，住到宇宙爆炸都没问题。但宅基地的房子有个问题，没房产证，没产权，没土地使用证，俗称小产权房。这种房子自己住没问题，但要想卖给外村人或者城里人，就难喽！</li>
<li>一般买这些地的，都是房地产公司，交的钱就叫土地出让金，但使用权是有期限的，比如70年，相当于租地。房地产公司怎么赚钱呢？很简单，盖楼卖给消费者，这就是我们熟悉的商品房。产权时间是从开发商拿地开始算的，以70年产权为例，实际你买的房子的产权到期时间可能要比70年短。</li>
<li>国家收回土地土地产权到期了，如果国家想收回来用，那你的房子就要拆迁了，你的人生可能就不一样了。</li>
</ul>
<h3 id="九、借钱那些事儿：如何避开借贷中的那些坑"><a href="#九、借钱那些事儿：如何避开借贷中的那些坑" class="headerlink" title="九、借钱那些事儿：如何避开借贷中的那些坑"></a>九、借钱那些事儿：如何避开借贷中的那些坑</h3><ul>
<li>个人、公司和政府，三者之间的不同组合，就对应了我们身边不同的金融产品。</li>
<li>按传统经济学家的说法，人是理性的，大家都只会把钱借给靠谱的人，也只会借自己有能力还的钱。次贷危机首先得弄清楚什么叫次贷：[插图]一边美国银行敢给，另一边矮矬穷真敢借，也不想想自己能不能还上</li>
<li>法律就说了，民间借贷的利率高过36%属于高利贷，是非法的。</li>
</ul>
<h3 id="十、消费心理学：消费者防剁手指南"><a href="#十、消费心理学：消费者防剁手指南" class="headerlink" title="十、消费心理学：消费者防剁手指南"></a>十、消费心理学：消费者防剁手指南</h3><ul>
<li>大家购物时，会先找差不多的货比一比，一般不会选高价和低价，而是选中间价。这就是托奥斯基的“价格锚点”理论。</li>
<li>特沃斯基和卡尼曼的“损失规避”理论。简单来说就是比起得到，大家更怕失去。所以就算是一件好东西，一旦发现会给自己带来损失，很多人就宁愿不要。</li>
</ul>
<h3 id="十一、传销大起底：珍爱生命，远离传销"><a href="#十一、传销大起底：珍爱生命，远离传销" class="headerlink" title="十一、传销大起底：珍爱生命，远离传销"></a>十一、传销大起底：珍爱生命，远离传销</h3><ul>
<li>整个过程都没有真正的产品，赚钱全靠拆东墙补西墙。这个简单的骗术，就是金融界大名鼎鼎的庞氏骗局。这个骗局的死穴就在于：需要不断有新钱注入，一旦没有蠢萌新人进来，大家全都要玩儿完。四个字形容它的特点，那就是：一旦停药，骗子就会赶紧拿钱跑路，大家的投资款就打水漂了。</li>
<li>如果有一天，再也发展不到下线了，整个系统就崩溃了。也就是说，传销的本质就是：不要产品，只要人。</li>
</ul>
<hr>
<h3 id="一、开篇：我们为什么要了解金融危机"><a href="#一、开篇：我们为什么要了解金融危机" class="headerlink" title="一、开篇：我们为什么要了解金融危机"></a>一、开篇：我们为什么要了解金融危机</h3><ul>
<li>经济有个定义：价值的创造、转化和实现。简单地说，经济就是资源配置，但是人类总是在这条路上跑偏。</li>
<li>博大精深的中华文化告诉我们，把“危机”拆开来看，就是：“危险”和“机会。</li>
<li>二战之所以能打起来，部分原因是美国的国内危机，演变成了全球危机。</li>
<li>金融危机不是绝对的坏事，也可能是社会的崩溃疗法</li>
</ul>
<h3 id="二、金融危机就要来了：明斯基时刻"><a href="#二、金融危机就要来了：明斯基时刻" class="headerlink" title="二、金融危机就要来了：明斯基时刻"></a>二、金融危机就要来了：明斯基时刻</h3><ul>
<li>人类社会的经济是有规律的，每次繁荣后面，都跟着一波波衰退。人们把这种周期性经济衰退的现象叫：经济危机。而经济的衰退常常是由于金融危机导致的。</li>
<li>经济是有周期的，金融危机经常发生，原因可能是金融不稳定。经济周期有大有小，很多小周期构成了一个大周期，明斯基时刻说的是大周期的转折点。</li>
<li>借的这部分钱，就叫杠杆。借钱用来扩充资产，就是加杠杆。杠杆让你赚得多，但赔起来也多。</li>
<li>杠杆越来越高，最后还不起了，可能就会引发危机。所以该咋做知道了吧？去杠杆啊！简单说就是还钱，一般政府都会做这些事：方法1：债务违约重组钱暂时还不上是吧？银行为了把钱要回来，只好想点别的办法，比如少还点，延长还款期限。方法2：财富再分配给土豪加税，把收来的钱用来发福利、创造就业岗位，这样失业的人就慢慢有了钱，就能把欠的还上。方法3：货币调节为了解决问题，政府会和中央银行商量，让中央银行多印一些钱，然后花到了大家身上。</li>
</ul>
<h3 id="三、一朵花酿成的惨案：郁金香泡沫（上）"><a href="#三、一朵花酿成的惨案：郁金香泡沫（上）" class="headerlink" title="三、一朵花酿成的惨案：郁金香泡沫（上）"></a>三、一朵花酿成的惨案：郁金香泡沫（上）</h3><ul>
<li>郁金香泡沫，堪称金融危机鼻祖。</li>
<li>赚了钱就按比例分红，赔了钱就只承担有限责任，这就是世界上第一家股份有限公司</li>
</ul>
<h3 id="四、一朵花酿成的惨案：郁金香泡沫（下）"><a href="#四、一朵花酿成的惨案：郁金香泡沫（下）" class="headerlink" title="四、一朵花酿成的惨案：郁金香泡沫（下）"></a>四、一朵花酿成的惨案：郁金香泡沫（下）</h3><ul>
<li>合同到期了，就能拿到郁金香，反正不会亏，大家都乐意。这种玩法就是期货的雏形。荷兰人全国总动员炒郁金香，船不造了，生意黄了，钱投进去连个响都没有，经济急剧下滑。</li>
<li>郁金香泡沫过去了，后来又有南海泡沫、密西西比泡沫，甚至次贷危机。人们好像从来不会吸取教训，直到现在咱们身边也还在发生这种事：所以看完这个故事，对咱们还是很有用的，起码你再看到有些东西很贵，但明显不值那个价，人们却一直往里砸钱投资时，就应该知道那很可能就是金融泡沫，要保持冷静。价格虚高的东西别碰，要投就投有价值的，这叫理性。</li>
</ul>
<h3 id="五、连牛顿也算不出的疯狂：南海泡沫"><a href="#五、连牛顿也算不出的疯狂：南海泡沫" class="headerlink" title="五、连牛顿也算不出的疯狂：南海泡沫"></a>五、连牛顿也算不出的疯狂：南海泡沫</h3><ul>
<li>对南海公司来说，“韭菜”就是一茬茬的钱，问题是怎么收割呢？南海贸易特许权本来就是个金字招牌，再加上政府的担保，就能让不明真相的老百姓信得不要不要的。“韭菜们”都看好南海公司，纷纷买入他们的股票。</li>
<li>上到国王，下到家庭主妇，全在炒股，却不管不问公司经营啥情况，这就很容易——出大事啊！</li>
</ul>
<h3 id="六、股票连涨13个月会怎么样：密西西比泡沫"><a href="#六、股票连涨13个月会怎么样：密西西比泡沫" class="headerlink" title="六、股票连涨13个月会怎么样：密西西比泡沫"></a>六、股票连涨13个月会怎么样：密西西比泡沫</h3><ul>
<li>他首先要做的不是跑业务，而是开始发股票，而且能用国债来换股票。大家都很看好公司，因此股票老值钱了。现在能用国债换，简直是睡觉都能笑醒！这样一换，国债被抵销，国家就不用还老百姓钱啦！法国经济繁荣靠股市，但股市其实很虚，因此所谓的经济繁荣就是个泡沫啊！最后路易十六被送上断头台，这就是著名的法国大革命。</li>
</ul>
<h3 id="七、房价是怎么被炒起来的：1837年美国大恐慌"><a href="#七、房价是怎么被炒起来的：1837年美国大恐慌" class="headerlink" title="七、房价是怎么被炒起来的：1837年美国大恐慌"></a>七、房价是怎么被炒起来的：1837年美国大恐慌</h3><ul>
<li>1837年美国大恐慌从本质上说就是一个美国人瞎炒房的故事。简单来说，贷款变难了，这叫信贷紧缩，缩得太紧，导致市场上没钱，美国经济就容易不景气。总结一下，美国跟英国房东打了两架，欠了外债，为了还钱开银行，薅了老百姓的黄金，最后把自己的经济搞坏了。</li>
<li>很快国内经济一落千丈，纸币没人信，黄金又没有，股票暴跌，很多行业破产，大家都找不到工作。这就是美国第一次萧条，史称美国大恐慌。</li>
<li>1848年，恐慌了11年的美国在加州的一个地方，发现了大金矿。本来缺黄金，一下子却变成了矿主，美国突然不慌了，这就是历史上著名的淘金热。</li>
<li>简单来说，美国大恐慌其实就是一个炒房的故事，房子是用来住的，不是用来炒的，可惜美国人并不懂这个道理。</li>
</ul>
<h3 id="八、美联储的诞生：1907年美国银行危机"><a href="#八、美联储的诞生：1907年美国银行危机" class="headerlink" title="八、美联储的诞生：1907年美国银行危机"></a>八、美联储的诞生：1907年美国银行危机</h3><ul>
<li>南方要搞农业，北方要搞工业，一言不合就开撕，这就是咱们熟悉的南北战争。</li>
<li>他来自传说中的摩根家族，据说当时身家达13亿美元。于是摩根撸起袖子，着手拯救美国：他先找了几家银行，成立了一个由富翁们组成，专门给发愁的信托和银行送钱的联盟——摩根干的其实是中央银行的活，所以美国觉得需要一家中央银行来统一管钱。成立新机构要取个新名字，叫啥好呢？美国老百姓已经听到银行就害怕了，所以不能有银行两个字。那就叫美国联邦储备局吧</li>
</ul>
<h3 id="九、实现美国梦的三大法宝：泰罗制、福特制和猪"><a href="#九、实现美国梦的三大法宝：泰罗制、福特制和猪" class="headerlink" title="九、实现美国梦的三大法宝：泰罗制、福特制和猪"></a>九、实现美国梦的三大法宝：泰罗制、福特制和猪</h3><h3 id="十、1929—1933年美国大萧条"><a href="#十、1929—1933年美国大萧条" class="headerlink" title="十、1929—1933年美国大萧条"></a>十、1929—1933年美国大萧条</h3><ul>
<li>自由放任主义。结果小公司一个个倒下，而强势的公司却越做越大，逐渐成了江湖的不败神话：垄断的意思大家都知道吧：一家公司赶走竞争者，占领市场一家独大。但垄断常常会产生不好的结果，少数人资源独占，而多数人吃糠咽菜，贫富差距很快就被拉大了。</li>
<li>当时的资本家一心想赚钱，玩命搞生产，可问题是：多数人穷得连饭都吃不起，他们能买得起啥？所以当时的社会背景就是：资本家们一瞅，一个个的都不消费，多影响自己赚钱国家经济啊！</li>
<li>消费力虚了，农业也跟着倒了血霉，农产品卖不出去，只能销毁。很多农民宁可把牛奶倒进河里，也不降价或者送给穷人。为什么呢？因为一旦牛奶降价，其他货为了卖出去，只能被迫降价，这样会导致卖家利润更低。另外，想卖货得先砸钱，比如投入运费，货倒了反而损失小。</li>
<li>经济危机最严重的问题就是失业。</li>
<li>由生产过剩引发的经济危机。</li>
</ul>
<h3 id="十一、拯救美国的两位“救市主”：胡佛和罗斯福"><a href="#十一、拯救美国的两位“救市主”：胡佛和罗斯福" class="headerlink" title="十一、拯救美国的两位“救市主”：胡佛和罗斯福"></a>十一、拯救美国的两位“救市主”：胡佛和罗斯福</h3><ul>
<li><p>胡佛是一个坚定的自由放任主义者，这种说法其实不太对，因为他在经济危机之后一直在积极干预经济。</p>
</li>
<li><p>新上任的总统就是罗斯福。罗大爷觉得，政府应该对市场插手，不能只当看大门的保安，想解决危机，就要做连你家垃圾都要管的——这套想法其实就是凯恩斯主义，当然里面的内容还有很多，这里简单理解一下就好。既然胡佛搞砸了，那这一套还好使吗？咱看看罗斯福怎么做的就知道了。<br>罗斯福放了个大招——废除金本位。金本位制度规定美元和黄金挂钩，两者价值要对等，不能瞎印美元。现在脱钩了，政府就能多印点美元给银行，而且美元一多就贬值。对其他国家来讲，美国商品便宜了，秒变抢手货。</p>
</li>
<li><p>政府搞基建招工，然后给工人们发工资。</p>
</li>
<li><p>胡佛和罗斯福的很多政策其实差不多，都整顿了银行，都不让降工资，但为啥一个失败而另一个却成功了呢？这里就要说一下经济周期了。啥叫经济周期？简单说就是：下滑期，再厉害也没用；上升期，躺赢不是梦。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
        <tag>Finance</tag>
      </tags>
  </entry>
  <entry>
    <title>单元测试使用总结</title>
    <url>/2020/11/11/20201111-dan-yuan-ce-shi-shi-yong-zong-jie/</url>
    <content><![CDATA[<h2 id="mockito使用"><a href="#mockito使用" class="headerlink" title="mockito使用"></a>mockito使用</h2><h3 id="mock实例"><a href="#mock实例" class="headerlink" title="mock实例"></a>mock实例</h3><ul>
<li><code>Test test = mock(Test.class);</code></li>
<li><code>Test test = spy(new Test());</code></li>
</ul>
<h3 id="在Spring中使用"><a href="#在Spring中使用" class="headerlink" title="在Spring中使用"></a>在Spring中使用</h3><ul>
<li><code>@Mock Test test;</code></li>
<li><code>@Spy Test test = new Test();</code></li>
<li><code>@MockBean Test test;</code> (起spring容器时)</li>
<li><code>@InjectMocks Test test;</code> (起mockito容器时的测试对象)</li>
<li>Spring boot使用@MockBean和@SpyBean来定义Mockito的mock和spy。</li>
<li>使用@mockBean，未mock的方法可能会导致返回默认值，从而导致异常的逻辑造成脏数据（可能是代码本来不完善）；可以注意尽量@SpyBean</li>
</ul>
<h3 id="mock使用"><a href="#mock使用" class="headerlink" title="mock使用"></a>mock使用</h3><ul>
<li><p><code>when().thenReturn()</code>模式 和 <code>doReturn().when()</code>模式<br>两种模式都用于模拟对象方法，在mock实例下使用时，基本上是没有差别的。但是，在spy实例下使用时，<code>when().thenReturn()</code>模式会执行原方法，而<code>doReturn().when()</code>模式不会执行原方法。</p>
</li>
<li><p><code>when(test.do(anyString())).thenReturn(true);</code></p>
</li>
<li><p>返回值为void： <code>doAnswer((Answer&lt;Void&gt;)invocation -&gt; null).when(test).do(anyString(),anyLong(),anyString());</code></p>
</li>
<li><p>抛异常：<code>doThrow(new RuntimeException(&quot;error&quot;)).when(test).do(anyLong(), anyString());</code></p>
</li>
<li><p><code>doReturn(expected).when(spyList).get(100);</code> (使用spy时)<br>- <code>org.mockito.Mockito.doReturn;</code> 注意不要导入powermock的包<br>- <code>doReturn().when()</code>模式: 用于模拟对象方法，直接返回期望的值、异常、应答，或调用真实的方法，无需执行原始方法</p>
</li>
<li><p>直接调用真实方法:<code>Mockito.doCallRealMethod().when(userService).getUser(userId);</code>, <code>Mockito.when(userService.getUser(userId)).thenCallRealMethod();</code></p>
</li>
<li><p>模拟可空参数方法: <code>Mockito.doReturn(user).when(userDAO).queryCompany(Mockito.anyLong(), Mockito.nullable(Long.class));</code></p>
</li>
<li><p>匹配null对象，可以使用isNull方法，或使用eq(null):<code>Mockito.doReturn(user).when(userDAO).queryCompany(Mockito.anyLong(), Mockito.isNull());</code>, <code>Mockito.when(userDAO.queryCompany(Mockito.anyLong(), Mockito.eq(null))).thenReturn(user);</code></p>
</li>
<li><p>模拟final方法: PowerMock提供对final方法的模拟，方法跟模拟普通方法一样。但是，需要把对应的模拟类添加到@PrepareForTest注解中。</p>
</li>
<li><p>模拟私有方法: PowerMock提供提对私有方法的模拟，但是需要把私有方法所在的类放在@PrepareForTest注解中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PowerMockito.when(userService, <span class="string">&quot;isSuperUser&quot;</span>, userId).thenReturn(!expected);</span><br><span class="line"><span class="comment">//通过模拟方法stub(存根)，也可以实现模拟私有方法。但是，只能模拟整个方法的返回值，而不能模拟指定参数的返回值。</span></span><br><span class="line">PowerMockito.stub(PowerMockito.method(UserService.class, <span class="string">&quot;isSuperUser&quot;</span>, Long.class)).toReturn(!expected);</span><br><span class="line"><span class="type">Method</span> <span class="variable">method</span> <span class="operator">=</span> PowerMockito.method(UserService.class, <span class="string">&quot;isSuperUser&quot;</span>, Long.class);</span><br><span class="line"><span class="type">Object</span> <span class="variable">actual</span> <span class="operator">=</span> method.invoke(userService, userId);</span><br></pre></td></tr></table></figure>
</li>
<li><p>模拟构造方法: PowerMock提供PowerMockito.whenNew方法来模拟构造方法，但是需要把使用构造方法的类放在@PrepareForTest注解中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PowerMockito.whenNew(MockClass.class).withNoArguments().thenReturn(expectedObject);</span><br><span class="line">PowerMockito.whenNew(MockClass.class).withArguments(someArgs).thenReturn(expectedObject);</span><br></pre></td></tr></table></figure></li>
<li><p>调用无访问权限的构造方法: 调用无访问权限的构造方法，可以使用PowerMock提供的Whitebox.invokeConstructor方法。</p>
</li>
<li><p>调用无权限访问的普通方法: 调用无访问权限的普通方法，可以使用PowerMock提供的Whitebox.invokeMethod方法。</p>
</li>
<li><p>附加匹配器<br>Mockito的AdditionalMatchers类提供了一些很少使用的参数匹配器，我们可以进行参数大于(gt)、小于(lt)、大于等于(geq)、小于等于(leq)等比较操作，也可以进行参数与(and)、或(or)、非(not)等逻辑计算等。<br><code>PowerMockito.when(mockList.get(AdditionalMatchers.geq(0))).thenReturn(expected);</code></p>
</li>
<li><p>Whitebox.setInternalState方法<br>  现在使用PowerMock进行单元测试时，可以采用Whitebox.setInternalState方法设置私有属性值: <code>Whitebox.setInternalState(Foo.class, &quot;FIELD_NAME&quot;, &quot;value&quot;);</code></p>
</li>
</ul>
<h3 id="mock静态方法"><a href="#mock静态方法" class="headerlink" title="mock静态方法"></a>mock静态方法</h3><ul>
<li>返回值为void： <code>PowerMockito.doNothing().when(FileUtils.class, &quot;writeStringToFile&quot;, any(File.class), anyString());</code></li>
<li><code>BDDMockito.given(FileUtils.readFileToString(eq(new File(file)))).willReturn(IOUtils.toString(getClass().getClassLoader().getResourceAsStream(&quot;test.json&quot;)));</code></li>
<li>前置初始化：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RunWith(PowerMockRunner.class)</span></span><br><span class="line">  <span class="meta">@PrepareForTest(&#123;FileUtils.class&#125;)</span></span><br><span class="line">  <span class="meta">@Before</span></span><br><span class="line">  &#123;</span><br><span class="line">     MockitoAnnotations.initMocks(<span class="built_in">this</span>)</span><br><span class="line">     PowerMockito.mockStatic(FileUtils.class);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="设置静态常量字段值"><a href="#设置静态常量字段值" class="headerlink" title="设置静态常量字段值"></a>设置静态常量字段值</h4><ul>
<li>有时候，我们需要对静态常量对象进行模拟，然后去验证是否执行了对应分支下的方法。比如：需要模拟Lombok的@Slf4j生成的log静态常量。但是，Whitebox.setInternalState方法和@InjectMocks注解并不支持设置静态常量，需要自己实现一个设置静态常量的方法：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">FieldHelper</span> &#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">setStaticFinalField</span><span class="params">(Class clazz, String fieldName, Object fieldValue)</span> <span class="keyword">throws</span> NoSuchFieldException, IllegalAccessException &#123;</span><br><span class="line"><span class="type">Field</span> <span class="variable">field</span> <span class="operator">=</span> clazz.getDeclaredField(fieldName);</span><br><span class="line">FieldUtils.removeFinalModifier(field);</span><br><span class="line">FieldUtils.writeStaticField(field, fieldValue, <span class="literal">true</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="使用Answer来生成期望的返回"><a href="#使用Answer来生成期望的返回" class="headerlink" title="使用Answer来生成期望的返回"></a>使用Answer来生成期望的返回</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">when(test.<span class="keyword">do</span>(anyList())).thenAnswer(</span><br><span class="line">            (Answer)invocation -&gt; &#123;</span><br><span class="line">                Object[] args = invocation.getArguments();</span><br><span class="line">                <span class="comment">//Object mock = invocation.getMock();</span></span><br><span class="line">                <span class="keyword">return</span> list.stream().filter(v -&gt; ((List&lt;Integer&gt;)args[<span class="number">0</span>]).contains(v.getAid())).collect(</span><br><span class="line">                    Collectors.toList());</span><br><span class="line">            &#125;);</span><br><span class="line">doReturn(resp).when(test).<span class="keyword">do</span>(argThat(<span class="keyword">new</span> <span class="title class_">ArgumentMatcher</span>&lt;List&lt;Long&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">matches</span><span class="params">(Object argument)</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> ((List&lt;Long&gt;)argument).size() == <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;));</span><br></pre></td></tr></table></figure>

<h3 id="verify使用"><a href="#verify使用" class="headerlink" title="verify使用"></a>verify使用</h3><ul>
<li>校验执行次数：Mockito提供vertify关键字来实现校验方法是否被调用，从未被调用never()，调用次数times(1), <code>verify(test).do(any());</code></li>
<li>验证私有方法<br><code>PowerMockito.verifyPrivate(userService).invoke(&quot;isSuperUser&quot;, userId);</code></li>
<li>验证方法调用并捕获参数值: Mockito提供ArgumentCaptor类来捕获参数值，通过调用forClass(Class clazz)方法来构建一个ArgumentCaptor对象，然后在验证方法调用时来捕获参数，最后获取到捕获的参数值并验证。如果一个方法有多个参数都要捕获并验证，那就需要创建多个ArgumentCaptor对象。</li>
<li>verify语句, 除times外，Mockito还支持atLeastOnce、atLeast、only、atMostOnce、atMost等次数验证器。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ListTest</span> &#123;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testAdd</span><span class="params">()</span> &#123;</span><br><span class="line">           List&lt;Integer&gt; mockedList = PowerMockito.mock(List.class);</span><br><span class="line">        PowerMockito.doReturn(<span class="literal">true</span>).when(mockedList).add(Mockito.anyInt());</span><br><span class="line">        mockedList.add(<span class="number">1</span>);</span><br><span class="line">        mockedList.add(<span class="number">2</span>);</span><br><span class="line">        mockedList.add(<span class="number">3</span>);</span><br><span class="line">        <span class="type">InOrder</span> <span class="variable">inOrder</span> <span class="operator">=</span> Mockito.inOrder(mockedList);</span><br><span class="line">        inOrder.verify(mockedList).add(<span class="number">1</span>);</span><br><span class="line">        inOrder.verify(mockedList).add(<span class="number">2</span>);</span><br><span class="line">        inOrder.verify(mockedList).add(<span class="number">3</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>验证调用参数</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ListTest</span> &#123;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testArgumentCaptor</span><span class="params">()</span> &#123;</span><br><span class="line">        Integer[] expecteds = <span class="keyword">new</span> <span class="title class_">Integer</span>[] &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line">        List&lt;Integer&gt; mockedList = PowerMockito.mock(List.class);</span><br><span class="line">        PowerMockito.doReturn(<span class="literal">true</span>).when(mockedList).add(Mockito.anyInt());</span><br><span class="line">        <span class="keyword">for</span> (Integer expected : expecteds) &#123;</span><br><span class="line">            mockedList.add(expected);</span><br><span class="line">        &#125;</span><br><span class="line">        ArgumentCaptor&lt;Integer&gt; argumentCaptor = ArgumentCaptor.forClass(Integer.class);</span><br><span class="line">        Mockito.verify(mockedList, Mockito.times(<span class="number">3</span>)).add(argumentCaptor.capture());</span><br><span class="line">        Integer[] actuals = argumentCaptor.getAllValues().toArray(<span class="keyword">new</span> <span class="title class_">Integer</span>[<span class="number">0</span>]);</span><br><span class="line">        Assert.assertArrayEquals(<span class="string">&quot;返回值不相等&quot;</span>, expecteds, actuals);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>确保验证完毕.<br>Mockito提供Mockito.verifyNoMoreInteractions方法，在所有验证方法之后可以使用此方法，以确保所有调用都得到验证。如果模拟对象上存在任何未验证的调用</li>
<li>验证静态方法。Mockito没有静态方法的验证方法，但是PowerMock提供这方面的支持。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RunWith(PowerMockRunner.class)</span></span><br><span class="line"><span class="meta">@PrepareForTest(&#123;StringUtils.class&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StringUtilsTest</span> &#123;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testVerifyStatic</span><span class="params">()</span> &#123;</span><br><span class="line">        PowerMockito.mockStatic(StringUtils.class);</span><br><span class="line">        <span class="type">String</span> <span class="variable">expected</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">        StringUtils.isEmpty(expected);</span><br><span class="line">        PowerMockito.verifyStatic(StringUtils.class);</span><br><span class="line">        ArgumentCaptor&lt;String&gt; argumentCaptor = ArgumentCaptor.forClass(String.class);</span><br><span class="line">        StringUtils.isEmpty(argumentCaptor.capture());</span><br><span class="line">        Assert.assertEquals(<span class="string">&quot;参数不相等&quot;</span>, argumentCaptor.getValue(), expected);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li><code>ReflectionTestUtils.setField(config, &quot;id&quot;, id);</code></li>
<li><code>Mockito.reset(test);</code></li>
<li><code>@VisibleForTesting</code></li>
<li>Mocking a method in the same test class using - Mockito:<a href="https://towardsdatascience.com/mocking-a-method-in-the-same-test-class-using-mockito-b8f997916109">https://towardsdatascience.com/mocking-a-method-in-the-same-test-class-using-mockito-b8f997916109</a></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PersonTest</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Test</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">playTest</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">Person</span> <span class="variable">person</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;name&quot;</span>, <span class="number">15</span>, <span class="string">&quot;23435678V&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">Person</span> <span class="variable">person1</span> <span class="operator">=</span> Mockito.spy(person);</span><br><span class="line"></span><br><span class="line">    Mockito.doReturn(<span class="literal">true</span>).when(person1).runInGround(<span class="string">&quot;ground&quot;</span>);</span><br><span class="line"></span><br><span class="line">    Assert.assertEquals(<span class="literal">true</span>, person1.isPlay());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一般不建议在同个类mock自己的方法，如果一定要，可以使用spy</p>
<ul>
<li>@Captor注解在字段级别创建参数捕获器。但是，在测试方法启动前，必须调用<code>MockitoAnnotations.openMocks(this)</code>进行初始化。</li>
<li>@PowerMockIgnore注解<br>为了解决使用PowerMock后，提示ClassLoader错误。</li>
</ul>
<h2 id="异常测试"><a href="#异常测试" class="headerlink" title="异常测试"></a>异常测试</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">   <span class="meta">@Rule</span></span><br><span class="line">   <span class="keyword">public</span> <span class="type">ExpectedException</span> <span class="variable">thrown</span> <span class="operator">=</span> ExpectedException.none();</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> &#123;</span><br><span class="line">       thrown.expect(<span class="keyword">new</span> <span class="title class_">BizExceptionCodeMatches</span>(ExceptionCodeEnum.FAIL_CODE.code()));</span><br><span class="line">       <span class="comment">//do</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test(expected = IndexOutOfBoundsException.class)</span></span><br></pre></td></tr></table></figure>

<h2 id="异步测试"><a href="#异步测试" class="headerlink" title="异步测试"></a>异步测试</h2><ul>
<li>异步系统的两种测试方法:<a href="https://mp.weixin.qq.com/s/ft7LDsLmJByxunPuqGUOuQ">https://mp.weixin.qq.com/s/ft7LDsLmJByxunPuqGUOuQ</a></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ExampleTest</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">Object</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Before</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="keyword">synchronized</span></span><br><span class="line">                (lock) &#123;</span><br><span class="line">                    <span class="comment">//获得锁</span></span><br><span class="line">                            monitorEvent();</span><br><span class="line">                    <span class="comment">//监听异步事件的到来</span></span><br><span class="line">                            lock.notifyAll();</span><br><span class="line">                    <span class="comment">//事件到达，释放锁</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span>  <span class="title function_">testAsynchronousMethod</span><span class="params">()</span> &#123;</span><br><span class="line">     callAsynchronousMethod();</span><br><span class="line">    <span class="comment">//调用异步方法，需要较长一段时间才能执行完，并触发事件通知</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 事件未到达时由于init已经获得了锁而阻塞，事件到达后因init中的锁释放而获得锁，</span></span><br><span class="line"><span class="comment">         * 此时异步任务已执行完成，可以放心的执行断言验证结果了</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">    <span class="keyword">synchronized</span></span><br><span class="line">        (lock) &#123;</span><br><span class="line">            assertTestResult();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="基于Spock的数据驱动测试"><a href="#基于Spock的数据驱动测试" class="headerlink" title="基于Spock的数据驱动测试"></a>基于Spock的数据驱动测试</h2><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SpockTest</span>  <span class="keyword">extends</span> <span class="title class_">Specification</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化</span></span><br><span class="line">    <span class="keyword">def</span> setupSpec() &#123;</span><br><span class="line">        println <span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;   setupSpec&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">def</span> setup() &#123;</span><br><span class="line">        println <span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;   setup&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">def</span> cleanup() &#123;</span><br><span class="line">        println <span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;   cleanup&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">def</span> cleanupSpec() &#123;</span><br><span class="line">        println <span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;   cleanupSpec&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="type">void</span> testAdd(<span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span> expect) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="symbol">expect:</span></span><br><span class="line">        <span class="keyword">assert</span> expect == a + b</span><br><span class="line"></span><br><span class="line">        <span class="symbol">where:</span></span><br><span class="line">        a | b | expect</span><br><span class="line">        <span class="number">1</span> | <span class="number">1</span> | <span class="number">2</span></span><br><span class="line">        <span class="number">2</span> | <span class="number">2</span> | <span class="number">4</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="使用rest-assured进行接口层测试"><a href="#使用rest-assured进行接口层测试" class="headerlink" title="使用rest-assured进行接口层测试"></a>使用rest-assured进行接口层测试</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RestAssuredMockMvcTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">before</span><span class="params">()</span>&#123;</span><br><span class="line">        RestAssured.registerParser(<span class="string">&quot;text/plain&quot;</span>, Parser.JSON);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">///https://github.com/rest-assured/rest-assured/wiki/Usage#spring-mock-mvc-module</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span>&#123;</span><br><span class="line"></span><br><span class="line">        given().</span><br><span class="line">                standaloneSetup(<span class="keyword">new</span> <span class="title class_">GreetingController</span>()).</span><br><span class="line">                param(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Johan&quot;</span>).</span><br><span class="line">                when().</span><br><span class="line">                get(<span class="string">&quot;/greeting&quot;</span>).</span><br><span class="line">                then().</span><br><span class="line">                statusCode(<span class="number">200</span>).</span><br><span class="line">                body(<span class="string">&quot;code&quot;</span>, equalTo(<span class="number">0</span>));</span><br><span class="line">                <span class="comment">//body(&quot;data&quot;, equalTo(&quot;Hello, Johan!&quot;));</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="事务测试"><a href="#事务测试" class="headerlink" title="事务测试"></a>事务测试</h2><ul>
<li>TODO</li>
</ul>
<h2 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h2><ul>
<li>单元测试的运行速度重要吗？<br>违背这个原则的典型反例，就是在单测中启动 Spring。</li>
<li>数据驱动测试（Data Driven Test）</li>
<li>mockito只能用于纯逻辑的验证，涉及事务那些还是没办法。单个类的单元测试逻辑正确不代表逻辑就覆盖全了，所以针对重要的接口需要单独集成测试用例</li>
<li>ContiPerf:: 更为优雅和方便的单元压力测试工具。</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul>
<li>[JDK11下Mock框架进化：从PowerMockito到Mockito Only]<a href="https://mp.weixin.qq.com/s/OsySrzocrMmJdk6C0_h60A">https://mp.weixin.qq.com/s/OsySrzocrMmJdk6C0_h60A</a></li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.baeldung.com/mockito-void-methods">https://www.baeldung.com/mockito-void-methods</a></li>
<li><a href="https://stackoverflow.com/questions/2276271/how-to-make-mock-to-void-methods-with-mockito">https://stackoverflow.com/questions/2276271/how-to-make-mock-to-void-methods-with-mockito</a></li>
<li><a href="https://github.com/eugenp/tutorials/tree/master/testing-modules/mockito">https://github.com/eugenp/tutorials/tree/master/testing-modules/mockito</a></li>
<li>&lt;&#x2F;<a href="https://stackoverflow.com/questions/9585323/how-do-i-mock-a-static-method-that-returns-void-with-powermock%3E">https://stackoverflow.com/questions/9585323/how-do-i-mock-a-static-method-that-returns-void-with-powermock&gt;</a></li>
<li><a href="https://www.cnblogs.com/Ming8006/p/6297333.html#c2.9">https://www.cnblogs.com/Ming8006/p/6297333.html#c2.9</a></li>
<li><a href="https://www.baeldung.com/mockito-annotations">https://www.baeldung.com/mockito-annotations</a></li>
<li><a href="https://javapointers.com/tutorial/difference-between-spy-and-mock-in-mockito/">https://javapointers.com/tutorial/difference-between-spy-and-mock-in-mockito/</a></li>
<li><a href="https://github.com/eugenp/tutorials/tree/master/testing-modules/mockito">https://github.com/eugenp/tutorials/tree/master/testing-modules/mockito</a></li>
<li><a href="https://github.com/rest-assured/rest-assured/wiki/Usage#spring-mock-mvc-module">https://github.com/rest-assured/rest-assured/wiki/Usage#spring-mock-mvc-module</a></li>
<li><a href="https://mp.weixin.qq.com/s/nIntjcrhgLQMiNo0XqPyyg">单元测试，只是测试吗？</a></li>
<li><a href="https://mp.weixin.qq.com/s/TjJ31yWTMwr4szz1JqtKcQ">单元测试难？来试试这些套路</a></li>
<li><a href="https://mp.weixin.qq.com/s/U1FArrcdFf3NKui6_Sf-qw">Spock单元测试框架以及在美团优选的实践</a></li>
<li>[阿里开源的 Mock 工具：TestableMock]</li>
<li><a href="https://mp.weixin.qq.com/s/hX_RIYs-nBnqVwdq5B4rhg">收藏！Java编程技巧之单元测试用例编写流程</a> – 这个很全了。。。</li>
<li><a href="https://stackoverflow.com/questions/30890011/whats-the-difference-between-mockito-matchers-isa-any-eq-and-same">https://stackoverflow.com/questions/30890011/whats-the-difference-between-mockito-matchers-isa-any-eq-and-same</a></li>
<li><a href="https://stackoverflow.com/questions/24295197/is-there-mockito-eq-matcher-for-varargs-array">https://stackoverflow.com/questions/24295197/is-there-mockito-eq-matcher-for-varargs-array</a></li>
<li><a href="https://stackoverflow.com/questions/5385161/powermock-testing-set-static-field-of-class">https://stackoverflow.com/questions/5385161/powermock-testing-set-static-field-of-class</a></li>
<li><a href="https://mp.weixin.qq.com/s/LSkTvpsTnBmdOB5nihkxng">Java单元测试技巧之PowerMock:</a></li>
</ul>
<hr>
<ul>
<li>转：分享一个观点：区分集成测试和单元测试的最本质差别在于，单元测试没有不可控外部依赖，也就是不会因为外部的原因导致测试失败。其它差别都不是能有效区分单元测试和集成测试的。</li>
</ul>
]]></content>
      <tags>
        <tag>unit-test</tag>
      </tags>
  </entry>
  <entry>
    <title>开发阶段checklist</title>
    <url>/2020/12/23/20201223-kai-fa-jie-duan-checklist/</url>
    <content><![CDATA[<ul>
<li>方案补全</li>
<li>索引复查； 主库从库查询检查；事务检查；写语句死锁风险检查<br>(更新语句要注意index_merge问题，避免死锁)</li>
<li>缓存策略</li>
<li>降级检查</li>
<li>异常捕捉处理</li>
<li>使用代码扫描工具</li>
<li>错误码整理</li>
<li>灰度策略；是否可回滚；是否可监控</li>
<li>日志补全</li>
<li>考虑异步操作</li>
<li>监控数据状态，比如某些任务表，监控失败率及时发现异常</li>
<li>git仓库包含多模块项目，要注意是否都发版了或注意改动范围，否则会导致代码已经合并到主干了，其他的项目却没上线，没能及时发现问题</li>
<li>测试用例<ul>
<li>注意实体转换的关键字段也需要覆盖用例，不然漏设置都无法察觉</li>
</ul>
</li>
<li>不能迷信单元测试，需要整条链路断点走一遍<ul>
<li>有时可能因为少传一个参数，参数是下一个方法用到的，局部的单元测试很难发现</li>
</ul>
</li>
<li>复查测试环境和生产环境的表结构是否一致<ul>
<li>有时为了方便快速在测试执行变更语句，而忘记同步到线上的变更SQL中</li>
</ul>
</li>
<li>上线申请事项记录</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>IT中的生活哲学</title>
    <url>/2021/07/06/20210706-it-zhong-de-sheng-huo-zhe-xue/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul>
<li>最近看完了《SRE：Google运维解密》之后，越来越觉得IT届的很多解决方案、流程设计、技术原理都来源于生活，或者说跟生活上的很多场景很类似。</li>
<li>本文的标题或许不太正确，并没字面上的包含关系，两者有时是相互借鉴的。</li>
<li>本文只是草稿，将持续记录个人认为的一些”生活哲学“。</li>
</ul>
<h2 id="生活哲学"><a href="#生活哲学" class="headerlink" title="生活哲学"></a>生活哲学</h2><h3 id="混沌工程"><a href="#混沌工程" class="headerlink" title="混沌工程"></a>混沌工程</h3><ol>
<li>在生活中总会出现一些小问题或事件，我们也会定时做一些演练，这样一旦发生大的突变事件时，我们才能更好的应对。</li>
</ol>
<h3 id="数据库落盘"><a href="#数据库落盘" class="headerlink" title="数据库落盘"></a>数据库落盘</h3><ol>
<li>为了保证数据不丢，在数据落盘时是现写日志，而不是直接修改数据行。这跟生活中点菜时记录客户的订单或者平常待办事件的备忘一个道理。既可以保证数据不丢，又可以提升处理时间。</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>方案设计时应该画什么图？</title>
    <url>/2021/07/30/20210730-fang-an-she-ji-shi-ying-gai-hua-shi-me-tu/</url>
    <content><![CDATA[<h2 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h2><ul>
<li>思维导图又叫脑图，使用一个中央关键词或想法引起形象化的构造和分类的想法，是一种结构化思维的树形发散图。</li>
</ul>
<h2 id="UML"><a href="#UML" class="headerlink" title="UML"></a>UML</h2><p><img src="/2021/07/30/20210730-fang-an-she-ji-shi-ying-gai-hua-shi-me-tu/UML%E5%88%86%E7%B1%BB.png"></p>
<ul>
<li>基本上大多情况，类图、时序图、活动图、状态图 已经够用。</li>
</ul>
<h3 id="用例图"><a href="#用例图" class="headerlink" title="用例图"></a>用例图</h3><ul>
<li>从用户角度描述系统功能，并指出各功能的操作者。</li>
<li>实际工作中，写功能说明，项目交接等情况可以使用。</li>
</ul>
<h3 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h3><ul>
<li>复杂数据结构，方便说明时可以使用</li>
<li>第一是领域模型设计，第二种是表实体关系设计。</li>
<li>组合 &gt; 聚合 &gt; 依赖 &gt; 关联</li>
</ul>
<h3 id="时序图（顺序图）"><a href="#时序图（顺序图）" class="headerlink" title="时序图（顺序图）"></a>时序图（顺序图）</h3><ul>
<li>按时间顺序描述系统之间的交互。</li>
<li>在方案设计中，涉及外部服务的调用、新增新组件（Redis、DB）或设计中涉及组件的关联较多等情况，应该有时序图。</li>
</ul>
<h3 id="协作图"><a href="#协作图" class="headerlink" title="协作图"></a>协作图</h3><ul>
<li>可视化的组织对象及相互作用（和时序图类似，后者强调时间顺序）</li>
<li>在方案设计中，需要描述多个对象之间的相互作用关系时，可以使用。</li>
</ul>
<h3 id="状态图-（状态机）"><a href="#状态图-（状态机）" class="headerlink" title="状态图 （状态机）"></a>状态图 （状态机）</h3><ul>
<li>描述类的对象所有可能的状态，以及事件发生时状态的转移条件</li>
<li>在方案设计中，涉及数据状态的（比如订单的支付状态，UGC的审核状态等）可以使用。</li>
<li>图不好表达双向状态转移，一般使用状态图+状态表来穷举描述状态变化。</li>
</ul>
<h3 id="活动图"><a href="#活动图" class="headerlink" title="活动图"></a>活动图</h3><ul>
<li>活动图和产品经理出的流程图差不多，都是动态图，活动图相对时序图关注更粗粒度的业务流程变化，其中一个活动可能包含多个时序。活动图可以通过纵向泳道和横向泳道划分，纵向泳道表示系统，横向泳道表示业务阶段。</li>
</ul>
<h3 id="组件图"><a href="#组件图" class="headerlink" title="组件图"></a>组件图</h3><ul>
<li>描述代码部件的物理结构及各部件之间的依赖关系，组件图有助于分析和理解部件之间的相互影响程度。</li>
<li>方案设计中，类似于架构设计，组件逻辑关系。</li>
</ul>
<h3 id="部署图"><a href="#部署图" class="headerlink" title="部署图"></a>部署图</h3><ul>
<li>定义系统中软硬件的物理体系结构。</li>
<li>灾备方案设计或新项目部署等场景，可以使用。</li>
</ul>
<h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><ul>
<li>架构图是为了抽象地表示软件系统的整体轮廓和各个组件之间的相互关系和约束边界，以及软件系统的物理部署和软件系统的演进方向的整体视图。</li>
</ul>
<p><img src="/2021/07/30/20210730-fang-an-she-ji-shi-ying-gai-hua-shi-me-tu/%E6%9E%B6%E6%9E%84%E5%9B%BE.png"></p>
<h3 id="业务架构"><a href="#业务架构" class="headerlink" title="业务架构"></a>业务架构</h3><ul>
<li>包括业务规划，业务模块、业务流程，对整个系统的业务进行拆分，对领域模型进行设计，把现实的业务转化成抽象对象。</li>
</ul>
<h3 id="应用架构"><a href="#应用架构" class="headerlink" title="应用架构"></a>应用架构</h3><ul>
<li>硬件到应用的抽象，包括抽象层和编程接口。应用架构和业务架构是相辅相成的关系。业务架构的每一部分都有应用架构。</li>
<li>应用作为独立可部署的单元，为系统划分了明确的边界，深刻影响系统功能组织、代码开发、部署和运维等各方面。应用架构定义系统有哪些应用、以及应用之间如何分工和合作。这里所谓应用就是各个逻辑模块或者子系统。</li>
<li>逻辑分层、对外接口协议、RPC调用协议等</li>
</ul>
<h3 id="数据架构"><a href="#数据架构" class="headerlink" title="数据架构"></a>数据架构</h3><ul>
<li>数据架构指导数据库的设计. 不仅仅要考虑开发中涉及到的数据库，实体模型，也要考虑物理架构中数据存储的设计。</li>
</ul>
<h3 id="代码架构"><a href="#代码架构" class="headerlink" title="代码架构"></a>代码架构</h3><ul>
<li>子系统代码架构主要为开发人员提供切实可行的指导，如果代码架构设计不足，就会造成影响全局的架构设计。比如公司内不同的开发团队使用不同的技术栈或者组件，结果公司整体架构设计就会失控。</li>
<li>框架、类库、配置、编码规范、代码分层等</li>
</ul>
<h3 id="技术架构"><a href="#技术架构" class="headerlink" title="技术架构"></a>技术架构</h3><ul>
<li>确定组成应用系统的实际运行组件（lvs，nginx，tomcat，php-fpm等），这些运行组件之间的关系，以及部署到硬件的策略。</li>
<li>平常所说的技术栈</li>
</ul>
<h3 id="部署拓扑架构图"><a href="#部署拓扑架构图" class="headerlink" title="部署拓扑架构图"></a>部署拓扑架构图</h3><ul>
<li>拓扑架构，包括架构部署了几个节点，节点之间的关系，服务器的高可用，网路接口和协议等，决定了应用如何运行，运行的性能，可维护性，可扩展性，是所有架构的基础。</li>
</ul>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="活动图与流程图的区别"><a href="#活动图与流程图的区别" class="headerlink" title="活动图与流程图的区别"></a>活动图与流程图的区别</h3><ol>
<li>流程图着重描述处理过程，它的主要控制结构是顺序、分支和循环，各个处理过程之间有严格的顺序和时间关系。而活动图描述的是对象活动的顺序关系所遵循的规则，它着重表现的是系统的行为，而非系统的处理过程。</li>
<li>活动图能够表示并发活动的情形，而流程图不行。</li>
<li>活动图是面向对象的，而流程图是面向过程的。</li>
</ol>
<h3 id="架构图的分类"><a href="#架构图的分类" class="headerlink" title="架构图的分类"></a>架构图的分类</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/rypUZQBQHI1A_JIfBNvI1A">画一手好的架构图是工程师进阶的开始</a></li>
</ul>
<h4 id="4-1视图"><a href="#4-1视图" class="headerlink" title="4+1视图"></a>4+1视图</h4><ol>
<li>场景视图</li>
<li>逻辑视图</li>
<li>物理视图</li>
<li>处理流程视图</li>
<li>开发视图</li>
</ol>
<h2 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h2><ol>
<li>需要对数据实体设计进行详细清晰的说明时，考虑使用类图；</li>
<li>新增功能涉及其他外部服务或组件的交互时，一般情况下都应该有时序图；</li>
<li>数据涉及多种状态且流转较复杂时，考虑使用状态图；</li>
<li>新服务搭建时，可以有部署图、组件图等；</li>
<li>较复杂的业务设计中，除了时序图，还可以考虑协作图、活动图等；</li>
<li>在需要对整体进行描述、规划时，可以使用架构图；</li>
<li>概要设计、详细设计</li>
</ol>
<ul>
<li><p>图的分类很多种，也没有统一的归类；参考不同图的意义，画出能清晰表达的图才是重点。</p>
</li>
<li><p>一份好的设计文档需要提供清晰的问题描述、整体的概要设计、涵盖各个细节的详细设计等。</p>
</li>
<li><p><a href="https://jishuin.proginn.com/p/763bfbd77085">怎么写出一份令人惊叹的设计文档？</a></p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/IG4HRjU-pOeaKBZ1ZRSiSQ">如何写出一篇好的技术方案？</a></p>
</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a href="https://blog.csdn.net/nangeali/article/details/48953587">UML九种图的分类</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/376084792">思维导图、UML图、架构图怎么画</a></li>
<li><a href="http://www.uml.org.cn/zjjs/202003061.asp?artid=23031">架构设计-谈谈架构</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/148670093">如何画好一张架构图？</a></li>
<li><a href="https://www.cnblogs.com/nizuimeiabc1/p/5909790.html">uml中活动图与流程图的区别</a></li>
<li><a href="https://mp.weixin.qq.com/s/oRrZIBLwjCRJG3xJcm5bdA">架构制图：工具与方法论</a> – 抽象，没怎么看懂</li>
<li><a href="https://mp.weixin.qq.com/s/QfVhutaw_iJy57v0VVatuA">我是怎么画架构图的？</a></li>
</ul>
]]></content>
      <tags>
        <tag>UML</tag>
        <tag>方案设计</tag>
        <tag>架构图</tag>
      </tags>
  </entry>
  <entry>
    <title>Java垃圾回收总结</title>
    <url>/2021/08/17/20210817-java-la-ji-hui-shou-zong-jie/</url>
    <content><![CDATA[<p><img src="/2021/08/17/20210817-java-la-ji-hui-shou-zong-jie/JVM_GC.png"></p>
<ul>
<li><p>Java中成熟的垃圾回收器有串行垃圾回收器、并行垃圾回收器、并发标记回收器（Concurrent Mark Sweep, CMS）、垃圾优先回收器（Garbage First，也称为G1）。在JDK 11中引入了一款新的垃圾回收器ZGC，在JDK 12中又引入了另一款新的垃圾回收器Shenandoah。虽然新的垃圾回收器不断地涌现，但是垃圾回收的基本算法变化并不大。简单来说，回收算法主要有复制、标记清除、标记压缩。JVM中不同的垃圾回收器都是基于这些基本算法实现的，不同的垃圾回收器区别在于：选择的算法不同，实现时后台线程采用的并行&#x2F;并发方式不同。</p>
</li>
<li><p>垃圾回收针对的是堆空间</p>
</li>
<li><p>目前垃圾回收算法主要有两类：</p>
<ul>
<li>引用计数法：在堆内存中分配对象时，会为对象分配一段额外的空间，这个空间用于维护一个计数器，如果对象增加了一个新的引用，则将增加计数器的值；如果一个引用关系失效，则减少计数器的值。当一个对象的计数器的值变为0，则说明该对象已经被废弃，处于不活跃状态，可以被回收。引用计数法需要解决循环依赖的问题</li>
<li>可达性分析法（也称为根引用分析法），基本思路就是通过根集合（root set）作为起始点，从这些节点出发，根据引用关系开始搜索，所经过的路径称为引用链，当一个对象没有被任何引用链访问到时，则证明此对象是不活跃的，可以被回收。在JVM中常见的根（root）有线程栈帧（thread frame，用于跟踪线程中活跃对象）、符号表（symbol dictionary）、字符串表（string table）、对象监视器（object synchronizer）、元数据对象（universe）等，这些根共同构成了根集合。</li>
</ul>
</li>
<li><p>JVM的垃圾回收采用了可达性分析法。垃圾回收算法也在不断地演化，按照不同的标准有不同的分类：</p>
<ul>
<li>从垃圾回收算法实现主要分为复制（copy）、标记清除（mark-sweep）和标记压缩（mark-compact）。</li>
<li>从回收方式上可以分为串行回收、并行回收、并发回收。</li>
<li>从内存管理上可以分为代管理和非代管理。</li>
</ul>
</li>
<li><p>JVM垃圾回收器基于分代管理和回收算法，结合回收的方式，实现了串行回收器、并行回收器、CMS、G1、ZGC和Shenandoah。</p>
</li>
<li><p>从程序执行方式的角度可以分为以下3类：</p>
<ul>
<li>串行执行：应用程序和垃圾回收器交替执行，垃圾回收器执行的时候应用程序暂停执行。串行执行指的是垃圾回收器有且仅有一个后台线程执行垃圾对象的识别和回收。</li>
<li>并行执行：应用程序和垃圾回收器交替执行，垃圾回收器执行的时候应用程序暂停执行。并行执行指的是垃圾回收器有多个后台线程执行垃圾对象的识别和回收，多个线程并行执行。</li>
<li>并发执行：应用程序和垃圾回收器同时运行，除了在某些必要的情况下垃圾回收器需要暂停应用程序的执行，其余的时候在应用程序运行的同时，垃圾回收器的后台线程也运行，如标识垃圾对象并回收垃圾对象所占的空间。<br><img src="/2021/08/17/20210817-java-la-ji-hui-shou-zong-jie/%E4%B8%8D%E5%90%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E7%9A%84%E5%B9%B6%E5%8F%91%E6%89%A7%E8%A1%8C.jpg"></li>
</ul>
</li>
<li><p>JKD7 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）</p>
</li>
<li><p>JKD8 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）</p>
</li>
<li><p>JKD9的默认垃圾回收器是G1</p>
</li>
<li><p>JDK15 正式删除CMS。JDK11就已经把CMS标记为过期。JDK9开始使用G1作为「默认」的垃圾回收器（JDK11中ZGC开始崭露头角）</p>
</li>
<li><p>Minor GC：又称新生代GC</p>
</li>
<li><p>Full GC：又称为Major GC或老年代GC</p>
</li>
</ul>
<p><img src="/2021/08/17/20210817-java-la-ji-hui-shou-zong-jie/%E5%85%B3%E4%BA%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E5%92%8C%E5%86%85%E5%AD%98%E5%A4%A7%E5%B0%8F%E7%9A%84%E5%8F%82%E8%80%83.png"></p>
<h3 id="垃圾收集器-种类"><a href="#垃圾收集器-种类" class="headerlink" title="垃圾收集器 种类"></a>垃圾收集器 种类</h3><ol>
<li>Serial 垃圾收集器（单线程、复制算法）[‘sɪriəl]</li>
<li>ParNew 垃圾收集器（Serial+多线程）【Serial收集器的多线程版本】</li>
<li>Parallel Scavenge 收集器（多线程复制算法、高效）[‘perə.lel] [‘skævəndʒ] 【“吞吐量优先”收集器】<br>自适应调节策略也是 ParallelScavenge 收集器与 ParNew 收集器的一个<br>重要区别。</li>
<li>Serial Old 收集器（单线程标记整理算法 ）【Serial收集器的老年代版本】</li>
<li>Parallel Old 收集器（多线程标记整理算法）【Parallel Scavenge收集器的老年代版本】</li>
<li>CMS 收集器（多线程标记清除算法） （Coucurrent Mark Sweep）【并发收集、低停顿】<br>最主要目标是获取最短垃圾回收停顿时间</li>
<li>G1 收集器 （Garbage-First）【面向服务端应用的垃圾收集器】</li>
</ol>
<ul>
<li><p>相比与 CMS 收集器，G1 收集器两个最突出的改进是：</p>
<ul>
<li>基于标记-整理算法，不产生内存碎片。</li>
<li>可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。</li>
</ul>
</li>
<li><p>CMS收集器的关注点尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器更关注系统的吞吐量（Throughput）。</p>
</li>
<li><p>CMS</p>
<ul>
<li>多线程，使用标记清除算法。并发收集，垃圾回收停顿时间短。但对CPU资源较敏感，CPU核心较少时会导致并发标记、并发清除时吞吐量骤减；无法处理浮动垃圾，老年代空间不能完全使用,需要预留一部分空间；由于基于标记清除算法，会产生大量空间碎片，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。</li>
</ul>
</li>
<li><p>G1</p>
<ul>
<li>多线程，从局部（两个Region之间）来看，是基于复制算法，从整体来看是基于标记整理算法，不会产生空间碎片，相比于CMS，可预测停顿时间。适合大堆，追求低停顿。</li>
</ul>
</li>
</ul>
<h3 id="JVM-GC参数"><a href="#JVM-GC参数" class="headerlink" title="JVM GC参数"></a>JVM GC参数</h3><ul>
<li>-XX:+UseSerialGC 开启此参数使用Serial &amp; Serial Old搜集器（client模式默认值）</li>
<li>-XX:+UseParNewGC 开启此参数使用ParNew &amp; Serial Old收集器</li>
<li>-XX:+UseParallelGC 开启此参数使用parallel scavenge &amp; Serial old收集器（server模式默认值）</li>
<li>-XX:+UseParallelOldGC 使用Parallel scavenge &amp; Parallel old收集器</li>
<li>-XX:+UseConcMarkSweepGC 使用ParNew &amp; CMS收集器 (使用ParNew + CMS + Serial Old的收集器组合进行垃圾回收，Serial Old作为CMS出现Concurrent Mode Failure失败后的后备收集器)</li>
<li>-XX:+UseG1GC</li>
</ul>
<h2 id="总结和适用场景"><a href="#总结和适用场景" class="headerlink" title="总结和适用场景"></a>总结和适用场景</h2><h3 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h3><ul>
<li>以获取最短回收停顿时间为目标的收集器。</li>
<li>CMS收集器工作时，GC工作线程与用户线程可以并发执行，以此来达到降低收集停顿时间的目的。</li>
<li>优点：并发收集、低停顿</li>
<li>CMS收集器之所以能够做到并发，根本原因在于采用基于“标记-清除”的算法并对算法过程进行了细粒度的分解。</li>
<li>CMS是老年代的垃圾回收器，在老年代分配不下的时候，触发CMS。</li>
<li>CMS的最大问题：CMS会使内存碎片化，老年代产生了很多的碎片，然后从年轻代过来的对象无法找到空间，造成了promotion failed。这时候，CMS既没有机会进行垃圾回收，又放不下新来的对象，在这种情况下，CMS会调用SerialOld来进行垃圾回收。这是一件很恐怖的事情。</li>
</ul>
<h3 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h3><ul>
<li>致力于在多CPU和大内存服务器上对垃圾回收提供软实时目标（soft real-time goal）和高吞吐量（high throughput）</li>
<li>G1适合8&#x2F;16G以上的内存使用</li>
<li>整体采用标记-整理算法，局部是通过是通过复制算法，不会产生内存碎片</li>
<li>G1垃圾收集器相对比其他收集器而言，最大的区别在于它取消了年轻代、老年代的物理划分，取而代之的是将堆划分为若干个区域（Region），这些区域中包含了有逻辑上的年轻代、老年代区域。这样做的好处就是，我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。</li>
<li>G1重新定义了堆空间，打破了原有的分代模型，将堆划分为一个个区域。这么做的目的是在进行收集时不必在全堆范围内进行，这是它最显著的特点。区域划分的好处就是带来了停顿时间可预测的收集模型：用户可以指定收集操作在多长时间内完成。即G1提供了接近实时的收集特性。</li>
<li>可预测的停顿</li>
<li>G1在逻辑上分代，在物理上不分代。G1引入了分而治之的思想，把内存分为一个一个的小块(region)。每个region逻辑上属于下面四种分代中的一种。</li>
<li>四种分代：<br>  a. Old区：老对象<br>  b .Survivor区：存活对象<br>  c. Eden区：新生对象<br>  d. Humongous区：大对象，如果这个对象特别大，可能会跨两个region。</li>
</ul>
<h3 id="ZGC"><a href="#ZGC" class="headerlink" title="ZGC"></a>ZGC</h3><ul>
<li>和G1类似，但ZGC的region的大小更加灵活和动态。zgc的region不会像G1那样在一开始就被划分为固定大小的region。</li>
<li>zgc的region核心亮点就是：动态。</li>
<li>停顿时间控制在10ms之内停顿时间不会因为堆变大而变长堆大小支持TB级。</li>
<li>ZGC在对象回收的吞吐量方面略逊于G1回收器（差距小于15%）</li>
<li><a href="https://mp.weixin.qq.com/s/BH7XAuSs4QsseIK-gMeD7A">Tencent Kona JDK11无暂停内存管理ZGC生产实践</a><ul>
<li>超大堆应用。超大堆（百 G 以上）下，CMS 或者 G1 如果发生 Full GC，停顿会在分钟级别，可能会造成业务的终端，强烈推荐使用 ZGC。</li>
<li>高 SLA 需求的应用。如对响应时间有 P999 时限要求的实时和软实时应用，此类应用无论堆大小，均推荐采用低停顿的 ZGC。</li>
</ul>
</li>
</ul>
<h3 id="Shenandoah"><a href="#Shenandoah" class="headerlink" title="Shenandoah"></a>Shenandoah</h3><ul>
<li>ZGC是Oracle JDK的。而Shenandoah只存在于OpenJDK中，因此使用时需注意你的JDK版本</li>
</ul>
<h3 id="新生代关系和组合关系"><a href="#新生代关系和组合关系" class="headerlink" title="新生代关系和组合关系"></a>新生代关系和组合关系</h3><ul>
<li>当 CMS回收失败时, 备选 Serial Old GC<br><img src="/2021/08/17/20210817-java-la-ji-hui-shou-zong-jie/HotSpot_%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8.png"></li>
</ul>
<p><img src="/2021/08/17/20210817-java-la-ji-hui-shou-zong-jie/G1_ZGC_Shenandoah.jpg"></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>新一代垃圾回收器ZGC设计与实现</li>
<li><a href="https://www.cnblogs.com/heyonggang/p/11718170.html">弄明白CMS和G1，就靠这一篇了</a></li>
<li><a href="https://blog.csdn.net/lyy9902/article/details/111504800">十种常见的垃圾回收器简介</a></li>
<li><a href="https://segmentfault.com/a/1190000021786789">Java 虚拟机系列三：垃圾收集器一网打尽，船新的 ZGC 和 Shenandoah 听说过吗</a></li>
<li>[JVM垃圾回收-垃圾回收的各种分类&amp; 垃圾收集器的组合关系(<a href="https://blog.csdn.net/qcl108/article/details/108875189">https://blog.csdn.net/qcl108/article/details/108875189</a>)</li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title>多IDC下微服务数据如何同步</title>
    <url>/2021/09/17/20210917-duo-idc-xia-wei-fu-wu-shu-ju-ru-he-tong-bu/</url>
    <content><![CDATA[<ul>
<li>最近公司出现跨机房调用redis超时导致的故障，借此简单记录一下微服务依赖的相关组件使用规范。</li>
</ul>
<h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><ol>
<li>每个服务的每个IDC对应一套Redis集群，原则上：<ul>
<li>不同服务不共用一套redis：避免业务相互影响，key定义冲突等问题；</li>
<li>不跨机房读写redis：避免不必要的时延等</li>
</ul>
</li>
<li>同个服务不同IDC的redis数据怎么同步？<ul>
<li>通过消息队列异地通知</li>
<li>如果一定要双写，异地IDC的同步尽量异步</li>
<li>如果一定要跨IDC读Redis，要控制好超时时间和降级</li>
</ul>
</li>
</ol>
<h3 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h3><ul>
<li>看具体业务选择合适的部署方式</li>
<li>数据不要求强一致，可覆盖的业务（比如用户基础信息），可以采用双活架构，MySQL使用双主架构，通过otter 同步数据</li>
<li>要求强一致，不可覆盖的业务（比如用户资产），可以采用主备架构，MySQL跨IDC搭建主从。</li>
</ul>
]]></content>
      <tags>
        <tag>微服务</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title>通过判断订单状态是否可以避免并发导致的问题？</title>
    <url>/2021/09/17/20210917-tong-guo-pan-duan-ding-dan-zhuang-tai-shi-fou-ke-yi-bi-mian-bing-fa-dao-zhi-de-wen-ti/</url>
    <content><![CDATA[<ul>
<li><p>首先重温一个问题：<a href="https://kingson4wu.github.io/2020/07/05/20200705-RPC%E5%8F%AF%E4%BB%A5%E5%92%8C%E4%BA%8B%E5%8A%A1%E7%BB%91%E5%AE%9A%E5%90%97/">RPC可以和事务绑定吗？</a></p>
</li>
<li><p>有以下业务场景：</p>
<ul>
<li>用户扣钱成功之后，可以玩一局游戏；如果用户没成功玩游戏，需要将已扣的钱退回给用户。</li>
</ul>
</li>
<li><p>服务架构：服务A(游戏服务)，服务B(用户资产服务)。</p>
</li>
<li><p>游戏订单状态：1（初始状态）；2（扣费成功）；3（退费成功）；4（不存在）</p>
</li>
<li><p>实现基本流程如下：</p>
</li>
<li><p>流程1:</p>
<pre>
玩游戏请求----------> 服务A
           [无事务] 
           [1.插入游戏订单（订单状态：1）]
           [2.RPC进行扣费]------------------------------------------------>服务B
           [3.更新游戏订单状态（1-> 2）(DB操作)] 
           （订单状态为2的可以参与游戏）</pre></li>
</ul>
<p></p>
<ul>
<li>流程2 （针对扣费成功但超时返回的情况）:<pre>
定时任务补偿----------> 服务A
           [无事务] 
           [1.查询订单状态为1的订单]
           [2.RPC查询扣费订单是否存在]------------------------------->服务B
           [3_1.不存在 -- 更新游戏订单状态（1-> 4）(DB操作)] 
           [3_2.存在 -- RPC取消扣费] ---------------------------------------->服务B
           [4.更新游戏订单状态（1-> 3）(DB操作)]</pre></li>
</ul>
<p></p>
<ul>
<li>流程1 和 流程2 在并发执行的时候会存在 用户退费成功但仍然可以玩游戏的问题：<ul>
<li>执行流程1中步骤2</li>
<li>执行流程2中步骤3_2</li>
<li>执行流程1中步骤3</li>
</ul>
</li>
</ul>
<h3 id="解决方案1"><a href="#解决方案1" class="headerlink" title="解决方案1"></a>解决方案1</h3><ul>
<li>加入订单时间校验：超过n分钟后的订单才允许退款（可以很大避免以上问题的发生，因为一个请求基本不可能执行几分钟还没结束）</li>
</ul>
<pre>
定时任务补偿----------> 服务A
             [无事务] 
             [0.查询订单状态为1的订单]
    新增判断 -   [1.查询订单创建时间是否超过n分钟，不满足暂不退款，中断执行] 
             [2.RPC查询扣费订单是否存在]------------------------------->服务B
             [3_1.不存在 -- 更新游戏订单状态（1-> 4）(DB操作)] 
             [3_2.存在 -- RPC取消扣费] ---------------------------------------->服务B
             [4.更新游戏订单状态（1-> 3）(DB操作)]
</pre>

<ul>
<li>该方案的缺点<ul>
<li>如果设置的订单退款超时时间太长，会导致用户被误扣的钱长时间未退款，引起投诉</li>
<li>设置足够合理的超时时间就一定能避免这个问题的发生了吗？不会存在极端情况，请求执行时间过长？</li>
</ul>
</li>
</ul>
<h3 id="解决方案2"><a href="#解决方案2" class="headerlink" title="解决方案2"></a>解决方案2</h3><ul>
<li>回到本文的标题。</li>
<li>通过和RPC绑事务的方式，也可以解决这个问题（不用通过配置时间差），本质是通过数据库锁的方式来解决。</li>
</ul>
<pre>
定时任务补偿----------> 服务A
             [1.查询订单状态为1的订单]
             [2.RPC查询扣费订单是否存在]------------------------------->服务B
             [3_1.不存在 -- 更新游戏订单状态（1-> 4）(DB操作)] 
             [新建事务] 
             [3_2.存在 -- 更新订单状态（1-> 3）(DB操作)]
             [ if （row = UPDATE order SET status = 3 WHERE status = 1) > 0 ]
             [4. RPC取消扣费] ---------------------------------------->服务B
             [5_1. 调用成功 - 提交事务]
             [5_1. 调用失败 - 异常回滚事务]
</pre>

<ol>
<li>扣费的时候，update order set status &#x3D; ’成功‘ where status &#x3D; ’初始状态‘ ；update raw &#x3D;&#x3D; 1 时， 执行RPC 冻结， 否则抛异常回滚事务</li>
<li>定时任务补偿退款的时候，update order set status &#x3D; ’取消冻结成功‘ where status &#x3D; ’初始状态‘ ；update row &#x3D;&#x3D; 1 时， 执行RPC 取消冻结， 否则抛异常回滚事务<ul>
<li>实际情况会比描述的复杂，因为status的最终值设置是根据RPC的结果来的，而不是一开始就能确定的；解决方案<ol>
<li>新加字段，统一 update 未执行 到 已执行， 通过新字段来判断是否执行db成功</li>
</ol>
</li>
</ul>
<ol start="2">
<li>select for update， 查的时候锁住该行数据</li>
<li>其他？</li>
</ol>
</li>
</ol>
<h3 id="解决方案3"><a href="#解决方案3" class="headerlink" title="解决方案3"></a>解决方案3</h3><ul>
<li>方案1和方案2的结合</li>
</ul>
<ol>
<li>1分钟后才执行流程2退费</li>
<li>流程2中【3_1】 和【4】绑事务，【4】变成update order set status&#x3D;3 where status&#x3D;1</li>
<li>流程1中【3】，变成 update order set status&#x3D;2 where status&#x3D;1</li>
</ol>
]]></content>
      <tags>
        <tag>RPC</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>CQRS笔记</title>
    <url>/2021/10/12/20211012-cqrs-bi-ji/</url>
    <content><![CDATA[<ul>
<li><a href="https://insights.thoughtworks.cn/backend-development-cqrs/">后端开发实践系列——简单可用的CQRS编码实践</a></li>
<li></li>
</ul>
<h3 id="个人认为："><a href="#个人认为：" class="headerlink" title="个人认为："></a>个人认为：</h3><ol>
<li>清除消息业务：写时只记录一个”清除时间”，读时只读取”清除时间”之后的数据，这是一种CQRS (避免写时操作太多数据，QPS不高，但单个请求需要操作多条数据的情况)</li>
<li>消息通知业务：写时只写在redis，定时任务从redis批量获取数据逐步写入的数据库（QPS高，但单个请求却不多，可以批量操作的情况）</li>
</ol>
]]></content>
      <tags>
        <tag>CQRS</tag>
      </tags>
  </entry>
  <entry>
    <title>raft学习笔记</title>
    <url>/2021/10/27/20211027-raft-xue-xi-bi-ji/</url>
    <content><![CDATA[<ul>
<li><p>Raft将共识问题分解三个子问题：</p>
<ol>
<li>Leader election 领导选举：有且仅有一个leader节点，如果leader宕机，通过选举机制选出新的leader；</li>
<li>Log replication 日志复制：leader从客户端接收数据更新&#x2F;删除请求，然后日志复制到follower节点，从而保证集群数据的一致性；</li>
<li>Safety 安全性：通过安全性原则来处理一些特殊case，保证Raft算法的完备性；</li>
</ol>
</li>
<li><p>所以，Raft算法核心流程可以归纳为：</p>
<ul>
<li>首先选出leader，leader节点负责接收外部的数据更新&#x2F;删除请求；</li>
<li>然后日志复制到其他follower节点，同时通过安全性的准则来保证整个日志复制的一致性；</li>
<li>如果遇到leader故障，followers会重新发起选举出新的leader；</li>
</ul>
</li>
<li><p>Raft规定：只有拥有最新提交日志的follower节点才有资格成为leader节点。具体做法：candidate竞选投票时会携带最新提交日志，follower会用自己的日志和candidate做比较。</p>
</li>
<li><p>因为日志提交需要超过半数的节点同意，所以针对日志同步落后的follower（还未同步完全部日志，导致落后于其他节点）在竞选leader的时候，肯定拿不到超过半数的票，也只有那些完成同步的才有可能获取超过半数的票成为leader。</p>
</li>
<li><p>日志更新判断方式是比较日志项的term和index：</p>
<ul>
<li>如果TermId不同，选择TermId最大的；</li>
<li>如果TermId相同，选择Index最大的；</li>
</ul>
</li>
<li><p>Raft对日志提交有额外安全机制：leader只能提交当前任期Term的日志，旧任期Term（以前的数据）只能通过当前任期Term的数据提交来间接完成提交。简单的说，日志提交有两个条件需要满足：</p>
<ul>
<li>当前任期；</li>
<li>复制结点超过半数；</li>
</ul>
</li>
<li><p>Raft在日志项提交上增加了限制：只有当前任期且复制超过半数的日志才可以提交。</p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/obnZm2Lhf_rKla2AxbrBlg">分布式一致性算法Raft</a></li>
<li><a href="https://mp.weixin.qq.com/s/zMnqOCUVvRLQuJUwvM3QRA">Raft 一致性算法论文中文译文</a></li>
</ul>
]]></content>
      <tags>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title>如何做数据库迁移</title>
    <url>/2022/01/14/20220114-ru-he-zuo-shu-ju-ku-qian-yi/</url>
    <content><![CDATA[<p>先抛出以下问题：<br>把MHA-1集群的Database-C 迁到 MHA-2 集群中，有没有简单高效的方案?<br><img src="/2022/01/14/20220114-ru-he-zuo-shu-ju-ku-qian-yi/migration.png"></p>
<hr>
<ul>
<li>方案1、在两个MHA集群，在建一套MHA3。MHA2的主作为MHA1的从？这样MH3切换的时候，应用服务就可以直接感知切到新库了；</li>
<li>方案2、先把C同步到2集群，然后做otter同步</li>
</ul>
<hr>
<ul>
<li>方案1： 存在的问题：<ul>
<li>中间再搞一套MHA，不是运维麻烦，而是多了一套中间库，可能会导致MHA的切换逻辑紊乱。</li>
</ul>
</li>
<li>方案2： <ul>
<li>业务方的服务要自行选择数据源进行切换 （流量低且数据一致性要求不高，考虑通过开关切换；否则需考虑停服等其他方案）</li>
<li>otter双向同步，业务最好同时只写一边（要注意旧库是否有自增主键；同步冲突策略设置，默认会冲突会同步中断）</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>数据迁移</tag>
      </tags>
  </entry>
  <entry>
    <title>nba选秀抽签具体是如何操作的？</title>
    <url>/2022/02/20/20220220-nba-xuan-xiu-chou-qian-ju-ti-shi-ru-he-cao-zuo-de/</url>
    <content><![CDATA[<p><a href="https://www.zhihu.com/question/52895544">nba选秀抽签具体是如何操作的？</a></p>
<ul>
<li>14个乒乓球分别贴上1-14数字，随机滚出4个，加起来是1001可能，其中11、12、13、14这个组合不算，剩下1000种可能。</li>
</ul>
<p><img src="/2022/02/20/20220220-nba-xuan-xiu-chou-qian-ju-ti-shi-ru-he-cao-zuo-de/nba%E9%80%89%E7%A7%80%E6%8A%BD%E7%AD%BE.jpg"></p>
<ul>
<li>闲来无事，使用Go粗暴模拟了一下</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;math/rand&quot;</span></span><br><span class="line">	<span class="string">&quot;sort&quot;</span></span><br><span class="line">	<span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">https://www.zhihu.com/question/52895544</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	n := <span class="number">14</span></span><br><span class="line">	m := <span class="number">4</span></span><br><span class="line">	nn := <span class="number">1</span></span><br><span class="line">	mm := <span class="number">1</span></span><br><span class="line">	nm := <span class="number">1</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= n; i++ &#123;</span><br><span class="line">		nn = nn * i</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= m; i++ &#123;</span><br><span class="line">		mm = mm * i</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= (n - m); i++ &#123;</span><br><span class="line">		nm = nm * i</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	all_result := <span class="built_in">make</span>([]<span class="type">string</span>, <span class="number">1000</span>)</span><br><span class="line">	all_result_map := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span>)</span><br><span class="line"></span><br><span class="line">	count := <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= <span class="number">11</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">for</span> j := i + <span class="number">1</span>; j &lt;= <span class="number">12</span>; j++ &#123;</span><br><span class="line">			<span class="keyword">for</span> k := j + <span class="number">1</span>; k &lt;= <span class="number">13</span>; k++ &#123;</span><br><span class="line">				<span class="keyword">for</span> l := k + <span class="number">1</span>; l &lt;= <span class="number">14</span>; l++ &#123;</span><br><span class="line">					<span class="comment">//fmt.Printf(&quot;%d -&gt; %d -&gt; %d -&gt; %d\n&quot;, i, j, k, l)</span></span><br><span class="line">					<span class="keyword">if</span> i == <span class="number">11</span> &amp;&amp; j == <span class="number">12</span> &amp;&amp; k == <span class="number">13</span> &amp;&amp; l == <span class="number">14</span> &#123;</span><br><span class="line">						<span class="keyword">continue</span></span><br><span class="line">					&#125;</span><br><span class="line">					all_result[count] = fmt.Sprintf(<span class="string">&quot;%d-%d-%d-%d&quot;</span>, i, j, k, l)</span><br><span class="line">					count++</span><br><span class="line">					all_result_map[fmt.Sprintf(<span class="string">&quot;%d-%d-%d-%d&quot;</span>, i, j, k, l)] = count</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	weight_arr := [<span class="number">14</span>]<span class="type">int</span>&#123;<span class="number">250</span>, <span class="number">199</span>, <span class="number">156</span>, <span class="number">119</span>, <span class="number">88</span>, <span class="number">63</span>, <span class="number">43</span>, <span class="number">28</span>, <span class="number">17</span>, <span class="number">11</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">5</span>&#125;</span><br><span class="line">	all_weight := <span class="number">0</span></span><br><span class="line">	source_map := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">int</span>]<span class="type">int</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> num, weight := <span class="keyword">range</span> weight_arr &#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; weight; i++ &#123;</span><br><span class="line">			source_map[i+<span class="number">1</span>+all_weight] = num + <span class="number">1</span></span><br><span class="line">		&#125;</span><br><span class="line">		all_weight = all_weight + weight</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	模拟前三顺位</span></span><br><span class="line"><span class="comment">	*/</span></span><br><span class="line">	all_hit_result := []<span class="type">int</span>&#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>&#125;</span><br><span class="line">	all_hit_result_second_round := []<span class="type">int</span>&#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>&#125;</span><br><span class="line">	all_hit_result_third_round := []<span class="type">int</span>&#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>&#125;</span><br><span class="line">	r := rand.New(rand.NewSource(time.Now().Unix()))</span><br><span class="line">	<span class="keyword">for</span> xx := <span class="number">0</span>; xx &lt; <span class="number">1000000</span>; xx++ &#123;</span><br><span class="line"></span><br><span class="line">		hit_map := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">int</span>]<span class="type">int</span>)</span><br><span class="line">		<span class="keyword">for</span> round := <span class="number">0</span>; round &lt; <span class="number">3</span>; round++ &#123;</span><br><span class="line">			all_ball := []<span class="type">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>&#125;</span><br><span class="line"></span><br><span class="line">			chosen_ball := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">4</span>)</span><br><span class="line">			<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">4</span>; i++ &#123;</span><br><span class="line"></span><br><span class="line">				hit := r.Intn(<span class="number">14</span> - i)</span><br><span class="line">				chosen_ball[i] = all_ball[hit]</span><br><span class="line">				index := hit</span><br><span class="line">				all_ball = <span class="built_in">append</span>(all_ball[:index], all_ball[index+<span class="number">1</span>:]...)</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			sort.Ints(chosen_ball)</span><br><span class="line">			result := fmt.Sprintf(<span class="string">&quot;%d-%d-%d-%d&quot;</span>, chosen_ball[<span class="number">0</span>], chosen_ball[<span class="number">1</span>], chosen_ball[<span class="number">2</span>], chosen_ball[<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> result == <span class="string">&quot;11-12-13-14&quot;</span> &#123;</span><br><span class="line">				round--</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			result_rank := source_map[all_result_map[result]]</span><br><span class="line"></span><br><span class="line">			value := hit_map[result_rank]</span><br><span class="line">			<span class="keyword">if</span> value == <span class="number">1</span> &#123;</span><br><span class="line">				round--</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> round == <span class="number">0</span> &#123;</span><br><span class="line">				all_hit_result[result_rank<span class="number">-1</span>]++</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> round == <span class="number">1</span> &#123;</span><br><span class="line">				all_hit_result_second_round[result_rank<span class="number">-1</span>]++</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> round == <span class="number">2</span> &#123;</span><br><span class="line">				all_hit_result_third_round[result_rank<span class="number">-1</span>]++</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			hit_map[result_rank] = <span class="number">1</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Println(<span class="string">&quot;第一轮&quot;</span>)</span><br><span class="line">	<span class="keyword">for</span> i, resut_hit := <span class="keyword">range</span> all_hit_result &#123;</span><br><span class="line">		fmt.Printf(<span class="string">&quot;%d -&gt; %d\n&quot;</span>, i+<span class="number">1</span>, resut_hit)</span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Println(<span class="string">&quot;第二轮&quot;</span>)</span><br><span class="line">	<span class="keyword">for</span> i, resut_hit := <span class="keyword">range</span> all_hit_result_second_round &#123;</span><br><span class="line">		fmt.Printf(<span class="string">&quot;%d -&gt; %d\n&quot;</span>, i+<span class="number">1</span>, resut_hit)</span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Println(<span class="string">&quot;第三轮&quot;</span>)</span><br><span class="line">	<span class="keyword">for</span> i, resut_hit := <span class="keyword">range</span> all_hit_result_third_round &#123;</span><br><span class="line">		fmt.Printf(<span class="string">&quot;%d -&gt; %d\n&quot;</span>, i+<span class="number">1</span>, resut_hit)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">		模拟100万次</span></span><br><span class="line"><span class="comment">		第一轮</span></span><br><span class="line"><span class="comment">	1 -&gt; 249512</span></span><br><span class="line"><span class="comment">	2 -&gt; 198836</span></span><br><span class="line"><span class="comment">	3 -&gt; 155714</span></span><br><span class="line"><span class="comment">	4 -&gt; 118849</span></span><br><span class="line"><span class="comment">	5 -&gt; 88395</span></span><br><span class="line"><span class="comment">	6 -&gt; 63352</span></span><br><span class="line"><span class="comment">	7 -&gt; 43285</span></span><br><span class="line"><span class="comment">	8 -&gt; 28016</span></span><br><span class="line"><span class="comment">	9 -&gt; 16892</span></span><br><span class="line"><span class="comment">	10 -&gt; 11093</span></span><br><span class="line"><span class="comment">	11 -&gt; 7894</span></span><br><span class="line"><span class="comment">	12 -&gt; 7004</span></span><br><span class="line"><span class="comment">	13 -&gt; 6100</span></span><br><span class="line"><span class="comment">	14 -&gt; 5058</span></span><br><span class="line"><span class="comment">	第二轮</span></span><br><span class="line"><span class="comment">	1 -&gt; 215647</span></span><br><span class="line"><span class="comment">	2 -&gt; 188267</span></span><br><span class="line"><span class="comment">	3 -&gt; 157704</span></span><br><span class="line"><span class="comment">	4 -&gt; 125474</span></span><br><span class="line"><span class="comment">	5 -&gt; 96543</span></span><br><span class="line"><span class="comment">	6 -&gt; 71033</span></span><br><span class="line"><span class="comment">	7 -&gt; 49195</span></span><br><span class="line"><span class="comment">	8 -&gt; 32360</span></span><br><span class="line"><span class="comment">	9 -&gt; 19803</span></span><br><span class="line"><span class="comment">	10 -&gt; 13185</span></span><br><span class="line"><span class="comment">	11 -&gt; 9521</span></span><br><span class="line"><span class="comment">	12 -&gt; 8252</span></span><br><span class="line"><span class="comment">	13 -&gt; 7031</span></span><br><span class="line"><span class="comment">	14 -&gt; 5985</span></span><br><span class="line"><span class="comment">	第三轮</span></span><br><span class="line"><span class="comment">	1 -&gt; 177455</span></span><br><span class="line"><span class="comment">	2 -&gt; 171603</span></span><br><span class="line"><span class="comment">	3 -&gt; 155736</span></span><br><span class="line"><span class="comment">	4 -&gt; 133323</span></span><br><span class="line"><span class="comment">	5 -&gt; 106458</span></span><br><span class="line"><span class="comment">	6 -&gt; 81193</span></span><br><span class="line"><span class="comment">	7 -&gt; 58185</span></span><br><span class="line"><span class="comment">	8 -&gt; 38863</span></span><br><span class="line"><span class="comment">	9 -&gt; 24146</span></span><br><span class="line"><span class="comment">	10 -&gt; 15550</span></span><br><span class="line"><span class="comment">	11 -&gt; 11508</span></span><br><span class="line"><span class="comment">	12 -&gt; 10064</span></span><br><span class="line"><span class="comment">	13 -&gt; 8634</span></span><br><span class="line"><span class="comment">	14 -&gt; 7282</span></span><br><span class="line"><span class="comment">	*/</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>NBA</tag>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>理解状态机原理及实践</title>
    <url>/2022/02/23/20220223-li-jie-zhuang-tai-ji-yuan-li-ji-shi-jian/</url>
    <content><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul>
<li><p>有限状态机FSM</p>
</li>
<li><p>描述事物的有限状态机模型的元素由以下组成：</p>
<ol>
<li>状态(State)：事物的状态，包括初始状态和所有事件触发后的状态</li>
<li>事件(Event)：触发状态变化或者保持原状态的事件</li>
<li>行为或转换(Action&#x2F;Transition)：执行状态转换的过程</li>
<li>检测器(Guard)：检测某种状态要转换成另一种状态的条件是否满足</li>
</ol>
</li>
<li><p><a href="https://www.jianshu.com/p/37281543f506">https://www.jianshu.com/p/37281543f506</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/46347732">深入浅出理解有限状态机</a></p>
</li>
<li><p>状态机的要素</p>
</li>
<li><p>状态机可归纳为4个要素，即现态、条件、动作、次态。“现态”和“条件”是因，“动作”和“次态”是果。详解如下：<br>  1. 现态：是指当前所处的状态。<br>  2. 条件：又称为“事件”。当一个条件被满足，将会触发一个动作，或者执行一次状态的迁移。<br>  3. 动作：条件满足后执行的动作。动作执行完毕后，可以迁移到新的状态，也可以仍旧保持原状态。动作不是必需的，当条件满足后，也可以不执行任何动作，直接迁移到新状态。<br>  4. 次态：条件满足后要迁往的新状态。“次态”是相对于“现态”而言的，“次态”一旦被激活，就转变成新的“现态”了。</p>
</li>
</ul>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><ol>
<li><p>定义状态</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">ProcessState</span> &#123;</span><br><span class="line"></span><br><span class="line">    INIT(<span class="number">0</span>, <span class="string">&quot;未开始&quot;</span>),</span><br><span class="line">    READY_ONE_SIDE(<span class="number">1</span>, <span class="string">&quot;一方准备完成&quot;</span>),</span><br><span class="line">    READY_ALL(<span class="number">2</span>, <span class="string">&quot;双方准备完成&quot;</span>),</span><br><span class="line">    CHAT(<span class="number">3</span>, <span class="string">&quot;发言完成&quot;</span>),</span><br><span class="line">    END(<span class="number">4</span>, <span class="string">&quot;结束&quot;</span>),</span><br><span class="line">    ;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> val;</span><br><span class="line">    <span class="keyword">private</span> String desc;</span><br><span class="line"></span><br><span class="line">    ProcessState(<span class="type">int</span> val, String desc) &#123;</span><br><span class="line">        <span class="built_in">this</span>.val = val;</span><br><span class="line">        <span class="built_in">this</span>.desc = desc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getVal</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>定义事件</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">ProcessEvent</span> &#123;</span><br><span class="line"></span><br><span class="line">    READY_ONE_SIDE(<span class="number">1</span>, <span class="string">&quot;一方准备&quot;</span>),</span><br><span class="line">		READY_ALL(<span class="number">2</span>, <span class="string">&quot;另一方准备&quot;</span>),</span><br><span class="line">		CHAT(<span class="number">3</span>, <span class="string">&quot;发言&quot;</span>),</span><br><span class="line">		FORBID_ALL(<span class="number">4</span>, <span class="string">&quot;全员禁言&quot;</span>),</span><br><span class="line">    ;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> Integer code;</span><br><span class="line">    <span class="keyword">private</span> String desc;</span><br><span class="line"></span><br><span class="line">    ProcessEvent(Integer code, String desc) &#123;</span><br><span class="line">        <span class="built_in">this</span>.code = code;</span><br><span class="line">        <span class="built_in">this</span>.desc = desc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">getCode</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> code;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>定义状态机</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProcessEventConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ProcessEvent event;</span><br><span class="line">    <span class="keyword">private</span> ProcessState fromState;</span><br><span class="line">    <span class="keyword">private</span> ProcessState toState;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">desc</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> fromState.getDesc() + <span class="string">&quot;_&quot;</span> + event.getDesc() + <span class="string">&quot;_&quot;</span> + toState.getDesc();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">List&lt;ProcessEventConfig&gt; configList = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(<span class="number">16</span>);</span><br><span class="line">configList.add(<span class="keyword">new</span> <span class="title class_">ProcessEventConfig</span>(ProcessEvent.READY_ONE_SIDE, ProcessState.INIT, ProcessState.READY_ONE_SIDE));</span><br><span class="line">configList.add(<span class="keyword">new</span> <span class="title class_">ProcessEventConfig</span>(ProcessEvent.READY_ALL, ProcessState.READY_ONE_SIDE, ProcessState.READY_ALL));</span><br><span class="line">configList.add(<span class="keyword">new</span> <span class="title class_">ProcessEventConfig</span>(ProcessEvent.CHAT, ProcessState.READY_ALL, ProcessState.CHAT));</span><br><span class="line">configList.add(<span class="keyword">new</span> <span class="title class_">ProcessEventConfig</span>(ProcessEvent.FORBID_ALL, ProcessState.CHAT, ProcessState.END));</span><br><span class="line"></span><br><span class="line">Map&lt;ProcessEvent, ProcessEventConfig&gt; eventResultStateConfigMap = <span class="keyword">new</span> <span class="title class_">EnumMap</span>&lt;&gt;(ProcessEvent.class);</span><br><span class="line"></span><br><span class="line">configList.forEach(eventConfig -&gt; eventResultStateConfigMap.put(eventConfig.getEvent(), eventConfig));</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>触发状态变化</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">fire</span><span class="params">(ProcessEvent event, Process process)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">ProcessEventConfig</span> <span class="variable">config</span> <span class="operator">=</span> Optional.ofNullable(eventResultStateConfigMap.get(event)).orElseThrow(() -&gt; ExceptionCodeEnum.AGRS_INVALID.newException(<span class="string">&quot;不存在该事件&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (process.getStatus() != config.getFromState().getVal()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        process.setRemark(config.desc());</span><br><span class="line">        process.setStatus(config.getToState().getVal());</span><br><span class="line"></span><br><span class="line">				<span class="comment">//DB改变状态</span></span><br><span class="line">				<span class="comment">/*update table set status=$&#123;status&#125; WHERE id=&#123;id&#125; AND status=$&#123;beforeStatus&#125;*/</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">suc</span> <span class="operator">=</span> processManager.updateStatus(process, config.getFromState().getVal());</span><br><span class="line">        <span class="keyword">if</span> (suc) &#123;</span><br><span class="line">               <span class="comment">//变更成功，业务逻辑    </span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> suc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <tags>
        <tag>状态机</tag>
        <tag>FSM</tag>
      </tags>
  </entry>
  <entry>
    <title>经典排序算法</title>
    <url>/2022/02/28/20220228-jing-dian-pai-xu-suan-fa/</url>
    <content><![CDATA[<ul>
<li><a href="https://www.cnblogs.com/onepixel/articles/7674659.html">十大经典排序算法（动图演示）</a></li>
</ul>
<h2 id="排序算法分类"><a href="#排序算法分类" class="headerlink" title="排序算法分类"></a>排序算法分类</h2><h3 id="一"><a href="#一" class="headerlink" title="(一)"></a>(一)</h3><ul>
<li>内部排序和外部排序</li>
</ul>
<h3 id="（二）"><a href="#（二）" class="headerlink" title="（二）"></a>（二）</h3><ol>
<li>比较类排序：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此也称为非线性时间比较类排序。(非线性时间)</li>
<li>非比较类排序：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此也称为线性时间非比较类排序。 (线性时间)</li>
</ol>
<h3 id="（三）"><a href="#（三）" class="headerlink" title="（三）"></a>（三）</h3><ol>
<li>非线性时间比较类排序：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此称为非线性时间比较类排序。如：快速排序、归并排序、堆排序、冒泡排序等。在排序的最终结果里，元素之间的次序依赖于它们之间的比较。每个数都必须和其他数进行比较，才能确定自己的位置。</li>
<li>线性时间非比较类排序：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此称为线性时间非比较类排序。如：计数排序、基数排序、桶排序。非比较排序是通过确定每个元素之前，应该有多少个元素来排序。针对数组arr，计算arr之前有多少个元素，则唯一确定了arr在排序后数组中的位置。</li>
</ol>
<h3 id="（四）"><a href="#（四）" class="headerlink" title="（四）"></a>（四）</h3><ol>
<li>比较类排序<ul>
<li>交换排序 (swap)<ul>
<li>冒泡排序 (bubble Sort) - 双重遍历，相邻元素两两比较交换</li>
<li>快速排序 (quick Sort) - 较复杂</li>
</ul>
</li>
<li>插入排序 (insertion)<ul>
<li>简单插入排序 (insertion sort) - 分左右两批，遍历有序列表，将无序的元素插入有序的列表</li>
<li>希尔排序 (shell sort) (缩小增量排序) - 较复杂</li>
</ul>
</li>
<li>选择排序 (selection)<ul>
<li>简单选择排序 (selection) - 双重遍历，每次找到最小的元素，最后和该趟遍历的第一个元素进行交换</li>
<li>堆排序 (heap sort)</li>
</ul>
</li>
<li>归并排序 (merge sort) - 即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 （递归）<ul>
<li>二路归并排序</li>
<li>多路归并排序</li>
</ul>
</li>
</ul>
</li>
<li>非比较类排序<ul>
<li>计数排序 (counting sort)</li>
<li>桶排序 (bucket sort)</li>
<li>基数排序 (radix sort)(分配排序)</li>
</ul>
</li>
</ol>
<h3 id="（五）"><a href="#（五）" class="headerlink" title="（五）"></a>（五）</h3><ul>
<li>算法复杂度</li>
</ul>
<table>
<thead>
<tr>
<th>排序方法</th>
<th>时间复杂度（平均）</th>
<th>时间复杂度（最坏）</th>
<th>时间复杂度（最好）</th>
<th>空间复杂度</th>
<th>稳定性</th>
</tr>
</thead>
<tbody><tr>
<td>冒泡排序</td>
<td>O(n^2)</td>
<td>O(n^2)</td>
<td>O(n)</td>
<td>O(1)</td>
<td>稳定</td>
</tr>
<tr>
<td>快速排序</td>
<td>O(nlog<sub>2</sub>n)</td>
<td>O(n^2)</td>
<td>O(nlog<sub>2</sub>n)</td>
<td>O(nlog<sub>2</sub>n)</td>
<td>不稳定</td>
</tr>
<tr>
<td>简单插入排序</td>
<td>O(n^2)</td>
<td>O(n^2)</td>
<td>O(n)</td>
<td>O(1)</td>
<td>稳定</td>
</tr>
<tr>
<td>希尔排序</td>
<td>O(n<sup>1.3</sup>)</td>
<td>O(n^2)</td>
<td>O(n)</td>
<td>O(1)</td>
<td>不稳定</td>
</tr>
<tr>
<td>简单选择排序</td>
<td>O(n^2)</td>
<td>O(n^2)</td>
<td>O(n^2)</td>
<td>O(1)</td>
<td>不稳定</td>
</tr>
<tr>
<td>堆排序</td>
<td>O(nlog<sub>2</sub>n)</td>
<td>O(nlog<sub>2</sub>n)</td>
<td>O(nlog<sub>2</sub>n)</td>
<td>O(1)</td>
<td>不稳定</td>
</tr>
<tr>
<td>归并排序</td>
<td>O(nlog<sub>2</sub>n)</td>
<td>O(nlog<sub>2</sub>n)</td>
<td>O(nlog<sub>2</sub>n)</td>
<td>O(n)</td>
<td>稳定</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>计数排序</td>
<td>O(n+k)</td>
<td>O(n+k)</td>
<td>O(n+k)</td>
<td>O(n+k)</td>
<td>稳定</td>
</tr>
<tr>
<td>桶排序</td>
<td>O(n+k)</td>
<td>O(n^2)</td>
<td>O(n)</td>
<td>O(n+k)</td>
<td>稳定</td>
</tr>
<tr>
<td>基数排序</td>
<td>O(n*k)</td>
<td>O(n*k)</td>
<td>O(n*k)</td>
<td>O(n+k)</td>
<td>稳定</td>
</tr>
</tbody></table>
<ul>
<li>相关概念：</li>
</ul>
<h4 id="1、时间复杂度"><a href="#1、时间复杂度" class="headerlink" title="1、时间复杂度"></a>1、时间复杂度</h4><ul>
<li>时间复杂度可以认为是对排序数据的总的操作次数。反映当n变化时，操作次数呈现什么规律。</li>
<li>常见的时间复杂度有：常数阶O(1),对数阶O(log2n),线性阶O(n), 线性对数阶O(nlog2n),平方阶O(n2)</li>
<li>时间复杂度O(1)：算法中语句执行次数为一个常数，则时间复杂度为O(1),</li>
</ul>
<h4 id="2、空间复杂度"><a href="#2、空间复杂度" class="headerlink" title="2、空间复杂度"></a>2、空间复杂度</h4><ul>
<li>空间复杂度是指算法在计算机内执行时所需存储空间的度量，它也是问题规模n的函数</li>
<li>空间复杂度O(1)：当一个算法的空间复杂度为一个常量，即不随被处理数据量n的大小而改变时，可表示为O(1)</li>
<li>空间复杂度O(log2N)：当一个算法的空间复杂度与以2为底的n的对数成正比时，可表示为O(log2n)， ax&#x3D;N，则x&#x3D;logaN，</li>
<li>空间复杂度O(n)：当一个算法的空间复杂度与n成线性比例关系时，可表示为0(n).</li>
</ul>
<h4 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><ul>
<li><a href="https://blog.csdn.net/qq_42907443/article/details/118329160">常见排序算法分类（排序算法，是算法的基石，你掌握多少？）</a></li>
<li>大O时间复杂度表示法：表示代码执行时间随数据规模增长的变化趋势，又称渐进时间复杂度</li>
<li>大O空间复杂度表示法：表示代码执行所占的内存空间随数据规模增长的变化趋势，又称渐进空间复杂度</li>
<li>复杂度分析法则<ul>
<li>单段代码，看循环的次数。</li>
<li>多段代码，看代码循环量级。</li>
<li>嵌套代码求乘积，比如递归和多重循环。</li>
<li>多个规模求加法，方法中并行的两个循环。</li>
</ul>
</li>
<li>常用的复杂度级别<ul>
<li>多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长，包括，O(1)(常数阶)、O(logn)(对数阶)、O(n)(线性阶)、O(nlogn)(线性对数阶)、O(n2)(平方阶)、O(n3)(立方阶)。</li>
<li>非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这列算法性能极差。包括，O(2^n)(指数阶)、O(n!)(阶乘阶)</li>
</ul>
</li>
</ul>
<h3 id="（六）"><a href="#（六）" class="headerlink" title="（六）"></a>（六）</h3><ul>
<li>稳定性</li>
<li>假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，A1&#x3D;A2，且A1在A2之前，而在排序后的序列中，A1仍在A2之前，则称这种排序算法是稳定的；否则称为不稳定的。</li>
<li>稳定也可以理解为一切皆在掌握中,元素的位置处在你在控制中.而不稳定算法有时就有点碰运气,随机的成分.当两元素相等时它们的位置在排序后可能仍然相同.但也可能不同.是未可知的.</li>
<li>不稳定排序算法<ul>
<li>快选希堆（快速排序，选择排序，希尔排序，堆排序）</li>
</ul>
</li>
</ul>
<h3 id="（七）"><a href="#（七）" class="headerlink" title="（七）"></a>（七）</h3><ul>
<li>算法总结</li>
<li>所需辅助空间最多：归并排序；<br>所需辅助空间最少：堆排序；<br>平均速度最快：快速排序；<br>不稳定：快速排序，希尔排序，堆排序。</li>
</ul>
<h4 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h4><ul>
<li>1、冒泡排序是一种用时间换空间的排序方法，n小时好</li>
<li>2、最坏情况是把顺序的排列变成逆序，或者把逆序的数列变成顺序，最差时间复杂度O(N^2)只是表示其操作次数的数量级</li>
<li>3、最好的情况是数据本来就有序，复杂度为O(n)</li>
</ul>
<h4 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h4><ul>
<li>1、n大时好，快速排序比较占用内存，内存随n的增大而增大，但却是效率高不稳定的排序算法。</li>
<li>2、划分之后一边是一个，一边是n-1个，<br>这种极端情况的时间复杂度就是O(N^2)</li>
<li>3、最好的情况是每次都能均匀的划分序列，O(N*log2N)</li>
</ul>
<h4 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h4><ul>
<li>1、n大时好，归并比较占用内存，内存随n的增大而增大，但却是效率高且稳定的排序算法。</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.cnblogs.com/onepixel/articles/7674659.html">十大经典排序算法（动图演示）</a></li>
<li><a href="https://blog.csdn.net/guidao13/article/details/86430483">Go语言经典排序算法实现</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/42586566">[算法总结] 十大排序算法</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/116046849">排序算法的稳定性</a></li>
<li><a href="https://www.cnblogs.com/xiaochun126/p/5086037.html">各种排序算法时间复杂度</a></li>
<li><a href="https://blog.csdn.net/qq_42907443/article/details/118329160">常见排序算法分类（排序算法，是算法的基石，你掌握多少？）</a> !!!</li>
</ul>
]]></content>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>关于轻量级分布式事件通知的思考</title>
    <url>/2022/03/12/20220312-guan-yu-qing-liang-ji-fen-bu-shi-shi-jian-tong-zhi-de-si-kao/</url>
    <content><![CDATA[<ul>
<li><p>有些业务场景，我们需要发出一个事件，通知到每一个进程。<br>比如数据变更，通知每个进程更新本地缓存。</p>
</li>
<li><p>使用MQ的话，以NSQ为例，将channel名设置为ip，那么每个进程都会收到这个事件；但是目前现在是k8s的时代，使用k8s部署进程，那么会导致某些旧ip的channel仍然存在，从而造成事件堆积。</p>
</li>
<li><p>redis虽然支持事件，但是微服务时代，不太建议每个业务的微服务都连同一个redis（同业务内的通知可以考虑）；使用一个公共的zk获取是一个可以考虑的方案，各服务启动时watch相应的节点即可。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>事件通知</tag>
      </tags>
  </entry>
  <entry>
    <title>轻量级微服务公共库设计</title>
    <url>/2022/03/22/20220322-qing-liang-ji-wei-fu-wu-gong-gong-ku-she-ji/</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><ul>
<li><p>减少拷贝代码，抽象公共业务组件和复用，快速支持产品需求</p>
</li>
<li><p>提升开发效率，增强排查能力</p>
</li>
<li><p>统一维护，提升代码质量，减少重复错误，提高服务可控性</p>
</li>
<li><p>公共嵌入式的sdk，其实有点类似一个轻量级的网关，sidecar，localproxy</p>
</li>
</ul>
<p><img src="/2022/03/22/20220322-qing-liang-ji-wei-fu-wu-gong-gong-ku-she-ji/common.png"></p>
<ul>
<li>为什么不使用API网关？<ol>
<li>有一定的机器和维护成本</li>
<li>跟组织架构有一定关系</li>
</ol>
</li>
</ul>
]]></content>
      <tags>
        <tag>公共库</tag>
        <tag>复用</tag>
        <tag>抽象</tag>
      </tags>
  </entry>
  <entry>
    <title>Scrum笔记</title>
    <url>/2022/04/02/20220402-scrum-bi-ji/</url>
    <content><![CDATA[<ul>
<li><p><a href="https://www.jianshu.com/p/7d3e2b86c737">https://www.jianshu.com/p/7d3e2b86c737</a></p>
</li>
<li><p>Scrum是一个过程框架，自上世纪90年代初以来，它就已经被应用于管理复杂产品的开发上。Scrum并不是构建产品的一种过程或一项技术</p>
</li>
<li><p>Scrum的精髓在于小团队。</p>
</li>
<li><p>Scrum基于经验过程控制理论，或称之为经验主义。</p>
</li>
<li><p>Scrum规定了4个正式事件，用于检视与适应上，这4个事件在Scrum事件章节中会加以描述：</p>
<p>Sprint计划会议<br>每日Scrum站会<br>Sprint评审会议<br>Sprint回顾会议</p>
</li>
<li><p>Scrum团队由一名产品负责人、开发团队和一名ScrumMaster组成。Scrum团队是跨职能的自组织团队。自组织团队自己选择如何以最好的方式来完成工作，而不是由团队之外的人来指导。跨职能团队拥有完成工作所需的全部技能，不需要依赖团队之外的人。Scrum的团队模式乃是设计用来提供最佳的灵活性、创造力和生产力。</p>
<p>Scrum团队迭代增量式地交付产品，籍此最大化获得反馈的机会。增量式交付“完成”的产品保证了一个可工作产品的潜在可用版本总是存在。</p>
</li>
<li><p>ScrumMaster服务于产品负责人<br>ScrumMaster服务于开发团队<br>ScrumMaster服务于组织</p>
</li>
<li><p>Scrum事件<br>Sprint除了本身作为一个事件以外，它还是其他所有事件的容器</p>
</li>
<li><p>Sprint是Scrum的核心，其长度(持续时间)为一个月或更短时间的限时，在这段时间内构建一个“完成的”、可用的和潜在可发布的产品增量。在整个开发过程期间，Sprint的长度通常保持一致。前一个Sprint结束后，新的下一个Sprint紧接着立即开始。</p>
<p>Sprint由Sprint计划会议、每日Scrum站会、开发工作、Sprint评审会议和Sprint回顾会议构成。</p>
</li>
<li><p>取消Sprint</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>Scrum</tag>
      </tags>
  </entry>
  <entry>
    <title>index_merge导致死锁问题</title>
    <url>/2022/04/03/20220403-index-merge-dao-zhi-si-suo-wen-ti/</url>
    <content><![CDATA[<h3 id="死锁日志"><a href="#死锁日志" class="headerlink" title="死锁日志"></a>死锁日志</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2021-09-02T17:29:31.339235+08:00 10137065 [Note] InnoDB: Transactions deadlock detected, dumping detailed information.</span><br><span class="line">2021-09-02T17:29:31.339268+08:00 10137065 [Note] InnoDB:</span><br><span class="line">*** (1) TRANSACTION:</span><br><span class="line"></span><br><span class="line">TRANSACTION 54557980, ACTIVE 0 sec fetching rows</span><br><span class="line">mysql tables in use 3, locked 3</span><br><span class="line">LOCK WAIT 9 lock struct(s), heap size 1136, 4 row lock(s)</span><br><span class="line">MySQL thread id 10137067, OS thread handle 140359751816960, query id 204818581 10.22.45.73 xxx_feed updating</span><br><span class="line">UPDATE `t_user_xxx_2` SET `end` = 1, `updateTime` = now() WHERE `userId`= 186435331 AND `type` = 2 AND `plotId`=1544270738147465267 AND `end` = 0</span><br><span class="line">2021-09-02T17:29:31.339367+08:00 10137065 [Note] InnoDB: *** (1) WAITING FOR THIS LOCK TO BE GRANTED:</span><br><span class="line"></span><br><span class="line">RECORD LOCKS space id 329 page no 2076 n bits 112 index PRIMARY of table `d_xxx_feed`.`t_user_xxx_2` trx id 54557980 lock_mode X locks rec but not gap waiting</span><br><span class="line">Record lock, heap no 33 PHYSICAL RECORD: n_fields 24; compact format; info bits 0</span><br><span class="line">0: len 8; hex 956e50cb8d06b6fb; asc nP ;;</span><br><span class="line">1: len 6; hex 000003307520; asc 0u ;;</span><br><span class="line">2: len 7; hex b0000000320110; asc 2 ;;</span><br><span class="line">3: len 8; hex 800000006f1fc602; asc o ;;</span><br><span class="line">4: len 4; hex 80000002; asc ;;</span><br><span class="line">5: len 24; hex e69c89e4b880e8b5b7e8818ae5a4a9e79a84e59097efbc9f; asc ;;</span><br><span class="line">6: len 2; hex 5b5d; asc [];;</span><br><span class="line">7: len 4; hex 80000000; asc ;;</span><br><span class="line">8: len 8; hex 8000000000000000; asc ;;</span><br><span class="line">9: len 8; hex 8000000000000000; asc ;;</span><br><span class="line">10: len 30; hex 7b22706c6f744964223a313534343236303535373335313230323637352c; asc &#123;&quot;plotId&quot;:1544260557351202675,; (total 233 bytes);</span><br><span class="line">11: len 12; hex e58f98e68081e4b8bbe4baba; asc ;;</span><br><span class="line">12: len 30; hex 68747470733a2f2f73747564696f696d67627373646c2e636c6f75642e6b; asc https://xxxximgbssdl.cloud.k; (total 75 bytes);</span><br><span class="line">13: len 4; hex 80000002; asc ;;</span><br><span class="line">14: len 8; hex 95551c4bc84d1d5b; asc U K M [;;</span><br><span class="line">15: len 0; hex ; asc ;;</span><br><span class="line">16: len 5; hex 99aa828508; asc ;;</span><br><span class="line">17: len 5; hex 99aa828507; asc ;;</span><br><span class="line">18: len 4; hex 80000000; asc ;;</span><br><span class="line">19: len 8; hex 956e50cb8990af73; asc nP s;;</span><br><span class="line">20: len 1; hex 80; asc ;;</span><br><span class="line">21: len 1; hex 80; asc ;;</span><br><span class="line">22: len 1; hex 81; asc ;;</span><br><span class="line">23: len 1; hex 80; asc ;;</span><br><span class="line"></span><br><span class="line">2021-09-02T17:29:31.342776+08:00 10137065 [Note] InnoDB: *** (2) TRANSACTION:</span><br><span class="line"></span><br><span class="line">TRANSACTION 54557981, ACTIVE 0 sec fetching rows, thread declared inside InnoDB 5000</span><br><span class="line">mysql tables in use 3, locked 3</span><br><span class="line">11 lock struct(s), heap size 1136, 7 row lock(s)</span><br><span class="line">MySQL thread id 10137065, OS thread handle 140359754024704, query id 204818583 10.31.45.123 xxx_feed updating</span><br><span class="line">UPDATE `t_user_xxxx_2` SET `end` = 1, `updateTime` = now() WHERE `userId`= 186435331 AND `type` = 2 AND `pId`=132434347351202675 AND `end` = 0</span><br><span class="line">2021-09-02T17:29:31.342867+08:00 10137065 [Note] InnoDB: *** (2) HOLDS THE LOCK(S):</span><br><span class="line"></span><br><span class="line">RECORD LOCKS space id 329 page no 2076 n bits 112 index PRIMARY of table `d_xxx_feed`.`t_user_xxx_2` trx id 54557981 lock_mode X locks rec but not gap</span><br><span class="line">Record lock, heap no 33 PHYSICAL RECORD: n_fields 24; compact format; info bits 0</span><br><span class="line">0: len 8; hex 956e50cb8d06b6fb; asc nP ;;</span><br><span class="line">1: len 6; hex 000003307520; asc 0u ;;</span><br><span class="line">2: len 7; hex b0000000320110; asc 2 ;;</span><br><span class="line">3: len 8; hex 800000006f1fc602; asc o ;;</span><br><span class="line">4: len 4; hex 80000002; asc ;;</span><br><span class="line">5: len 24; hex e69c89e4b880e8b5b7e8818ae5a4a9e79a84e59097efbc9f; asc ;;</span><br><span class="line">6: len 2; hex 5b5d; asc [];;</span><br><span class="line">7: len 4; hex 80000000; asc ;;</span><br><span class="line">8: len 8; hex 8000000000000000; asc ;;</span><br><span class="line">9: len 8; hex 8000000000000000; asc ;;</span><br><span class="line">10: len 30; hex 7b22706c6f744964223a313534343236303535373335313230323637352c; asc &#123;&quot;plotId&quot;:1544260557351202675,; (total 233 bytes);</span><br><span class="line">11: len 12; hex e58f98e68081e4b8bbe4baba; asc ;;</span><br><span class="line">12: len 30; hex 68747470733a2f2f73747564696f696d67627373646c2e636c6f75642e6b; asc https://xxximgbssdl.cloud.k; (total 75 bytes);</span><br><span class="line">13: len 4; hex 80000002; asc ;;</span><br><span class="line">14: len 8; hex 95551c4bc84d1d5b; asc U K M [;;</span><br><span class="line">15: len 0; hex ; asc ;;</span><br><span class="line">16: len 5; hex 99aa828508; asc ;;</span><br><span class="line">17: len 5; hex 99aa828507; asc ;;</span><br><span class="line">18: len 4; hex 80000000; asc ;;</span><br><span class="line">19: len 8; hex 956e50cb8990af73; asc nP s;;</span><br><span class="line">20: len 1; hex 80; asc ;;</span><br><span class="line">21: len 1; hex 80; asc ;;</span><br><span class="line">22: len 1; hex 81; asc ;;</span><br><span class="line">23: len 1; hex 80; asc ;;</span><br><span class="line"></span><br><span class="line">2021-09-02T17:29:31.345307+08:00 10137065 [Note] InnoDB: *** (2) WAITING FOR THIS LOCK TO BE GRANTED:</span><br><span class="line"></span><br><span class="line">RECORD LOCKS space id 329 page no 574 n bits 680 index idx_userId_type of table `d_xxx_feed`.`t_user_xxx_2` trx id 54557981 lock_mode X locks rec but not gap waiting</span><br><span class="line">Record lock, heap no 567 PHYSICAL RECORD: n_fields 3; compact format; info bits 0</span><br><span class="line">0: len 8; hex 800000006f1fc602; asc o ;;</span><br><span class="line">1: len 4; hex 80000002; asc ;;</span><br><span class="line">2: len 8; hex 956e50cb8d06b6fb; asc nP ;;</span><br><span class="line"></span><br><span class="line">2021-09-02T17:29:31.345666+08:00 10137065 [Note] InnoDB: *** WE ROLL BACK TRANSACTION (1)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="表结构"><a href="#表结构" class="headerlink" title="表结构"></a>表结构</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t_user_xxx_2` (</span><br><span class="line">`id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;xxId&#x27;</span>,</span><br><span class="line">`userId` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;发布人userId&#x27;</span>,</span><br><span class="line">`type` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;xxx&#x27;</span>,</span><br><span class="line">`content` <span class="type">varchar</span>(<span class="number">4000</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;文字&#x27;</span>,</span><br><span class="line">`images` <span class="type">varchar</span>(<span class="number">4000</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;图片&#x27;</span>,</span><br><span class="line">`deleted` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;1&#x27;</span> COMMENT <span class="string">&#x27;动态状态,0：新增，1：删除&#x27;</span>,</span><br><span class="line">`commentCnt` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;评论数&#x27;</span>,</span><br><span class="line">`likeCnt` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;点赞数&#x27;</span>,</span><br><span class="line">`contentExt` <span class="type">varchar</span>(<span class="number">4000</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;内容扩展&#x27;</span>,</span><br><span class="line">`nickname` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;昵称&#x27;</span>,</span><br><span class="line">`userLogo` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;头像&#x27;</span>,</span><br><span class="line">`userType` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;xxx&#x27;</span>,</span><br><span class="line">`rId` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;xxxid&#x27;</span>,</span><br><span class="line">`remark` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;备注&#x27;</span>,</span><br><span class="line">`createTime` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line">`updateTime` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;更新时间&#x27;</span>,</span><br><span class="line">`roomId` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;房间id&#x27;</span>,</span><br><span class="line">`pId` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;xxid&#x27;</span>,</span><br><span class="line">`<span class="keyword">end</span>` tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;是否结束&#x27;</span>,</span><br><span class="line">`hideType` tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;隐藏类型：xxx&#x27;</span>,</span><br><span class="line">`status` tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;1&#x27;</span> COMMENT <span class="string">&#x27;审核状态：0审核中，1审核通过，2审核不通过&#x27;</span>,</span><br><span class="line">`contentStatus` tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;0不违规，1违规&#x27;</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">KEY `idx_userId_type` (`userId`,`type`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">KEY `idx_createTime` (`createTime`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">KEY `idx_type` (`type`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">KEY `idx_user_rId` (`userId`,`rId`) <span class="keyword">USING</span> BTREE,</span><br><span class="line">KEY `idx_pId` (`pId`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 COMMENT<span class="operator">=</span><span class="string">&#x27;以动态发布者userId模10分表&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="四种类型的行锁"><a href="#四种类型的行锁" class="headerlink" title="四种类型的行锁"></a>四种类型的行锁</h3><ul>
<li>记录锁，间隙锁，Next-key 锁和插入意向锁。这四种锁对应的死锁日志各不相同，如下：<ul>
<li>记录锁（LOCK_REC_NOT_GAP）: <code>lock_mode X locks rec but not gap</code></li>
<li>间隙锁（LOCK_GAP）: <code>lock_mode X locks gap before rec</code></li>
<li>Next-key 锁（LOCK_ORNIDARY）: <code>lock_mode X</code></li>
<li>插入意向锁（LOCK_INSERT_INTENTION）: <code>lock_mode X locks gap before rec insert intention</code></li>
</ul>
</li>
</ul>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><ul>
<li>通过explain分析<code>explain SELECT 1 FROM t_user_xxx_2 WHERE userId = xxxx AND type = 2 AND pId = 434444</code> 得出以下</li>
<li>语句的type是index_merge，Extra的信息是Using intersect(idx_user_type,idx_pId)，执行计划走了index_merge优化，单个语句通过两个索引(idx_userId_type,idx_pId)来提取记录集合并取交集获得最终结果集。</li>
</ul>
<h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><ol>
<li>关闭：index_merge_intersection&#x3D;off （解决思路：直接关闭MySQL的优化）</li>
<li>删掉多余的索引idx_pId（解决思路：建立合理的索引）— 此案例中，根据业务实际情况，使用该方案解决</li>
<li>先查，再使用主键或唯一索引来更新（解决思路：缩小索引范围） （推荐）</li>
<li>强制走idx_userId_type 索引</li>
<li>添加userId + type + pId的组合索引，这样就可以避免掉index merge</li>
</ol>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li>[MySQL update use index merge(Using intersect) increase chances for deadlock]<br>(<a href="https://developer.aliyun.com/article/8963">https://developer.aliyun.com/article/8963</a>)</li>
<li><a href="https://dev.mysql.com/doc/refman/8.0/en/index-merge-optimization.html#index-merge-intersection">https://dev.mysql.com/doc/refman/8.0/en/index-merge-optimization.html#index-merge-intersection</a></li>
</ul>
]]></content>
      <tags>
        <tag>index_merge</tag>
        <tag>dead_lock</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>后端技术思维导图</title>
    <url>/2022/04/29/20220429-hou-duan-ji-zhu-si-wei-dao-tu/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>FFmpeg笔记</title>
    <url>/2022/05/05/20220505-ffmpeg-bi-ji/</url>
    <content><![CDATA[<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&mid=2247491924&idx=1&sn=0fdd9e7a0d290158bf6c3d76725ea943&chksm=e92adc5bde5d554">图片拼接成特效视频</a><ul>
<li>FFmpeg</li>
<li>MediaCodec</li>
<li>OpenGL</li>
</ul>
</li>
</ul>
<h2 id="JavaCV"><a href="#JavaCV" class="headerlink" title="JavaCV"></a>JavaCV</h2><ul>
<li><p>JavaCV是对各种常用计算机视觉库的封装后的一组jar包，其中封装了ffmpeg、OpenCV、libdc1394、OpenKinect、videoInput和ARToolKitPlus等计算机视觉编程人员常用库的接口，可以通过其中的utility类方便的在包括Android在内的Java平台上调用这些接口。其中使用最多的应该就是FFmpeg了。</p>
</li>
<li><p>找出人脸，同时比较两张图片中的人脸相似度：<a href="https://blog.csdn.net/nicebooks/article/details/8175002">https://blog.csdn.net/nicebooks/article/details/8175002</a>,<br><a href="https://www.cnblogs.com/webRobot/p/6216994.html">https://www.cnblogs.com/webRobot/p/6216994.html</a>,<br><a href="https://blog.csdn.net/u014365862/article/details/48212891">https://blog.csdn.net/u014365862/article/details/48212891</a></p>
</li>
<li><p><a href="https://blog.csdn.net/xxxlllbbb/article/details/104819683">基于JavaCV技术实现RTMP推流和拉流功能</a></p>
</li>
</ul>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><ul>
<li><p>FFmpeg常用命令汇总+文档汇总：<a href="https://www.jianshu.com/p/f07f0be088d0">https://www.jianshu.com/p/f07f0be088d0</a></p>
</li>
<li><p>ffplay命令播放媒体</p>
<ul>
<li>播放本地文件 : <code>ffplay -window_title &quot;test time&quot; -ss 2 -t 10 -autoexit test.mp4</code></li>
<li>播放网络流: <code>ffplay -window_title &quot;rtmp stream&quot; rtmp://202.69.69.180:443/webcast/bshdlive-pc</code></li>
</ul>
</li>
</ul>
<h3 id="怎样快速的转换FLV视频为MP4格式"><a href="#怎样快速的转换FLV视频为MP4格式" class="headerlink" title="怎样快速的转换FLV视频为MP4格式"></a>怎样快速的转换FLV视频为MP4格式</h3><ul>
<li><p><a href="https://www.zhihu.com/question/65224766/answer/252226264">https://www.zhihu.com/question/65224766/answer/252226264</a></p>
</li>
<li><p>单个文件，就用如下命令：<br><code>ffmpeg -i &quot;input.flv&quot; -c copy &quot;output.mp4&quot;</code></p>
</li>
<li><p>如果是整个文件夹中的所有flv文件需要批量转成mp4，那么使用以下命令：<br><code>for %i in (*.flv) do ffmpeg -i &quot;%i&quot; -c copy &quot;%~ni.mp4&quot;</code></p>
</li>
<li><p>flv&#x2F;mp4文件的合并有时候通过某些下载工具得到的flv&#x2F;mp4文件是多段的，比如B站视频上下载一集40分钟左右的纪录片实际上是8个小片段，这时候可以新建一个txt文本文件，把你需要合并的flv&#x2F;mp4和这个txt放在同一个文件夹里面，然后把需要合并的flv&#x2F;mp4文件的名字按照顺序写在txt文件中并保存，格式如下：</p>
<pre>
file '【国家地理】COSMOS系列【熟肉-对后十一集修复】 (P10. 气候变化)[00].mp4'
file '【国家地理】COSMOS系列【熟肉-对后十一集修复】 (P10. 气候变化)[01].mp4'
file '【国家地理】COSMOS系列【熟肉-对后十一集修复】 (P10. 气候变化)[02].mp4'
file '【国家地理】COSMOS系列【熟肉-对后十一集修复】 (P10. 气候变化)[03].mp4'
file '【国家地理】COSMOS系列【熟肉-对后十一集修复】 (P10. 气候变化)[04].mp4'
file '【国家地理】COSMOS系列【熟肉-对后十一集修复】 (P10. 气候变化)[05].mp4'
file '【国家地理】COSMOS系列【熟肉-对后十一集修复】 (P10. 气候变化)[06].mp4'
file '【国家地理】COSMOS系列【熟肉-对后十一集修复】 (P10. 气候变化)[07].mp4'
</pre>
<p><code>ffmpeg -f concat -safe 0 -i files.txt -c copy output.mp4</code>即可得到一个完整的mp4文件</p>
</li>
</ul>
<h3 id="rtmp推流"><a href="#rtmp推流" class="headerlink" title="rtmp推流"></a>rtmp推流</h3><ul>
<li><code>ffmpeg -re -i 1.mp4 -c copy -f flv rtmp://127.0.0.1:1935/live/movie</code></li>
<li><a href="https://juejin.cn/post/690947934664628634ing3">如何开发一款H5小程序直播</a></li>
<li><a href="https://www.jianshu.com/p/c141fc7881e7">利用ffmpeg实现rtmp推流</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/73984438">ffmpeg的RTMP推流</a></li>
</ul>
<h2 id="名词概念"><a href="#名词概念" class="headerlink" title="名词概念"></a>名词概念</h2><ul>
<li>FFmpeg的名称来自MPEG视频编码标准，前面的“FF”代表“Fast Forward”</li>
<li>解复用(demux)，表示从一路输入中分离出多路流(视频、音频、字幕等)。<br>把不同的流从某种容器中解析出来，这种行为叫做解复用(demux)</li>
<li>编解码器(Codec)：以帧为单位实现压缩数据和原始数据之间的相互转换的</li>
<li>复用(mux)：把不同的流按照某种容器的规则放入容器，这种行为叫做复用（mux）</li>
<li>码率和帧率是视频文件的最重要的基本特征，对于他们的特有设置会决定视频质量。如果我们知道码率和时长那么可以很容易计算出输出文件的大小。</li>
<li>帧率：帧率也叫帧频率，帧率是视频文件中每一秒的帧数，肉眼想看到连续移动图像至少需要15帧。</li>
<li>码率：比特率(也叫码率，数据率)是一个确定整体视频&#x2F;音频质量的参数，秒为单位处理的位数，码率和视频质量成正比，在视频文件中中比特率用bps来表达。</li>
<li><a href="https://zhuanlan.zhihu.com/p/117523405">https://zhuanlan.zhihu.com/p/117523405</a></li>
</ul>
<h3 id="FFMPEG-中I帧、B帧、P帧、PTS、DTS"><a href="#FFMPEG-中I帧、B帧、P帧、PTS、DTS" class="headerlink" title="FFMPEG 中I帧、B帧、P帧、PTS、DTS"></a>FFMPEG 中I帧、B帧、P帧、PTS、DTS</h3><ul>
<li><a href="https://www.jianshu.com/p/2cfc19b4938c">https://www.jianshu.com/p/2cfc19b4938c</a></li>
<li>I帧表示关键帧，又称intra picture，I帧画面完整保留，解码时只需要本帧数据就可以完成（因为包含完整画面）。</li>
<li>P帧前向预测编码帧 又称predictive-frame，表示的是这一帧跟之前的一个关键帧（或P帧）的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。（也就是差别帧，P帧没有完整画面数据，只有与前一帧的画面差别的数据）</li>
<li>B帧双向预测内插编码帧 又称bi-directional interpolated prediction frame，是双向差别帧，也就是B帧记录的是本帧与前后帧的差别，换言之，要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是解码时CPU会比较累。</li>
<li>因此，I帧和P帧的解码算法比较简单，资源占用也比较少，I帧只要自己完成就行了，至于P帧，也只需要解码器把前一个画面缓存一下，遇到P帧时就使用之前缓存的画面就行。如果视频流只有I和P，解码器可以不管后面的数据，边读边解码，线性前进。如果视频流还有B帧，则需要缓存前面和当前的视频帧，待后面视频帧获得后，再解码。</li>
</ul>
<h3 id="ffmpeg-x2F-ffplay-x2F-ffprobe区别"><a href="#ffmpeg-x2F-ffplay-x2F-ffprobe区别" class="headerlink" title="ffmpeg&#x2F;ffplay&#x2F;ffprobe区别"></a>ffmpeg&#x2F;ffplay&#x2F;ffprobe区别</h3><ul>
<li>ffmpeg:<br>Hyper fast Audio and Video encoder<br>超快音视频编码器（类似爱剪辑）</li>
<li>ffplay:<br>Simple media player<br>简单媒体播放器</li>
<li>ffprobe:<br>Simple multimedia streams analyzer<br>简单多媒体流分析器</li>
</ul>
<h2 id="播放软件推荐：VLC"><a href="#播放软件推荐：VLC" class="headerlink" title="播放软件推荐：VLC"></a>播放软件推荐：VLC</h2><ul>
<li>要播放视频直播流，或者测试一个直播视频地址是否可以使用。这里推荐 VLC 媒体播放器。功能强大且跨平台。支持 Windows、Mac OS、Linux、Android、iOS。<br>官网地址：<a href="http://www.videolan.org/">http://www.videolan.org/</a><br>打开播放器，选择菜单中“媒体”-&gt;“打开网络串流…”。在弹出页面中填入视频地址即可。</li>
</ul>
<hr>
<ul>
<li>windows 录屏软件Captura – TODO</li>
<li>FFmpeg最全教程：<a href="https://cloud.tencent.com/developer/article/1773248">https://cloud.tencent.com/developer/article/1773248</a></li>
<li>FFmpeg jar 库，无需安装 –TODO javacv</li>
<li>​ffprobe 是一个多媒体流分析工具。它从多媒体流中收集信息，并且以人类和机器可读的形式打印出来。它可以用来检测多媒体流的容器类型，以及每一个多媒体流的格式和类型。它可以作为一个独立的应用来使用，也可以结合文本过滤器执行更复杂的处理。</li>
</ul>
]]></content>
      <tags>
        <tag>FFmpeg</tag>
      </tags>
  </entry>
  <entry>
    <title>直播流媒体协议——笔记</title>
    <url>/2022/05/05/20220505-zhi-bo-xie-yi-bi-ji/</url>
    <content><![CDATA[<ul>
<li>RTMP 协议:<a href="https://www.jianshu.com/p/d511d59b185c">https://www.jianshu.com/p/d511d59b185c</a></li>
<li>RTMP、RTSP、HTTP视频协议详解（附：直播流地址、播放软件）:<a href="https://www.hangge.com/blog/cache/detail_1325.html">https://www.hangge.com/blog/cache/detail_1325.html</a></li>
<li>RTMP、HTTP-FLV、HLS，你了解常见的三大直播协议吗：<a href="https://zhuanlan.zhihu.com/p/48100533">https://zhuanlan.zhihu.com/p/48100533</a></li>
<li><a href="https://www.cnblogs.com/stringarray/p/13027230.html">网络协议-流媒体协议 </a></li>
</ul>
<hr>
<ul>
<li><a href="https://www.cnblogs.com/stringarray/p/13027230.html">https://www.cnblogs.com/stringarray/p/13027230.html</a></li>
</ul>
<hr>
<ul>
<li><a href="https://cloud.tencent.com/document/product/267/7968">https://cloud.tencent.com/document/product/267/7968</a></li>
</ul>
<h2 id="推流协议"><a href="#推流协议" class="headerlink" title="推流协议"></a>推流协议</h2><ul>
<li>虽然 RTMP 在直播领域不是特别流行，但是在推流服务，也就是“主播”到“服务器”这个方向上 RTMP 居于主导地位，目前国内的视频云服务都是以 RTMP 为主要推流协议（由于直播 SDK 第一个功能模块就是主播推流，所以也被称为是 RTMP SDK）。</li>
</ul>
<h2 id="播放协议"><a href="#播放协议" class="headerlink" title="播放协议"></a>播放协议</h2><ul>
<li><p>目前常见的直播协议包括：RTMP、 FLV、HLS 和 WebRTC。</p>
</li>
<li><p>RTMP：RTMP 协议比较全能，既可以用来推送又可以用来直播，其核心理念是将大块的视频帧和音频帧拆分，然后以小数据包的形式在互联网上进行传输，而且支持加密，因此隐私性相对比较理想，但拆包组包的过程比较复杂，所以在海量并发时也容易出现一些不可预期的稳定性问题。</p>
</li>
<li><p>FLV：FLV 协议由 Adobe 公司主推，格式极其简单，只是在大块的视频帧和音视频头部加入一些标记头信息，由于这种简洁，在延迟表现和大规模并发方面都很成熟，唯一的不足就是在手机浏览器上的支持非常有限，但是用作手机端 App 直播协议却异常合适。</p>
</li>
<li><p>HLS：苹果推出的解决方案，将视频分成5秒 - 10秒的视频小分片，然后用 m3u8 索引表进行管理，由于客户端下载到的视频都是5秒 - 10秒的完整数据，故视频的流畅性很好，但也同样引入了很大的延迟（HLS 的一般延迟在10秒 - 30秒左右）。相比于 FLV， HLS 在 iPhone 和大部分 Android 手机浏览器上的支持非常给力，所以常用于 QQ 和微信朋友圈的 URL 分享。</p>
</li>
<li><p>WebRTC：名称源自网页即时通信（Web Real-Time Communication）的缩写，是一个支持网页浏览器进行实时语音对话或视频对话的API。它于2011年06月01日开源并在 Google、Mozilla、Opera 支持下被纳入万维网联盟的 W3C 推荐标准。快直播正是用的 WebRTC 协议，它是标准直播在超低延迟播放场景下的延伸，比传统直播协议延迟更低，为观众提供毫秒级的极致直播观看体验。 能够满足一些对延迟性能要求更高的特定场景需求，例如在线教育、体育赛事直播、在线答题等。</p>
</li>
</ul>
<hr>
<h1 id="RTC技术（WebRTC）"><a href="#RTC技术（WebRTC）" class="headerlink" title="RTC技术（WebRTC）"></a>RTC技术（WebRTC）</h1><ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/377100294">https://zhuanlan.zhihu.com/p/377100294</a></p>
</li>
<li><p>RTC（Real time communication）实时通信，是实时音视频的一个简称，我们常说的RTC技术一般指的是WebRTC技术，已经被 W3C 和 IETF 发布为正式标准。</p>
</li>
<li><p>解决什么问题</p>
<ul>
<li>直播中我们关心的几个点：延迟、质量、成本等。 传统rtmp直播痛点：TCP，延迟高、拥塞导致卡顿问题较多（质量问题）。 互联网网络复杂、延时敏感、实时音视频流畅度及清晰度较低以和运营成本较高等。 没有一项技术能兼顾并解决直播中的所有问题，RTC是时延、流畅、质量、成本等的平衡，成为技术选型落地的模型。</li>
</ul>
</li>
</ul>
<h2 id="RTC-VS-RTMP"><a href="#RTC-VS-RTMP" class="headerlink" title="RTC VS RTMP"></a>RTC VS RTMP</h2><ul>
<li><p>RTC (UDP) VS RTMP (TCP)</p>
</li>
<li><p>RTMP只是TCP上的一个标准协议，所以接入是一个标准体系，推流端可以是OBS这种直播软件工具，也可自开发rtmp推流工具，播放端可以是Flash播放器（Adobe 2020 12月份已经弃用）、服务端有技术成熟的CDN技术和设施进行分发、Native的播放器或者flv.js&#x2F;hls.js这种开源播放器组件，遵循rtmp、flv、hls标准即可，接入成本比较低。而一个完善的RTC服务应用，需要从推流端、服务端、到拉流端，一整套完整的全链路闭环技术。</p>
</li>
<li><p>RTC+RTMP</p>
<ul>
<li>互动连麦+服务端转推rtmp至CDN，CDN分发给观众。</li>
</ul>
</li>
</ul>
<h2 id="RTC的应用场景"><a href="#RTC的应用场景" class="headerlink" title="RTC的应用场景"></a>RTC的应用场景</h2><ul>
<li>视频会议、在线教育小班课、大班课、1v1视频连麦、多人视频连麦互动、语音聊天室、在线面试、在线医疗、云游戏、智能家居、在线签约、在线K歌等，遍地开花。 比如Zoom、腾讯会议、钉钉会议、微信音视频聊天</li>
</ul>
<h2 id="RTC服务提供商"><a href="#RTC服务提供商" class="headerlink" title="RTC服务提供商"></a>RTC服务提供商</h2><ul>
<li>声网、腾讯云音视频、即构、阿里云RTC、华为云RTC、微吼VRTC、网易云信RTC、Ucloud RTC、融云RTC、拍乐云等。</li>
</ul>
<hr>
<h2 id="腾讯云音视频"><a href="#腾讯云音视频" class="headerlink" title="腾讯云音视频"></a>腾讯云音视频</h2><ul>
<li><a href="https://cloud.tencent.com/document/product/267/70440">https://cloud.tencent.com/document/product/267/70440</a></li>
<li>在开播端，基于实时音视频 TRTC 来实现，通过 TRTC 协议完成主播推流。仅需1个TRTC应用 + 1个推流域名，即可把主播的直播流推流至云端。在观众端，默认情况下，使用 CDN 方式进行拉流观看， CDN 观看费用较低。如果主播端有 PK 需求，直接互相播放对方的流即可。</li>
</ul>
<h2 id="即构"><a href="#即构" class="headerlink" title="即构"></a>即构</h2><ul>
<li><a href="https://doc-zh.zego.im/article/5416">https://doc-zh.zego.im/article/5416</a></li>
<li>语聊房:<a href="https://doc-zh.zego.im/article/4903">https://doc-zh.zego.im/article/4903</a><ul>
<li>麦上用户可以发起混流，即把多路音频流混合成单流。推流后混流，麦下用户在拉流时只需要拉一路流即可收听所上麦上用户的互动音频，降低开发实现上的复杂性以及对设备的性能要求。</li>
</ul>
</li>
<li>秀场直播:<a href="https://doc-zh.zego.im/article/11202">https://doc-zh.zego.im/article/11202</a></li>
</ul>
<h2 id="声网"><a href="#声网" class="headerlink" title="声网"></a>声网</h2><ul>
<li>互动直播：<a href="https://www.agora.io/cn/interactive-live-streaming-premium">https://www.agora.io/cn/interactive-live-streaming-premium</a></li>
</ul>
]]></content>
      <tags>
        <tag>RTMP</tag>
        <tag>HTTP-FLV</tag>
        <tag>HLS</tag>
        <tag>RTC</tag>
      </tags>
  </entry>
  <entry>
    <title>长连接服务需注意什么？</title>
    <url>/2022/05/06/20220506-chang-lian-jie-fu-wu-xu-zhu-yi-shi-me/</url>
    <content><![CDATA[<h2 id="边缘服务"><a href="#边缘服务" class="headerlink" title="边缘服务"></a>边缘服务</h2><ul>
<li>边缘服务的网络质量很重要，覆盖不好会有弱网问题</li>
</ul>
<h2 id="网络相关命令"><a href="#网络相关命令" class="headerlink" title="网络相关命令"></a>网络相关命令</h2><ul>
<li><p>dig命令 ：</p>
<ul>
<li>一个域名可以有两种类型的指向，如果一个 域名指向 称为一个 记录 （Record）的话，那么就有两种 记录类型 （Record Type），分别是：<br>A记录 ：指向一个IP地址 （地址记录）<br>CNAME ：指向一个其他的域名（别名记录）<br>NS : 名字服务器记录(理解为dns服务器 )</li>
</ul>
</li>
<li><p>linux查看网络路由跳转<br><code>traceroute   www.baidu.com</code></p>
</li>
<li><p>查看路由表<br><code>route -n（netstat -rn）</code>  </p>
</li>
<li><p>nslookup</p>
</li>
</ul>
<h2 id="使用tcp长连通信-（个人总结）"><a href="#使用tcp长连通信-（个人总结）" class="headerlink" title="使用tcp长连通信 （个人总结）"></a>使用tcp长连通信 （个人总结）</h2><ul>
<li>一般都是直接用ip端口的方式；一般情况下域名都是公共的，很少会为了某些业务暴露端口，所以一般直接ip端口直接连应用（边缘服务器？？）  </li>
<li>使用ip端口相连会有部分用户连不上的问题，比如只有北京的外网ip，用户在广州，可能会连接不稳定（没走专线）</li>
<li>非tcp长连，普通的http请求走域名（或cdn），返回用户一个就近的ip，进入这个ip之后，之后的通信都是内网通信（运营商内网，专线，CDN专线等）</li>
<li>所以一般使用tcp长连，需要很多个边缘节点ip，分布在各个地方的机房，并配合合适的调度策略（根据机器的负载情况）（腾讯im有大量的边缘服务？）</li>
<li>如果没足够的边缘机器（部署几个重要的边缘服务，其他的降级走http（域名），不走长连？？）</li>
<li>注意NAT的使用<ul>
<li><a href="https://mp.weixin.qq.com/s/wlqxDDVUj0zH52JpK12L5w">解Bug之路-NAT引发的性能瓶颈</a></li>
<li>使用同一个NAT地址的机器，timestamp是不能保证同步的(即使一致也没用，per-host PAWS机制的存在会导致问题)。<ul>
<li>TCP长连接服务，最好服务上有外网ip，否则直接用NAT转发，容易造成问题</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="边缘计算机器"><a href="#边缘计算机器" class="headerlink" title="边缘计算机器"></a>边缘计算机器</h3><ul>
<li>边缘计算机器（Edge Computing Machine，ECM）通过将计算能力从中心节点下沉到靠近用户的边缘节点，为您提供低时延、高可用、低成本的边缘计算服务。</li>
<li>CDN俗称“边缘节点服务”。可用于网站加速、将源站内容分发至最接近用户的节点，使用户可就近取得所需内容，提高用户访问的响应速度和成功率。解决因分布、带宽、服务器性能带来的访问延迟问题，适用于站点加速、点播、直播等场景。</li>
<li>还有边缘节点服务（Edge Node Service, ENS）提供基于CDN的边缘弹性基础设施，使您可以将计算、转发等业务下沉至边缘。降低响应时延和带宽成本、减轻中心集群压力，适用于“中心+边缘”架构模型下的各类业务。</li>
</ul>
<h2 id="使用websocket"><a href="#使用websocket" class="headerlink" title="使用websocket"></a>使用websocket</h2><h2 id="BGP-AnyCast"><a href="#BGP-AnyCast" class="headerlink" title="BGP AnyCast"></a>BGP AnyCast</h2><ul>
<li><p>时延敏感度高的内容服务业务（比如这里说的长连接服务）</p>
<ul>
<li>针对https&#x2F;tcp等对时延敏感的协议（涉及多次握手的协议），由于用户位置流动，而数据中心相对固定，因此会随着用户的移动，体验可能出现严重下降。</li>
<li>基于以上背景，可在全球有相关业务的地址位置部署小型数据中心，所有小型数据中心和总部数据中心保持长期稳定的TCP会话连接。当相对于总部的远端用户访问服务时，TCP连接实际是发送至用户当地的小型数据中心，从而降低了访问延时，提高了用户体验度。</li>
<li>在全球大规模部署多个节点时，为了确保用户能就近访问所在地的数据中心，可把所有小型数据中心的IP采用相同地址，通过BGP发布至Internet。</li>
<li>当用户访问服务时，DNS解析会返回此小型数据中心的IP，然后用户运营商会根据就近原则路由用户数据到最近的小型数据中心，从而达到了上面所述的优化延迟的目的。</li>
</ul>
</li>
<li><p>AnyCast适用于无连接的UDP，以及有连接的TCP协议；基于AnyCast的特性——就近原则，很大程度上提升了客户端的响应速度。</p>
</li>
<li><p>AnyCast缺点</p>
<ul>
<li>AnyCast严重依赖于BGP的选路原则，在整个Internet网络拓扑复杂的情况下，可能导致次优路由选择</li>
</ul>
</li>
<li><p>BGP AnyCast 的部署成本比较大，基本由一定规模的公司才会实施这一套方案（比如阿里云、腾讯云等），并以云服务的形式提供给其他企业使用。</p>
</li>
<li><p>以腾讯云为例</p>
<ul>
<li>Anycast 公网加速（Anycast Internet Acceleration，AIA）是一个覆盖多地的动态加速网络，可以大幅提升您业务的公网访问体验。AIA 不同于其他应用层加速服务，它能实现 IP 传输的质量优化和多入口就近接入，减少网络传输的抖动、丢包，最终提升云上应用的服务质量，扩大服务范围，精简后端部署。</li>
</ul>
</li>
<li><p>疑惑：在AnyCast网络中多个主机用同一个IP，这岂不是IP地址冲突了？</p>
<ol>
<li>首先，每一个节点主机处在不同的地理位置，相互之间不在同一个广播域内。所以把所有主机配置成相同的IP地址并不会引起我们日常所见的IP地址冲突；</li>
<li>其次，在仅仅配置相同IP之外，还需要借助BGP协议进行地址宣告，通过BGP，各个站点向Internet宣告相同的AnyCast IP地址。</li>
</ol>
</li>
<li><p><a href="https://cloud.tencent.com/document/product/644/12623">最佳实践</a></p>
</li>
</ul>
<pre>
背景说明
某游戏公司，BACKEND 服务集群在首尔。该公司不希望部署多套逻辑和数据层，从而降低成本，但又希望全球的客户能够接入，需要全局漂移 IP 作为访问的唯一入口，并可做全局的就近分配、动态流量分配、故障剔除。

痛点说明
该游戏公司由客户自建的 IDC 和中小型公有云厂商不具备网络跨地域调度能力，更无 Anycast 能力，显然无法满足客户需求。易被如下问题困扰：

区分多个外网 IP，每个地域都部署集群，维护多个逻辑层，数据层跨地域读写，一致性和实时性较差。
只能寄希望于运营商链路质量。首尔某运营商网络故障导致 A、U 等多家服务商 BGP 网络异常，部分地区无法访问，该游戏的用户流失严重。
DDoS 攻击流量集中在一个 IP 上，影响巨大。

方案说明
针对客户需求，腾讯云帮助客户实现以下方案，方案示意图如下：

方案重点如下：

使用 Anycast 的 EIP，该 IP 同时在多地 Anycast，实现多地同服。
用户后端集中维护一套集群，然后绑定 Anycast 类型的 EIP。该 EIP 借助腾讯云内网和 POP 点，多地发路由。
客户不用感知网络路径的选择，无需手动指定 IP 的发布位置，流量就近完成了全局负载均衡，从最优的地域进出，后端得到简化。同时，客户的 IP 得到收敛，无需每个地域配一个 IP 和 DNS 规则，在备案和管理上得到简化。
传输质量得到提高。
多个 IP 发布地，实现了多路径，增加了网络的容错能力。此外，就近接入后走的是专线传输，比公网传输更可靠、更低延时，提升了玩家的体验。
</pre>


<h3 id="BGP-AnyCast-原理要点"><a href="#BGP-AnyCast-原理要点" class="headerlink" title="BGP AnyCast 原理要点"></a>BGP AnyCast 原理要点</h3><ul>
<li><p>任播(Anycast)，又称为选播、泛播或任意播</p>
</li>
<li><p>利用一个（多个） as号码在不同的地区广播相同的一个ip段。<br>利用bgp的寻路原则，短的as path 会选成最优路径（bgp寻路原则之n），从而优化了访问速度。<br>其实bgp anycast是不同服务器用了相同的ip地址。</p>
</li>
<li><p>Anycast技术也存在一定的局限性:<br>使用Anycast中的共享单播地址不能作为客户端发起请求，因为请求的响应不一定能返回到发起的Anycast单播地址。因此，目前Anycast仅适合一些特定的上层协议，从目前的实际应用来看， Anycast最广泛的应用是DNS的部署。</p>
</li>
<li><p>IP Anycast＋BGP的部署必须使用能够运行BGP的设备与其他自治域进行路由交换，通常使用的设备是路由器或三层交换机。然后将目标主机直接接入路由器或通过负载均衡设备将多台主机接入路由器</p>
</li>
<li><p>在IP Anycast＋BGP整体部署之前应多方面考虑各种因素，着重考虑自治域号申请、IP地址规划等问题</p>
</li>
<li><p>Anycast IP，则是集Multicast和Unicast特性于一身的特殊IP地址类型</p>
</li>
<li><p>Anycast实质上是一种网络技术，它借助于网络中动态路由协议实现服务的负载均衡和冗余，从实现类型上分，可以分为subnet Anycast和Global Anycas: Subnet Anycast是指所有目的主机都位于同一网段，此方式仅提供负载均衡和冗余，对安全度提升没有实质效果; Global Anycast是指目的主机处于不同网段，可能处于不同城市，甚至分布在全球各地，在实际应用中Global Anycast中目标主机的部署除地理位置的考虑外，多接入不同自治域的网络中。</p>
</li>
<li><p>当使用Anycast的目标主机接入到不同自治域时，因为难以使用某一自治域的IP地址，所以通常使用Anycast的共享单播地址拥有独立的自治域号，并通过BGP协议与不同自治域网络交换路由，即IP Anycast＋BGP。</p>
</li>
<li><p>在实际应用中，任播 (Anycast) 是一种网络寻址和路由的策略。Anycast 采用将一个单播地址分配到处于 Internet 中多个不同物理位置的主机上，发送到这个主机的报文被网络路由到路由协议度量的最近的目标主机上。<br>  例如：在 IP 网络上通过一个 Anycast 地址标识一组提供特定服务的主机，同时服务访问方并不关心提供服务的具体是哪一台主机（比如：DNS 或者镜像服务），访问该地址的报文可以被 IP 网络路由到这一组目标中的任何一台主机上。</p>
</li>
<li><p>使用anycast，数据传输路径：client -&gt; anycast ip -&gt; 内网ip -&gt; 内网机器</p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://cloud.tencent.com/developer/article/1473063">002.AnyCast技术浅析</a></li>
<li><a href="https://cloud.tencent.com/document/product/644/12612">https://cloud.tencent.com/document/product/644/12612</a></li>
<li><a href="https://cloud.tencent.com/document/product/644/12623">最佳实践</a></li>
<li><a href="https://www.linuxidc.com/Linux/2014-08/105816.htm">DNS多点部署IP Anycast+BGP实战分析</a></li>
<li><a href="https://www.cnblogs.com/du-z/p/15603392.html">IP anycast + BGP 网络技术</a></li>
<li><a href="https://juejin.cn/post/6844903638679175175">浅析 AnyCast 技术</a></li>
</ul>
]]></content>
      <tags>
        <tag>长连接</tag>
      </tags>
  </entry>
  <entry>
    <title>高效工作方法论总结</title>
    <url>/2022/05/07/20220507-gao-xiao-gong-zuo-fang-fa-lun-zong-jie/</url>
    <content><![CDATA[<h2 id="思考维度"><a href="#思考维度" class="headerlink" title="思考维度"></a>思考维度</h2><ul>
<li>事前, 事中, 事后</li>
<li>从三个维度  预防，及时发现，止损  三个出发</li>
<li>what when why who how</li>
<li>5W3H(what、when、why、who、where、how、how much、how feel)</li>
<li>金字塔思维: 主治：思维混乱，分不清主次重点 - 提高逻辑性和条理性; 总-分-总 过去-现在-将来 第一-第二-第三.</li>
<li>STAR 法则: 主治：不知道如何表达 - 讲述故事的绝佳手段; 情境(situation)、任务(task)、行动(action)、结果(result)</li>
<li>SMART 原则: 主治：不知道如何着手做目标管理 - 制定目标的黄金准则; 目标具体(Specific)、可度量(Measurable)、可实现(Attainable)、现实性(Realistic)、时限(Time bound)</li>
<li>PDCA 循环： 主治：工作计划性差, 自律性弱 - 过程管理: 持续反馈-&gt;持续改进 ；计划（plan）、执行（do）、 检查（check）、调整（Adjust）</li>
<li>四象限法则: 主治：时间分配不合理- 尽量在做最重要的事情;</li>
</ul>
<h2 id="结构化思维"><a href="#结构化思维" class="headerlink" title="结构化思维"></a>结构化思维</h2><ol>
<li>表达要有逻辑(所有的逻辑关系都在这四种顺序之内)</li>
</ol>
<ul>
<li>演绎（因果）顺序</li>
<li>时间（步骤）顺序</li>
<li>空间（结构）顺序</li>
<li>程度（重要性）顺序</li>
</ul>
<ol start="2">
<li>做事要有套路</li>
</ol>
<ul>
<li>5W2H:Why、Who、When、Where、What、How 和 How much</li>
</ul>
<ol start="3">
<li>建立中心</li>
</ol>
<ul>
<li>定义清楚要解决的问题，要明确目标<ul>
<li>自上而下:适用于问题比较明确的情况，我们只需要找到问题的核心要素即可，然后进行展开即可。</li>
<li>自下而上:对于问题不够明确的情况，我们需要对多种杂乱的内容，进行分类、剪枝、归纳汇总成一个中心。</li>
</ul>
</li>
<li>抽象层次越高，要解决的问题域越宽，外延越大</li>
</ul>
<ol start="4">
<li>结构化分解</li>
</ol>
<ul>
<li>分解的策略就是我们上文提到的四种逻辑顺序，即演绎顺序、时间顺序、空间顺序和程度顺序</li>
<li>在做空间分解的时候，要注意满足 MECE（Mutually Exclusive Collectively Exhaustive，相互独立，完全穷尽）原则</li>
</ul>
<h2 id="合理安排自己的时间"><a href="#合理安排自己的时间" class="headerlink" title="合理安排自己的时间"></a>合理安排自己的时间</h2><ol>
<li>每天提前一小时醒来</li>
<li>每天提前 15 分钟到公司</li>
<li>下班前花 15 分钟总结</li>
<li>减少玩手机的时候</li>
<li>把时间切割成小块</li>
<li>碎片化时间利用</li>
<li>给休息生活留出时间</li>
</ol>
<hr>
<ul>
<li>抽象思维：帮助我们快速抽取面对问题的关键要素和本质，可以是其他能力的“元能力”</li>
<li>分层思维：帮助我们拆解问题，分而治之，划清问题和职责边界</li>
<li>归纳思维：帮助我们从个性问题中抽象出问题的一般规律和得出共同结论</li>
<li>结构化思维：帮助我们沉淀自己的知识树，逐步系统性的思考问题</li>
</ul>
<hr>
<h2 id="深度工作总结"><a href="#深度工作总结" class="headerlink" title="深度工作总结"></a>深度工作总结</h2><ul>
<li>如果你无法学习，就无法成功</li>
<li>无干扰状态下保持专注</li>
<li>高质量工作产出&#x3D;时间×专注度</li>
<li>转移工作、注意力残留 -&gt; 专注、深度工作</li>
<li>深度工作并非是我们的经济中唯一有价值的技能，不培养这种能力也有可能做得很好，但是不需要深度工作的职业会越来越少。</li>
<li>最小阻力原则</li>
<li>忙碌代表生产能力（Busyness as Proxy for Productivity）：在工作中，对于生产能力和价值没有明确的指标时，很多知识工作者都会采用工业时代关于生产能力的指标，以可视的方式完成很多事情。</li>
<li>支持深度工作往往要抵制新的高科技</li>
<li>当工作中没有明确目标时，围绕浮浅工作的表面忙碌会成为一种本能</li>
<li>工作其实比休闲时光更容易带来享受？</li>
<li>意志力是有限的</li>
<li>培养深度工作的习惯，关键在于越过良好的意图，在工作生活中加入一些特别设计的惯例和固定程序，使得进入并保持高度专注状态消耗的意志力最小化。！！！！！</li>
<li>选定你的深度哲学（节奏哲学）、并习惯化</li>
<li>恰当展开协作可以提升你在职业生活中深度工作的质量</li>
<li>这种隔音办公室与宽阔公共空间的组合，形成了中心辐射型的创新建筑结构，在这里偶遇的意外发现和与世隔绝的深度思考都能实现。</li>
<li>专注于少量“极端重要的目标”</li>
<li>引领性指标</li>
<li>专注于极度重要目标上的深度工作状态时间</li>
<li>4DX框架下的4种原则 ！！！</li>
<li>在整个4DX的实验过程中，目标的明晰性，辅以引领性指标计分板提供的简单但却难以回避的反馈，促使我达到了此前从未实现的深度状态。</li>
<li>定期放松大脑！！工作日结束的时候，在第二天早晨到来之前，屏蔽掉对工作问题的担忧。</li>
<li>定期休息大脑可以提升深度工作的质量。工作时，努力工作。完成时，就放松下来。</li>
<li>不要不断分心，而要不断专注</li>
<li>设定一个几乎不可能的时间期限；深度工作需要专注的强度远远超出了大部分知识工作者的舒适区。</li>
<li>有成果的冥想</li>
<li>远离社交媒体</li>
<li>在晚上或周末到来之前就确定要做的事情是十分重要的。（避免陷入其他无效的诱惑）</li>
<li>人的智力系统可以进行长时间的高强度活动：它不像人的手脚一样会疲倦。除睡觉以外，它只需要变化，而不是停止。！！！</li>
<li>如果你想抵御娱乐网站对你时间和精力的诱惑，那么就给大脑找一些高质量的替代活动。这样不仅可以使我们避免分心，保持专注的能力，同时还有可能实现本内特的宏伟目标：体验到何为生活，而不仅仅是生存。</li>
<li>减少浮浅工作在我们日程中的分量，而不是将其消除</li>
<li>一天的每一分钟都要做好计划（笔记本）</li>
<li>深度工作要求你尊重自己的时间。要做到真正尊重时间，下面这一条建议是个很不错的开端：提前决定你一天的每一分钟要做什么工作。</li>
<li>5点半之前结束工作。固定日程生产力。</li>
<li>变得不容易联系到；文档化</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/zH9kFjJQ5zE9mKGEiwEYAA">如何提升职业工作效率</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/500696193">一线技术人的成长思考总结</a></li>
</ul>
]]></content>
      <tags>
        <tag>效率</tag>
      </tags>
  </entry>
  <entry>
    <title>算法基础总结</title>
    <url>/2022/05/10/20220510-suan-fa-ji-chu-zong-jie/</url>
    <content><![CDATA[<ul>
<li>O这个符号的意思是“忽略重要项以外的内容”，读音同Order。O（n2）的含义就是“算法的运行时间最长也就是n2的常数倍”，准确的定义请参考相关专业书籍。重点在于，通过这种表示方法，我们可以直观地了解算法的时间复杂度</li>
<li>当我们知道选择排序的时间复杂度为O（n2）、快速排序的时间复杂度为O（nlogn）时，很快就能判断出快速排序的运算更为高速。二者的运行时间根据输入n产生的变化程度也一目了然。</li>
</ul>
<h2 id="一、链表"><a href="#一、链表" class="headerlink" title="一、链表"></a>一、链表</h2><h2 id="二、数组"><a href="#二、数组" class="headerlink" title="二、数组"></a>二、数组</h2><h2 id="三、栈"><a href="#三、栈" class="headerlink" title="三、栈"></a>三、栈</h2><h2 id="四、队列"><a href="#四、队列" class="headerlink" title="四、队列"></a>四、队列</h2><h2 id="五、哈希表"><a href="#五、哈希表" class="headerlink" title="五、哈希表"></a>五、哈希表</h2><h2 id="六、堆"><a href="#六、堆" class="headerlink" title="六、堆"></a>六、堆</h2><ul>
<li>堆是一种图的树形结构，被用于实现“优先队列”（priority queues）</li>
<li>优先队列是一种数据结构，可以自由添加数据，但取出数据时要从最小值开始按顺序取出</li>
<li>如果需要频繁地从管理的数据中取出最小值，那么使用堆来操作会非常方便。</li>
</ul>
<h2 id="七、二叉查找树"><a href="#七、二叉查找树" class="headerlink" title="七、二叉查找树"></a>七、二叉查找树</h2><ul>
<li>二叉查找树（又叫作二叉搜索树或二叉排序树）是一种数据结构，采用了图的树形结构</li>
<li>二叉查找树有两个性质。第一个是每个结点的值均大于其左子树上任意一个结点的值。</li>
<li>有很多以二叉查找树为基础扩展的数据结构，比如“平衡二叉查找树”。这种数据结构可以修正形状不均衡的树，让其始终保持均衡形态，以提高查找效率。</li>
<li>种子结点数可以自由设定，并且形状均衡的树便是B树。</li>
</ul>
<hr>
<h1 id="图"><a href="#图" class="headerlink" title="图"></a>图</h1><ul>
<li>由顶点和连接每对顶点的边所构成的图形就是图。</li>
<li>这个值叫作边的“权重”或者“权”，加了权的图被称为“加权图”。没有权的边只能表示两个顶点的连接状态，而有权的边就可以表示顶点之间的“连接程度”</li>
<li>有向图、无向图</li>
</ul>
<h2 id="广度优先搜索"><a href="#广度优先搜索" class="headerlink" title="广度优先搜索"></a>广度优先搜索</h2><ul>
<li>广度优先搜索会优先从离起点近的顶点开始搜索。</li>
<li>候补顶点是用“先入先出”（FIFO）的方式来管理的，因此可以使用“队列”这个数据结构。</li>
<li>广度优先搜索的特征为从起点开始，由近及远进行广泛的搜索。因此，目标顶点离起点越近，搜索结束得就越快。</li>
</ul>
<h2 id="深度优先搜索"><a href="#深度优先搜索" class="headerlink" title="深度优先搜索"></a>深度优先搜索</h2><ul>
<li>深度优先搜索会沿着一条路径不断往下搜索直到不能再继续为止，然后再折返，开始搜索下一条候补路径。</li>
<li>此处，候补顶点是用“后入先出”（LIFO）的方式来管理的，因此可以使用“栈”这个数据结构。</li>
<li>广度优先搜索选择的是最早成为候补的顶点，因为顶点离起点越近就越早成为候补，所以会从离起点近的地方开始按顺序搜索；而深度优先搜索选择的则是最新成为候补的顶点，所以会一路往下，沿着新发现的路径不断深入搜索。</li>
</ul>
<h2 id="贝尔曼-福特算法"><a href="#贝尔曼-福特算法" class="headerlink" title="贝尔曼-福特算法"></a>贝尔曼-福特算法</h2><ul>
<li>贝尔曼-福特（Bellman-Ford）算法是一种在图中求解最短路径问题的算法。最短路径问题就是在加权图指定了起点和终点的前提下，寻找从起点到终点的路径中权重总和最小的那条路径。</li>
<li>贝尔曼也因为提出了该算法中的一个重要分类“动态规划”而被世人所熟知。</li>
</ul>
<h2 id="狄克斯特拉算法"><a href="#狄克斯特拉算法" class="headerlink" title="狄克斯特拉算法"></a>狄克斯特拉算法</h2><ul>
<li>狄克斯特拉（Dijkstra）算法也是求解最短路径问题的算法，使用它可以求得从起点到终点的路径中权重总和最小的那条路径路径。</li>
</ul>
<h2 id="A-算法"><a href="#A-算法" class="headerlink" title="A*算法"></a>A*算法</h2><ul>
<li>A<em>（A-Star）算法也是一种在图中求解最短路径问题的算法，由狄克斯特拉算法发展而来。狄克斯特拉算法会从离起点近的顶点开始，按顺序求出起点到各个顶点的最短路径。也就是说，一些离终点较远的顶点的最短路径也会被计算出来，但这部分其实是无用的。与之不同，A</em>就会预先估算一个值，并利用这个值来省去一些无用的计算。</li>
</ul>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>[我的第一本算法书] - 宫崎修一 石田保辉</li>
</ul>
]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>开发golang程序和进行内网穿透，作为微信公众号服务器</title>
    <url>/2022/06/01/20220601-ge-ren-golang-xiang-mu-jian-yao-miao-shu/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>一直想部署一个私有服务，平常在外的时候可以为自己提供服务。<br>私有服务的好处是，可以根据自己的需求，开发程序，提供个人定制化的服务</p>
</blockquote>
</blockquote>
<h2 id="服务器的选择"><a href="#服务器的选择" class="headerlink" title="服务器的选择"></a>服务器的选择</h2><ol>
<li>阿里云、腾讯云等<ul>
<li>优点：使用方便，只要有网络就可以连上</li>
<li>缺点：有持续产生的费用，对于个人服务来说，平常几乎都是闲置，性价比很低</li>
</ul>
</li>
<li>自建服务器<ul>
<li>优点：总体成本低，购买服务器后，后续只有有电有网就行，无需其他额外成本</li>
<li>缺点：需要外网能访问（需要绑定外网ip或者代理接入转发）</li>
</ul>
</li>
</ol>
<ul>
<li>本着能省就省的原则，最终还是采用了方案2 ：上淘宝买一个一百多块的小型服务器！</li>
</ul>
<h2 id="如何使外网环境能访问到服务器"><a href="#如何使外网环境能访问到服务器" class="headerlink" title="如何使外网环境能访问到服务器"></a>如何使外网环境能访问到服务器</h2><ul>
<li>服务器有了之后，通过网线连接到家庭网络即可正常上网了，那么外网环境怎么访问呢？<br>通过一番研究之后，最终决定通过在服务器上部署ngrok代理来实现，不知道啥是ngrok的自行搜索即可</li>
</ul>
<h2 id="编程语言选择"><a href="#编程语言选择" class="headerlink" title="编程语言选择"></a>编程语言选择</h2><ul>
<li>本人平常工作都是使用Java，但经过一番考虑之后，我最终选择了Go作为开发语言</li>
</ul>
<ol>
<li>想学习，通过实践熟悉</li>
<li>足够轻量，打包成一个二进制文件即可，特别适合这种低配版服务器</li>
</ol>
<ul>
<li>个人Go程序代码：<a href="https://github.com/Kingson4Wu/mp_weixin_server">https://github.com/Kingson4Wu/mp_weixin_server</a></li>
</ul>
<h2 id="前端终端选择"><a href="#前端终端选择" class="headerlink" title="前端终端选择"></a>前端终端选择</h2><ul>
<li><p>平常在外都是使用android的手机，但是作为后端开发，本人只会android的hello world。<br>有考虑使用网页，但是现在前端很卷了，用传统的html+js开发，以我的水平开发出来，至少前期体验也一般。</p>
</li>
<li><p>经过一番考虑，就在决定直接通过个人的微信公众号来作为前端，在公众号后台配置自己的服务器地址即可</p>
</li>
</ul>
<h2 id="微信通知的实现"><a href="#微信通知的实现" class="headerlink" title="微信通知的实现"></a>微信通知的实现</h2><ul>
<li><p>平常自己有一些个性定时任务，需要通知消息到自己，使用微信来通知是最好的，毕竟大家目前都是微信的重度用户了。</p>
</li>
<li><p>但现在微信对公众号的通知限制越来越多了，最后我选择通过发送邮件的方式来实现。在微信配置QQ邮箱接收邮件通知即可。</p>
</li>
</ul>
<h2 id="服务架构"><a href="#服务架构" class="headerlink" title="服务架构"></a>服务架构</h2><p><img src="/2022/06/01/20220601-ge-ren-golang-xiang-mu-jian-yao-miao-shu/golang_project_3.png"></p>
<h2 id="外网环境下如何进行服务部署更新"><a href="#外网环境下如何进行服务部署更新" class="headerlink" title="外网环境下如何进行服务部署更新"></a>外网环境下如何进行服务部署更新</h2><ul>
<li>平常在家庭网络下，开发Go程序，本地编译打包成二进制文件，上传到服务器更新程序即可<br>在外网环境下，使用花生壳等端口映射软件即可。我使用花生壳映射端口后，就可以通过ssh登录到家里的服务器，接下来就可以为所欲为了。</li>
</ul>
<h2 id="部署流程"><a href="#部署流程" class="headerlink" title="部署流程"></a>部署流程</h2><p><img src="/2022/06/01/20220601-ge-ren-golang-xiang-mu-jian-yao-miao-shu/golang_deploy_2.png"></p>
<h2 id="结论总结"><a href="#结论总结" class="headerlink" title="结论总结"></a>结论总结</h2><ul>
<li>家庭网络 + 小型服务器 + Go程序 + ngrok + 微信公众号 + 邮箱通知 + 花生壳</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/272594212">golang如何优雅的实现重启服务(fvbock&#x2F;endless)</a></li>
</ul>
]]></content>
      <tags>
        <tag>Go</tag>
        <tag>ngrok</tag>
        <tag>wechat</tag>
        <tag>mail</tag>
      </tags>
  </entry>
  <entry>
    <title>Java跨平台能完全做到一次编写到处运行？</title>
    <url>/2022/07/05/20220705-java-kua-ping-tai-neng-wan-quan-zuo-dao-yi-ci-bian-xie-dao-chu-yun-xing/</url>
    <content><![CDATA[<p><img src="/2022/07/05/20220705-java-kua-ping-tai-neng-wan-quan-zuo-dao-yi-ci-bian-xie-dao-chu-yun-xing/lionel-messi.jpg"></p>
<ul>
<li>最近定位一个问题，花了不少时间。事后回想起来挺低级的，在此记录一下。</li>
</ul>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li>spring i18n, 在windows和mac生效，在linux不生效。</li>
</ul>
<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><ol>
<li>资源文件的名字为小写（message_zh_hant.proprties）</li>
<li>而文件读取时包含大写（message_zh_Hant.proprties）（这里不得不吐槽一下，spring无论请求参数传的是大写还是小写，最终都会转成大写去读文件，而且这么简单的功能，代码写得及其复杂，浪费了不少时间去debug）</li>
<li>windows和mac大小写不敏感，所以能读取文件成功，而linux则大小写敏感，则读取不成功（说好的Java跨平台呢？但跨平台包括处理这种不兼容的问题？似乎很难界定。）</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>windows和mac文件名对大小写不敏感，而linux则大小写敏感；</li>
<li>即使使用Java编写代码，特殊的场景还是需要考虑各平台的兼容问题。</li>
</ul>
]]></content>
      <tags>
        <tag>大小写敏感</tag>
      </tags>
  </entry>
  <entry>
    <title>谈谈跨域</title>
    <url>/2022/07/20/20220720-tan-tan-kua-yu/</url>
    <content><![CDATA[<ul>
<li><p>JQuery的jsonp的success与jsonpCallback的关系:<a href="https://www.cnblogs.com/non-clockwork-cheng/p/6637491.html">https://www.cnblogs.com/non-clockwork-cheng/p/6637491.html</a>,<br><a href="https://www.cnblogs.com/tapt/p/6524946.html">https://www.cnblogs.com/tapt/p/6524946.html</a></p>
</li>
<li><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$.<span class="title function_">ajax</span>(&#123;</span><br><span class="line">              <span class="attr">type</span>: <span class="string">&quot;get&quot;</span>,</span><br><span class="line">              <span class="attr">async</span>:<span class="literal">false</span>,</span><br><span class="line">              <span class="attr">url</span>: <span class="string">&quot;http://192.168.1.102:8080/carop/jsonp&quot;</span>,</span><br><span class="line">              <span class="attr">dataType</span>: <span class="string">&quot;jsonp&quot;</span>,</span><br><span class="line">              <span class="attr">jsonpCallback</span>:<span class="string">&quot;jsonpCallback&quot;</span>,              </span><br><span class="line">              <span class="attr">success</span>: <span class="keyword">function</span>(<span class="params">data</span>)&#123;</span><br><span class="line">              <span class="title function_">alert</span>(data.<span class="property">name</span>+<span class="string">&quot;\n &quot;</span>+data.<span class="property">tel</span>);</span><br><span class="line">              &#125;</span><br><span class="line"> &#125;); </span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>jsonp和jsonpcallback的使用:<a href="https://www.cnblogs.com/zhangruiqi/p/7880642.html">https://www.cnblogs.com/zhangruiqi/p/7880642.html</a></p>
</li>
</ul>
<pre>
1. jsonp、jsonpCallback  jsonp跨域时可以自定义的两个参数
2. jsonp: 回掉函数名的参数名，默认callback，服务端通过它来获取到回调函数名
3. jsonpCallback: 回调函数名，默认jquery自动生成
4. 指定jsonpCallback时可以将回掉函数写在ajax外面做其他操作，不指定时不能这样做，只能在success里做操作

一般jquery跨域用到的两个方法为：$.ajax 和$.getJSON

最后，仔细安静下来，细读 json 官方文档后发现这么一段：

JSON数据是一种能很方便通过JavaScript解析的结构化数据。如果获取的数据文件存放在远程服务器上（域名不同，也就是跨域获取数据），则需要使用jsonp类型。使用这种类型的话，会创建一个查询字符串参数 callback=? ，这个参数会加在请求的URL后面。服务器端应当在JSON数据前加上回调函数名，以便完成一个有效的JSONP请求。如果要指定回调函数的参数名来取代默认的callback，可以通过设置$.ajax()的jsonp参数。

其实jquery跨域的原理是通过外链 <script>  来实现的,然后在通过回调函数加上回调函数的参数来实现真正的跨域

Jquery 在每次跨域发送请求时都会有callback这个参数，其实这个参数的值就是回调函数名称，所以，服务器端在发送json数据时，应该把这个参数放到前面，这个参数的值往往是随机生成的，如：jsonp1294734708682，同时也可以通过 $.ajax 方法设置 jsonpcallback 方法的名称。
</pre>

<ul>
<li><p>解决跨域有几种</p>
<ol>
<li>通过jsonp跨域(需要服务端配合),原理:动态创建script.jsonp的解决方式（仅支持GET方式）</li>
<li>跨域资源共享（CORS）,服务端设置Access-Control-Allow-Origin<ul>
<li>nginx反向代理接口跨域 : <code>add_header Access-Control-Allow-Origin http://www.domain1.com; </code></li>
</ul>
</li>
<li>使用jsonp还不如响应添加Access-Control-Allow-Origin?<ul>
<li>传统的跨域请求没有好的解决方案，无非就是jsonp和iframe，随着跨域请求的应用越来越多，W3C提供了跨域请求的标准方案（Cross-Origin Resource Sharing）。IE8、Firefox 3.5 及其以后的版本、Chrome浏览器、Safari 4 等已经实现了 Cross-Origin Resource Sharing 规范，实现了跨域请求。<br>在服务器响应客户端的时候，带上Access-Control-Allow-Origin头信息。</li>
<li>说明jsonp其实已经过时?是以前  CORS没出现前的方案?</li>
</ul>
</li>
</ol>
</li>
<li><p>springboot中通过cors协议解决跨域问题：<a href="https://www.cnblogs.com/520playboy/p/7306008.html">https://www.cnblogs.com/520playboy/p/7306008.html</a></p>
</li>
</ul>
</script></pre>]]></content>
      <tags>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title>DNS解惑</title>
    <url>/2022/08/01/20220801-dns-jie-huo/</url>
    <content><![CDATA[<h2 id="相关名词"><a href="#相关名词" class="headerlink" title="相关名词"></a>相关名词</h2><ul>
<li>DNS（Domain Name System）域名系统: 域名和IP地址映射关系</li>
<li>LocalDNS : 本地DNS服务器，一般是ISP（Internet Service Provider）提供。ISP，即是互联网服务提供商(比如电信、联通和移动三大电信运营商)；对于不同运营商间的互联互通，一般是采用BGP peering（对等）的方式进行</li>
<li>地址解析协议，即ARP（Address Resolution Protocol）是将IP地址转换为MAC地址（TCP&#x2F;IP数据链路层协议）；DNS协议则是将域名转换为IP地址（TCP&#x2F;IP应用层协议）</li>
<li>ICANN  互联网名称与数字地址分配机构（The Internet Corporation for Assigned Names and Numbers）,全世界域名的最高管理机构。</li>
<li>CNNIC：中国互联网络信息中心（China Internet Network Information Center，CNNIC）是经国家主管部门批准，于1997年6月3日组建的管理和服务机构，行使国家互联网络信息中心的职责。</li>
<li>可逆DNS（rDNS，reverse DNS）是一种把一个IP地址分解成一个域名的方法，正像域名系统（DNS）把域名分解成关联的IP地址。</li>
</ul>
<h2 id="DNS解析流程"><a href="#DNS解析流程" class="headerlink" title="DNS解析流程"></a>DNS解析流程</h2><ul>
<li>不考虑每部分DNS缓存的情况下，DNS解析流程大致如下：</li>
</ul>
<ol>
<li>【递归查询】用户机器（比如浏览器）-&gt; 本地DNS服务器 </li>
<li>【迭代查询】本地DNS服务器 -&gt; DNS根服务器(返回域服务器)</li>
<li>【迭代查询】本地DNS服务器 -&gt; 域服务器(返回DNS服务器列表)</li>
<li>【迭代查询】本地DNS服务器(选择一个DNS服务器) -&gt; DNS服务器(返回域名对应的IP)（或返回其他权限服务器的IP地址，取决于域名的解析配置）</li>
<li>本地DNS服务器 -&gt; 权限服务器（可选步骤，取决于上一步的返回）</li>
<li>用户机器（根据IP发送请求访问）</li>
</ol>
<p><img src="/2022/08/01/20220801-dns-jie-huo/dns-resolution-linux-1920x994.webp"></p>
<ul>
<li><p><a href="https://devconnected.com/how-to-flush-dns-cache-on-linux/">https://devconnected.com/how-to-flush-dns-cache-on-linux/</a></p>
</li>
<li><p>浏览器等各个部分一般会缓存DNS记录一段时间</p>
</li>
<li><p>本地DNS服务器（LocalDNS）使用迭代查询的方式请求；请求发起方（浏览器）使用递归查询的方式请求</p>
</li>
<li><p>递归查询：本机向本地域名服务器发出一次查询请求，就静待最终的结果。如果本地域名服务器无法解析，自己会以DNS客户机的身份向其它域名服务器查询，直到得到最终的IP地址告诉本机</p>
</li>
<li><p>迭代查询：本地域名服务器向根域名服务器查询，根域名服务器告诉它下一步到哪里去查询，然后它再去查，每次它都是以客户机的身份去各个服务器查询。</p>
</li>
<li><p>通俗地说，递归就是把一件事情交给别人，如果事情没有办完，哪怕已经办了很多，都不要把结果告诉我，我要的是你的最终结果，而不是中间结果；如果你没办完，请你找别人办完。<br>迭代则是我交给你一件事，你能办多少就告诉我你办了多少，然后剩下的事情就由我来办。</p>
</li>
</ul>
<h2 id="域名的管理"><a href="#域名的管理" class="headerlink" title="域名的管理"></a>域名的管理</h2><ul>
<li><p>.com等国际顶级域名的管理机构是ICANN；.cn等国内域名的管理机构是CNNIC</p>
</li>
<li><p>用whois可以查询域名的相关信息</p>
</li>
<li><p>域名具有管理密码和转移密码，域名转移密码又称为授权码（Authorization code）或 域名EPP代码（EPP Key）</p>
</li>
<li><p>域名其实是具有一定的层次结构的，从上到下依次为：根域名、顶级域名（top level domain，TLD）、二级域名、（三级域名）<br>先来讲讲顶级域名（TLD），即最高层级的域名。简单说，就是网址的最后一个部分。比如，网址<a href="http://www.baidu.com/">www.baidu.com</a> 的顶级域名就是 .com。ICANN 的一项主要工作，就是规定哪些字符串可以当作顶级域名。</p>
</li>
<li><p>ICANN 自己不会去管理这些顶级域名，因为根本管不过来。想想看，顶级域名有1000多个，每个顶级域名下面都有许多批发商，如果每个都要管，就太麻烦了。ICANN 的政策是，每个顶级域名都找一个托管商，该域名的所有事项都由托管商负责。ICANN 只与托管商联系，这样管理起来就容易多了。举例来说，.cn 国家顶级域名的托管商就是中国互联网络信息中心（CNNIC），它决定了 .cn 域名的各种政策。</p>
</li>
<li><p>由于 ICANN 管理着所有的顶级域名，所以它是最高一级的域名节点，被称为根域名（root domain）。在有些场合，<a href="http://www.xxx.com/">www.xxx.com</a> 被写成 <a href="http://www.xxx.com.,即最后还会多出一个点.这个点就是根域名./">www.xxx.com.，即最后还会多出一个点。这个点就是根域名。</a></p>
</li>
<li><p>理论上，所有域名的查询都必须先查询根域名，因为只有根域名才能告诉你，某个顶级域名由哪台服务器管理。事实上也确实如此，ICANN 维护着一张列表（根域名列表），里面记载着顶级域名和对应的托管商。</p>
</li>
</ul>
<h2 id="DNS服务器类别"><a href="#DNS服务器类别" class="headerlink" title="DNS服务器类别"></a>DNS服务器类别</h2><h3 id="权威-DNS"><a href="#权威-DNS" class="headerlink" title="权威 DNS"></a>权威 DNS</h3><ul>
<li>权威 DNS 指域名在域名注册商处所设置的 DNS 服务器地址。该地址决定了该域名的解析管理权（新增，删除，修改等）。比如 DNSPod 的权威服务器：*.dnspod.net, * dnsv3.com 等。当域名设置权威服务器并设置了解析记录后，客户端请求域名时，权威服务器将返回该域名的对应的解析记录信息。</li>
</ul>
<h3 id="Local-DNS"><a href="#Local-DNS" class="headerlink" title="Local DNS"></a>Local DNS</h3><ul>
<li><p>Local DNS 是 DNS 查询中的第一个节点。Local DNS 作为客户端与 DNS 域名服务器的中间人。客户端发送 DNS 查询时，Local DNS 将使用缓存的数据进行响应，或者将向根域名服务器发送请求，接着向根域名服务器发送另一个请求，然后向权威 DNS 发送最后一个请求。收到来自包含已请求 IP 地址的权威 DNS 服务器的响应后，Local DNS 将向客户端发送响应。</p>
</li>
<li><p>在此过程中，Local DNS 将缓存从权威 DNS 服务器收到的信息。当一个客户端请求的域名 IP 地址是另一个客户端最近请求的 IP 地址时，Local DNS 可绕过与域名服务器进行通信的过程，并仅从第二个客户端的缓存中为第一个客户端提供所请求的记录。</p>
</li>
</ul>
<h3 id="公共-DNS"><a href="#公共-DNS" class="headerlink" title="公共 DNS"></a>公共 DNS</h3><ul>
<li>公共DNS，指面向所有互联网用户的全球公共递归域名解析服务。和仅使用本地 LocalDNS 的传统解析服务相比，公共解析服务，一般具备更加“快速”、“稳定”、“安全”互联网访问。</li>
</ul>
<h2 id="DNS常用命令"><a href="#DNS常用命令" class="headerlink" title="DNS常用命令"></a>DNS常用命令</h2><ul>
<li>dig、 host、nslookup、traceroute、whois</li>
</ul>
<h2 id="解惑"><a href="#解惑" class="headerlink" title="解惑"></a>解惑</h2><h3 id="域名提供商和电信服务提供商之间DNS的关系？"><a href="#域名提供商和电信服务提供商之间DNS的关系？" class="headerlink" title="域名提供商和电信服务提供商之间DNS的关系？"></a>域名提供商和电信服务提供商之间DNS的关系？</h3><ol>
<li>域名提供商(域名注册商)（ICANN等授权的管理机构）；电信服务提供商（ISP）</li>
<li>ISP的DNS：LocalDNS</li>
<li>域名提供商的DNS （腾讯、阿里云等），将自己的dns服务的ip直接在各个ISP中进行登记，使得ISP的DNS服务能转发过来查找，得到域名对应的ip</li>
<li>域名并不依赖平台，比如阿里万网只是个注册商，注册完域名后有相应的转移密码。转移密码有多种用途，比如可以在多个DNS服务商托管域名解析（有的域名注册商不一定有对应的DNS服务，而且在多个DNS服务商解析可以起到容灾作用）</li>
</ol>
<h3 id="运营商DNS和公共DNS"><a href="#运营商DNS和公共DNS" class="headerlink" title="运营商DNS和公共DNS"></a>运营商DNS和公共DNS</h3><ul>
<li>如何不特意去设置，我们用的就是运营商DNS（由DHCP分配）</li>
<li>目前国内电信运营商通过使用DNS劫持和DNS污染的方法，干扰用户正常上网，使得用户无法访问众多国外常用服务，因此可以使用公共DNS</li>
</ul>
<h3 id="自己创建的域名怎么让其他dns服务器解析"><a href="#自己创建的域名怎么让其他dns服务器解析" class="headerlink" title="自己创建的域名怎么让其他dns服务器解析"></a>自己创建的域名怎么让其他dns服务器解析</h3><ul>
<li>除非用户自行设置指定你的dns服务公网ip，否则只有成为认证通过的注册服务商才行</li>
<li>比如阿里云域名的解析生效，第一步是 阿里云 DNS 必须首先生效，然后等待世界各地 Local DNS 生效，可以通俗的理解为各大电信运营管理的 DNS 需要及时同步 阿里云 DNS 解析记录，才能最终生效。 网站是否能访问，直接相关的是 Local DNS， 阿里 云解析都是实时生效的，一般只需几秒即可同步到各地 Local DNS 上，但各地 Local DNS 均有缓存机制，解析的最终生效取决于各运营商刷新时间。</li>
</ul>
<h3 id="DNS解析相关疑问"><a href="#DNS解析相关疑问" class="headerlink" title="DNS解析相关疑问"></a>DNS解析相关疑问</h3><ul>
<li>DNS协议是应用层的协议，解析过程发生在用户态。</li>
<li>DNS协议既使用了UDP，也使用了TCP，使用的端口号都为 53。大多数情况下 DNS 都使用 UDP 进行传输。</li>
<li>DNS在区域传输的时候使用TCP协议，其他时候使用UDP协议；DNS区域传输的时候使用TCP协议</li>
<li>举个例子：浏览器返回某个HTTP服务<ol>
<li>浏览器调用“DNS解析模块”发出UDP请求得到域名的ip（DNS 应用层）</li>
<li>浏览器调用TCP（内核系统调用）发出HTTP请求（TCP 传输层）</li>
<li>TCP通过ARP协议得到mac地址 （ARP 数据链路层）</li>
</ol>
</li>
<li>“DNS解析模块” 是在哪里实现的？<ol>
<li>程序自行解析实现（从&#x2F;etc&#x2F;resolv.conf中取出本地dns server地址列表， 发送DNS请求(UDP报文)并获得结果）</li>
<li>调用到c标准库的getaddrinfo或getnameinfo函数<ul>
<li>要想知道getaddrinfo是如何查询信息的，可以用strace工具，追踪getaddrinfo函数 在执行时打开了哪些文件</li>
<li>resolv.conf是各种操作系统域名系统解析器（DNS Resolver）的配置文件。每当一个程序需要通过域名来访问Internet上面的其它主机时，需要利用Resolver库函数将域名转换成对应的IP，然后才可进行访问。</li>
<li>域名系统解析器（DNS Resolver）并非一个可执行程序，而是C语言的一系列库函数，用于解析resolv.conf获取域名对应的IP。</li>
</ul>
</li>
<li>操作系统中并不存在“DNS 查询”这个系统调用; 不同程序可能采用不同的策略获取名字对应的 IP 地址</li>
</ol>
</li>
</ul>
<h3 id="dns-resolver相关"><a href="#dns-resolver相关" class="headerlink" title="dns-resolver相关"></a>dns-resolver相关</h3><ul>
<li><a href="https://docs.microsoft.com/en-us/windows/win32/dns/dns-resolvers">https://docs.microsoft.com/en-us/windows/win32/dns/dns-resolvers</a></li>
<li><a href="https://datacadamia.com/os/linux/resolv.conf">https://datacadamia.com/os/linux/resolv.conf</a>    </li>
<li><a href="https://www.kernel.org/doc/html/latest/networking/dns_resolver.html">DNS Resolver Module</a><ul>
<li>The DNS resolver module provides a way for kernel services to make DNS queries by way of requesting a key of key type dns_resolver. These queries are upcalled to userspace through &#x2F;sbin&#x2F;request-key.</li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://cloud.tencent.com/developer/article/2000101">DNS、CDN加速和域名解析之间的关系</a></li>
<li><a href="https://www.vpsgongyi.net/archives/2197.html">权威DNS、Local DNS、公共DNS有什么区别</a></li>
<li><a href="https://www.cnblogs.com/wuyepeng/p/9835839.html">DNS用的是TCP协议还是UDP协议</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/351059293">超详细 DNS 协议解析</a></li>
<li><a href="https://blog.csdn.net/baidu_37964071/article/details/80500825">DNS（域名解析协议）详解</a></li>
<li><a href="https://www.cnblogs.com/battzion/p/4235562.html">getaddrinfo工作原理分析</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/42898476">Linux DNS 查询剖析</a></li>
</ul>
]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title>说说CDN</title>
    <url>/2022/08/02/20220802-shuo-shuo-cdn/</url>
    <content><![CDATA[<h2 id="相关名词"><a href="#相关名词" class="headerlink" title="相关名词"></a>相关名词</h2><ul>
<li>CDN（Content Delivery Network）（内容分发网络）：提供内容给用户就近访问</li>
</ul>
<h2 id="CDN域名解析流程"><a href="#CDN域名解析流程" class="headerlink" title="CDN域名解析流程"></a>CDN域名解析流程</h2><ul>
<li>浏览器发起HTTP请求到本地DNS服务器，本地DNS服务器使用CNAME的方式，将资源域名重定向到CDN服务</li>
</ul>
<ol>
<li>用户机器（比如浏览器）-&gt; LocalDNS</li>
<li>LocalDNS -&gt; 域名授权DNS服务 (返回域名CNAME)</li>
<li>LocalDNS -&gt; 请求CNAME域名（重新走域名解析流程，DNS根服务器，域服务器等）（返回CNAME对应的ip）</li>
<li>LocalDNS -&gt; CNAME对应的CDN服务器（CDN策略，查找出最佳的CDN节点的IP地址）</li>
<li>LocalDNS返回CDN节点IP地址给浏览器</li>
<li>用户机器（比如浏览器）-&gt; CDN节点（若无缓存）</li>
<li>CDN节点 -&gt; 回源服务器拉取资源 (可选)</li>
</ol>
<ul>
<li>添加CNAME记录需要在您的域名厂商处配置；CNAME的配置和域名的解析配置一起的</li>
</ul>
<h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><h3 id="服务接口的数据可以使用CDN来缓存？"><a href="#服务接口的数据可以使用CDN来缓存？" class="headerlink" title="服务接口的数据可以使用CDN来缓存？"></a>服务接口的数据可以使用CDN来缓存？</h3><ul>
<li>CDN不仅可以缓存静态资源（图片，视频等），对于一些数据变更不大的接口，可以适当缓存接口数据。比如配置，利用CDN缓存几分钟是合理的。</li>
</ul>
<h3 id="不能缓存数据的接口，可以使用CDN吗？"><a href="#不能缓存数据的接口，可以使用CDN吗？" class="headerlink" title="不能缓存数据的接口，可以使用CDN吗？"></a>不能缓存数据的接口，可以使用CDN吗？</h3><ul>
<li>结论：可以使用CDN，但注意GET接口响应头设置为不缓存(比如设置 Cache-Control:no-cache)</li>
</ul>
<ol>
<li>通过CDN加速回源效果（使用CDN快速传输的特性）<ul>
<li>比如一般情况下，用户访问通过普通公网，需要经过20个路由才到达服务器</li>
<li>使用CDN加速后，通过5CDN节点就到达服务器了（这里涉及服务器端在CDN的接入点、用户端CDN部署的覆盖范围是否足够大）</li>
</ul>
</li>
<li>使用CDN隐藏服务器真实IP,起到提升安全性等作用</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://cloud.tencent.com/developer/article/2000101">DNS、CDN加速和域名解析之间的关系</a></li>
<li><a href="https://kingson4wu.github.io/2020/08/20/20200820-%E5%85%B3%E4%BA%8ECDN%E7%BC%93%E5%AD%98/">关于CDN缓存总结摘要</a></li>
</ul>
]]></content>
      <tags>
        <tag>CDN</tag>
      </tags>
  </entry>
  <entry>
    <title>推送技术总结</title>
    <url>/2022/08/05/20220805-tui-song-ji-zhu-zong-jie/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li><p>从客户端是手机APP的角度来理解推送（PUSH），展示的形式有两种：</p>
<ol>
<li>App 推送：消息内容通过手机通知栏（状态栏）展示</li>
<li>应用内消息：各种业务数据推送（通过定义模版或命令号等方式推送给APP内的业务使用）</li>
</ol>
</li>
<li><p>从Web端角度看理解推送，一般只有网页内消息（跟手机APP的应用内消息是一样的类型）  </p>
</li>
<li><p>APP推送：</p>
<ol>
<li>在线推送（应用级方案）：APP进程控制推送消息，理论上只要APP要获得“手机通知栏”的权限（一般通过在APP内维持长连接来进行推送，但前提是APP已经启动和运行，并且能常驻）</li>
<li>离线推送（系统级方案）：通过手机操作系统或手机厂商提供的通道进行推送。这种推送方式可以在APP未启动的情况下，推送APP的消息。</li>
<li>APP进程运行时，应该优先走在线推送，自己的推送系统更快、更有保障。</li>
</ol>
</li>
<li><p>应用场景</p>
<ul>
<li>APP推送：电商内APP（推送促销消息）</li>
<li>应用内消息：直播类APP（推送送礼特效消息）</li>
<li>APP推送和应用内消息都需要：IM类APP（推送用户聊天信息）</li>
</ul>
</li>
<li><p>从推送的实现角度看，基本可以概括为两种：主动轮询（pull 拉）和长连接 （push 推）</p>
</li>
</ul>
<h2 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h2><ul>
<li>以下实现方式没有进行严格分类，从原理上看存在相互联系</li>
</ul>
<ol>
<li><p>HTTP轮询</p>
<ol>
<li>短轮询（Polling）</li>
<li>长轮询（Long-polling）(Nacos和apollo配置中心也是用这种)</li>
</ol>
<ul>
<li>从TCP的角度看HTTP长轮询：HTTP开启keepalive，服务端保持连接并不需要发额外数据包，有数据时可以立刻推送，跟TCP长连推送无异。展示服务端有点费连接的相关资源，数据包是HTTP相比较大而已。</li>
</ul>
</li>
<li><p>SSE (Server Sent Event 服务器发送事件)</p>
<ul>
<li>sse 单通道，只能服务端向客户端发消息； webscoket 是双通道</li>
<li>实现成本较低</li>
<li>http 协议，服务端响应的是text&#x2F;event-stream类型的数据流信息</li>
<li>场景：站内信、未读消息数、状态更新、股票行情、监控数量等场景</li>
</ul>
</li>
<li><p>WebSocket</p>
</li>
<li><p>MQTT （通常结合TCP长连接一起使用）</p>
</li>
<li><p>TCP长连接（自定义消息或protobuf等格式）</p>
</li>
<li><p>系统级方案</p>
<ul>
<li>Android和IOS本身的消息推送（Android的C2DM和IOS的APNS，系统与服务器建立连接，APP向系统注册关注的消息，实现系统级消息推送）</li>
<li>国内Android无法访问Google服务器，所以国内的手机厂商比如小米、OPPO、华为等，都实现来各自的系统级推送。</li>
<li>避免维持长连接而导致的过多资源消耗，IM类要求即时的更应该接系统级推送</li>
</ul>
</li>
<li><p>第三方推送平台</p>
<ul>
<li>集成各种手机平台，各种推送类型，甚至短信等推送</li>
<li>简单来说：由专业的平台做专业的事（太麻烦了，我只是想推送了消息，帮我搞定吧。。。）</li>
</ul>
</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/wIs5wi7rf0RFFGl7sR3J8g">7种 实现web实时消息推送的方案</a></li>
<li><a href="https://www.cnblogs.com/yihuihui/p/12622729.html">SSE 服务器发送事件详解</a></li>
</ul>
]]></content>
      <tags>
        <tag>PUSH</tag>
      </tags>
  </entry>
  <entry>
    <title>Chrome下载文件时暂停和继续是什么原理？</title>
    <url>/2022/08/30/20220830-chrome-xia-zai-wen-jian-shi-zan-ting-he-ji-xu-shi-shi-me-yuan-li/</url>
    <content><![CDATA[<ul>
<li>这个问题很久前就研究过了，觉得挺有意思，这里总结记录一下</li>
<li>所有的文字整理来源于: <a href="https://bbs.csdn.net/topics/392163074">https://bbs.csdn.net/topics/392163074</a>,感谢wjyiooo的耐心解答</li>
</ul>
<h2 id="Range"><a href="#Range" class="headerlink" title="Range"></a>Range</h2><ul>
<li>Range，是在 HTTP&#x2F;1.1（<a href="http://www.w3.org/Protocols/rfc2616/rfc2616.html%EF%BC%89%E9%87%8C%E6%96%B0%E5%A2%9E%E7%9A%84%E4%B8%80%E4%B8%AA">http://www.w3.org/Protocols/rfc2616/rfc2616.html）里新增的一个</a> header field，也是现在众多号称多线程下载工具（如 FlashGet、迅雷等）实现多线程下载的核心所在。</li>
</ul>
<h2 id="chrome-版本58"><a href="#chrome-版本58" class="headerlink" title="chrome 版本58"></a>chrome 版本58</h2><ol>
<li>抓包确认，chrome点击暂停的时候会发送一系列窗口变动应答，将窗口降到5，并且不再应答ACK包。 当点击恢复的时候只是重新发送ACK给服务器，同时将窗口重新设置为256。</li>
<li>以上可以确认它的“续传”只是利用TCP滑动窗口的特性，跟断不断网没关系，也不属于真正意义的断点续传功能（一般用range头部实现）。当然如果你中断网络超过了服务器的TCP连接超时时间那么就不能续传了，而且如果关闭浏览器即使网络非常正常也不能续传（也是因为TCP连接断了）。</li>
<li>在等待足够长时间让TCP连接关掉后，chrome就可以断点续传了，原理也是头部带range。</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>本地有临时下载文件</li>
<li>短时间内点继续，利用的是TCP滑动窗口的特性（与服务器未断开）</li>
<li>长时间之后点继续，再次发请求，带range头，继续下载剩余部分（与服务器断开）</li>
</ol>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="使用Range进行多线程下载"><a href="#使用Range进行多线程下载" class="headerlink" title="使用Range进行多线程下载"></a>使用Range进行多线程下载</h3><ul>
<li>Http 请求头 Range:<a href="https://www.cnblogs.com/1995hxt/p/5692050.html">https://www.cnblogs.com/1995hxt/p/5692050.html</a></li>
</ul>
<ol>
<li>curl -H “Range: bytes&#x3D;0-1551” <a href="http://127.0.0.1:8180/bg-upper.png">http://127.0.0.1:8180/bg-upper.png</a> -v -o 0-1151.png</li>
<li>curl -H “Range: bytes&#x3D;1552-3103” <a href="http://127.0.0.1:8180/bg-upper.png">http://127.0.0.1:8180/bg-upper.png</a> -v -o 1552-end.png</li>
<li>合并 cat 0-1151.png 1552-end.png &gt; filename.png</li>
</ol>
]]></content>
      <tags>
        <tag>HTTP</tag>
        <tag>Range</tag>
        <tag>断点续传</tag>
      </tags>
  </entry>
  <entry>
    <title>关于HTTP相关协议的一些总结</title>
    <url>/2022/09/05/20220905-guan-yu-http-xiang-guan-xie-yi-de-yi-xie-zong-jie/</url>
    <content><![CDATA[<h2 id="粗浅概括"><a href="#粗浅概括" class="headerlink" title="粗浅概括"></a>粗浅概括</h2><ul>
<li>HTTP - TCP</li>
<li>HTTPS - TCP + TLS </li>
<li>SPDY -&gt; TCP + TLS + 多路复用、头部压缩等特性 –&gt; 发展成 HTTP&#x2F;2<ul>
<li>SPDY是Speedy的音，是更快的意思</li>
</ul>
</li>
<li>HTTP&#x2F;2 - TCP + TLS(理论上可选) + 多路复用、头部压缩等特性</li>
<li>QUIC - UDP –&gt; 发展成 HTTP&#x2F;3</li>
<li>HTTP&#x2F;3 - UDP</li>
</ul>
<h2 id="其他基础"><a href="#其他基础" class="headerlink" title="其他基础"></a>其他基础</h2><ul>
<li>RTT(Round-Trip Time): 往返时延。在计算机网络中它是一个重要的性能指标，表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。</li>
</ul>
<h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><ul>
<li>请求-响应模式（半双工）</li>
</ul>
<ul>
<li>安全问题</li>
</ul>
<h3 id="“队头堵塞”-（线头阻塞）（Head-of-line-blocking）（HOLB）"><a href="#“队头堵塞”-（线头阻塞）（Head-of-line-blocking）（HOLB）" class="headerlink" title="“队头堵塞” （线头阻塞）（Head-of-line blocking）（HOLB）"></a>“队头堵塞” （线头阻塞）（Head-of-line blocking）（HOLB）</h3><ul>
<li>HTTP 1.1 默认启用长TCP连接，但所有的请求-响应都是按序进行的(串行发送和接收)</li>
<li>HTTP 1.1 的管道机制：客户端可以同时发送多个请求，但服务端也需要按请求的顺序依次给出响应的；</li>
<li>客户端在未收到之前所发出所有请求的响应之前，将会阻塞后面的请求(排队等待)，这称为”队头堵塞”</li>
</ul>
<h3 id="管道机制-Pipelining"><a href="#管道机制-Pipelining" class="headerlink" title="管道机制(Pipelining)"></a>管道机制(Pipelining)</h3><ul>
<li>在管道机制下，服务端如何控制按顺序返回响应的？<ul>
<li>HTTP是应用层协议，当然由各个应用程序按照规范自行实现了</li>
<li>比如使用nginx，或jetty等，若服务端需要支持管道机制，都要底层逻辑自行实现，避免暴露给业务层</li>
<li>那么因为要按顺序响应，那么当最前的请求的处理较慢时，同样会对服务端产生阻塞。</li>
</ul>
</li>
<li>Pipelining需要客户端和服务端同时支持</li>
<li>几乎所有的浏览器都是默认关闭或者不支持Pipelining的：对性能的提高有限、大文件会阻塞优先级更高的小文件等</li>
<li>只有GET和HEAD要求可以进行管线化，而POST则有所限制</li>
</ul>
<h2 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h2><ul>
<li><p>HTTPS（HTTP over TLS&#x2F;SSL）,TLS&#x2F;SSL(会话层)</p>
</li>
<li><p>SSL（Secure Socket Layer）是安全套接层，TLS（Transport Layer Security）是传输层安全协议，建立在SSL3.0协议规范，是 SSL3.0 的后续版本。</p>
</li>
<li><p>TLS可以用在TCP上，也可以用在无连接的UDP报文上。协议规定了身份认证、算法协商、密钥交换等的实现。</p>
</li>
<li><p>SSL是TLS的前身，现在已不再更新</p>
</li>
</ul>
<h3 id="jks、pfx和cer-证书文件"><a href="#jks、pfx和cer-证书文件" class="headerlink" title="jks、pfx和cer 证书文件"></a>jks、pfx和cer 证书文件</h3><ul>
<li>jks是JAVA的keytools证书工具支持的证书私钥格式。</li>
<li>pfx是微软支持的私钥格式。</li>
<li>cer是证书的公钥。</li>
</ul>
<h3 id="权威证书颁发的公钥匙一般是预装的"><a href="#权威证书颁发的公钥匙一般是预装的" class="headerlink" title="权威证书颁发的公钥匙一般是预装的"></a>权威证书颁发的公钥匙一般是预装的</h3><ul>
<li><p><a href="https://www.cnblogs.com/yungyu16/p/13329305.html">SSL&#x2F;TLS协议详解(中)——证书颁发机构</a></p>
</li>
<li><p>当我们安装浏览器或操作系统时，将会附有一组证书颁发机构，例如DigiCert。当浏览器自带DigiCert时，这意味着浏览器具有DigiCert的公钥，网站可以向DigiCert索取证书和签名。因此，DigiCert将使用DigiCerts私钥在服务器证书上进行加密签名。当我们发起连接时，服务器将发送嵌入了其公钥的证书。由于浏览器具有DigiCert的公钥，因此可以在服务器证书上验证DigiCert的签名，同时也说明证书上写的服务器的公钥是可信的。</p>
</li>
<li><p>根据RSA的加密原理，如果用CA的公钥解密成功，说明该证书的确是用CA的私钥加密的，可以认为被验证方是可信的。</p>
</li>
</ul>
<h2 id="HTTP-x2F-2"><a href="#HTTP-x2F-2" class="headerlink" title="HTTP&#x2F;2"></a>HTTP&#x2F;2</h2><ul>
<li>全双工</li>
<li>二进制格式传输、多路复用、header压缩、服务端推送、优先级和依赖关系、重置、流量控制</li>
</ul>
<h3 id="多路复用-Multiplexing"><a href="#多路复用-Multiplexing" class="headerlink" title="多路复用(Multiplexing)"></a>多路复用(Multiplexing)</h3><ul>
<li>客户端发送多个请求和服务端给出多个响应的顺序不受限制, 避免”队头堵塞” </li>
<li>每个数据流都有一个唯一的编号，从而让请求和响应对应起来</li>
<li>客户端和服务器 可以发生信号取消某个数据流，并保持这个连接</li>
<li>客户端还可以提升提升某个数据流优先级</li>
</ul>
<h3 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h3><ul>
<li>HTTP&#x2F;2 沒规定一定要使用加密（例如 SSL），但目前大部分浏览器的 HTTP&#x2F;2 都需要在 HTTPs上运行</li>
<li>gRPC 虽然使用 HTTP&#x2F;2，但默认并没有需要配置加密证书</li>
</ul>
<h3 id="重用连接（针对浏览器）"><a href="#重用连接（针对浏览器）" class="headerlink" title="重用连接（针对浏览器）"></a>重用连接（针对浏览器）</h3><ul>
<li>使用HTTP1.1协议，浏览器为了快速，针对同一域名设置了一定的并发数，稍微加快速度</li>
<li>使用HTTP&#x2F;2，浏览器针对同一个域名的资源，只建立一个tcp连接通道</li>
</ul>
<h3 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a>头部压缩</h3><ul>
<li>头部压缩也存在一些缺点 ，不管是Client还是Server，都要维护索引表，以确定每个索引值对应HTTP header的信息，通过占用更多内存换取数据量传输的减少（空间换时间）。</li>
</ul>
<h3 id="推送"><a href="#推送" class="headerlink" title="推送"></a>推送</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/OyogMagLsm2jh2pgg0Symw">Chrome将禁用HTTP&#x2F;2服务器推送（Server Push）支持</a><ul>
<li>这功能逻辑本身就有问题，比如资源存放在单个业务服务器上，并行推送多个静态资源只会降低响应速度，性能不升反降。而对于前后端分离的业务来说，HTTP&#x2F;2 本身就支持多路复用，server push 只能稍微降低浏览器解析 html 的时间，对现代浏览器来说性能提升可以忽略不计。</li>
</ul>
</li>
</ul>
<h2 id="HTTP-x2F-3"><a href="#HTTP-x2F-3" class="headerlink" title="HTTP&#x2F;3"></a>HTTP&#x2F;3</h2><ul>
<li><p>HTTP&#x2F;1.x 有连接无法复用、队头阻塞、协议开销大和安全因素等多个缺陷</p>
</li>
<li><p>HTTP&#x2F;2 通过多路复用、二进制流、Header 压缩等等技术，极大地提高了性能，但是还是存在着问题的</p>
</li>
<li><p>QUIC 基于 UDP 实现，是 HTTP&#x2F;3 中的底层支撑协议，该协议基于 UDP，又取了 TCP 中的精华，实现了即快又可靠的协议</p>
</li>
<li><p>HTTP3.0，也称作HTTP over QUIC。HTTP3.0的核心是QUIC(读音quick)协议，由Google在2015年提出的SPDY v3演化而来的新协议，传统的HTTP协议是基于传输层TCP的协议，而QUIC是基于传输层UDP上的协议，可以定义成：HTTP3.0基于UDP的安全可靠的HTTP2.0协议。</p>
</li>
<li><p>在网络条件较差的情况下，HTTP&#x2F;3在增强网页浏览体验方面的效果非常好 </p>
</li>
<li><p>TCP从来就不适合处理有损无线环境中的数据传输</p>
</li>
<li><p>TCP中的行头阻塞</p>
</li>
</ul>
<h3 id="TCP的限制"><a href="#TCP的限制" class="headerlink" title="TCP的限制"></a>TCP的限制</h3><ol>
<li>TCP可能会间歇性地挂起数据传输<ul>
<li>TCP流的行头阻塞（HoL）: 序列号较低的数据段丢包问题，导致阻塞</li>
</ul>
</li>
<li>TCP不支持流级复用</li>
<li>TCP会产生冗余通信<ul>
<li>TCP连接握手会有冗余的消息交换序列，即使是与已知主机建立的连接也是如此。</li>
</ul>
</li>
</ol>
<h3 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h3><ul>
<li>选择UDP作为底层传输层协议。抛弃TCP的缺点（TCP传输确认、重传慢启动等），同时。此外QUIC是用户层协议，不需要每次协议升级时修改内核；</li>
<li>流复用和流控：解决了行头阻塞问题。</li>
<li>灵活的拥塞控制机制、更好的错误处理能力、更快的握手</li>
<li>新的HTTP头压缩机制，称为QPACK，是对HTTP&#x2F;2中使用的HPACK的增强（QUIC流是不按顺序传递的，在不同的流中可能包含不同的HTTP头）</li>
</ul>
<h3 id="采用HTTP-x2F-3的限制"><a href="#采用HTTP-x2F-3的限制" class="headerlink" title="采用HTTP&#x2F;3的限制"></a>采用HTTP&#x2F;3的限制</h3><ul>
<li>不仅涉及到应用层的变化，还涉及到底层传输层的变化</li>
<li>UDP会话会被防火墙的默认数据包过滤策略所影响</li>
<li>中间层，如防火墙、代理、NAT设备等需要兼容</li>
<li>需迫使中间层厂商标准化</li>
<li>HTTP&#x2F;3在现有的UDP之上，以QUIC的形式在传输层处理，增加了HTTP&#x2F;3在整个协议栈中的占用空间。这使得HTTP&#x2F;3较为笨重，不适合某些IoT设备</li>
<li>NGINX和Apache等主流web服务器需要支持</li>
</ul>
<h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><h3 id="HTTP-与-TCP-backlog关系"><a href="#HTTP-与-TCP-backlog关系" class="headerlink" title="HTTP 与 TCP backlog关系"></a>HTTP 与 TCP backlog关系</h3><ol>
<li>没直接关系</li>
<li>HTTP是应用层协议，TCP backlog 是应用程序在操作系统层接收tcp连接的队列数</li>
<li>比如tomcat，作为一个HTTP应用服务，TCP backlog对应其acceptCount的配置</li>
</ol>
<h3 id="关于-HTTP-keepalive"><a href="#关于-HTTP-keepalive" class="headerlink" title="关于 HTTP keepalive"></a>关于 HTTP keepalive</h3><ul>
<li><p>要利用HTTP的keep-alive机制，需要服务器端和客户端同时支持</p>
</li>
<li><p>HTTP是应用层协议，具体的表现行为取决于HTTP服务器以及HTTP client的实现</p>
</li>
<li><p><a href="https://blog.csdn.net/Kingson_Wu/article/details/72512825">wireshark抓包简单查看HTTP keep-alive原理</a></p>
</li>
<li><p><a href="https://blog.csdn.net/Kingson_Wu/article/details/80102077">继续深入理解HTTP keepalive</a></p>
</li>
</ul>
<ol>
<li>keepalive 是否开启服务端控制还是客户端控制？<ul>
<li>keepalive可以由双方共同控制，需要双方都开启才能生效，HTTP1.1客户端默认开启，客户端想关闭可以通过设置Connection: Close，服务端同样想关闭可以设置Connection: Close。双方哪方先收到Connection: Close 则由收到方关闭（前提是双方的实现都支持，比如telnet就不支持）</li>
</ul>
</li>
<li>keepalive的时间是由服务端控制还是客户端控制？<ul>
<li>时间主要还是由服务端控制，时间一到由服务端主动关闭，当然客户端如果有实现设置一定时间后，由客户端主动关闭也可以。一般的HTTPclient库都有提供相应的配置，设置关闭长期不使用的连接，如connectionManager.closeIdleConnections(readTimeout * 2, TimeUnit.MILLISECONDS);</li>
<li><a href="https://my.oschina.net/greki/blog/83350">HTTPs://my.oschina.net/greki/blog/83350</a></li>
</ul>
</li>
<li>keepalive时间一到，是由客户端主动关闭还是服务端主动关闭？<ul>
<li>哪方的时间短，由哪一方来关闭，除非双方的实现有更明确的协议</li>
</ul>
</li>
<li>如果客户端不是HTTPclient，使用telnet连接服务端？<ul>
<li>telnet客户端除了连接时进行三次握手，用来发送数据接收数据，基本无其他实现逻辑。即接收到服务器的响应之后，不会有相关HTTP协议的处理。</li>
</ul>
</li>
</ol>
<h3 id="HTTP-keepalive-VS-TCP-keepalive"><a href="#HTTP-keepalive-VS-TCP-keepalive" class="headerlink" title="HTTP keepalive VS TCP keepalive"></a>HTTP keepalive VS TCP keepalive</h3><ul>
<li><a href="https://zhuanlan.zhihu.com/p/385597183">HTTPs://zhuanlan.zhihu.com/p/385597183</a>; <a href="https://juejin.cn/post/6992845852192702477">HTTPs://juejin.cn/post/6992845852192702477</a></li>
<li>HTTP 的 Keep-Alive，是由应用层（用户态）  实现的，称为 HTTP 长连接；</li>
<li>TCP 的 Keepalive，是由 TCP 层（内核态）  实现的，称为 TCP 保活机制；</li>
<li>HTTP协议的Keep-Alive意图在于短时间内连接复用，希望可以短时间内在同一个连接上进行多次请求&#x2F;响应。</li>
<li>TCP的KeepAlive机制意图在于保活、心跳，检测连接错误。当一个TCP连接两端长时间没有数据传输时(通常默认配置是2小时)，发送keepalive探针，探测链接是否存活。</li>
<li>tcp的keepalive是在ESTABLISH状态的时候，双方如何检测连接的可用行。而HTTP的keep-alive说的是如何避免进行重复的TCP三次握手和四次挥手的环节。</li>
<li>总之，HTTP的Keep-Alive和TCP的KeepAlive不是一回事。</li>
</ul>
<h3 id="Chrome中HTTP下载续传原理"><a href="#Chrome中HTTP下载续传原理" class="headerlink" title="Chrome中HTTP下载续传原理"></a>Chrome中HTTP下载续传原理</h3><ul>
<li><a href="https://kingson4wu.github.io/2022/08/30/20220830-Chrome%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%97%B6%E6%9A%82%E5%81%9C%E5%92%8C%E7%BB%A7%E7%BB%AD%E6%98%AF%E4%BB%80%E4%B9%88%E5%8E%9F%E7%90%86%EF%BC%9F/">Chrome下载文件时暂停和继续是什么原理？</a></li>
</ul>
<h3 id="HTTP连接复用时，同一个连接上的多个请求和响应如何对应上？"><a href="#HTTP连接复用时，同一个连接上的多个请求和响应如何对应上？" class="headerlink" title="HTTP连接复用时，同一个连接上的多个请求和响应如何对应上？"></a>HTTP连接复用时，同一个连接上的多个请求和响应如何对应上？</h3><ul>
<li>“队头堵塞”（Head-of-line blocking）：所有的请求-响应都是按序进行的（HTTP）</li>
<li>多路复用(Multiplexing)：每个数据流都有一个唯一的编号，从而让请求和响应对应起来（HTTP&#x2F;2）</li>
</ul>
<h3 id="可以外网使用HTTP-x2F-3，再转发到内网的HTTP服务？"><a href="#可以外网使用HTTP-x2F-3，再转发到内网的HTTP服务？" class="headerlink" title="可以外网使用HTTP&#x2F;3，再转发到内网的HTTP服务？"></a>可以外网使用HTTP&#x2F;3，再转发到内网的HTTP服务？</h3><ul>
<li>上层nginx使用HTTP3，下层应用服务器（如spring boot jetty等）还是使用HTTP，其实理论上是可以的。nginx转发时要由接受到的udp包改成tcp发送。（内网丢包概率一般应该比外网丢包低很多），如果采用这种转发方式，这就意味着内网无法使用四层负载转发，因为底层协议不一样（udp和tcp）</li>
<li>现在主流的代理服务Nginx&#x2F;Apache都没有实现QUIC，一些比较小众的代理服务如Caddy就实现了</li>
</ul>
<h3 id="使用HTTPS还存在中间人攻击？"><a href="#使用HTTPS还存在中间人攻击？" class="headerlink" title="使用HTTPS还存在中间人攻击？"></a>使用HTTPS还存在中间人攻击？</h3><ul>
<li><p>结论：可以避免。只要不信任不安全的HTTPs网站，就不会被中间人攻击</p>
</li>
<li><p>中间人攻击:<a href="https://urlify.cn/zQj6f2">HTTPs://urlify.cn/zQj6f2</a></p>
</li>
<li><p>既然证书是公开的，如果要发起中间人攻击，我在官网上下载一份证书作为我的服务器证书，那客户端肯定会认同这个证书是合法的，如何避免这种证书冒用的情况？<br>其实这就是非加密对称中公私钥的用处，虽然中间人可以得到证书，但私钥是无法获取的，一份公钥是不可能推算出其对应的私钥，中间人即使拿到证书也无法伪装成合法服务端，因为无法对客户端传入的加密数据进行解密。</p>
</li>
<li><p>只要客户端是我们自己的终端，我们授权的情况下，便可以组建中间人网络，而抓包工具便是作为中间人的代理。</p>
</li>
</ul>
<pre>
Q: 为什么需要证书？
A: 防止”中间人“攻击，同时可以为网站提供身份证明。

Q: 使用 HTTPS 会被抓包吗？
A: 会被抓包，HTTPS 只防止用户在不知情的情况下通信被监听，如果用户主动授信，是可以构建“中间人”网络，代理软件可以对传输内容进行解密。
</pre> 

<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="cURL-发-HTTP-x2F-2请求"><a href="#cURL-发-HTTP-x2F-2请求" class="headerlink" title="cURL 发 HTTP&#x2F;2请求"></a>cURL 发 HTTP&#x2F;2请求</h3><ol>
<li>Mac OS Curl HTTP&#x2F;2 支持<br><code> brew install curl --with-ngHTTP2</code></li>
</ol>
<pre>
/usr/local/Cellar/curl/7.50.3/bin/curl --HTTP2 -kI  HTTPs://localhost:8443/user/1
HTTP/2 200
server: Jetty(9.3.10.v20160621)
date: Sun, 30 Oct 2016 02:08:46 GMT
content-type: application/json;charset=UTF-8
content-length: 23
</pre>

<ol start="2">
<li>linux:<a href="https://www.sysgeek.cn/curl-with-HTTP2-support/">HTTPs://www.sysgeek.cn/curl-with-HTTP2-support/</a></li>
</ol>
<h3 id="HTTP-x2F-3-握手优化"><a href="#HTTP-x2F-3-握手优化" class="headerlink" title="HTTP&#x2F;3 握手优化"></a>HTTP&#x2F;3 握手优化</h3><ul>
<li>1倍时延 &#x3D; 一次单向传输时延 &#x3D; 0.5 RTT</li>
<li><a href="https://mp.weixin.qq.com/s/Xo9HgZXfn28VibIE9OFHqw">HTTPS 的 7 次握手以及 9 倍时延</a></li>
<li>HTTPS: 7 次握手以及 9 倍时延 (4.5 RTT); HTTP&#x2F;3: 3 次握手以及 5 倍时延 (2.5 RTT)<pre>
当客户端想要通过 HTTPS 请求访问服务端时，整个过程需要经过 7 次握手并消耗 9 倍的延迟。如果客户端和服务端因为物理距离上的限制，RTT 约为 40ms 时，第一次请求需要 ~180ms；不过如果我们想要访问美国的服务器，RTT 约为 200ms 时，这时 HTTPS 请求的耗时为 ~900ms，这就是一个比较高的耗时了。我们来总结一下 HTTPS 协议需要 9 倍时延才能完成通信的原因：</pre></li>
</ul>
<p>TCP 协议需要通过三次握手建立 TCP 连接保证通信的可靠性（1.5-RTT）；<br>TLS 协议会在 TCP 协议之上通过四次握手建立 TLS 连接保证通信的安全性（2-RTT）；<br>HTTP 协议会在 TCP 和 TLS 上通过一次往返发送请求并接收响应（1-RTT）；<br>需要注意的是，本文对往返延时的计算都基于特定的场景以及特定的协议版本，网络协议的版本在不断更新和演进，过去忽略的问题最开始都会通过补丁的方式更新，但是最后仍然会需要从底层完成重写。</p>
<p>HTTP&#x2F;3 就是一个这样的例子，它会使用基于 UDP 的 QUIC 协议进行握手，将 TCP 和 TLS 的握手过程结合起来，把 7 次握手减少到了 3 次握手，直接建立了可靠并且安全的传输通道，将原本 ~900ms 的耗时降低至 ~500ms，<br></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.cnblogs.com/XiongMaoMengNan/p/8425724.html">HTTP协议篇(一)：多路复用、数据流</a></li>
<li><a href="https://developer.aliyun.com/article/436989">HTTP管线化(HTTP pipelining)</a></li>
<li><a href="https://imququ.com/post/HTTP2-resource.html">HTTP&#x2F;2 资料汇总</a></li>
<li><a href="https://www.codetd.com/article/10088188">HTTP，HTTPs，spdy，HTTP2等协议的主要区别详解</a></li>
<li><a href="https://www.infoq.cn/article/IgME_4ebP3d46m3tHbaT">一文看完 HTTP3 的演化历程</a></li>
<li><a href="https://mp.weixin.qq.com/s/i-QUbVRVicqzMSZ9FUVCfQ">深入解读HTTP3的原理及应用</a></li>
<li><a href="https://urlify.cn/zQj6f2">HTTPS 原理分析——带着疑问层层深入</a></li>
</ul>
]]></content>
      <tags>
        <tag>HTTP</tag>
        <tag>HTTP/3</tag>
        <tag>HTTP/2</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title>有了TCP的keepalive，应用层还需要实现保活逻辑吗？</title>
    <url>/2022/09/06/20220906-you-liao-tcp-de-keepalive-ying-yong-ceng-huan-xu-yao-shi-xian-bao-huo-luo-ji-ma/</url>
    <content><![CDATA[<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul>
<li>对于实时性高的业务，基本都需要在应用层自行实现保活逻辑，应用层的心跳协议是必不可少的</li>
</ul>
<h2 id="TCP-keepalive-的-问题"><a href="#TCP-keepalive-的-问题" class="headerlink" title="TCP keepalive 的 问题"></a>TCP keepalive 的 问题</h2><ol>
<li>检测周期长，开启后默认是2h（系统内核参数 tcp_keepalive_time），这就意味着服务端可能维持着一个死连接；</li>
<li>TCP keepalive 是由操作系统负责探查，即便进程死锁，或阻塞等，操作系统也会收发 TCP keepalive 消息，无法及时感知客户端已经实际已经下线；</li>
</ol>
<h2 id="应用层实现心跳的基本做法"><a href="#应用层实现心跳的基本做法" class="headerlink" title="应用层实现心跳的基本做法"></a>应用层实现心跳的基本做法</h2><ol>
<li>服务端和客户端都开启tcp keepalive</li>
<li>客户端定时发心跳包到服务端</li>
<li>服务端根据自定义的规则，在一定时间内收不到心跳包的时，断开客户端的连接。</li>
</ol>
<h2 id="应用层实现心跳保活逻辑的好处"><a href="#应用层实现心跳保活逻辑的好处" class="headerlink" title="应用层实现心跳保活逻辑的好处"></a>应用层实现心跳保活逻辑的好处</h2><ol>
<li>可以在发送心跳包的同时顺带业务或指令数据，这样服务端获得客户端的详细状态，同时可以更好满足业务场景</li>
<li>可以灵活控制探查客户端的时间和策略，更快下线有异常的连接，减少服务端不必要的负担</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="http://www.zhihu.com/question/35013918">在以TCP为连接方式的服务器中，为什么在服务端设计当中需要考虑心跳？</a></li>
<li><a href="https://www.felix021.com/blog/read.php?2076">闲说HeartBeat心跳包和TCP协议的KeepAlive机制</a></li>
<li><a href="http://www.nowamagic.net/academy/detail/23350382">TCP协议的KeepAlive机制与HeartBeat心跳包</a></li>
</ul>
]]></content>
      <tags>
        <tag>TCP</tag>
        <tag>keepalive</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP连接中的各种状态</title>
    <url>/2022/09/07/20220907-tcp-lian-jie-zhong-de-ge-chong-zhuang-tai/</url>
    <content><![CDATA[<p><img src="/2022/09/07/20220907-tcp-lian-jie-zhong-de-ge-chong-zhuang-tai/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png"></p>
<p><img src="/2022/09/07/20220907-tcp-lian-jie-zhong-de-ge-chong-zhuang-tai/TCP%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96.png"></p>
<h2 id="状态说明"><a href="#状态说明" class="headerlink" title="状态说明"></a>状态说明</h2><ul>
<li>CLOSED：无连接是活动的或正在进行</li>
<li>LISTEN：服务器在等待进入呼叫</li>
<li>SYN_RECV：一个连接请求已经到达，等待确认</li>
<li>SYN_SENT：应用已经开始，打开一个连接</li>
<li>ESTABLISHED：正常数据传输状态</li>
<li>FIN_WAIT1：应用说它已经完成</li>
<li>FIN_WAIT2：另一边已同意释放</li>
<li>ITMED_WAIT：等待所有分组死掉</li>
<li>CLOSING：两边同时尝试关闭</li>
<li>TIME_WAIT：另一边已初始化一个释放</li>
<li>LAST_ACK：等待所有分组死掉</li>
</ul>
<h3 id="flags-标志"><a href="#flags-标志" class="headerlink" title="flags 标志"></a>flags 标志</h3><ul>
<li>S(SYN)</li>
<li>F(FIN)</li>
<li>P(PUSH)</li>
<li>R(RST)</li>
</ul>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="查看主机上的TCP连接状态"><a href="#查看主机上的TCP连接状态" class="headerlink" title="查看主机上的TCP连接状态"></a>查看主机上的TCP连接状态</h3><ul>
<li><code>netstat –an</code></li>
<li><code>netstat –an |grep &#39;CLOSE_WAIT&#39;</code></li>
<li><code>ss -t -n|grep 5000</code></li>
</ul>
<h3 id="统计当前各种状态的连接的数量的命令"><a href="#统计当前各种状态的连接的数量的命令" class="headerlink" title="统计当前各种状态的连接的数量的命令"></a>统计当前各种状态的连接的数量的命令</h3><ul>
<li><code>netstat -n | awk &#39;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&#39;</code></li>
</ul>
<h3 id="查看指定端口的连接"><a href="#查看指定端口的连接" class="headerlink" title="查看指定端口的连接"></a>查看指定端口的连接</h3><ul>
<li><code>netstat -an | awk &#39;NR==2 || $4~/65016/&#39;</code>（client）</li>
<li><code>netstat -an | awk &#39;NR==2 || $5~/8080/&#39;</code>（server）</li>
</ul>
<h3 id="Linux-netstat命令详解"><a href="#Linux-netstat命令详解" class="headerlink" title="Linux netstat命令详解"></a>Linux netstat命令详解</h3><ul>
<li><a href="http://www.cnblogs.com/ggjucheng/archive/2012/01/08/2316661.html">http://www.cnblogs.com/ggjucheng/archive/2012/01/08/2316661.html</a></li>
</ul>
<h3 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h3><ul>
<li><p>想知道我们可以通过哪几个网卡抓包，可以使用-D参数 : <code>tcpdump –D</code></p>
</li>
<li><p>将抓包结果存放在文件中(可以用Wireshark打开查看) : <code>tcpdump –w google.cap</code></p>
</li>
<li><p>其中http协议的数据包都给过滤出来: <code>tcpdump –r google.cap http</code></p>
</li>
<li><p><a href="http://www.cnblogs.com/zhuimengle/p/5737848.html">http://www.cnblogs.com/zhuimengle/p/5737848.html</a></p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="http://elf8848.iteye.com/blog/1739571">TCP&#x2F;IP TIME_WAIT状态原理</a></li>
</ul>
<h2 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h2><ul>
<li><a href="https://blog.csdn.net/yunhua_lee/article/details/40513677">tcp 三次握手和四次断连深入分析：连接状态和socket API的关系</a><ul>
<li>close函数其实本身不会导致tcp协议栈立刻发送fin包，而只是将socket文件的引用计数减1，当socket文件的引用计数变为0的时候，操作系统会自动关闭tcp连接，此时才会发送fin包。</li>
<li>这也是多进程编程需要特别注意的一点，父进程中一定要将socket文件描述符close，否则运行一段时间后就可能会出现操作系统提示too many open files</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>TIME_WAIT解析</title>
    <url>/2022/09/07/20220907-time-wait-jie-xi/</url>
    <content><![CDATA[<p><img src="/2022/09/07/20220907-time-wait-jie-xi/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.jpeg"></p>
<h2 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT"></a>TIME_WAIT</h2><ul>
<li>通信双方建立TCP连接后，主动关闭(FIN)连接的一方就会进入TIME_WAIT状态<ul>
<li>客户端主动关闭连接时，发送最后一个ack后，会进入TIME_WAIT状态，再停留2个MSL时间，进入CLOSED状态</li>
</ul>
</li>
</ul>
<h2 id="TIME-WAIT状态存在的理由"><a href="#TIME-WAIT状态存在的理由" class="headerlink" title="TIME_WAIT状态存在的理由"></a>TIME_WAIT状态存在的理由</h2><ol>
<li><p>可靠地实现TCP全双工连接的终止</p>
<ul>
<li>TCP协议在关闭连接的四次握手过程中，最终的ACK是由主动关闭连接的一端（后面统称A端）发出的，如果这个ACK丢失，对方（后面统称B端）将重发出最终的FIN，因此A端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A端不维持TIME_WAIT状态，而是处于CLOSED 状态，那么A端将响应RST分节，B端收到后将此分节解释成一个错误（在java中会抛出connection reset的SocketException)。</li>
<li>因而，要实现TCP全双工连接的正常终止，必须处理终止过程中四个分节任何一个分节的丢失情况，主动关闭连接的A端必须维持TIME_WAIT状态 。</li>
<li>对一个具体实现所给定的MSL值，处理的原则是：当TCP执行一个主动关闭，并发回最后一个ACK，该连接必须在TIMEWAIT状态停留的时间为2倍的MSL。这样可尽可能让TCP再次发送最后的ACK以防这个ACK丢失(另一端超时并重发最后的FIN)。</li>
<li>总结：尽量避免主动关闭方ack丢失导致被关闭方异常（理论上从应用层看，被关闭方需要对这种异常进行处理，因为万一主动关闭方断电了呢）</li>
</ul>
</li>
<li><p>允许老的重复分节在网络中消逝</p>
<ul>
<li>TCP分节可能由于路由器异常而“迷途”，在迷途期间，TCP发送端可能因确认超时而重发这个分节，迷途的分节在路由器修复后也会被送到最终目的地，这个迟到的迷途分节到达时可能会引起问题。在关闭“前一个连接”之后，马上又重新建立起一个相同的IP和端口之间的“新连接”，“前一个连接”的迷途重复分组在“前一个连接”终止后到达，而被“新连接”收到了。为了避免这个情况，TCP协议不允许处于TIME_WAIT状态的连接启动一个新的可用连接，因为TIME_WAIT状态持续2MSL，基本可以保证当成功建立一个新TCP连接的时候，来自旧连接重复分组已经在网络中消逝。</li>
<li>IP包的最大生存时间记录在其TTL字段中，即MSL，超过将过期丢弃</li>
</ul>
</li>
</ol>
<h2 id="MSL时间"><a href="#MSL时间" class="headerlink" title="MSL时间"></a>MSL时间</h2><ul>
<li>MSL就是maximum segment lifetime(最大分节生命期），这是一个IP数据包能在互联网上生存的最长时间，超过这个时间IP数据包将在网络中消失 。MSL在RFC 1122上建议是2分钟，而源自berkeley的TCP实现传统上使用30秒。<br>TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL字段  </li>
<li>TIME_WAIT状态维持时间是两个MSL时间长度，也就是在1-4分钟。Windows操作系统就是4分钟。</li>
<li>为什么需要2MSL？<ul>
<li>第一个MSL是为了等自己发出去的最后一个ACK从网络中消失，同时让旧的数据包基本在网络中消失；</li>
<li>第二MSL是为了等在对端收到ACK之前的一刹那可能重传的FIN报文从网络中消失（主要目的）</li>
<li>问题：重传的FIN报文会重传多少次？<ul>
<li>重发次数由 tcp_orphan_retries 参数控制</li>
</ul>
</li>
<li>所以如果最后一个ack丢了，且对端又重试发FIN，那么还是无法避免FIN包没过期，所以2MSL只是尽可能，但这时旧的数据包基本消失了</li>
</ul>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>TIME_WAIT主动关闭方的状态  </li>
<li>TIME_WAIT存在的原因<ol>
<li>防止主动关闭方最后的ACK丢失，确保远程TCP接收到连接中断的请求</li>
<li>允许老的重复数据包在网络中过期</li>
</ol>
</li>
</ul>
<h2 id="TIME-WAIT产生的场景"><a href="#TIME-WAIT产生的场景" class="headerlink" title="TIME_WAIT产生的场景"></a>TIME_WAIT产生的场景</h2><ul>
<li>进入TIME_WAIT状态的一般情况下是客户端。</li>
<li>大多数服务器端一般执行被动关闭，服务器不会进入TIME_WAIT状态。<br>但在服务器端关闭某个服务再重新启动时，服务器是会进入TIME_WAIT状态的。<br>可以使用SO_REUSEADDR选项来复用端口。</li>
</ul>
<pre>
举例：
1.客户端连接服务器的80服务，这时客户端会启用一个本地的端口访问服务器的80，访问完成后关闭此连接，立刻再次访问服务器的
80，这时客户端会启用另一个本地的端口，而不是刚才使用的那个本地端口。原因就是刚才的那个连接还处于TIME_WAIT状态。
2.客户端连接服务器的80服务，这时服务器关闭80端口，立即再次重启80端口的服务，这时可能不会成功启动，原因也是服务器的连
接还处于TIME_WAIT状态。
</pre>

<h2 id="作为客户端和服务器"><a href="#作为客户端和服务器" class="headerlink" title="作为客户端和服务器"></a>作为客户端和服务器</h2><ol>
<li>服务端提供服务时，一般监听一个端口就够了；</li>
<li>客户端则是使用一个本地的空闲端口（大于1024），与服务器的端口建立连接；<ul>
<li>如果使用短连接请求，那么客户端将会产生大量TIME_WAIT状态的端口（本地最多就能承受6万个TIME_WAIT状态的连接就无端口可用了，后续的短连接就会产生address already in use : connect的异常）</li>
<li>因此，作为短连接请求的压测服务器，不能在短时间连续使用；</li>
<li>一般来说一台机器可用Local Port 3万多个，如果是短连接的话，一个连接释放后默认需要60秒回收，30000&#x2F;60 &#x3D;500 这是大概的理论TPS值</li>
</ul>
</li>
<li>一个提供高并发的服务器，同时依赖第三方服务（间接看来服务端也作为第三方服务的客户端），怎么应对 ？<ul>
<li>一般情况都是启用keepalive选项，避免短连接服务（一般依赖方也不会多达几千个，即调用的ip和端口不一样）</li>
<li>启用SO_REUSEADDR选项</li>
</ul>
</li>
<li>大多数服务器端一般执行被动关闭，服务器不会进入TIME_WAIT状态</li>
</ol>
<h2 id="如何复用TIME-WAIT端口"><a href="#如何复用TIME-WAIT端口" class="headerlink" title="如何复用TIME_WAIT端口"></a>如何复用TIME_WAIT端口</h2><ol>
<li>应用层发出请求前指定，如何Java HttpClient中设置reuseaddr<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">httpClient.setHttpRequestRetryHandler(<span class="keyword">new</span> <span class="title class_">DefaultHttpRequestRetryHandler</span>());</span><br><span class="line">httpClient.setReuseStrategy(<span class="keyword">new</span> <span class="title class_">DefaultConnectionReuseStrategy</span>());</span><br><span class="line">httpClient.setKeepAliveStrategy(<span class="keyword">new</span> <span class="title class_">DefaultConnectionKeepAliveStrategy</span>());</span><br></pre></td></tr></table></figure></li>
<li>调整内核参数（net.ipv4.tcp_tw_reuse）</li>
</ol>
<h2 id="总结避免TIME-WAIT的方法"><a href="#总结避免TIME-WAIT的方法" class="headerlink" title="总结避免TIME_WAIT的方法"></a>总结避免TIME_WAIT的方法</h2><ol>
<li>使用长连接（基本大部分业务场景都可以）</li>
<li>避免主动关闭</li>
<li>关闭的时候使用RST的方式 （比如程序中设置socket的SO_LINGER选项）(应用层貌似不是很方便实现)</li>
<li>TIME_WAIT状态的TCP允许重用</li>
<li>增大可用端口范围，默认是 net.ipv4.ip_local_port_range &#x3D; 32768 61000 （即对同一个服务器的ip+port可创建28233个连接）（只能缓解问题，不能根本解决问题）</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.iteye.com/blog/elf8848-1739571">TCP&#x2F;IP TIME_WAIT状态原理</a></li>
<li><a href="https://blog.51cto.com/kerry/105233">发现大量的TIME_WAIT解决办法</a></li>
<li>[《TCP IP详解卷一》18.6.1]</li>
<li><a href="https://mp.weixin.qq.com/s/LNWv5I-klJCBCX4e84WbTQ">为什么 TCP 协议有 TIME_WAIT 状态</a></li>
<li><a href="https://www.cnblogs.com/joker1937/articles/12487776.html">TCP四次挥手为何需要TIME_WAIT以及为何是2MSL？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/398890723">TCP 才不傻：三次握手和四次挥手的异常处理</a></li>
<li><a href="https://www.helloworld.net/p/4875307437">tcp短连接TIME_WAIT问题解决方法大全</a></li>
</ul>
]]></content>
      <tags>
        <tag>TCP</tag>
        <tag>TIME_WAIT</tag>
      </tags>
  </entry>
  <entry>
    <title>你记得设置TCP_NODEPLAY吗？</title>
    <url>/2022/09/07/20220907-ni-ji-de-she-zhi-tcp-nodeplay-ma/</url>
    <content><![CDATA[<ul>
<li><p>有接触过TCP服务器实现的同学都会知道，需要注意TCP_NODELAY参数，为什么呢？</p>
</li>
<li><p>若没有开启TCP_NODELAY，那么在发送小包的时候，可能会出现这样的现象：<br>通过 TCP socket 分多次发送较少的数据时，比如小于 1460 或者 100 以内，对端可能会很长时间收不到数据，导致本端应用程序认为超时报错。</p>
</li>
</ul>
<h2 id="Nagle算法（Nagle‘s-Algorithm）"><a href="#Nagle算法（Nagle‘s-Algorithm）" class="headerlink" title="Nagle算法（Nagle‘s Algorithm）"></a>Nagle算法（Nagle‘s Algorithm）</h2><ul>
<li><p>TCP&#x2F;IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。（一个连接会设置MSS参数，因此，TCP&#x2F;IP希望每次都能够以MSS尺寸的数据块来发送数据）。</p>
</li>
<li><p>Nagle算法就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。</p>
</li>
<li><p>Nagle算法的基本定义是任意时刻，最多只能有一个未被确认的小段。 所谓“小段”，指的是小于MSS尺寸的数据块，所谓“未被确认”，是指一个数据块发送出去后，没有收到对方发送的ACK确认该数据已收到。</p>
</li>
<li><p>举个例子，一开始client端调用socket的write操作将一个int型数据(称为A块)写入到网络中，由于此时连接是空闲的（也就是说还没有未被确认的小段），因此这个int型数据会被马上发送到server端，接着，client端又调用write操作写入一个int型数据（简称B块），这个时候，A块的ACK没有返回，所以可以认为已经存在了一个未被确认的小段，所以B块没有立即被发送，一直等待A块的ACK收到（大概40ms之后）(ACK延迟机制的超时时间)，B块才被发送。</p>
</li>
<li><p>Nagle算法的改进在于：如果发送端欲多次发送包含少量字符的数据包（一般情况下，后面统一称长度小于MSS的数据包为小包，与此相对，称长度等于MSS的数据包为大包，为了某些对比说明，还有中包，即长度比小包长，但又不足一个MSS的包），则发送端会先将第一个小包发送出去，而将后面到达的少量字符数据都缓存起来而不立即发送，直到收到接收端对前一个数据包报文段的ACK确认、或当前字符属于紧急数据，或者积攒到了一定数量的数据（比如缓存的字符数据已经达到数据包报文段的最大长度）等多种情况才将其组成一个较大的数据包发送出去。<br> TCP在三次握手建立连接过程中，会在SYN报文中使用MSS（Maximum Segment Size）选项功能，协商交互双方能够接收的最大段长MSS值。</p>
</li>
</ul>
<h2 id="ACK延迟机制-TCP-Delayed-Acknoledgement"><a href="#ACK延迟机制-TCP-Delayed-Acknoledgement" class="headerlink" title="ACK延迟机制(TCP Delayed Acknoledgement)"></a>ACK延迟机制(TCP Delayed Acknoledgement)</h2><ul>
<li>TCP&#x2F;IP中不仅仅有Nagle算法(Nagle‘s Algorithm)，还有一个ACK延迟机制(TCP Delayed Ack) 。当Server端收到数据之后，它并不会马上向client端发送ACK，而是会将ACK的发送延迟一段时间（假设为t），它希望在t时间内server端会向client端发送应答数据，这样ACK就能够和应答数据一起发送，就像是应答数据捎带着ACK过去。</li>
<li>也就是如果一个 TCP 连接的一端启用了Nagle算法，而另一端启用了ACK延时机制，而发送的数据包又比较小，则可能会出现这样的情况：发送端在等待接收端对上一个packet的Ack才发送当前的packet，而接收端则正好延迟了此Ack的发送，那么这个正要被发送的packet就会同样被延迟。当然Delayed Ack是有个超时机制的，而默认的超时正好就是40ms。</li>
<li>现代的 TCP&#x2F;IP 协议栈实现，默认几乎都启用了这两个功能，那岂不每次都会触发这个延迟问题？事实不是那样的。仅当协议的交互是发送端连续发送两个packet，然后立刻read的时候才会出现问题。</li>
</ul>
<h2 id="总结：问题出现的三个条件"><a href="#总结：问题出现的三个条件" class="headerlink" title="总结：问题出现的三个条件"></a>总结：问题出现的三个条件</h2><ol>
<li>发送小包（仅当协议的交互是发送端连续发送两个 packet，然后立刻 read 的 时候才会出现问题。）</li>
<li>发送方启用了Nagle算法（发送方未接收到上一个包的ack，且待发送的是小包，则会等待）</li>
<li>接收方启用了ACK延时机制 且没及时准备好数据（希望响应ack可以和响应的数据一起发送，等待本端响应数据的准备）</li>
</ol>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><ul>
<li>开启TCP_NODELAY：禁用Nagle算法，禁止后当然就不会有它引起的一系列问题了。</li>
<li>优化协议：连续 write 小数据包，然后 read 其实是一个不好的网络编程模式，这样的连续 write 其实应该在应用层合并成一次 write。</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="另一个问题的例子-HTTP服务"><a href="#另一个问题的例子-HTTP服务" class="headerlink" title="另一个问题的例子(HTTP服务)"></a>另一个问题的例子(HTTP服务)</h3><ul>
<li><p><a href="https://cloud.tencent.com/developer/article/1621142">神秘的40毫秒延迟与TCP_NODELAY</a></p>
</li>
<li><p>接口响应时间在client端开启keepalive后连续请求时由0ms变成40ms</p>
</li>
<li><p>因为设计的一些不足，我没能做到把 短小的 HTTP Body 连同 HTTP Headers 一起发送出去，而是分开成两次调用实 现的，之后进入 epoll_wait 等待下一个 Request 被发送过来（相当于阻塞模 型里直接 read）。正好是 write-write-read 的模式</p>
</li>
<li><p>那么 write-read-write-read 会不会出问题呢？维基百科上的解释是不会：</p>
<ul>
<li>“The user-level solution is to avoid write-write-read sequences on sockets. write-read-write-read is fine. write-write-write is fine. But write-write-read is a killer. So, if you can, buffer up your little writes to TCP and send them all at once. Using the standard UNIX I&#x2F;O package and flushing write before each read usually works.”</li>
<li>我的理解是这样的：因为第一个 write 不会被缓冲，会立刻到达接收端，如果是 write-read-write-read 模式，此时接收端应该已经得到所有需要的数据以进行 下一步处理。接收端此时处理完后发送结果，同时也就可以把上一个packet 的 Ack 可以和数据一起发送回去，不需要 delay，从而不会导致任何问题。</li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://blog.csdn.net/majianfei1023/article/details/51558941">TCP_NODELAY和Nagle算法</a></li>
</ul>
]]></content>
      <tags>
        <tag>TCP</tag>
        <tag>TCP_NODELAY</tag>
      </tags>
  </entry>
  <entry>
    <title>我的几张TCP原理学习手绘图</title>
    <url>/2022/09/08/20220908-wo-de-ji-zhang-tcp-yuan-li-xue-xi-shou-hui-tu/</url>
    <content><![CDATA[<h2 id="网络寻址原理"><a href="#网络寻址原理" class="headerlink" title="网络寻址原理"></a>网络寻址原理</h2><p><img src="/2022/09/08/20220908-wo-de-ji-zhang-tcp-yuan-li-xue-xi-shou-hui-tu/%E7%BD%91%E7%BB%9C%E5%AF%BB%E5%9D%80%E5%8E%9F%E7%90%86.jpg"></p>
<h2 id="负载均衡模式"><a href="#负载均衡模式" class="headerlink" title="负载均衡模式"></a>负载均衡模式</h2><p><img src="/2022/09/08/20220908-wo-de-ji-zhang-tcp-yuan-li-xue-xi-shou-hui-tu/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%A8%A1%E5%BC%8F.jpg"></p>
]]></content>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>我的重构（翻译）经历</title>
    <url>/2022/10/18/20221018-wo-de-chong-gou-fan-yi-jing-li/</url>
    <content><![CDATA[<p><img src="/2022/10/18/20221018-wo-de-chong-gou-fan-yi-jing-li/messi4.png"></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ol>
<li>这里的重构基本指的是：把用A语言写的服务，使用B语言重写</li>
<li>工作的大部分内容其实就是人肉代码翻译</li>
<li>当然，重构通常也伴随的架构的优化和调整</li>
<li>最后，为了保证工作的顺利进行和服务的稳定切换，也总结了一些经验</li>
<li>下面将简要讲述作者的三段重构经历，分别是将三种不同的语言重构成Java（本人公司的所在的业务的主要语言就是Java，个人没特殊语言癖好），作者其实对这三种语言都不熟悉，是怎么完成重构任务的呢？</li>
</ol>
<h2 id="一、PHP重构成Java（“一比一”迁移）"><a href="#一、PHP重构成Java（“一比一”迁移）" class="headerlink" title="一、PHP重构成Java（“一比一”迁移）"></a>一、PHP重构成Java（“一比一”迁移）</h2><ul>
<li>负责该业务的模块</li>
<li>启动环境太复杂，较复杂的逻辑通过在线工具运行验证</li>
<li>和熟悉该业务的PHP同事合作</li>
<li>切换服务接口使用灰度策略和配置开关</li>
<li>覆盖好测试用例</li>
</ul>
<ul>
<li>没本地环境，必要时在线运行验证</li>
</ul>
<h2 id="二、C-重构成Java（站在“巨人的肩膀”上重新出发）"><a href="#二、C-重构成Java（站在“巨人的肩膀”上重新出发）" class="headerlink" title="二、C++重构成Java（站在“巨人的肩膀”上重新出发）"></a>二、C++重构成Java（站在“巨人的肩膀”上重新出发）</h2><ul>
<li>其他公司业务调整，业务并入，需复制一套业务功能基本相同的服务</li>
<li>通过参考原业务的代码，发现其中架构存在的问题，进行优化；参考其中的实现，避免在新实现中出现考虑不周（站在“巨人的肩膀”上）</li>
<li>和第一段重构经历不同的是，原服务只是作为参考，在业务功能上一摸一样，并不需要在内部实现上保持和原来完全一致，但是新服务需要融入现有的服务基础体系</li>
<li>有意思的优化，原来因为业务逻辑的需要使用单体服务，新服务使用新的巧妙设计，是服务可以有多实例运行</li>
</ul>
<ul>
<li>不需要本地环境，阅读参考即可</li>
</ul>
<h2 id="三、Lua重构成Java（对当前“一无所知”也没关系）"><a href="#三、Lua重构成Java（对当前“一无所知”也没关系）" class="headerlink" title="三、Lua重构成Java（对当前“一无所知”也没关系）"></a>三、Lua重构成Java（对当前“一无所知”也没关系）</h2><ul>
<li>本地把环境跑起来，通过调试验证逻辑</li>
<li>新业务需要，需要参考部分逻辑，同时进行重构，反哺原业务团队</li>
</ul>
<ul>
<li>需要本地环境，验证原本一无所知的逻辑</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>编程语言的语言其实大同小异，花半天左右基本可以快速熟悉语法，在阅读代码的时候遇到不懂的地方，即时查阅即可；</li>
<li>对于一些复杂的逻辑，可以通过编写代码块，执行验证输出；可以在本地环境运行，也可以利用在线工具运行；</li>
<li>对于历史包袱较重的，要善于利用灰度策略；</li>
<li>阅读代码后，跟熟悉业务的同学请教确认，和同事们讨论有时也是很有必要的。</li>
</ol>
]]></content>
      <tags>
        <tag>重构</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>技术选型要注意什么?</title>
    <url>/2022/11/18/20221118-ji-zhu-xuan-xing-yao-zhu-yi-shi-me/</url>
    <content><![CDATA[<p><img src="/2022/11/18/20221118-ji-zhu-xuan-xing-yao-zhu-yi-shi-me/messi3.png"></p>
<ul>
<li><p>充分了解才能用，基本了解，大局实现，</p>
</li>
<li><p>充分测试，压测分析profile，</p>
</li>
<li><p>非核心业务试行，</p>
</li>
<li><p>业界选择，不是说别人牛，是因为别人拿业务来验证过</p>
</li>
<li><p>待整理</p>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>N年前的笔记备忘查阅</title>
    <url>/2023/01/28/20230128-n-nian-qian-de-bi-ji-bei-wang-cha-yue/</url>
    <content><![CDATA[<p><img src="/2023/01/28/20230128-n-nian-qian-de-bi-ji-bei-wang-cha-yue/messi_ronaldo.jpg"></p>
<ul>
<li><a href="https://blog.csdn.net/kingson_wu/article/details/22665155">正则表达式和Matcher,Pattern的简单用法</a></li>
<li><a href="https://blog.csdn.net/kingson_wu/article/details/38960559">如何在同一台电脑使用不同的账号提交到同一个github仓库</a></li>
<li><a href="https://blog.csdn.net/kingson_wu/article/details/51175732">Spring源码阅读之数据自动绑定</a></li>
<li><a href="https://blog.csdn.net/kingson_wu/article/details/51408032">Hessian跨语言调用实例</a></li>
<li><a href="https://blog.csdn.net/kingson_wu/article/details/51953889">关于Java权限控制SecurityManager的理解</a></li>
<li><a href="https://blog.csdn.net/kingson_wu/article/details/70217230">关于系统间数据一致性（跨进程事务）的解决方案</a></li>
<li><a href="https://blog.csdn.net/kingson_wu/article/details/72512825">wireshark抓包简单查看HTTP keep-alive原理</a></li>
<li><a href="https://blog.csdn.net/kingson_wu/article/details/80102077">继续深入理解HTTP keepalive</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>对工作中接触过的几种编程语言及其部署架构的看法</title>
    <url>/2023/07/02/20230702-dui-gong-zuo-zhong-jie-hong-guo-de-ji-chong-bian-cheng-yu-yan-ji-qi-bu-shu-jia-gou-de-kan-fa/</url>
    <content><![CDATA[<h2 id="公司V"><a href="#公司V" class="headerlink" title="公司V"></a>公司V</h2><p><img src="/2023/07/02/20230702-dui-gong-zuo-zhong-jie-hong-guo-de-ji-chong-bian-cheng-yu-yan-ji-qi-bu-shu-jia-gou-de-kan-fa/01.V_Java.drawio.png"></p>
<ul>
<li><p>使用Java作为编程语言</p>
</li>
<li><p>使用Spring-MVC框架</p>
</li>
<li><p>使用Tomcat作为Web容器</p>
</li>
<li><p>打包运行方式：</p>
<ol>
<li>服务器预安装了Java和Tomcat</li>
<li>将代码打包成war包</li>
<li>将war包上传到服务器的Tomcat的web目录</li>
<li>重启tomcat更新服务</li>
</ol>
</li>
</ul>
<h2 id="公司U"><a href="#公司U" class="headerlink" title="公司U"></a>公司U</h2><p><img src="/2023/07/02/20230702-dui-gong-zuo-zhong-jie-hong-guo-de-ji-chong-bian-cheng-yu-yan-ji-qi-bu-shu-jia-gou-de-kan-fa/02.U_Java.drawio.png"></p>
<ul>
<li><p>使用Java作为编程语言</p>
</li>
<li><p>使用二次开发的Play1.x作为web框架（底层基于Netty）</p>
</li>
<li><p>公司在框架自行研发了服务发现等功能</p>
</li>
<li><p>打包运行方式：</p>
<ol>
<li>服务器预安装了Java</li>
<li>将代码打包成Zip包</li>
<li>将zip包上传到服务器的指定目录</li>
<li>通过信号停止服务（kill），通过Java命令启动服务</li>
</ol>
</li>
</ul>
<h2 id="公司B"><a href="#公司B" class="headerlink" title="公司B"></a>公司B</h2><p><img src="/2023/07/02/20230702-dui-gong-zuo-zhong-jie-hong-guo-de-ji-chong-bian-cheng-yu-yan-ji-qi-bu-shu-jia-gou-de-kan-fa/03.D_Java.drawio.png"></p>
<ul>
<li><p>使用Java作为编程语言</p>
</li>
<li><p>使用Spring-Boot框架</p>
</li>
<li><p>使用Tomcat作为Web容器</p>
</li>
<li><p>打包运行方式：</p>
<ol>
<li>服务器预安装了Java和Tomcat</li>
<li>将代码打包成war包</li>
<li>将war包上传到服务器的Tomcat的web目录</li>
<li>重启tomcat更新服务</li>
</ol>
</li>
</ul>
<h2 id="公司K"><a href="#公司K" class="headerlink" title="公司K"></a>公司K</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><p><img src="/2023/07/02/20230702-dui-gong-zuo-zhong-jie-hong-guo-de-ji-chong-bian-cheng-yu-yan-ji-qi-bu-shu-jia-gou-de-kan-fa/04.K_Java.drawio.png"></p>
<ul>
<li><p>使用Java作为编程语言</p>
</li>
<li><p>使用二次开发的Spring-Boot和Spring-Cloud作为web框架</p>
</li>
<li><p>公司在框架自行研发了服务发现，服务治理，数据库切换、容灾相关等功能</p>
</li>
<li><p>打包运行方式：</p>
<ol>
<li>服务器预安装了Java</li>
<li>将代码打包成Zip包</li>
<li>将zip包上传到服务器的指定目录</li>
<li>通过信号停止服务（kill），通过Java命令启动服务</li>
</ol>
</li>
</ul>
<h3 id="Lua"><a href="#Lua" class="headerlink" title="Lua"></a>Lua</h3><p><img src="/2023/07/02/20230702-dui-gong-zuo-zhong-jie-hong-guo-de-ji-chong-bian-cheng-yu-yan-ji-qi-bu-shu-jia-gou-de-kan-fa/04.K_Lua.drawio.png"></p>
<ul>
<li><p>使用Lua作为编程语言</p>
</li>
<li><p>使用OpenResty作为服务器</p>
</li>
<li><p>公司开发了一些通用的sdk，在OpenResty配置中include即可</p>
</li>
<li><p>打包运行方式：</p>
<ol>
<li>服务器预安装了OpenResty</li>
<li>将代码文件上传到指定的目录</li>
<li>执行 <code>nginx -s reload</code> 更新OpenResty的lua文件即可</li>
</ol>
</li>
</ul>
<h3 id="PHP"><a href="#PHP" class="headerlink" title="PHP"></a>PHP</h3><p><img src="/2023/07/02/20230702-dui-gong-zuo-zhong-jie-hong-guo-de-ji-chong-bian-cheng-yu-yan-ji-qi-bu-shu-jia-gou-de-kan-fa/04.K_PHP.drawio.png"></p>
<ul>
<li><p>使用PHP作为编程语言</p>
</li>
<li><p>使用OpenResty作为服务器</p>
</li>
<li><p>打包运行方式：</p>
<ol>
<li>服务器预安装了OpenResty和PHP</li>
<li>将代码文件上传到指定的目录</li>
<li>执行 <code>nginx -s reload</code> 更新OpenResty的PHP文件即可</li>
</ol>
</li>
</ul>
<h3 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h3><p><img src="/2023/07/02/20230702-dui-gong-zuo-zhong-jie-hong-guo-de-ji-chong-bian-cheng-yu-yan-ji-qi-bu-shu-jia-gou-de-kan-fa/04.K_Go.drawio.png"></p>
<ul>
<li><p>使用Go作为编程语言</p>
</li>
<li><p>打包运行方式：</p>
<ol>
<li>将代码打包成二进制可执行文件</li>
<li>使用nohup运行二进制即可（有的使用supervisor，有的使用systemctl）</li>
</ol>
</li>
</ul>
<h2 id="对这些编程语言和运行方式的理解和看法"><a href="#对这些编程语言和运行方式的理解和看法" class="headerlink" title="对这些编程语言和运行方式的理解和看法"></a>对这些编程语言和运行方式的理解和看法</h2><h3 id="Java-1"><a href="#Java-1" class="headerlink" title="Java"></a>Java</h3><ul>
<li>编译语言</li>
<li>Java服务需要运行在JVM上，而JVM是使用C++实现的</li>
<li>Java代码编译后本质上是一堆字节码文件，不具备单独运行的能力</li>
<li>运行Java字节码，需要JRE环境</li>
</ul>
<h3 id="PHP-1"><a href="#PHP-1" class="headerlink" title="PHP"></a>PHP</h3><ul>
<li>脚本语言</li>
<li>PHP通常和Web服务器搭配（比如Apache和Nginx），对外提供Web服务</li>
<li>以Nginx为例，Nginx不能直接处理PHP脚本，需要使用FastCGI协议将请求转发到PHP解释器<br>（因此，首先需要安装PHP和FastCGI进程管理器，例如php-fpm）</li>
<li>通常情况下，PHP解释器会安装在机器本机上。当Nginx通过FastCGI协议与PHP解释器进行通信时，它会将请求转发到运行在本机的FastCGI进程管理器，然后再将请求转发到本机上运行的PHP解释器</li>
</ul>
<h3 id="Lua-1"><a href="#Lua-1" class="headerlink" title="Lua"></a>Lua</h3><ul>
<li>脚本语言</li>
<li>以OpenResty作为web服务器运行Lua脚本是一种方式</li>
<li>Nginx + LuaJIT &#x3D; OpenResty</li>
</ul>
<h4 id="OpenResty"><a href="#OpenResty" class="headerlink" title="OpenResty"></a>OpenResty</h4><ul>
<li>OpenResty本质上是将 LuaJIT 的虚拟机嵌入到 Nginx 的管理进程和工作进程中，同一个进程内的所有协程都会共享这个虚拟机，并在虚拟机中执行Lua代码。在性能上，OpenResty接近或超过 Nginx 的C模块，而且开发效率更高。</li>
<li>OpenResty中的核心技术cosocket将 Lua 协程和 Nginx 的事件机制结合在一起，最终实现了非阻塞网络IO。不仅和HTTP客户端之间的网络通信是非阻塞的，与MySQL、Memcached以及Redis等众多后端之间的网络通信也是非阻塞的。</li>
</ul>
<h4 id="Openresty-是怎么嵌入lua虚拟机的"><a href="#Openresty-是怎么嵌入lua虚拟机的" class="headerlink" title="Openresty 是怎么嵌入lua虚拟机的"></a>Openresty 是怎么嵌入lua虚拟机的</h4><ul>
<li>OpenResty 是一个基于 Nginx 的 Web 应用服务器，它可以通过嵌入 Lua 脚本语言来实现高性能的 Web 应用程序。OpenResty 在运行过程中通过 LuaJIT 虚拟机来解释执行 Lua 代码。</li>
<li>OpenResty 在编译时会将 LuaJIT 虚拟机源代码打包成动态链接库，然后将其嵌入到 Nginx 中。OpenResty 运行时会通过 LuaJIT 虚拟机来加载和执行 Lua 代码，从而实现了高性能的 Web 应用程序。</li>
</ul>
<h3 id="Go-1"><a href="#Go-1" class="headerlink" title="Go"></a>Go</h3><ul>
<li>编译语言</li>
<li>编译成二进制文件后，可以直接在服务器运行，相比其他语言，一般可以认为没其他依赖</li>
</ul>
<h3 id="个人看法"><a href="#个人看法" class="headerlink" title="个人看法"></a>个人看法</h3><ul>
<li>Lua比较小众，不适合做大型的业务开发，而且debug比较不方便；</li>
<li>PHP在业界已经是快被淘汰的语言了，不做仔细研究，初步体验感觉一般（可能是受限于公司的维护环境过于糟糕，各种老版本，和高深莫测的代码）；</li>
<li>Java是我职业生涯接触最久的编程语言，谈不上喜欢也谈不上讨厌，但自从学习了Go之后，有了新的体会；</li>
<li>当初学习Go的其中一个原因是自己的个人项目比较轻量，Go其中一个优势是不依赖其他软件就可以运行，而且分发方便；</li>
<li>Go使用AOT的方式编译，针对特定平台，除了加快启动速度，也使程序打包体积大大减少；</li>
<li>当然Java也可以用graalvm打成二进制文件启动（没尝试过，感觉还是有不少前置条件）；</li>
<li>除此之外，还有很多其他以后补充</li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Go</tag>
        <tag>PHP</tag>
        <tag>Lua</tag>
        <tag>OpenResty</tag>
        <tag>Tomcat</tag>
        <tag>Spring-MVC</tag>
      </tags>
  </entry>
  <entry>
    <title>谈谈定时任务的原理和应用</title>
    <url>/2023/07/03/20230703-tan-tan-ding-shi-ren-wu-de-yuan-li-he-ying-yong/</url>
    <content><![CDATA[<h2 id="定时任务的原理"><a href="#定时任务的原理" class="headerlink" title="定时任务的原理"></a>定时任务的原理</h2><ul>
<li><p>本质是开一个线程,无限循环,检查本地的当前时间,是否符合执行的条件</p>
</li>
<li><p>Redis: 比如redis-5.0.8，起了一个线程不停的循环检查，比对当前时间（gettimeofday）判断是否需要执行</p>
</li>
<li><p>Golang: 起一个goroutine无限循环,从最小堆中取符合时间的任务</p>
</li>
<li><p>Java: 单线程, 无限循环,最小堆: java.util.TimerThread#mainLoop</p>
</li>
</ul>
<h2 id="定时任务类型"><a href="#定时任务类型" class="headerlink" title="定时任务类型"></a>定时任务类型</h2><ul>
<li><p>定时任务一般分为 本地定时任务 和 分布式定时任务</p>
</li>
<li><p>比如定时加载数据到本地缓存的时候，这时一般就使用本地定时任务</p>
</li>
<li><p>而有些任务定时只需要执行一次， 现在很多服务都不是单点了，这就需要分布式定时任务来进行调度了</p>
</li>
</ul>
<h2 id="分布式定时任务使用示例"><a href="#分布式定时任务使用示例" class="headerlink" title="分布式定时任务使用示例"></a>分布式定时任务使用示例</h2><ul>
<li><p>业界上可选择的定时任务工具很多，在工作中使用最多的是Saturn，个人觉得还是很方便的，其他分布式定时任务的原理其实基本大同小异</p>
</li>
<li><p>官网地址： <a href="https://github.com/vipshop/Saturn">https://github.com/vipshop/Saturn</a></p>
</li>
<li><p><a href="https://github.com/vipshop/Saturn/wiki/Saturn%E6%9E%B6%E6%9E%84%E6%96%87%E6%A1%A3">Saturn架构文档</a></p>
</li>
</ul>
<h3 id="Saturn"><a href="#Saturn" class="headerlink" title="Saturn"></a>Saturn</h3><ul>
<li>如果是Java服务，可以很方便的接入Saturn，可以直接通知到服务</li>
<li>但如果是其他语言，则是通过执行shell命令间接实现的</li>
</ul>
<h3 id="使用域信号通知通知服务"><a href="#使用域信号通知通知服务" class="headerlink" title="使用域信号通知通知服务"></a>使用域信号通知通知服务</h3><ul>
<li><p>这里Go应用为例子，通过域信号结合shell命令，从而方便使用saturn定时任务</p>
</li>
<li><p>client端：提供shell命令，供saturn定时调用</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> SockPath = <span class="string">&quot;/tmp/notify-os.sock&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">notifyRun</span><span class="params">(task *notifyTask)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">	httpc := http.Client&#123;</span><br><span class="line">		Transport: &amp;http.Transport&#123;</span><br><span class="line">			DialContext: <span class="function"><span class="keyword">func</span><span class="params">(_ context.Context, _, _ <span class="type">string</span>)</span></span> (net.Conn, <span class="type">error</span>) &#123;</span><br><span class="line">				<span class="keyword">return</span> net.Dial(<span class="string">&quot;unix&quot;</span>, SockPath)</span><br><span class="line">			&#125;,</span><br><span class="line">		&#125;,</span><br><span class="line">	&#125;</span><br><span class="line">	response, err := httpc.Get(<span class="string">&quot;http://unix/&quot;</span> + task.name + <span class="string">&quot;?&quot;</span> + task.args)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">var</span> buf = <span class="built_in">make</span>([]<span class="type">byte</span>, <span class="number">1024</span>)</span><br><span class="line">	response.Body.Read(buf)</span><br><span class="line">	logger.Infof(<span class="string">&quot;finish notify task: %s, args:%s, resp: %s&quot;</span>, task.name, task.args, <span class="type">string</span>(buf))</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>server端：提供uds服务，介绍请求触发执行相应的任务</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">type</span> ser <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s ser)</span></span> ServeHTTP(rw http.ResponseWriter, r *http.Request) &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">if</span> err := <span class="built_in">recover</span>(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			logger.Errorf(<span class="string">&quot;notify server panic, r: %s, err:%s&quot;</span>, r.RequestURI, err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	name := r.URL.Path</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> strings.HasPrefix(name, <span class="string">&quot;/&quot;</span>) &#123;</span><br><span class="line">		name = name[<span class="number">1</span>:]</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> job, ok := jobs[name]; ok &#123;</span><br><span class="line">		args := <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span>&#123;&#125;</span><br><span class="line">		<span class="keyword">for</span> k, v := <span class="keyword">range</span> r.URL.Query() &#123;</span><br><span class="line">			args[k] = v[<span class="number">0</span>]</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> job.Handler(args) &#123;</span><br><span class="line">			rw.Write([]<span class="type">byte</span>(<span class="string">&quot;ok&quot;</span>))</span><br><span class="line">			logger.Infof(<span class="string">&quot;job run success, name:%s, args: %s&quot;</span>, name, args)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			rw.Write([]<span class="type">byte</span>(<span class="string">&quot;fail&quot;</span>))</span><br><span class="line">			logger.Errorf(<span class="string">&quot;job run fail, name:%s, args: %s&quot;</span>, name, args)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	rw.Write([]<span class="type">byte</span>(<span class="string">&quot;not exist&quot;</span>))</span><br><span class="line">	logger.Warnf(<span class="string">&quot;job not exist, name:%s&quot;</span>, name)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NotifyServe</span><span class="params">()</span></span> &#123;</span><br><span class="line">	sockPath := utils.BizConfig(<span class="string">&quot;notify_uds_file&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> sockPath == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(<span class="string">&quot;sockPath is nil&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	logger.Info(<span class="string">&quot;Unix NotifyServe ...&quot;</span>)</span><br><span class="line">	os.Remove(sockPath)</span><br><span class="line">	server := http.Server&#123;</span><br><span class="line">		Handler: ser&#123;&#125;,</span><br><span class="line">	&#125;</span><br><span class="line">	unixListener, err := net.Listen(<span class="string">&quot;unix&quot;</span>, sockPath)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="built_in">panic</span>(err)</span><br><span class="line">	&#125;</span><br><span class="line">	server.Serve(unixListener)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>windows 平台没有uds，可以使用普通的HTTP接口代替</li>
</ul>
]]></content>
      <tags>
        <tag>Go</tag>
        <tag>定时任务</tag>
        <tag>Saturn</tag>
        <tag>UDS</tag>
      </tags>
  </entry>
  <entry>
    <title>我接触过的几种服务发现和rpc</title>
    <url>/2023/07/04/20230704-wo-jie-hong-guo-de-ji-chong-fu-wu-fa-xian-he-rpc/</url>
    <content><![CDATA[<h1 id="公司V"><a href="#公司V" class="headerlink" title="公司V"></a>公司V</h1><ul>
<li>主要Java语言</li>
<li>最原始</li>
<li>没有服务发现</li>
<li>通过域名调用，服务器ip配置在nginx</li>
<li>数据传输使用JSON协议</li>
</ul>
<h1 id="公司U"><a href="#公司U" class="headerlink" title="公司U"></a>公司U</h1><ul>
<li>主要Java语言</li>
<li>公司基础团队自己实现服务发现机制</li>
<li>服务发现使用netty做tcp长链，用于服务注册等</li>
<li>服务sdk从服务中心获取所调用的对端服务的ip和端口</li>
<li>通过tcp长链通知服务上下线等</li>
<li>通过服务的ip和端口调用</li>
<li>数据传输使用hessian协议</li>
</ul>
<h1 id="公司K"><a href="#公司K" class="headerlink" title="公司K"></a>公司K</h1><h2 id="部门1"><a href="#部门1" class="headerlink" title="部门1"></a>部门1</h2><h3 id="版本v1"><a href="#版本v1" class="headerlink" title="版本v1"></a>版本v1</h3><ul>
<li>主要Java语言</li>
<li>使用Eureka做服务发现（HTTP协议）</li>
<li>服务sdk从Eureka获取所调用的对端服务的ip和端口</li>
<li>通过HTTP接口从Eureka定时更新服务实例</li>
<li>通过服务的ip和端口调用</li>
<li>数据传输使用Thrift协议&#x2F;JSON协议</li>
</ul>
<h3 id="版本v2"><a href="#版本v2" class="headerlink" title="版本v2"></a>版本v2</h3><ul>
<li>在版本1的基础上增加LocalProxy 作为代理</li>
<li>加入local proxy （service mesh）<br>（服务a）-&gt;本地LP -&gt;（服务b）</li>
</ul>
<h3 id="版本v3"><a href="#版本v3" class="headerlink" title="版本v3"></a>版本v3</h3><ul>
<li>在k8s 部署</li>
<li>让每个pod都是单独的实例，ip和物理机一样可以访问，使用calico打通网络，兼容原来的服务发现机制，暂时不使用k8s的service功能<br>（服务a）-&gt;远程LP -&gt;（服务b）</li>
</ul>
<h3 id="版本v4"><a href="#版本v4" class="headerlink" title="版本v4"></a>版本v4</h3><ul>
<li>使用Istio替换LP </li>
<li>LP（linkerd）使用Euerka，Istio使用k8s service</li>
<li>（服务a）-&gt;istio-istio →（服务b）</li>
<li>内部调用：（服务a，istio-envoy1）-》（istio-envoy2，服务b）<br>（）标识同一个pod</li>
</ul>
<h2 id="部门2"><a href="#部门2" class="headerlink" title="部门2"></a>部门2</h2><ul>
<li>使用nginx二次开发，作为localproxy，以域名作为服务名</li>
<li>比较原始的方案（公司起步比较早，当时的方案一直沿用至今）</li>
</ul>
]]></content>
      <tags>
        <tag>RPC</tag>
        <tag>服务发现</tag>
        <tag>service discovery</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在大量数据中判断给定的是否在其中</title>
    <url>/2023/07/30/20230730-ru-he-zai-da-liang-shu-ju-zhong-pan-duan-gei-ding-de-shi-fou-zai-qi-zhong/</url>
    <content><![CDATA[<h2 id="1、-Bloom-Filter"><a href="#1、-Bloom-Filter" class="headerlink" title="1、 Bloom Filter"></a>1、 Bloom Filter</h2><ul>
<li>缺点：只能增不能减，且有误判场景需要单独处理</li>
<li>可以使用当前进程级的Bloom Filter，也可以使用Redis的Bloom Filter</li>
</ul>
<h2 id="2、-文件存储"><a href="#2、-文件存储" class="headerlink" title="2、 文件存储"></a>2、 文件存储</h2><ul>
<li><p>可以使用类似Java的MappedByteBuffer来保存数据</p>
</li>
<li><p>缺点：只能保存连续的一定范围的数字对应的值</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/353988136">Java文件读写与MappedByteBuffer</a></p>
</li>
<li><p>使用示例：</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.nio.MappedByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.FileChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Paths;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.StandardOpenOption;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MappedByteBufferTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;==&quot;</span>+ ID_SIZE);</span><br><span class="line">        System.out.println(<span class="string">&quot;==&quot;</span>+ getBufferIndex(<span class="number">1032387525</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;==&quot;</span>+ getBufferIndex(<span class="number">227081157</span>));</span><br><span class="line">        <span class="comment">// 两个数字模结果冲突</span></span><br><span class="line">        <span class="comment">// 这种方案只能保存连续的一定范围的数字对应的值</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">ID_SIZE</span> <span class="operator">=</span> <span class="number">1024</span> * <span class="number">1024</span> * <span class="number">32</span> * <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">getBufferIndex</span><span class="params">(<span class="type">long</span> idx)</span> &#123;</span><br><span class="line">        <span class="comment">//每个id占用8个字节</span></span><br><span class="line">        <span class="keyword">return</span> (<span class="type">int</span>) ((idx % ID_SIZE) * <span class="number">8</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 写入：mappedByteBuffer.putLong(int index, long value);</span></span><br><span class="line"><span class="comment">     * 读取：mappedByteBuffer.getLong(int index);</span></span><br><span class="line"><span class="comment">     * 注：MappedByteBuffer对index的最大范围是Int.MaxValue()</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 上面的表述计算有问题</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2G = 2^31 字节</span></span><br><span class="line"><span class="comment">     * ==&gt; 1b= 2^3 ; 1k = 2^10 b ; 1M = 2^20 b ; 1G = 2^30 b; 2G = 2^31 字节</span></span><br><span class="line"><span class="comment">     * long 64 位，即 2^3 字节 = 2^3</span></span><br><span class="line"><span class="comment">     * 2G = 2^31 字节 能存储多少个，应该是 2^31 / 2^3 = 2^28</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 31 - 3 = 28 = 10 + 10 + 5 = 1024 * 1024 * 32 * 8</span></span><br><span class="line">    <span class="comment">// 根据每个模之后的倍数放在不通的文件，所以不会冲突</span></span><br><span class="line">    <span class="comment">//如果分文件，比如10个，那么78在第8个文件的低第七个； 78%10、78/10</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * https://zhuanlan.zhihu.com/p/353988136</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testMappedByteBuffer</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">File</span> <span class="variable">file</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;/Users/kingsonwu/downloads/test.log&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span>(!file.exists())&#123;</span><br><span class="line">            file.createNewFile();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">FileChannel</span> <span class="variable">fileChannel</span> <span class="operator">=</span> FileChannel.open(Paths.get(URI.create(<span class="string">&quot;file:/Users/kingsonwu/downloads/test.log&quot;</span>)),</span><br><span class="line">                StandardOpenOption.WRITE, StandardOpenOption.READ);</span><br><span class="line">        <span class="type">MappedByteBuffer</span> <span class="variable">mappedByteBuffer</span> <span class="operator">=</span> fileChannel.map(FileChannel.MapMode.READ_WRITE, <span class="number">0</span>, Integer.MAX_VALUE);</span><br><span class="line">        <span class="comment">//fileChannel.close();</span></span><br><span class="line">        <span class="comment">//mappedByteBuffer.position(1024);</span></span><br><span class="line">        <span class="comment">//mappedByteBuffer.putLong(10000L);</span></span><br><span class="line"></span><br><span class="line">        mappedByteBuffer.putLong(getBufferIndex(<span class="number">1032387525</span>), <span class="number">1032387528111L</span>);</span><br><span class="line">        mappedByteBuffer.putLong(getBufferIndex(<span class="number">1032387526</span>), <span class="number">1032387529567L</span>);</span><br><span class="line">        mappedByteBuffer.putLong((ID_SIZE - <span class="number">2</span>)*<span class="number">8</span>, <span class="number">4032387529569443654L</span>);</span><br><span class="line">        <span class="comment">//mappedByteBuffer.putLong((ID_SIZE_2)*8, 1032387529569L);</span></span><br><span class="line"></span><br><span class="line">        mappedByteBuffer.force();</span><br><span class="line"></span><br><span class="line">        System.out.println(mappedByteBuffer.getLong(getBufferIndex(<span class="number">1032387525</span>)));</span><br><span class="line">        System.out.println(mappedByteBuffer.getLong(getBufferIndex(<span class="number">1032387526</span>)));</span><br><span class="line">        System.out.println(mappedByteBuffer.getLong((ID_SIZE - <span class="number">2</span>)*<span class="number">8</span>));</span><br><span class="line">        <span class="comment">//System.out.println(mappedByteBuffer.getLong((ID_SIZE_2 )*8));</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="3、Tendis"><a href="#3、Tendis" class="headerlink" title="3、Tendis"></a>3、Tendis</h2><ul>
<li>使用tendis可以将数据存储到磁盘，避免全部数据都保存在内存，从而节约内存</li>
<li>Redis的痛点之一就是内存成本高，访问频率(QPS)没那么高, 依然占用大量机器, 维护成本很高</li>
<li><a href="https://blog.csdn.net/Tencent_TEG/article/details/115878121">Redis vs Tendis：冷热混合存储版架构揭秘</a></li>
<li>使用 rocksdb 作为存储引擎, LSM Tree</li>
</ul>
]]></content>
      <tags>
        <tag>Bloom Filter</tag>
        <tag>Tendis</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次socket泄露问题排查记录</title>
    <url>/2023/07/30/20230730-ji-yi-ci-socket-xie-lu-wen-ti-pai-cha-ji-lu/</url>
    <content><![CDATA[<h2 id="结论先行"><a href="#结论先行" class="headerlink" title="结论先行"></a>结论先行</h2><ul>
<li>服务死锁导致大量请求hang住，进程无法提供服务且大量socket泄漏</li>
</ul>
<h3 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h3><ul>
<li>服务某些逻辑处理不当导致死锁</li>
<li>大量请求hang住没有响应</li>
<li>上层的nginx超时主动关闭连接</li>
<li>服务被关闭连接，导致大量CLOSE_WAIT</li>
<li>由于服务对连接处理不当（待分析原因TODO），导致大量socket泄漏</li>
</ul>
<hr>
<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="TCP状态图"><a href="#TCP状态图" class="headerlink" title="TCP状态图"></a>TCP状态图</h3><ul>
<li>从网上找的<br><img src="/2023/07/30/20230730-ji-yi-ci-socket-xie-lu-wen-ti-pai-cha-ji-lu/TCP%E7%8A%B6%E6%80%81%E5%9B%BE.jpg"></li>
</ul>
<h3 id="相关排查命令"><a href="#相关排查命令" class="headerlink" title="相关排查命令"></a>相关排查命令</h3><pre>
sudo lsof | grep sock | awk '{++S[$1]} END {for(a in S) print a, S[a]}' | sort -nr
sudo lsof | awk '/sock/ {++S[substr($0, index($0, $9))]} END {for(a in S) print a, S[a]}'
sudo lsof | grep sock|grep 'identify protocol'|awk ' {++S[$2]} END {for(a in S) print a, S[a]}'| sort -nr
//打开句柄数目最多的进程
lsof -n|awk '{print $2}'| sort | uniq -c | sort -nr | head
//查看close_wait连接统计：
sudo netstat -anp|grep 'CLOSE_WAIT'|grep 'ssogo'| awk '{print $5}'|sort |uniq -c | sort -nr
//查看FIN_WAIT2连接统计：
sudo netstat -anp|grep 'FIN_WAIT2'|grep 'ssogo'| awk '{print $5}'|sort |uniq -c | sort -nr
//查看CLOSE_WAIT最多的进程
sudo netstat -anp|grep 'CLOSE_WAIT'| awk '{print $7}'|sort |uniq -c | sort -nr
sudo netstat -anp|grep 'FIN_WAIT2'| awk '{print $7}'|sort |uniq -c | sort -nr
</pre>

<h3 id="ss"><a href="#ss" class="headerlink" title="ss"></a>ss</h3><ul>
<li>在 ss -s 命令的输出中，”closed” 表示已关闭的 TCP 连接的数量。</li>
</ul>
<blockquote>
<blockquote>
<p>具体地，TCP 的 “closed” 状态表示连接已经关闭，不再使用，并且不再具有任何网络连接或状态信息。这些连接处于已经结束的状态，但它们的套接字资源还未被完全释放或回收。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在输出结果中，”closed” 数量是指当前处于已关闭状态的 TCP 连接的数量。这些连接可能是先前已经建立的连接，已经完成了其通信任务，双方都关闭了连接，并且连接的套接字资源等待系统进行资源回收。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>需要注意的是，已关闭的连接数量的增加和减少是动态的，因为在系统的运行过程中，套接字的打开和关闭是常见的网络操作。</p>
</blockquote>
</blockquote>
<h2 id="lsof"><a href="#lsof" class="headerlink" title="lsof"></a>lsof</h2><ul>
<li><p><code>lsof| grep &quot;can&#39;t identify protocol&quot;</code><br>如果存在很多，则代表socket泄漏，同时会显示哪个进程使用的sock未关闭。</p>
</li>
<li><p><a href="http://mdba.cn/2015/03/10/tcp-socket%E6%96%87%E4%BB%B6%E5%8F%A5%E6%9F%84%E6%B3%84%E6%BC%8F/">tcp-socket文件句柄泄漏</a></p>
</li>
</ul>
<hr>
<h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><ul>
<li>TODO</li>
</ul>
<hr>
<h2 id="处理过程1"><a href="#处理过程1" class="headerlink" title="处理过程1"></a>处理过程1</h2><p><img src="/2023/07/30/20230730-ji-yi-ci-socket-xie-lu-wen-ti-pai-cha-ji-lu/socket%E6%95%B0%E9%87%8F%E6%9A%B4%E6%B6%A8.png"></p>
<ul>
<li><p>紧急重启服务（业务Go服务）后socket数量下降</p>
</li>
<li><p>在现场已经没了的情况下，分析发现机器上本身已经存在大量socket泄漏的情况</p>
</li>
</ul>
<p>![](20230730-记一次socket泄露问题排查记录&#x2F;identify protocol.png)</p>
<p><img src="/2023/07/30/20230730-ji-yi-ci-socket-xie-lu-wen-ti-pai-cha-ji-lu/process.png"><br><img src="/2023/07/30/20230730-ji-yi-ci-socket-xie-lu-wen-ti-pai-cha-ji-lu/process2.png"></p>
<ul>
<li><p>nginx和gateway都reload，那么nginx会产生新的worker进程，但是应该shutdown的老进程因为和gateway还有连接，所以也不会销毁，这样时间长了会有很多处于shutting状态的进程，这些进程都会占用资源。</p>
</li>
<li><p>初步怀疑是这些异常的nginx worker进程导致的，于是处理所有机器上这些异常（kill）</p>
<ol>
<li>如果清掉这些异常进程后，问题不再发生，那么很大可能就是这个原因导致的</li>
<li>如果问题还继续发生，说明是其他的原因</li>
</ol>
</li>
</ul>
<hr>
<h2 id="处理过程2"><a href="#处理过程2" class="headerlink" title="处理过程2"></a>处理过程2</h2><ul>
<li>即使上次清理了所有有问题的nginx worker进程，释放了大量泄漏的socket，相同的问题后续还是发生了</li>
</ul>
<p><img src="/2023/07/30/20230730-ji-yi-ci-socket-xie-lu-wen-ti-pai-cha-ji-lu/%E8%BF%87%E7%A8%8B2-1.png"></p>
<ul>
<li>还是出现了大量的closed状态，已经大量的close_wait和fin_wait2状态</li>
</ul>
<p><img src="/2023/07/30/20230730-ji-yi-ci-socket-xie-lu-wen-ti-pai-cha-ji-lu/%E8%BF%87%E7%A8%8B2-1.png"></p>
<ul>
<li>通过lsof查看，确实是Go业务进程泄漏的socket</li>
</ul>
<p><img src="/2023/07/30/20230730-ji-yi-ci-socket-xie-lu-wen-ti-pai-cha-ji-lu/%E8%BF%87%E7%A8%8B2-3.png"></p>
<ul>
<li><p>上图的正常状态下，close_wait和fin_wait2状态的数量，并没那么多</p>
</li>
<li><p>todo： 后续统计一下：</p>
</li>
</ul>
<pre>
//查看close_wait连接统计：
sudo netstat -anp|grep 'CLOSE_WAIT'|grep 'ssogo'| awk '{print $5}'|sort |uniq -c | sort -nr
//查看FIN_WAIT2连接统计：
sudo netstat -anp|grep 'FIN_WAIT2'|grep 'ssogo'| awk '{print $5}'|sort |uniq -c | sort -nr
//查看CLOSE_WAIT最多的进程
sudo netstat -anp|grep 'CLOSE_WAIT'| awk '{print $7}'|sort |uniq -c | sort -nr
sudo netstat -anp|grep 'FIN_WAIT2'| awk '{print $7}'|sort |uniq -c | sort -nr
</pre>

<ul>
<li><p>通过pprof输出进程的goroutine情况，从数量和堆栈分析，大量goroutine锁住，导致请求被hang住 </p>
</li>
<li><p>至此，问题的基本表现分析如下</p>
<ol>
<li>Go进程出问题hang住大量请求</li>
<li>上层的nginx超时主动关闭连接，状态变成FIN_WAIT2，而Go进程对应的socket拦截则变成CLOSE_WAIT<ul>
<li>查看设置为 proxy_read_timeout 10（即10s）：proxy_read_timeout 是用来设置与后端代理服务器之间的读取超时时间，它控制 Nginx 从后端代理服务器读取响应的最长等待时间。当从后端服务器读取响应数据的时间超过了设置的超时时间，Nginx 将认为后端服务器的响应已经超时，并且会中断与后端服务器的连接。</li>
</ul>
</li>
<li>Go进程对已关闭的连接处理异常，导致大量“can’t identify protocol” <ul>
<li>请求被hang住，进程没释放，socket会占有（不然被新的请求占有造成数据包混乱）</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><h4 id="can’t-identify-protocol-是怎么出现的？"><a href="#can’t-identify-protocol-是怎么出现的？" class="headerlink" title="can’t identify protocol 是怎么出现的？"></a>can’t identify protocol 是怎么出现的？</h4><ul>
<li><a href="https://idea.popcount.org/2012-12-09-lsof-cant-identify-protocol/">https://idea.popcount.org/2012-12-09-lsof-cant-identify-protocol/</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">PORT = <span class="number">9918</span></span><br><span class="line"></span><br><span class="line">sd = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">sd.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, <span class="number">1</span>)</span><br><span class="line">sd.bind((<span class="string">&#x27;0.0.0.0&#x27;</span>, PORT))</span><br><span class="line">sd.listen(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">if</span> os.fork() == <span class="number">0</span>:</span><br><span class="line">        sd.close()</span><br><span class="line">        cd = socket.socket(socket.AF_INET,</span><br><span class="line">                           socket.SOCK_STREAM)</span><br><span class="line">        cd.connect((<span class="string">&#x27;127.0.0.1&#x27;</span>, PORT))</span><br><span class="line">        sys.exit()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Server process pid=%i&quot;</span> % (os.getpid(),)</span><br><span class="line">sockets = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    (cd, address) = sd.accept()</span><br><span class="line">    sockets.append(cd)</span><br><span class="line">    cd.shutdown(socket.SHUT_WR)</span><br><span class="line"></span><br><span class="line">os.system(<span class="string">&quot;lsof -p %i&quot;</span> % (os.getpid(),))</span><br><span class="line">```   </span><br><span class="line"></span><br><span class="line">+ `cd.connect((<span class="string">&#x27;127.0.0.1&#x27;</span>, PORT))`之后没有执行`cd.close()`（关闭客户端套接字，确保连接被正确关闭）, 直接执行 sys.exit()，导致连接没有正确关闭，从而出现了<span class="string">&quot;can&#x27;t identify protocol&quot;</span>的问题</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 为什么lsof和ss的执行结果不同</span></span><br><span class="line">+ ss命令显示closed状态的socket，在lsof显示的是can<span class="string">&#x27;t identity protocol</span></span><br><span class="line"><span class="string">+ 大概是两个命令实现的原理差异吧</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#### 通过模拟client断开，server端hang住</span></span><br><span class="line"><span class="string">+ https://raw.githubusercontent.com/Kingson4Wu/awesome-tools/main/network/http-print.c 加上 `sleep(600);`的代码</span></span><br><span class="line"><span class="string">+ curl --connect-timeout 10 -m 20 &quot;http://XXXXXXX&quot;</span></span><br><span class="line"><span class="string">+ 执行lsof 只出现了‘CLOSE_WAIT’,没有出现 can&#x27;</span>t identity protocol</span><br><span class="line"></span><br><span class="line"><span class="comment">#### go进程为什么没正确关闭socket</span></span><br><span class="line">+ todo</span><br><span class="line">+ strace -p</span><br><span class="line"></span><br><span class="line"><span class="comment">#### strace 怎么使用</span></span><br><span class="line">+ todo</span><br><span class="line"></span><br><span class="line"><span class="comment">### gin怎么设置接受的socket数量</span></span><br><span class="line">+ todo</span><br><span class="line">+ gin接收请求数量上限设置</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="comment">## 处理过程3</span></span><br><span class="line">+ 分析Go进程死锁原因</span><br><span class="line"></span><br><span class="line">+ 通过分析pprof的goroutine堆栈</span><br><span class="line"></span><br><span class="line">```go</span><br><span class="line"><span class="built_in">type</span> GuardPolicy struct &#123;</span><br><span class="line">	mu      *sync.RWMutex</span><br><span class="line">	errData <span class="built_in">map</span>[*sql.DB]<span class="built_in">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">type</span> sortPool struct &#123;</span><br><span class="line">	connPool gorm.ConnPool</span><br><span class="line">	errCnt   <span class="built_in">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (s *GuardPolicy) countErr(db *gorm.DB) &#123;</span><br><span class="line">	<span class="keyword">if</span> db.Error == nil || errors.Is(db.Error, gorm.ErrRecordNotFound) &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> ins, ok := db.Statement.ConnPool.(*sql.DB); ok &#123;</span><br><span class="line">		s.mu.Lock()</span><br><span class="line">		defer s.mu.Unlock()</span><br><span class="line">		s.errData[ins] = s.errData[ins] + <span class="number">1</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (s *GuardPolicy) Resolve(connPools []gorm.ConnPool) gorm.ConnPool &#123;</span><br><span class="line">	var x = make([]*sortPool, <span class="number">0</span>, <span class="built_in">len</span>(connPools))</span><br><span class="line">	<span class="keyword">for</span> i := <span class="built_in">range</span> connPools &#123;</span><br><span class="line">		p, ok := connPools[i].(*sql.DB)</span><br><span class="line">		<span class="keyword">if</span> !ok &#123;</span><br><span class="line">			x = append(x, &amp;sortPool&#123;connPool: connPools[i], errCnt: <span class="number">0</span>&#125;)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			s.mu.RLock()</span><br><span class="line">			defer s.mu.RUnlock()</span><br><span class="line">			x = append(x, &amp;sortPool&#123;connPool: connPools[i], errCnt: s.errData[p]&#125;)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	sort.Slice(x, func(i, j <span class="built_in">int</span>) <span class="built_in">bool</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> x[i].errCnt &lt;= x[j].errCnt</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">return</span> x[<span class="number">0</span>].connPool</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（1） goroutine1: s.mu.RLock()<br>（2） goroutine2: s.mu.Lock() - 等待（1）<br>（3） goroutine1: s.mu.RLock() - 等待（2）<br>相当于goroutine1自己等待自己</p>
<ul>
<li>问chatgpt：<br>是的，提供的代码存在死锁风险。死锁可能发生在Resolve方法中。</li>
</ul>
<p>在Resolve方法中，对于sql.DB类型的连接，当读取errData映射的错误计数时，使用了RWMutex的读锁（s.mu.RLock()）。但是，在循环的每次迭代中都会调用defer s.mu.RUnlock()，这会在for循环结束时解锁，而不是在每次迭代结束时解锁。</p>
<p>这意味着如果在某次循环迭代中获取了读锁，但在获取下一个读锁之前已经进入了循环的下一次迭代，那么这两次迭代将持有读锁，但没有释放，从而导致死锁。</p>
<p>要解决这个问题，可以将读锁的获取和解锁放在同一次循环迭代中，确保每次获取读锁后都会及时释放，而不会在后续迭代中持有读锁。以下是修改后的代码：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *GuardPolicy)</span></span> Resolve(connPools []gorm.ConnPool) gorm.ConnPool &#123;</span><br><span class="line">	<span class="keyword">var</span> x = <span class="built_in">make</span>([]*sortPool, <span class="number">0</span>, <span class="built_in">len</span>(connPools))</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> connPools &#123;</span><br><span class="line">		p, ok := connPools[i].(*sql.DB)</span><br><span class="line">		<span class="keyword">if</span> !ok &#123;</span><br><span class="line">			x = <span class="built_in">append</span>(x, &amp;sortPool&#123;connPool: connPools[i], errCnt: <span class="number">0</span>&#125;)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			s.mu.RLock()</span><br><span class="line">			errCnt := s.errData[p]</span><br><span class="line">			s.mu.RUnlock()</span><br><span class="line">			x = <span class="built_in">append</span>(x, &amp;sortPool&#123;connPool: connPools[i], errCnt: errCnt&#125;)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	sort.Slice(x, <span class="function"><span class="keyword">func</span><span class="params">(i, j <span class="type">int</span>)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> x[i].errCnt &lt;= x[j].errCnt</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">return</span> x[<span class="number">0</span>].connPool</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="扩展-1"><a href="#扩展-1" class="headerlink" title="扩展"></a>扩展</h2><ul>
<li>跟这个很像：<a href="https://ms2008.github.io/2019/07/04/golang-redis-deadlock/">线上一次大量 CLOSE_WAIT 复盘</a></li>
</ul>
<hr>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://blog.csdn.net/wodatoucai/article/details/69389288">tcp socket文件句柄泄漏</a></li>
<li><a href="https://www.cnblogs.com/rootq/articles/1403720.html">确认是否有socket泄露</a></li>
<li><a href="https://zzyongx.github.io/blogs/socket_fd_leak.html">记一次排查socket fd泄漏</a></li>
<li><a href="https://zzyongx.github.io/blogs/socket_fd_leak_2.html">又一次排查socket fd泄漏</a></li>
<li><a href="https://blog.csdn.net/stpeace/article/details/57103089">socket句柄泄漏问题的定位： losf和strace的联合使用</a></li>
</ul>
]]></content>
      <tags>
        <tag>TCP</tag>
        <tag>CLOSED</tag>
      </tags>
  </entry>
  <entry>
    <title>小团队管理经验</title>
    <url>/2024/03/26/20240326-xiao-tuan-dui-guan-li-jing-yan/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>转眼工作十年了，从20年10月开始，断断续续做了近三年的小团队管理，这里作简要总结一下。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>所谓小团队管理，其实就是现在说的虚线组长，需要写代码、给团队提供指导等，但是由于不是高级别大领导，不需要应付很多烦人的破事。从这层来看，挺适合我这种性格的人。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下是以小团队为背景来总结的，格局显得较小；当然每个人的观点不一样，不一定是正确的理解。</p>
</blockquote>
</blockquote>
<h2 id="核心要点（对自己）"><a href="#核心要点（对自己）" class="headerlink" title="核心要点（对自己）"></a>核心要点（对自己）</h2><ul>
<li>情商、基于别人的角度思考<ul>
<li>个人习惯采取对内温和对外强硬的方式；当然结合自身情况和环境具体选择；这个方法可以让你更好的理解人和事情；我不认为所谓的“情商高”就是“老好人”。</li>
</ul>
</li>
<li>以身作则<ul>
<li>以自己为榜样，让团队其他成员看到正确的做事方式等；包括技术方案、沟通方式等，当然包括一些无法避免的脏活累活等；用高效和人性化等方式应对 。</li>
</ul>
</li>
<li>令人信服的技术功底<ul>
<li>小团队管理的特点，就是领头的人也是需要写代码和干实事，而且跟团队成员的距离是最近的；需要保持自己良好的技术功底，才能更好的给团队提供有效的建议；另外作为有追求的技术人，谁都想跟着比自己优秀的人一起共事。</li>
</ul>
</li>
<li>保证成员尽量免干扰、休息时间如无必要不打扰<ul>
<li>这一点是我基于人性化的角度考虑的，有些人可能会觉得不重要。给团队提供深度工作的环境，才能提升效率；在一些不紧急的事情少，要做到不随意打扰，减少团队的负面情绪。对应上面第一条，将心比心，每个人都想要良好的工作体验。</li>
</ul>
</li>
<li>真诚、谦虚、透明<ul>
<li>尽量保持团队一定的透明度，减少不必要的暗箱操作。大部分情况下不需要开会，只需要一篇简明扼要的文档，即可让团队快速了解事情的内容。团队成员也在发展，要清楚有一天他们的能力会超过你。而我一直坚持的做法是，业务上坚持写文档，尽量减少业务壁垒（也是为自己放假偷懒准备），技术上提供合理的建议，不遗余力的提高自己的“可替代性”。</li>
<li>认清自己。领导需要团队的力量才能发挥作用。不要错把平台的能力当作自己的能力。把公司的给予当作自己的给予。</li>
</ul>
</li>
<li>人性化管理<ul>
<li>现在很多公司都追求狼性文化，说着各种假话哄下属为自己加班干活</li>
<li>个人管理经验理念是，先做人再做领导</li>
<li>如非必要。不严厉。许多人还没到那个层级就采取低端没人情味的管理方式。要和同事成为朋友，营造友好的工作环境，而不是一味向上管理。</li>
</ul>
</li>
<li>尽量保持技术更新升级<ul>
<li>在确保充分测试，稳定灰度的同时，适量的升级有利于系统的稳定，增加维护人员的积极性。这种东西无法直接给出具体收益，但应该长远考虑，一味的保守只会让技术越来越落后</li>
</ul>
</li>
</ul>
<h2 id="核心要点（对团队）"><a href="#核心要点（对团队）" class="headerlink" title="核心要点（对团队）"></a>核心要点（对团队）</h2><ul>
<li>聪明、叙述简明扼要、能抓重点</li>
<li>乐于分享、采用高效的分享手段（文章即可）、实事求是</li>
<li>有团队主人翁意识，主动了解业务</li>
<li>对技术原理好奇并积极探索</li>
<li>尊重别人的时间</li>
<li>跟进事情有反馈和结论</li>
<li>在正确的事情面前，敢于说不</li>
<li>重视自己的“可替代性”、免于个人单点、提升团队容错性</li>
</ul>
<h2 id="小团队技术管理者的事项列表"><a href="#小团队技术管理者的事项列表" class="headerlink" title="小团队技术管理者的事项列表"></a>小团队技术管理者的事项列表</h2><ul>
<li>业务侧<ul>
<li>快速满足需求</li>
<li>通用业务组件抽象</li>
<li>旧业务熟悉</li>
<li>定期删除无用代码，增加代码可维护性</li>
<li>遗留需求记录和跟进</li>
<li>业务知识文档化，方便查阅和备忘</li>
<li>需求上线时间定时跟进（你就是项目经理）</li>
</ul>
</li>
<li>技术侧<ul>
<li>旧业务梳理和重构</li>
<li>架构灾备和优化、资源隔离等</li>
<li>通用工具类封装</li>
<li>管理后台搭建 （解放技术）</li>
<li>服务异常监控（后端接口，前端APM等各个维度）</li>
<li>技术组件升级，提升团队技术广度</li>
<li>废弃业务下线，回收资源</li>
<li>业务技术调研，团队具备快速满足产品新需求的能力</li>
<li>分享，相互学习，个人认为文档就行了，会议实际上挺形式和浪费大家的时间</li>
<li>帮助review方案和代码</li>
<li>技术债务登记和逐步处理（分优先级[每个季度一定要完成一定比例的低优先级任务]，保持代码洁癖，不给后来人挖坑）</li>
<li>开发规范制定（避免后续维护混乱，也方便大家日常开发查阅）</li>
<li>开发阶段和上线阶段checklist，避免犯重复的错误，避免上线遗漏导致项目延期</li>
<li>技术面试</li>
<li>应急处理、日常维护等文档化（公开、透明、高效）</li>
<li>团队文档整理规划<ul>
<li>新人指引</li>
<li>业务模块（服务模块、业务知识整理、业务交接记录、业务安全风险点）</li>
<li>工作规划（需求列表、技术规划、技术债务）</li>
<li>开发规范（项目上线流程、公共库说明、开发协议、服务架构图、业务逻辑开发套路等）</li>
<li>工作文档（应急、日常维护等）<ul>
<li>常见问题处理导航</li>
</ul>
</li>
<li>技术文档（技术型、分享类）</li>
<li>技术方案（日常需求上线方案归档）</li>
<li>复盘、故障报告</li>
<li>业务调研</li>
<li>其他备份</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://kingson4wu.github.io/2021/08/13/20210813-ge-ren-guan-li-jing-yan-zong-jie/">个人管理经验总结</a></li>
</ul>
]]></content>
      <tags>
        <tag>团队管理</tag>
      </tags>
  </entry>
  <entry>
    <title>职场中“马后炮”现象</title>
    <url>/2024/03/27/20240327-zhi-chang-zhong-ma-hou-pao-xian-xiang/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>职场中有一种奇怪又平常的现象：没出事就没人重视，出事了就各种马后炮。</p>
</blockquote>
</blockquote>
<ul>
<li><p>以软件开发人员平常应对的事情为例，这里其实有一种无奈的解释：</p>
<ol>
<li>需求这么多还没做完，有什么充分的理由去重视这个问题？</li>
<li>你把事情做好了，完全不出事，怎么证明是你的功劳？</li>
</ol>
</li>
<li><p>普通的干实事的程序员，最讨厌跟行外人谈收益。就像把代码写好了，自然后续维护成本就低了。但是硬要把他转化为节约多少人力。只想一心老老实实写代码的程序员，好心做个事情还要花费心力想办法给你解释，久而久之自然是多一事不如少一事。所谓劣币驱逐良币，有追求的程序员自然离开了，剩下的可想而知。</p>
</li>
<li><p>那么，难道这个问题就无解吗？</p>
<ul>
<li>当然不是。要建立在不干涉和充分信任的基础上。CEO相信CTO，CTO当然知道把代码写好的好处，所以也不需要底下做事的人过分解释。</li>
<li>但实际上很多公司，CTO不做CTO的事，只是专注向上汇报，还把汇报的事情层层外包给下面的人。导致本应该自己屏蔽，让底下安心做事的事情，层层透传，苦了干实事的人。而自己就成了汇总PPT的汇报员。</li>
</ul>
</li>
<li><p>最后讲一个故事</p>
<pre>
魏文王问扁鹊曰：“子昆弟三人其孰最善为医？”
扁鹊曰：“长兄最善，中兄次之，扁鹊最为下。”
魏文王曰：“可得闻邪？”
扁鹊曰：“长兄于病视神，未有形而除之，故名不出于家。中兄治病，其在毫毛，故名不出于闾。若扁鹊者，镵血脉，投毒药，副肌肤，故名出闻于诸侯。”
魏文王曰：“善。”
</pre>
</li>
<li><p>善战者无赫赫之功</p>
</li>
<li><p>防患于未然的人不如亡羊补牢者获得的赞誉多</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>JOB</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title>对服务架构中的聚合层理解</title>
    <url>/2024/03/28/20240328-dui-fu-wu-jia-gou-zhong-de-ju-he-ceng-li-jie/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>以前刚毕业的时候，进入一个组，叫中间层，那时候还懵懵懂懂不知道想表达啥意思</p>
</blockquote>
</blockquote>
<p><img src="/2024/03/28/20240328-dui-fu-wu-jia-gou-zhong-de-ju-he-ceng-li-jie/%E8%81%9A%E5%90%88%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84.jpeg"></p>
<ul>
<li><p>图来源网上，已未知出处</p>
</li>
<li><p>这个组是直接给app提供接口的，主要的职能大概有以下</p>
<ul>
<li>业务适配</li>
<li>服务聚合</li>
<li>数据展示</li>
<li>安全隔离</li>
</ul>
</li>
<li><p>聚合服务，简单的来说就是聚合底层的各个业务系统，给用户端应用提供接口</p>
<ul>
<li>（直接对接用户前端的接口服务，手机app，网站，h5等用户终端）</li>
<li>BFF —— Backends for frontends（服务于前端的后端），是为了让后端API满足不同的前端使用场景，而演进出来的一种模式。</li>
<li><a href="https://mp.weixin.qq.com/s/IZ5wD2Dc5k83dP6dR8M9xg">BFF避坑指南</a></li>
</ul>
</li>
<li><p>那么这个组有存在的必要吗？特别是现在服务内部都微服务化，很多业务服务都是直接对app提供接口的。</p>
</li>
<li><p>先从表面上看看使不使用聚合层各自的特点和好处</p>
<ul>
<li>使用聚合层<ol>
<li>前端需要对接的接口比较少，对前端来说比较友好</li>
<li>聚合层可以聚合底层业务的接口，相比前端直接对接，有些业务场景可以提升接口性能</li>
<li>能根据前端的业务场合适配和统一改动，便于快速迭代和打补丁等</li>
<li>可以根据前端对数据的不同使用场景，减少不必要的性能损耗<ul>
<li>如果统一接口，入参就会变得复杂，增加前端的对接成本</li>
</ul>
</li>
</ol>
</li>
<li>不使用聚合层<ol>
<li>有些业务场景，减少多一层调用，有利于提升性能</li>
<li>业务接口可以复用，不需要聚合层再包一层，减少开发时间<ul>
<li>前提：整个公司统一接口规范，同个接口可以复用于不同app</li>
</ul>
</li>
<li>分散接口故障风险。一个业务故障，不会导致其他业务也故障。<ul>
<li>相对使用聚合层，聚合层的服务不可用，整个app都会受影响</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
<li><p>仔细想想，简单理解，其实使用聚合层就是水平架构，不使用就是垂直架构；根据康威定律，其实公司决定使用哪种方案，一定程度还受公司组织关系的影响。</p>
</li>
<li><p>提外话：由于前后端分离的流行。聚合层服务有时候会由前端团队来维护。使用node服务用于聚合页面和后端接口，从而提升性能。相对于传统的聚合层，前端的聚合层比较轻量化，基本是无状态服务，不存储数据和加工数据，纯粹做聚合接口和页面。</p>
</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/fy5-qiZ54TLJCCTXarKonQ">“胖瘦” BFF：常见的两种微服务形态</a></li>
</ul>
]]></content>
      <tags>
        <tag>架构</tag>
        <tag>服务架构</tag>
        <tag>聚合层</tag>
      </tags>
  </entry>
  <entry>
    <title>提升自己职场中的“可替代性”</title>
    <url>/2024/03/29/20240329-ti-sheng-zi-ji-zhi-chang-zhong-de-ke-ti-dai-xing/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>怎么看待职场中的“业务壁垒”？</p>
</blockquote>
</blockquote>
<ul>
<li><p>在我的工作中，曾经发生过这样一件事：有一天我们在讨论，能不能实现一个业务通用组件，让各个业务接入，提升业务需求的开发效率等，这时候有一个同事就跟我说：‘那如果真的实现的话，那你这边的业务就啥都没了’，言外之意就是我这边“没事做了”。我给他的回答是：‘没关系，只要是有意义，有价值，对公司是正确的就行’</p>
</li>
<li><p>那么？我真的那么爱公司吗？</p>
<ul>
<li>当然不是，我只是觉得应该做自己认为正确的事，顺便说一下漂亮话忽悠一下。</li>
</ul>
</li>
<li><p>在工作中，你们到遇到很多“业务壁垒”。通俗来讲，这个东西只有他会，或者短期内只有他能搞定。你甚至会觉得一股恶心，就是很乱很难受，并惊叹对方的忍耐力。</p>
</li>
<li><p>然而，无数的事实证明了，这个世界不会因为没有谁就不行。</p>
</li>
<li><p>而我的原则是：做正确的事，不制造业务壁垒；保持出色的整理学习能力，输出业务文档，让自己随时可替换，甚至寻找可以替换自己的人；不做狭义对自己有利的事，尽量做广义对公司有利的事。</p>
</li>
<li><p>具体来说，可以这样阐述</p>
<ol>
<li>“业务壁垒”不是我认同的核心竞争力，甚至混乱的“业务壁垒”不是我能忍受的工作体验；</li>
<li>出色的整理学习能力，坚信长期主义，才是我认同的核心竞争力；</li>
<li>我在提升自己可替代性的同时，也是在提升自己的“不可替代性”；而有些地方，并不需要“不可替代性”的人；</li>
<li>提升自己可替代性，其实也是在保持业务的稳定；不会因个人而大受影响，甚至我因此可以放心度假，因为我会的东西，别人也可以快速学会和处理；</li>
</ol>
</li>
<li><p>关于“可替代性”另外补充：</p>
<ul>
<li>增加自己的安全感（休假可以找到别人）</li>
<li>增加别人（比如上级）的安全感（万一找不到，出意外有其他人解决）</li>
<li>个人清高，一定程度上，喜欢更高维度的不可替代性</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>JOB</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title>ToB业务随便讲讲</title>
    <url>/2024/04/01/20240401-tob-ye-wu-sui-bian-jiang-jiang/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>以下内容格局比较小，仅做个人记录</p>
</blockquote>
</blockquote>
<ul>
<li><p>从我个人接触过的ToB和ToC业务讲，有以下特点（当然肯定不是一定对的，毕竟业务形态实在太多，我没真正接触过的，就不提了）：</p>
<ul>
<li>ToC的业务团队，一般只做若干个业务模块；不同的业务有不同的团队</li>
<li>ToB的业务团队，需要对接几乎所有业务，进而对外提供平台能力</li>
</ul>
</li>
<li><p>关于ToB业务的规范</p>
<ul>
<li>ToB的业务，出于通用性，会制定各种规范由客户进行对接</li>
<li>当然，所谓的规范，有时候是看哪方处于强势</li>
<li>弱势方即使作为平台也要给客户做定制化</li>
<li>比如一个简单的回调规范，客户不配合，需要平台这边按照他们的规范适配</li>
<li>但同样支付宝和微信作为平台，难道要支付宝和微信去适配每个接入方？无非是谁更强势的问题。</li>
<li>从这方面看，可以一定判断出这个公司目前的状况</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>ToB</tag>
      </tags>
  </entry>
  <entry>
    <title>再浅谈接口的安全性和回调机制</title>
    <url>/2024/04/02/20240402-zai-qian-tan-jie-kou-de-an-quan-xing-he-hui-diao-ji-zhi/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>最近的工作原因，涉及到接口充权益的接口安全性问题，这里趁热再说说个人看法</p>
</blockquote>
</blockquote>
<ul>
<li><p>基于之前写的这篇<a href="https://kingson4wu.github.io/2020/07/12/20200712-shi-yong-hui-diao-ji-zhi-ti-gao-jie-kou-an-quan-xing/">使用回调机制提高接口安全性</a>继续聊。上次扩展中提到是不是可以使用非对称加密，替换回调验证？目前我所负责的业务确实使用这种方式。</p>
</li>
<li><p>业务中要对接多个渠道，渠道需要调业务的接口来加权益，为了安全性，目前的做法是由渠道自己生成RSA私钥，提供RSA公钥到业务这边。渠道使用私钥生成签名，业务这边则使用公钥解密验证，从而保证请求是合法的。</p>
</li>
<li><p>其实这里还是有潜在漏洞，之前的文章也提到过，如何保证私钥不泄漏？虽然说保证私钥不泄漏是渠道自己的问题，但是多年的经验告诉我，大多数公司并没有很好的保存这些私钥的方法。按照我的猜想，这些私钥在公司内部会被经常拷贝发送，至少开发人员基本都有办法知道的。万一知道私钥的人后续离职了作恶呢？</p>
</li>
<li><p>而我们经常对接一下小渠道，参差不齐。尽可能保证渠道的安全也是我们作为平台要积极考虑的问题。</p>
</li>
<li><p>所以个人的看法，即使使用RSA保证签名的合法，还是要提供回调的能力，提供给渠道，通过二次校验保证知道私钥的人也无法直接从自己的私人客户端发起请求并成功加权益。毕竟回调的请求是到达渠道方的正式服务器，要在正式服务器上线恶意代码，靠谱的公司都有一定的限制和管控。</p>
</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul>
<li>接口一般都会分外网访问和内网访问，我们平常要注意避免只能内网访问的接口暴露给外网访问，因为大多数情况下，我们的内网接口会安全性低一点。</li>
</ul>
]]></content>
      <tags>
        <tag>接口回调</tag>
        <tag>接口安全</tag>
        <tag>非对称加密</tag>
      </tags>
  </entry>
  <entry>
    <title>打工人心态应该是怎样的？</title>
    <url>/2024/04/02/20240402-da-gong-ren-xin-tai-ying-gai-shi-zen-yang-de/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>先来两段经典的话:</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一<br>为众人抱薪者，不可使其冻毙于风雪；<br>为大众谋福利者，不可使其孤军奋战；<br>为自由开路者，不可使其困顿于荆棘。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>二<br>愿中国青年都摆脱冷气，只是向上走。<br>不要听自暴自弃者的话。<br>能做事的做事，能发声的发声。<br>有一份光，发一份热。<br>就令萤火一般，也可以在黑暗里发一点光。<br>不必等候炬火。</p>
</blockquote>
</blockquote>
<ul>
<li><p>迫于由于现实的压迫，大家普遍焦虑，也会在工作中认怂，即使是不合理不正确负能量的等等；</p>
</li>
<li><p>这些其实都能理解，不管是迫于生活压力，还是对方给得实在太多等原因；</p>
</li>
<li><p>但有时，希望我们可以</p>
<ul>
<li>我们只是个打工的，有些东西不必过度较真</li>
<li>虽是打工但也人格独立和自尊，不必唯唯诺诺</li>
<li>有自己的时间分配和生活，不必紧盯信息，实在紧急对方会打电话</li>
<li>不必焦虑，事事回复，根据自身情况，适当保持高姿态</li>
<li>换位思考，容人之度，当然容人不是纵容</li>
<li>工作时专注和高质量，不浪费自己时间</li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.163.com/dy/article/I21SD6BV0514ANQM.html"></a></li>
</ul>
]]></content>
      <tags>
        <tag>JOB</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title>这件事情你需要跟进吗？</title>
    <url>/2024/04/03/20240403-zhe-jian-shi-qing-ni-xu-yao-gen-jin-ma/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>在工作中，大多数情况下，大家都喜欢积极跟进事情的人。但有时候，这事情你真的要跟进吗？</p>
</blockquote>
</blockquote>
<ul>
<li><p>关于这个问题，其实并不是0或1这么简单。很多时候取决于公司的工作氛围或者分工、以及你对自己的定位等情况。</p>
</li>
<li><p>在工作中，在相当长的时间里，我执行力特别强的人。我的原则是事事有结论（不给别人挖坑，不让事情烂尾）。所以我会很积极的跟进事情。</p>
</li>
<li><p>但渐渐的，我开始怀疑，有些事情是你需要跟进的吗？</p>
</li>
<li><p>以技术人员为例。你需要把自己当项目经理那样跟进事情吗？答案是分情况。</p>
</li>
<li><p>有些情况你需要跟到底，而有些情况你只需要尽你责任即可，毕竟你有更重要的事情去做，或者说你的价值不应该在这里虚耗。</p>
</li>
</ul>
<h3 id="以下情况可能需要你跟进"><a href="#以下情况可能需要你跟进" class="headerlink" title="以下情况可能需要你跟进"></a>以下情况可能需要你跟进</h3><ol>
<li>属于你自己责任范围内的事情</li>
<li>这个事情是你主导发起的事情，关于你绩效等</li>
<li>你的公司的范围就是要你做项目经理，而且你也能接受（精神损失费不够另说）</li>
<li>你个人有意愿通过这种方式发展自己的综合素质或人脉等等</li>
</ol>
<h3 id="其他情况不需要跟进到底"><a href="#其他情况不需要跟进到底" class="headerlink" title="其他情况不需要跟进到底"></a>其他情况不需要跟进到底</h3><ol>
<li>已经当天反馈结果并提供解决问题的方向</li>
<li>需求方并未声明事情的优先级，自身也未跟进（说明不重要，不要经常给别人做无用功）</li>
<li>技术侧不应该每件事都跟进那么深入，尽了自己的义务即可，毕竟要合理分工</li>
<li>关于管理人员：不能以治标不治本的方式解决问题，技术领导应该表明立场，也是以后类似问题的处理立场，而不是一味认怂服从，累死下面的兄弟，而且没啥成长，纯粹苦力活</li>
<li>关于自身的话语权：作为基层员工，有些事情就是推不动，这个大家都很清楚，做到及时反馈的义务即可</li>
</ol>
]]></content>
      <tags>
        <tag>JOB</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title>职场中的“善于沟通”和“高情商”</title>
    <url>/2024/04/05/20240405-zhi-chang-zhong-de-shan-yu-gou-tong-he-gao-qing-shang/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>很多人普遍认为，不跟人起冲突，能得到别人满意的评价，那么就一定程度上证明他高情商以及沟通能力好。<br>然而，这种观点真的正确吗？在某些情况下，这样做是否必要呢？</p>
</blockquote>
</blockquote>
<ul>
<li><p>先说结论，在高人才密度的公司中，基本也应该确实是这样。因为大家能相互理解，目标是做正确的事，简明扼要节约时间提升沟通效率，尊重别人及尊重自己，对有能力的人表示钦佩并愿意向他们学习。</p>
</li>
<li><p>相反在低密度人才的公司或者公司领导人不开明等情况下，情况就有所不同。举例来说，如果公司内部人际关系不够平等，或者产品地位高于技术。产品需求缺乏认真性和逻辑性，技术人员只能被动接受，甚至放任不管，那么这种沟通方式就变得有问题了。技术人员默默忍受、妥协，把自己变成产品的需求完善员，即使自己的时间被浪费也不可惜。</p>
</li>
<li><p>当金钱和地位给予足够时，技术人员选择妥协也可以理解。否则，那简直就是对自己的不尊重。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>JOB</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title>记录限免业务的经验</title>
    <url>/2024/04/06/20240406-ji-lu-xian-mian-ye-wu-de-jing-yan/</url>
    <content><![CDATA[<ul>
<li><p>由于业务需要，比如歌曲，我们需要对部分歌曲开放限免的功能，而且需要限制开放限免的场景。比如这首歌在场景A免费，在场景B收费。</p>
</li>
<li><p>先说正确的做法，下发另外一个字段比如free_token，通过这个字段判断业务来源，和判断是否可以免费。free_token是随着对应的场景查询时下发的，是变化的。即同一个歌曲的free_token不是唯一的。</p>
</li>
<li><p>现在有另外一种情况，想对现有的业务做限免（前端业务是不认free_token的）。这时可以把歌曲id使用free_token的值来下发，后续通过歌曲id来判断是否符合限免。</p>
<ul>
<li>这样做有个前提，就是前端业务没有使用歌曲id来做唯一性的业务（因为这是歌曲id是变化的），比如收藏。所以使用这个方案，要充分测试，而且可能还有其他不兼容的场景。</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>限免</tag>
      </tags>
  </entry>
  <entry>
    <title>从Java转Go的个人体会</title>
    <url>/2024/04/07/20240407-cong-java-zhuan-go-de-ge-ren-ti-hui/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>这里仅从一个业务开发的角度谈谈体会，格局较低，仅做个人记录<br>编程语言是程序员接触和使用最多的工具<br>后端技术基础的深度是快速学习和适应新语言的关键</p>
</blockquote>
</blockquote>
<ul>
<li><p>基于<a href="https://kingson4wu.github.io/2023/07/02/20230702-dui-gong-zuo-zhong-jie-hong-guo-de-ji-chong-bian-cheng-yu-yan-ji-qi-bu-shu-jia-gou-de-kan-fa/">对工作中接触过的几种编程语言及其部署架构的看法</a>继续聊。</p>
</li>
<li><p>截至目前，职业生涯五分之四的时间都是在使用Java。出于个人意愿和兴趣，以及行业的发展形势，也系统的自学了Go语言，并在个人的小项目实践。在一次意外的组织变动中，我转岗到了新团队，并开始使用Go，由于之前自己的自学基础，基本是无缝切换到新语言。可能是由于团队人员大部分是从Lua或PHP开始转Go的，在那里甚至感觉自己稍稍领先。</p>
</li>
<li><p>Go抽象业务比Java麻烦，代码不美观，但是它原生高并发，而且微服务下很多时候就一个后端服务，业务足够小，不需要复杂的设计模式等，并不需要像以前写大型Java应用这样做非常多的抽象，还能打二进制包，甚至还能保证一个团队所有人代码都是相同风格</p>
</li>
<li><p>以下讲一些个人看法，比较乱甚至不正确，仅做个人记录</p>
<ol>
<li>小型项目省内存</li>
<li>写命令行程序方便简单</li>
<li>现在绝大部分功能都有相应的官方库和开源库</li>
<li>运行无需环境依赖，直接打包成二进制可执行程序（Java现在也可以了，可能大部分业务场景下体积还较大）</li>
<li>支持交叉编译，不要特定平台</li>
<li>打包体积小（根据代码实际使用情况打包-这点是我一直苦苦寻找的）<ul>
<li>Go语言中有未用代码消除和可执行文件瘦身机制。只有在程序执行路径上被调用的函数才会进入最终的可执行文件，未被调用的函数会被消除</li>
<li><a href="https://mp.weixin.qq.com/s/s60J4eA_d0hqrXj-XMPpXA">Go未用代码消除与可执行文件瘦身</a></li>
</ul>
</li>
</ol>
</li>
<li><p>为什么现在大多数人都会认为Java启动慢占内存呢？</p>
<ul>
<li>首先不是Java自身的原因，而是跟实际使用场景有关</li>
<li>使用Java大多数用来做业务开发，也习惯引入很多依赖库，首当其冲就是SpringBoot等框架</li>
<li>多数都是spring相关类、proxy&#x2F;cglib，以及各种bean配置</li>
<li>而且很多类都是在启动的时候初始化的</li>
</ul>
</li>
<li><p>微服务下的编程语言</p>
<ul>
<li>在K8S流行之前，Java通常是使用SpringCloud</li>
<li>其实微服务相关技术，在K8S已经实现了</li>
<li>无论是使用Go还是Java，目前都应该向K8S靠近</li>
<li>还有一点，K8S本身就是用Go实现的</li>
</ul>
</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul>
<li><p><a href="https://github.com/Kingson4Wu/graalvm_demo">体验Graalvm+SpringBoot+Java21构建原生程序</a></p>
</li>
<li><p>在内存利用效率上，Go语言确实比Java做得更好，在4个不同的角度来总结</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/-N4eqdXb9a93uvOWfE4ScQ">Golang与Java全方位对比总结</a></li>
</ul>
<ol>
<li>Java的JIT策略比Golang的AOT策略<ul>
<li>Java在运行时相比Golang多占用了一些内存。原因在于：<ul>
<li>Java运行态中包含了一个完整的解释器、一个JIT编译期以及一个垃圾回收器，这会显著地增加内存。</li>
<li>Golang语言直接编译到机器码，运行态只包含机器码和一个垃圾回收器。</li>
</ul>
</li>
<li>因此Golang的运行态相对消耗内存较少。</li>
</ul>
</li>
<li>内存分配和垃圾回收器<ul>
<li>Java确实在起步占用上偏多，毕竟jvm需要更多内存做jit，默认的gc算法对内存要求偏高，但这不能代表后续占用仍然线性增长。如果目标是启动成百上千个内存需求较少的进程，那Java确实不擅长。</li>
</ul>
</li>
<li>并发<ul>
<li>协程模型比线程模型更加节省内存。</li>
</ul>
</li>
<li>反射<ul>
<li>Golang的反射更加简单，导致框架的内存消耗Golang程序比Java程序优秀。主要是因为： Java的框架实现中大量使用反射，并使用hashmap缓存信息，这2个都是极度消耗内存的行为。 Golang的框架中也使用reflect、map。但是Golang是面向interface和值类型的，这导致Golang的反射模型要比Java的反射模型简单非常多，反射过程要产生的对象数量也少非常多。</li>
</ul>
</li>
</ol>
</li>
<li><p>为什么一些已经选择 Java 的公司，现在又开始考虑使用 Go？</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/ZKL-M54IBx9CSkYKoLdsUA">为什么要用Go重写Dubbo？</a></li>
<li>相较于 Java，Go 在启动速度、编译速度、内存使用和高并发（如协程）方面都有明显优势。所以，那些已经采用 Java 的公司现在也在考虑引入 Go。但要注意的是，目前这样的公司仍然是少数。另外，一些公司并没有严格规定技术栈的选择，因此新成立的部门或新业务团队可以自由选择，而他们可能更倾向于选择 Go 作为开发语言。</li>
<li>小结: 总的来说，无论是选择 Java 还是 Go，都是有其合理性的。一家公司同时选择这两种语言也同样合理。尽管这样的公司占比不大，但 Java 与 Go 之间的交流需求仍然存在。</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Go</tag>
        <tag>编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title>业务开发中使用BI的海量数据处理能力</title>
    <url>/2024/04/25/20240425-ye-wu-kai-fa-zhong-shi-yong-bi-de-hai-liang-shu-ju-chu-li-neng-li/</url>
    <content><![CDATA[<ul>
<li>BI的数据统计跑数结果一般是T+1生成的</li>
</ul>
<ol>
<li>实时性要求不高的功能，用于推荐等其他业务功能，可用于统计和监控等</li>
<li>对实时性要求高的功能，做后置的监控，及早发现逻辑错误</li>
</ol>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>BI</tag>
      </tags>
  </entry>
  <entry>
    <title>业务开发中的术与道</title>
    <url>/2024/05/07/20240507-ye-wu-kai-fa-zhong-de-zhu-yu-dao/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>从事IT行业若干年，有时回首，不禁感叹，很多技术方案和日常生活息息相关，可以相互借鉴。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下只是草稿，以后有缘再整理</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>以下每项并不是独立，而是相互重叠的</p>
</blockquote>
</blockquote>
<ul>
<li>从日常的工作中总结常用的套路，勤记录，提升后续的效率</li>
<li>多开发一些能提高效率的小工具，逐步优化，并可以给其他同事使用</li>
<li>抽时间回顾和总结</li>
<li>对用户的业务数据感兴趣，并思考哪些技术优化值得做</li>
</ul>
<h1 id="技术追求"><a href="#技术追求" class="headerlink" title="技术追求"></a>技术追求</h1><ul>
<li>提升自身和团队的水平、服务架构合理性和性能的考虑、提高开发效率和体验</li>
</ul>
<h2 id="定时任务使用UDS作为触发运行的通知方式"><a href="#定时任务使用UDS作为触发运行的通知方式" class="headerlink" title="定时任务使用UDS作为触发运行的通知方式"></a>定时任务使用UDS作为触发运行的通知方式</h2><ul>
<li>基于架构的完全性考虑：不暴露非本机触发的机会</li>
<li>基于架构的合理性考虑：复用已有服务的逻辑和资源，无需新开进程</li>
<li>具体实现看：<a href="https://kingson4wu.github.io/2023/07/03/20230703-tan-tan-ding-shi-ren-wu-de-yuan-li-he-ying-yong/">谈谈定时任务的原理和应用</a> - 使用域信号通知通知服务</li>
</ul>
<h1 id="代码质量"><a href="#代码质量" class="headerlink" title="代码质量"></a>代码质量</h1><h2 id="使用代码扫描工具"><a href="#使用代码扫描工具" class="headerlink" title="使用代码扫描工具"></a>使用代码扫描工具</h2><ul>
<li>比如Java的Sonar、Golang的golint等</li>
</ul>
<h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><ul>
<li>及时发现新代码逻辑问题，以及发现避免误改动等</li>
<li>提交代码检查并及时阻断</li>
</ul>
<h2 id="代码Review"><a href="#代码Review" class="headerlink" title="代码Review"></a>代码Review</h2><ul>
<li>上面的事项自动化，比如和gitlab pipeline结合，在开发阶段就及时修正；</li>
<li>后续代码review可以避免审核低级问题，提高效率</li>
</ul>
<h1 id="开发效率"><a href="#开发效率" class="headerlink" title="开发效率"></a>开发效率</h1><h2 id="脚本工具"><a href="#脚本工具" class="headerlink" title="脚本工具"></a>脚本工具</h2><ul>
<li>开发快速生成curl脚本的工具，便于快速定位问题，以及反馈时提供复现实例；</li>
</ul>
<h1 id="代码复用"><a href="#代码复用" class="headerlink" title="代码复用"></a>代码复用</h1><h2 id="通用组件抽象"><a href="#通用组件抽象" class="headerlink" title="通用组件抽象"></a>通用组件抽象</h2><ul>
<li>apollo灰度工具</li>
<li>bi数据上报组件</li>
<li>消息通知组件</li>
</ul>
<h2 id="业务组件抽象"><a href="#业务组件抽象" class="headerlink" title="业务组件抽象"></a>业务组件抽象</h2><ul>
<li>目前都流行微服务，但有很多上游的逻辑是可以复用的，可以抽象出来，通过代码库的方式复用</li>
</ul>
<h1 id="服务稳定"><a href="#服务稳定" class="headerlink" title="服务稳定"></a>服务稳定</h1><h2 id="灰度工具"><a href="#灰度工具" class="headerlink" title="灰度工具"></a>灰度工具</h2><ul>
<li>为保证改动一旦出问题，降低影响，开发基于配置中心的灰度工具，可以根据业务属性进行灰度</li>
</ul>
<h1 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h1><ul>
<li>使用wrk、pprof等工具分析优化</li>
</ul>
<h1 id="文档化"><a href="#文档化" class="headerlink" title="文档化"></a>文档化</h1><h2 id="常规事情文档化"><a href="#常规事情文档化" class="headerlink" title="常规事情文档化"></a>常规事情文档化</h2><h2 id="复杂事情文档化"><a href="#复杂事情文档化" class="headerlink" title="复杂事情文档化"></a>复杂事情文档化</h2>]]></content>
      <tags>
        <tag>开发效率</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊配置中心</title>
    <url>/2024/05/09/20240509-liao-liao-pei-zhi-zhong-xin/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>第一次接触配置中心，是快十年前了，那时的配置中心还没像现在那么多成熟的开源项目，很多公司都需要结合自身业务自研。</p>
</blockquote>
</blockquote>
<h2 id="使用配置中心的好处"><a href="#使用配置中心的好处" class="headerlink" title="使用配置中心的好处"></a>使用配置中心的好处</h2><ol>
<li>快速发布变更配置，实时生效</li>
<li>对于不复杂的系统或业务配置，可以避免写繁琐的后台，但又具备快速变更的功能</li>
<li>读取配置性能高，一般配置后，都是以内存变量的方式常驻在服务中，可以说读取配置几乎零成本</li>
</ol>
<h2 id="配置中心的核心-推送原理"><a href="#配置中心的核心-推送原理" class="headerlink" title="配置中心的核心-推送原理"></a>配置中心的核心-推送原理</h2><blockquote>
<blockquote>
<p>这里主要讲一下个人实际接触的三种原理，其实从宏观本质上看，三种方案原理是一致的</p>
</blockquote>
</blockquote>
<ol>
<li>第一家公司的配置中心自研方案，借助ZooKeeper的临时节点变更事件，从而实现实时推送</li>
</ol>
<p><img src="/2024/05/09/20240509-liao-liao-pei-zhi-zhong-xin/zookeeper_config_center.png"></p>
<ol start="2">
<li><p>第二家公司的服务治理中心的实现方案，使用Netty使服务中心和各服务之间建立TCP长链接，从而实现配置推送</p>
</li>
<li><p>第三家公司使用Apollo开源项目作为配置中心，原理是使用HTTP的Long polling方案</p>
</li>
</ol>
<ul>
<li>从原理的本质上看，三者都是通过保持TCP连接不断开，从而复用这个通道进行数据推送</li>
<li>除了推送的实现很重要之外，后台管理系统的设计和客户端的SDK也很重要。因为光能实时推送是不够的，要让接入配置中心方便，以及能方便管理和发布配置也是很关键的。在这一点上，Apollo这个开源项目是很不错的。</li>
</ul>
]]></content>
      <tags>
        <tag>配置中心</tag>
        <tag>ZooKeeper</tag>
        <tag>Apollo</tag>
      </tags>
  </entry>
  <entry>
    <title>程序员的职业素养_摘要</title>
    <url>/2014/03/02/20140302-cheng-xu-yuan-de-zhi-ye-su-yang-zhai-yao/</url>
    <content><![CDATA[<p>专业主义的精髓就在于将公司的利益视同个人的利益。</p>
<p>不能忽略完整的测试环节，否则就交付软件是不负责任的。</p>
<p>为自己的不完美负责。代码难免出现bug，但这并不意味着你不用对它们负责。</p>
<p>让QA找不出任何问题。把自己没把握的代码发送给QA是不专业的，违背了“不行损害之事”的原则。</p>
<p>有些代码很难测试，是因为设计时就没考虑如何测试。唯一的解决办法就是要设计易于测试的代码，最好事先写测试，再写要测的代码。</p>
<p>专业开发人员不会为了发布功能而破坏结构。结构良好的代码更灵活。<br>所有软件项目的根本指导原则是，软件要易于修改。<br>如果希望自己的软件灵活可变，那就应该时常修改它。</p>
<p>职业发展是你自己的事。雇主没有义务确保你在职场能够立于不败之地。<br>雇主出了钱，你必须付出时间和精力。一周工作60个小时，前40小时给雇主，后20小时是给自己的。你应该看书，练习，学习，做一些提升职业能力的事情。<br>每天大概是3个小时是给自己提升的，你可以在路上学习，在公交学习等，利用一些时间碎片。<br>一周有168小时，给你雇主40小时，为自己的职业发展留20小时，剩下的108小时再留56小时给睡眠，那么还剩52小时可做其他的事。<br>其实这样让你免于枯竭匮乏，假设你热爱软件开发，渴望成为专业开发者，在那20个小时里，就应该做能够激发，强化你的热情的事，那20小时是充满乐趣！</p>
<p>IT行业发展迅猛，要时常了解自己的领域，坚持广泛学习才不至于落伍，但并不意味着忘掉过去。别忘了桑塔亚纳的诅咒：“不能铭记过去的人，注定重蹈先人的覆辙”。</p>
<p>每个软件开发人员必须精通的事项：<br>设计模式。GOF书中的全部24种模式。<br>设计原则。必须了解SOLID原则，而且深刻了解组件设计原则。<br>方法。必须理解XP，Scrum，精益，看板，瀑布，结构化分析及结构化设计等。<br>实践。必须掌握测试驱动开发，面向对象设计，结构化编程，持续集成和结对编程。<br>工件。必须了解如何使用UML图，DFD图，结构图，Petri网络图，状态迁移图表，流程图和决策表。</p>
<p>练习。业精于勤，真正专业人士往往勤学苦干，以求得自身技能的纯属精炼。<br>合作。学习的第二个最佳方法就是与他人合作。从彼此身上学到很多东西，而且能在更短的时间内更高质量地完成更多工作。<br>并不是要花全部时间一直和别人共事，独处的时间也更重要。<br>辅导。教学相长，想迅速牢固地掌握某些事实和观念，最好的方法就是与由你负责的人交流这些内容。传道授业中，导师也会从中受益。</p>
<p>了解业务领域。了解自己所开发项目的业务领域，了解该领域的基本架构和基本知识，一边同客户和用户访谈。花时间与业内专家交流，了解他们的原则和价值观念。</p>
<p>雇主的问题就是你的问题。弄明白这些问题，并寻求最佳解决方案。开发系统时，站在雇主的角度思考，确保开发的功能真正满足雇主的需要。</p>
<p>二</p>
<p>许诺“尝试”，就意味着你承认自己之前未尽全力，承认自己还有余力可施。<br>只要你许诺会去“尝试”，你其实是在承诺你会确保成功。<br>从本质上讲，承诺“尝试”就是一种不诚实的表现。你这么做的原因，可能是为了护住面子和避免冲突。</p>
<p>坚守专业主义精神，不能为了赶工而写出糟糕的代码，如果不能做到，当初就应该说“不”。</p>
<p>三</p>
<p>口头上说。心里认真。付诸行动。<br>做出承诺，包含三个步骤。<br>1口头上说自己将会去做。<br>2心里认真对待做出的承诺。<br>3真正付诸行动。</p>
<p>没有做到自己对他人之前的承诺，会让自己难堪。言必信，行必果。<br>你只能承诺自己能完全控制的事。<br>如果你不尽早告诉别人可能的问题，就错失了让他们帮助你达成目标，兑现承诺的机会。</p>
<p>若为了赶工完成任务，周六日加班，那么要求周三才上班也是应该的。</p>
<p>四</p>
<p>编码是一项颇具挑战也十分累人的智力活动。相比其他，编码要求更加聚精会神。<br>自己的代码要让其他人看得懂。</p>
<p>如果感到疲劳或者心烦意乱，千万不要编码。<br>奉献精神和职业素养，更多意义上指要遵循纪律原则而非成为长时间工作的工作狂。<br>要确保自己已经将睡眠，健康和生活方式调整到最佳状况，这样才能做到每天的8个小时工作时间内全力以赴。</p>
<p>焦虑的时候不要急着编码，否则那些代码都会很糟糕，要先处理或降低一下自己的焦虑情绪。</p>
<p>听音乐是可能无法写好代码。事实上，听音乐似乎消耗了至为重要的一部分脑力资源，而这些资源本该用于编码设计良好的整洁代码。</p>
<p>中断无法避免，总有人会打断你，消耗你的时间。发生这种情况时要记住一点，也许下次也会轮到你去打断别人请求帮助。<br>因此，礼貌地表现出乐于助人的态度才是专业的态度。</p>
<p>“创造性输出”依赖于“创造性输入”。</p>
<p>软件开发人员或许会认为调试时间并非编码时间，但对公司来说，调试时间和编码时间是一样昂贵的。</p>
<p>当大脑已经无法正常思考却硬逼自己在深夜还加班解决问题，你只会把自己折腾得更累，回家洗澡之类的反而会豁然开朗。<br>当碰到困难而受阻时，当你感到疲倦时，就离开一会儿，让富有创造力的潜意识接管问题。<br>精力分配得当，你将能在更短的时间内以更少的精力完成更多的事情。让自己保持好节奏，让团队保持好节奏。<br>了解你的创造力和智力运行的模式，充分发挥它们的优势而非与之背道而驰。<br>埋头忙于解决问题时，有时候可能会由于和问题贴得太近，无法看清楚所有的可选项。由于大脑中富有创造力的部分被紧张的专注力所抑制，你会错过漂亮的解决方案。</p>
<p>互相帮助是每个程序员的职责所在。作为专业人士，要以随时帮助别人为荣。<br>当然你需要独处时间，你可以直接并礼貌的告诉别人你在某个时间段不希望被人打扰。</p>
<p>接受他人的帮助。如果有人向你伸出援手，要诚挚接受，心怀感激地接受帮助并诚意合作。<br>不要因为自己进度压力很大，就推开伸来的援手。不妨给他半个小时的时间。如果到时那个人不能真正帮到你，再礼貌地致歉用感谢结束谈话也不迟。要记住，如同要以乐于助人为荣一样，也要以乐于接受别人的帮助为荣。<br>要学会如何求助。如果帮助唾手可得却让自己一个人堵在那儿，是很不专业的表现。</p>
<p>辅导缺乏经验的程序员是那些经验丰富的程序员的职责。向资深导师寻求辅导也是年轻程序员的专业职责。</p>
<p>五</p>
<p>测试驱动开发 TDD Test-Driven Development</p>
<p>TDD三项法则：<br>1在编好失败单元测试之前，不要编写任何产品代码。<br>2只要有一个单元测试失败了，就不要再写测试代码；无法通过编译也是一种失败情况。<br>3产品代码恰好能够让当前失败的单元测试成功通过即可，不要多写。</p>
<p>TDD是专业人士的选择。它是一项能够提升代码确定性，给程序员鼓励，降低代码缺陷率，优化文档和设计的原则。对TDD的各项尝试表明，不使用TDD就说明你可能还不够专业。</p>
<p>有些情况下，TDD也会有局限。</p>
<p>六</p>
<p>保持不落伍的一种方法是为开源项目贡献代码。</p>
<p>职业程序员是用自己的时间来练习。老板的职责不包括避免你的技术落伍，也不包括为你打造一份好看的履历。<br>既然你是用自己的时间练习，就不必限制在老板规定的语言和平台。可以选择你喜欢的语言，练习你喜欢的技术。</p>
<p>七</p>
<p>八</p>
<p>九</p>
<p>受到邀请的会议没有必要全部参加。参加的会议太多，其实只能证明你不够专业。理智使用时间，谨慎选择，礼貌拒绝。<br>邀请你参加会议的人并不负责管理你的时间，为时间负责的只有你。<br>领导最重要的责任之一，就是帮你从某些会议脱身。好的领导一定会主动维护你拒绝出席的决定，因为他和你一样关心你的时间。</p>
<p>如果会议让人厌烦，就离席。如果你发现参加某个会议是在浪费时间，就应当想个礼貌的方法退出来。<br>重要的是，你应当明白，继续呆在会议室里是浪费时间；继续参加对你没有太多意义的会议，是不专业的行为。</p>
<p>如果受到会议邀请，务必弄清楚指定的议题是什么，每个议题花多长时间没要取得什么成果。如果得不到确切的答案，你可以礼貌拒绝。</p>
<p>专业开发人员会安排好他们的睡眠，保证清晨有饱满的注意力去上班。</p>
<p>运动需要肌肉的注意力，而编程需要的是心智的注意力。肌肉注意力有助于改善心智注意力。</p>
<p>时间拆分与番茄工作法。</p>
<p>专业开发人员会评估每个任务的优先级，排除个人喜好和需要，按照真实的紧急程度来执行任务。</p>
<p>选择了走不通的技术道路，你对这个决定越是坚持，浪费时间就越多。<br>专业开发人员不会执拗于某个不容放弃的主意，他们会保持开放的头脑来听取其他意见，让自己有多种选择，一旦看清楚，就会避开。</p>
<p>十</p>
<p>专业开发人员能够清楚区分预估和承诺。只有在确切知道可以完成的前提下，他们才会给出承诺。而且会尽可能清楚说明预估的概率分布，这样主管就可以做出合适的计划。<br>大多数情况下，专业人士都不会给出确切的承诺，而是提供概率预估，来描述期望完成时间及可能的变数。</p>
<p>十一</p>
<p>即使有压力，专业人士也会冷静果断。尽管压力不断增大，他仍然会坚守所受的训练和纪律，他知道这些是他赖以战胜有最后期限和承诺所带来的压力感的最好方法。</p>
<p>快速前进确保最后期限的方法，便是保持整洁。专业人士不会为了快点前进而乱来。脏乱只会导致缓慢。</p>
<p>观察自己在危机时刻的反应，就可以了解自己的信念。如果在危机中依然遵循着你守持的纪律，就说明你确信这些纪律。<br>如果在平常时候你会注意保持代码整洁，但在危机时刻你却产出混乱的代码，就说明你并不真正相信混乱会导致速度下降。<br>如果你遵守的纪律原则是工作的最佳方式，那么即使是深度危机中，也要坚决秉持这些纪律原则。</p>
<p>十二</p>
<p>专业程序员最糟糕的表现就是两耳不闻窗外事，只顾一头将自己埋在技术堆里，甚至连公司业务火烧眉毛行将崩溃了也不闻不问。<br>你的工作职责就是要让业务免于陷入困顿，让公司可以长久发展下去。<br>专业程序员会花时间去理解业务。他们会和用户讨论他们正在使用的软件，会和销售人员与市场人员讨论所遭遇的问题，会和经理们沟通，明确团队的短期目标和长期目标。</p>
<p>不正常的团队最糟糕的症状是，每个程序员在自己代码周边筑起一道高墙，拒绝让其他程序员接触到这些代码。<br>这样会造成许多重复代码，模块间的接口完全是杂乱混淆而非正交的。<br>将代码所有权的各种隔断全部打破，由整个团队共同拥有全部代码的做法，相较于此要好得多。<br>专业开发人员不会阻止别人修改代码的。他们通过合作来达到学习的目的。</p>
<p>十三</p>
<p>十四</p>
<p>计算机科班毕业生的质量一直令我颇感失望。究其原因，并不是这些毕业生不够聪明或缺乏天份，而是由于大学并没有教授真正的编程之道。</p>
<p>我们今天的做法和我所提倡的理想化的学徒制程序，这两者之间的主要差异在于技术方面的传授，培训，督导和检查。<br>观念上最大差别在于，专业主义价值观和技术敏锐度需要进行不断的传授，培育，滋养和文火慢炖，直至其深植入文化当中。<br>我们当前的做法之所以传承无力， 主要是因为其中缺少了资深人士辅导新人向其传授技艺的环节。</p>
<hr>
<p>编辑推荐</p>
<p>编程大师Bob大叔40年编程生涯心得体会<br>讲解成为真正专业程序员所需态度原则<br>业界权威好评，广受赞誉<br>助您职业生涯迈上更高台阶</p>
<p>媒体推荐</p>
<p>Bob大叔的这本新作又一次抬高了专业程序员的门槛，指出了他们需要在历练尚浅的软件开发职业生涯中需要不断精进的内容。<br>——Markus Gartner,it-agile公司资深软件开发者</p>
<p>有一些技术书颇具启发与教益，有一些则读来轻松喜悦且富有趣味，但很少有技术书籍能够同时兼具所有这四个特色。我感觉Martin所有的书都可归入此列。<br>——George Bullock，微软公司资深程序经理</p>
<p>如果计算机科学学位要求有“毕业后必读书单”，本书当在其列。本书描述了迈向专业程序员的修炼旅程……而且阅读起来确实异常有趣。<br>——Jeff Overvey，伊利诺伊大学厄本那-香槟分校</p>
<p>如果你期望自己能成为软件专业人士，那么本书不容错过。<br>——R.L.Bogetti,Baxter Healthcare公司系统主设计师</p>
<p>作者简介</p>
<p>Robert C.Martin<br>世界级软件开发大师，设计模式和敏捷开发先驱，敏捷联盟首任主席，C++ Report前主编，背后辈程序员尊称为“Bob大叔”。20世纪70年代初成为职业程序员，后创办Object Mentor公司并任总裁。Martin还是一名多产的作家，至今已发表数百篇文章、论文和博客，除本书外，还著有《代码整洁之道》、《敏捷软件开发：原则、模式和实践》、《UML：Java程序员指南》等。他最近创办了cleancoders.com网站，专为软件开发人员提供教育视频。</p>
<p>目录</p>
<p>目　录</p>
<p>第1章　专业主义　1<br>1.1　清楚你要什么　2<br>1.2　担当责任　2<br>1.3　首先，不行损害之事　4<br>1.3.1　不要破坏软件功能　4<br>1.3.2　不要破坏结构　7<br>1.4　职业道德　8<br>1.4.1　了解你的领域　10<br>1.4.2　坚持学习　11<br>1.4.3　练习　11<br>1.4.4　合作　12<br>1.4.5　辅导　12<br>1.4.6　了解业务领域　13<br>1.4.7　与雇主&#x2F;客户保持一致　13<br>1.4.8　谦逊　13<br>1.5　参考文献　14</p>
<p>第2章　说“不”　15<br>2.1　对抗角色　17<br>2.2　高风险时刻　20<br>2.3　要有团队精神　22<br>2.3.1　试试看　24<br>2.3.2　消极对抗　25<br>2.4　说“是”的成本　27<br>2.5　如何写出好代码　34</p>
<p>第3章　说“是”　37<br>3.1　承诺用语　39<br>3.1.1　识别“缺乏承诺”的征兆　40<br>3.1.2　真正的承诺听起来是怎样的　41<br>3.1.3　总结　43<br>3.2　学习如何说“是”　43<br>3.2.1　“试试”的另一面　43<br>3.2.2　坚守原则　44<br>3.3　结论　47</p>
<p>第4章　编码　48<br>4.1　做好准备　49<br>4.1.1　凌晨3点写出的代码　50<br>4.1.2　焦虑时写下的代码　51<br>4.2　流态区　53<br>4.2.1　音乐　54<br>4.2.2　中断　55<br>4.3　阻塞　55<br>4.4　调试　57<br>4.5　保持节奏　60<br>4.5.1　知道何时应该离开一会　60<br>4.5.2　开车回家路上　61<br>4.5.3　洗澡　61<br>4.6　进度延迟　61<br>4.6.1　期望　62<br>4.6.2　盲目冲刺　62<br>4.6.3　加班加点　63<br>4.6.4　交付失误　63<br>4.6.5　定义“完成”　64<br>4.7　帮助　64<br>4.7.1　帮助他人　64<br>4.7.2　接受他人的帮助　65<br>4.7.3　辅导　66<br>4.8　参考文献　66</p>
<p>第5章　测试驱动开发　67<br>5.1　此事已有定论　69<br>5.2　TDD的三项法则　69<br>5.3　TDD的优势　70<br>5.3.1　确定性　70<br>5.3.2　缺陷注入率　71<br>5.3.3　勇气　71<br>5.3.4　文档　72<br>5.3.5　设计　72<br>5.3.6　专业人士的选择　73<br>5.4　TDD的局限　73<br>5.5　参考文献　74</p>
<p>第6章　练习　75<br>6.1　引子　75<br>6.1.1　10的22次方　76<br>6.1.2　转变　77<br>6.2　编程柔道场　79<br>6.2.1　卡塔　80<br>6.2.2　瓦萨　81<br>6.2.3　自由练习　81<br>6.3　自身经验的拓展　82<br>6.3.1　开源　82<br>6.3.2　关于练习的职业道德　82<br>6.4　结论　83<br>6.5　参考文献　83</p>
<p>第7章　验收测试　84<br>7.1　需求的沟通　84<br>7.1.1　过早精细化　86<br>7.1.2　迟来的模糊性　87<br>7.2　验收测试　89<br>7.2.1　“完成”的定义　89<br>7.2.2　沟通　91<br>7.2.3　自动化　92<br>7.2.4　额外工作　93<br>7.2.5　验收测试什么时候写，由谁来写　93<br>7.2.6　开发人员的角色　94<br>7.2.7　测试的协商与被动推进　95<br>7.2.8　验收测试和单元测试　96<br>7.2.9　图形界面及其他复杂因素　97<br>7.2.10　持续集成　98<br>7.3　结论　98</p>
<p>第8章　测试策略　99<br>8.1　QA应该找不到任何错误　100<br>8.1.1　QA也是团队的一部分　100<br>8.1.2　需求规约定义者　100<br>8.1.3　特性描述者　100<br>8.2　自动化测试金字塔　101<br>8.2.1　单元测试　101<br>8.2.2　组件测试　102<br>8.2.3　集成测试　103<br>8.2.4　系统测试　104<br>8.2.5　人工探索式测试　104<br>8.3　结论　105<br>8.4　参考文献　105</p>
<p>第9章　时间管理　106<br>9.1　会议　107<br>9.1.1　拒绝　107<br>9.1.2　离席　108<br>9.1.3　确定议程与目标　109<br>9.1.4　立会　109<br>9.1.5　迭代计划会议　109<br>9.1.6　迭代回顾和DEMO展示　110<br>9.1.7　争论&#x2F;反对　110<br>9.2　注意力点数　111<br>9.2.1　睡眠　112<br>9.2.2　咖啡因　112<br>9.2.3　恢复　112<br>9.2.4　肌肉注意力　112<br>9.2.5　输入与输出　113<br>9.3　时间拆分和番茄工作法　113<br>9.4　要避免的行为　114<br>9.5　死胡同　115<br>9.6　泥潭　115<br>9.7　结论　116</p>
<p>第10章　预估　117<br>10.1　什么是预估　119<br>10.1.1　承诺　119<br>10.1.2　预估　120<br>10.1.3　暗示性承诺　121<br>10.2　PERT　122<br>10.3　预估任务　125<br>10.4　大数定律　127<br>10.5　结论　127<br>10.6　参考文献　128</p>
<p>第11章　压力　129<br>11.1　避免压力　131<br>11.1.1　承诺　131<br>11.1.2　保持整洁　132<br>11.1.3　危机中的纪律　132<br>11.2　应对压力　133<br>11.2.1　不要惊慌失措　133<br>11.2.2　沟通　133<br>11.2.3　依靠你的纪律原则　133<br>11.2.4　寻求帮助　134<br>11.3　结论　134</p>
<p>第12章　协作　135<br>12.1　程序员与人　137<br>12.1.1　程序员与雇主　137<br>12.1.2　程序员与程序员　140<br>12.2　小脑　142<br>12.3　结论　143</p>
<p>第13章　团队与项目　144<br>13.1　只是简单混合吗　144<br>13.1.1　有凝聚力的团队　145<br>13.1.2　如何管理有凝聚力的团队　146<br>13.1.3　项目承包人的困境　147<br>13.2　结论　148<br>13.3　参考文献　148</p>
<p>第14章　辅导、学徒期与技艺　149<br>14.1　失败的学位教育　149<br>14.2　辅导　150<br>14.2.1　DIGI-COMP I, 我的第一台计算机　150<br>14.2.2　高中时代的ECP-18　152<br>14.2.3　非常规辅导　154<br>14.2.4　艰难的锤炼　155<br>14.3　学徒期　156<br>14.3.1　软件学徒期　158<br>14.3.2　现实情况　159<br>14.4　技艺　160<br>14.5　结论　161</p>
<p>附录　工具　162</p>
<p>​</p>
]]></content>
  </entry>
  <entry>
    <title>《人性的弱点》摘要</title>
    <url>/2020/07/19/20200719-ren-xing-de-ruo-dian-zhai-yao/</url>
    <content><![CDATA[<p><img src="/2020/07/19/20200719-ren-xing-de-ruo-dian-zhai-yao/Shanghai_Beach_2.png"></p>
<p>十年前看过这本书，现在早就忘掉差不多了，重新整理一下。</p>
<hr>
<ol>
<li>与人相处的大秘窍：献出你真实，诚恳的赞赏。</li>
<li>如果这样做，你将到处受欢迎：真诚的对别人发生兴趣。</li>
<li>在辩论中，获得最大利益的唯一方法，就是避免辩论。</li>
<li>要真诚的以他人的观点去看事情。</li>
<li>在批评对方之前，不妨先谈谈你自己的错误。</li>
<li>请对方帮忙。</li>
</ol>
<hr>
<h2 id="第一篇-待人的基本技巧"><a href="#第一篇-待人的基本技巧" class="headerlink" title="第一篇　待人的基本技巧"></a>第一篇　待人的基本技巧</h2><h3 id="第一章如欲采蜜，勿蹴蜂房"><a href="#第一章如欲采蜜，勿蹴蜂房" class="headerlink" title="第一章如欲采蜜，勿蹴蜂房"></a>第一章如欲采蜜，勿蹴蜂房</h3><ul>
<li>批评是没有用的，因它使人增加一层防御，而且竭力的替自己辩护。批评也是危险的，它会伤害了一个人的自尊，和自重的感觉，并激起他的反抗。</li>
<li>人类自然的天性，是做错事只会责备别人，而绝不会责备自己，我们每个人都是如此的。</li>
<li>不要批评，责怪或抱怨。</li>
</ul>
<h3 id="第二章-与人相处的大秘窍"><a href="#第二章-与人相处的大秘窍" class="headerlink" title="第二章　与人相处的大秘窍"></a>第二章　与人相处的大秘窍</h3><ul>
<li>自重感，这是一种痛苦的，而且急待解决的人类「饥饿」，如果能诚挚的满足这种内心饥饿的人，就可以将人们掌握在他手掌之中。</li>
<li>寻求自重感的欲望，是人类和动物间，一项重要的差别。它使人努力成为伟人或强盗。</li>
<li>献出你真实，诚恳的赞赏。</li>
</ul>
<h3 id="第三章-左右逢源的方法"><a href="#第三章-左右逢源的方法" class="headerlink" title="第三章　左右逢源的方法"></a>第三章　左右逢源的方法</h3><ul>
<li>如果有一个成功秘诀的话，那就是如何得到对方『立场」 的能力；由他的观点设想，正同由你自己的观点一样。</li>
<li>一个人能设身于他人境地，能了解他人意念活动，他不必考虑到将来的前途如何。</li>
<li>永远站在别人立场去打算、设想，并由对方的观点，去观察事物的趋向。</li>
<li>先激起对方某种迫切的需要，若能做到这点就可左右逢源，否则到处碰壁。</li>
<li>威立姆．温德，有一次说过：「表现自己，那是人性最主要的需要。」可是，为什么在我们事业上，不用这种同样的心理学呢？<br>引起别人的渴望。</li>
</ul>
<pre>
●提要
不要批评，责怪或抱怨。
献出你真实，诚恳的赞赏。
引起别人的渴望。
</pre>

<hr>
<h2 id="第二篇-使人喜欢你的六种方法"><a href="#第二篇-使人喜欢你的六种方法" class="headerlink" title="第二篇 使人喜欢你的六种方法"></a>第二篇 使人喜欢你的六种方法</h2><h3 id="第一章-如果这样做，你将到处受欢迎"><a href="#第一章-如果这样做，你将到处受欢迎" class="headerlink" title="第一章　如果这样做，你将到处受欢迎"></a>第一章　如果这样做，你将到处受欢迎</h3><ul>
<li>真诚的对别人发生兴趣。</li>
</ul>
<h3 id="第二章-如何给人好印象"><a href="#第二章-如何给人好印象" class="headerlink" title="第二章　如何给人好印象"></a>第二章　如何给人好印象</h3><ul>
<li>微笑！</li>
<li>如果你希望别人用一副高兴、欢愉的神情来接待你，那么你自己先要用这样的神情去对别人。</li>
<li>遇到人就展开一个轻松的微笑。</li>
<li>行动该是追随着一个人自己的感受………可是事实上，行动和感受，是并道而驰的。所以你需要快乐时，可以强迫自己快乐起来。</li>
<li>没有给人微笑的人，更需要别人给他微笑。</li>
</ul>
<h3 id="第三章-你要避免发生麻烦，就请这样做"><a href="#第三章-你要避免发生麻烦，就请这样做" class="headerlink" title="第三章　你要避免发生麻烦，就请这样做"></a>第三章　你要避免发生麻烦，就请这样做</h3><ul>
<li>你要记住你所接触中，每一个人的姓名。</li>
<li>最简单、最明显、而又是最重要的如何获得好感的方法，就是记住对方的姓名，使别人感到自己很重要</li>
</ul>
<h3 id="第四章-如何养成优美而得人好感的谈吐"><a href="#第四章-如何养成优美而得人好感的谈吐" class="headerlink" title="第四章　如何养成优美而得人好感的谈吐"></a>第四章　如何养成优美而得人好感的谈吐</h3><ul>
<li>做一个善于静听的人，鼓励别人多谈谈他们自己。</li>
<li>很少人能拒受那专心注意所包含的谄媚。</li>
<li>专心静听着对你讲话的人，那是最重要的，再也没有比这个更重要的了</li>
<li>最爱挑剔的人，最激烈的批评者，往往会在一个怀有忍耐、同情的静听者面前软化下来</li>
<li>他们所喜欢的，不是善于谈话的人，是那些静静听着的人。能养成善于静听能力的人，似乎要比任何好性格的人少见。</li>
<li>要使别人对你感到兴趣，先要对别人感到兴趣。</li>
</ul>
<h3 id="第五章-如何使人感到兴趣"><a href="#第五章-如何使人感到兴趣" class="headerlink" title="第五章　如何使人感到兴趣"></a>第五章　如何使人感到兴趣</h3><ul>
<li>就别人的兴趣谈论。</li>
</ul>
<h3 id="第六章-如何使人很快的喜欢你"><a href="#第六章-如何使人很快的喜欢你" class="headerlink" title="第六章　如何使人很快的喜欢你"></a>第六章　如何使人很快的喜欢你</h3><ul>
<li>使别人感觉到他的重要–必需真诚的这样做。</li>
<li>如果我们是那样的卑贱自私，不从别人身上得到什么，就不愿意分给别人一点快乐，假如我们的气量比一个酸苹果还小，那我们所要遭遇到的，也绝对是失败。</li>
<li>自重的欲望，是人们天性中最急切的要求。</li>
<li>最重要的定律：「你希望别人怎样待你，你就该怎样去对待别人。」</li>
<li>真诚，一股出自内心的赞赏的力量。</li>
<li>爱默生所说的：「凡我所遇到的人，都有比我优越的地方，而在那些方面，我能向他学习。」<pre>
●提要
使人喜欢你的六种方法
第一项规则：真诚的对别人发生兴趣。
第二项规则：微笑。
第三项规则：记住你所接触中，每一个人的姓名。
第四项规则：做一个善于静听的人，鼓励别人多谈谈他们自己。
第五项规则：就别人的兴趣谈论。
第六项规则：使别人感觉到他的重要--必需真诚的这样做。
</pre></li>
</ul>
<hr>
<h2 id="第三篇-得人同意于你的十二种方法"><a href="#第三篇-得人同意于你的十二种方法" class="headerlink" title="第三篇　得人同意于你的十二种方法"></a>第三篇　得人同意于你的十二种方法</h2><h3 id="第一章-你不可能在争辩中获胜"><a href="#第一章-你不可能在争辩中获胜" class="headerlink" title="第一章　你不可能在争辩中获胜"></a>第一章　你不可能在争辩中获胜</h3><ul>
<li>在辩论中，获得最大利益的唯一方法，就是避免辩论。</li>
<li>「永远避免正面的冲突！」</li>
<li>天下只有一种方法，能得到辩论的最大胜利，那就是尽量避免辩论………避免辩论，就像避开毒蛇和地震一样。</li>
<li>「我们绝不可能用辩论使一个无知的人心服口服。」</li>
<li>「跟这种冷厉，傲慢，固执的稽查员讲理，那等于是废话……．跟他争辩愈久，他愈是固执，所以我决定避免跟他争论，换个话题，赞赏他几句。</li>
<li>释迦牟尼曾这样说过：「恨永远无法止恨，只有爱可以止恨。」<br>所以误会不能用争论来解决，而需要用外交手腕，和赋予对方同情来解决。</li>
</ul>
<h3 id="第二章-如何避免制造敌人"><a href="#第二章-如何避免制造敌人" class="headerlink" title="第二章　如何避免制造敌人"></a>第二章　如何避免制造敌人</h3><ul>
<li>你可以用神态、声调，或是手势，告诉一个人他错了，就像我们用话一样的有效……而如果你告诉他错了，你以为他会感激你？不，永远不会！因为你对他的智力、判断、自信、自尊，都直接的给予打击，他不但不会改变他的意志，而且还想向你反击。如果你运用柏拉图、康德的逻辑来跟他理论，他还是不会改变自己的意志，因为你已伤了他的自尊。</li>
<li>我所知道的只有一件事，那就是我什么也不知道。</li>
<li>很少人有逻辑性，我们大多数的人，都怀有成见，我们之间，都受到嫉妒、猜疑、恐惧，和傲慢所毁伤。</li>
<li>任何事情只要运用若干的手腕；并不需要告诉对方，他是如何的错误。</li>
<li>尊重别人的意见，永速别指摘对方是错的。</li>
</ul>
<h3 id="第三章-如果你错了就承认"><a href="#第三章-如果你错了就承认" class="headerlink" title="第三章　如果你错了就承认"></a>第三章　如果你错了就承认</h3><ul>
<li>迅速、坦白的承认错误</li>
<li>假如我们已知道一定要受到责罚，那我们何不先责备自己，找出自己的缺点，那是不是比从别人嘴说出的批评，要好受得多？<br>你如在别人责备你之前，很快的找个机会承认自己的错误，对方想要说的话，你已替他说了，他就没有话可说，那你有百分之九十九会获得他的谅解。</li>
<li>任何一个愚蠢的人，都会尽力辩护自己的过错………而多数愚蠢的人是这样的一个能承认自己错误的人，却可使他出类拔萃，并且给人一种尊贵、高尚的感觉。</li>
<li>若是我们对了，我们巧妙婉转的让别人赞同我们的观点。可是，当我们错误的时候，我们要快速的、坦直的承认我们的错误。运用这种方法，不但能获得惊人的效果，而且在若干情形下，比替自己辩护更为有趣。</li>
<li>「用争夺的方法，你永远无法得到满足。可是当你谦让的时候，你可以得到比你所期望的更多。」</li>
</ul>
<h3 id="第四章-使你走上理智的大路"><a href="#第四章-使你走上理智的大路" class="headerlink" title="第四章　使你走上理智的大路"></a>第四章　使你走上理智的大路</h3><ul>
<li>以友善的方法开始。</li>
<li>温柔、友善的力量，永远胜过愤怒和暴力。</li>
<li>『让我们坐下一起商量，如果我们之间意见不同，我们不妨想想看原因到底何在，主要的症结是什么？。我们不久就可看出，彼此的意见相距并不很远，不同的地方很少，而相同的地方却很多。也就是说只要忍耐，加上彼此的诚意，我们就可以更接近了。」</li>
</ul>
<h3 id="第五章-苏格拉底的秘密"><a href="#第五章-苏格拉底的秘密" class="headerlink" title="第五章　苏格拉底的秘密"></a>第五章　苏格拉底的秘密</h3><ul>
<li>跟人们谈话时，别开始就谈你们意见相左的事，不妨谈些彼此间赞同的事情。</li>
<li>有说话技巧的人，开始的时候就能得到很多「是」的反应，唯有如此，他才能将听者的心埋，导向正面方向。</li>
<li>他的处世技巧，现在被称为「苏格拉底辩论法」，就是以「是，是，」作为他唯一的反应观点。他问的问题，都是他的反对者，所愿意接受而同意的。他连续不断的获得对方的同意、承认，到最后，使反对者在不知不觉中，接受了在数分钟前，他还坚决否认的结论。</li>
</ul>
<h3 id="第六章-处理一个抱怨者的安全手法"><a href="#第六章-处理一个抱怨者的安全手法" class="headerlink" title="第六章　处理一个抱怨者的安全手法"></a>第六章　处理一个抱怨者的安全手法</h3><ul>
<li>这是实在的，即使是我们的朋友，也宁愿多谈他们自己的成就；喜欢听我们吹嘘的人，可说少之又少。</li>
<li>法国哲学家洛希夫克，曾这样说过：「如果你想得到仇人，你就胜过你的朋友，可是，如果想获得更多的朋友，就让你的朋友胜过你。」</li>
<li>因为当朋友胜过我们时，那就可以满足了他的自重感。可是，当我们显出胜过朋友时，那会使他有种自卑的感觉，并会引起猜疑和妒忌。</li>
<li>德国人有句俗语，那是：「当我们所猜疑、妒忌的人，发生一桩不幸的事时，会使我们有一种恶意的快感。」</li>
<li>所以，别让我们表现出太多的成就来，我们要虚怀若谷、处处谦冲，那样会永远使人喜欢你，谁都愿意跟你接近。</li>
<li>生命是短促的，别把我们不值一提的成就，作为谈话的资料，令人听了厌烦。我们要鼓励别人多说话。仔细想一想，你实在没有什么可以夸耀的。</li>
</ul>
<h3 id="第七章-如何使人跟你合作"><a href="#第七章-如何使人跟你合作" class="headerlink" title="第七章　如何使人跟你合作"></a>第七章　如何使人跟你合作</h3><ul>
<li>没有人喜欢强迫自己去买一样东西，或是被人派遣去做一件事。我们都喜欢随自已的心愿买东西，或是照着自己的意思去做事情。同时，希望有人跟我们谈谈我们的愿望、需要、想法。</li>
<li>要让他觉得这是他自己的意思。</li>
</ul>
<h3 id="第八章-一个创造奇迹的公式"><a href="#第八章-一个创造奇迹的公式" class="headerlink" title="第八章　一个创造奇迹的公式"></a>第八章　一个创造奇迹的公式</h3><ul>
<li>要真诚的以他人的观点去看事情。</li>
<li>你接触到每一件事时，会处处替别人着想。而且以对方的观点，去观察这件事情。</li>
</ul>
<h3 id="第九章-每个人所需要的"><a href="#第九章-每个人所需要的" class="headerlink" title="第九章　每个人所需要的"></a>第九章　每个人所需要的</h3><ul>
<li>同情对方的意念和欲望。</li>
<li>你是不是愿意得到一句神妙的语句？一个可以停止争辩，消除怨恨，制造好感，使人们注意的听你谈话的语句。<br>是的，就有这样一句话，让我告诉你。你对人开始这样说：「对你所感觉到的情形，我一点也不会责怪你，如果我是你的话，我也有同样的感觉。」<br>就这样一句简单的话，世界上最狡猾，最固执的人，也会软化下来。可是你必需极是真诚的说出那些话来，假如你是对方的话，你当然有他同样的感觉。</li>
<li>你明天遇到的人，其中可能有四分之三都饥渴似的需要同情…．！如果你同情他们，他们就会喜欢你。</li>
<li>当你接到这样一封信的时候，第一件事，就是如何用严正的措辞，去对付一个不礼貌而鲁莽的人，接着，或许你就动笔写信了。<br>可是，如果你是一个聪明的人，你会把这封信放进抽屉里锁起来，经过两天后，再把这封信拿出来……像这类的信，迟上几天寄出，也不会受到什么影响。但当你两天后再拿出这封信来看时，你就不会投入邮箱，那就是我所采取的途径。</li>
<li>盖慈博士在他那一部著名的「教育心理学」书上，这样写着：一人类普遍的追求同情，孩子们会急切的显示他受伤的地方。有的甚至于故意自己割伤、弄伤，以博得大人们的同情。」<br>成人们也有类似的情形，他们会到处向人显示他的损伤，说出他们的意外事故，所患的疾病，特别是开刀手术后的经过。「自怜! 实际上是一般人的习性。」</li>
</ul>
<h3 id="第十章-人人都喜欢的吸引力"><a href="#第十章-人人都喜欢的吸引力" class="headerlink" title="第十章　人人都喜欢的吸引力"></a>第十章　人人都喜欢的吸引力</h3><ul>
<li>事实确实是如此，凡你所见到的人–甚至你照镜子时所看到的那个人- 都会把自己看得很高尚，他对自己的估计，都希望是良好而不自私的。<br>银行家摩根，在他一篇分析的文稿中说：人会做一件事，都有两种理由存在……一种是好听的，一种是真实的。</li>
<li>要改变一个人的意志，需要激发他高尚的动机</li>
</ul>
<h3 id="第十一章-实行、推进，别停顿下来"><a href="#第十一章-实行、推进，别停顿下来" class="headerlink" title="第十一章　实行、推进，别停顿下来"></a>第十一章　实行、推进，别停顿下来</h3><ul>
<li>现在是表演的时代，只是叙述其中的原理，还不能有具体的效果。这种原理需要生动、活泼，需要使它更有趣、更戏剧化，所以必需用有效的「表演术」。</li>
<li>使你的意念戏剧化。</li>
</ul>
<h3 id="第十二章-当你无计可施时，不妨试试这个"><a href="#第十二章-当你无计可施时，不妨试试这个" class="headerlink" title="第十二章　当你无计可施时，不妨试试这个"></a>第十二章　当你无计可施时，不妨试试这个</h3><ul>
<li>让司华伯用他自己的话来解释：「如果我们想要完成一件事，必须鼓励竞争，那并不是说争着去赚钱，而是要有一种胜过别人的欲望。」<br>争胜的欲望加上挑战的心理，对一个有血气的人来说，是一种最有效的激励。</li>
<li>激将法<ul>
<li>党魁伯位德用了激将法，他转身向罗斯福大声的说：「难道圣巨恩山的英雄，竟是这样一个弱者？」</li>
<li>司密斯见他犹疑不决的样子，微笑说：「年轻人，我不会怪你感到害怕……是的，那边确实不是一个太平的地方，那是需要一个有、大人物。才干的人，才能有这份魄力去做的。」</li>
</ul>
</li>
<li>只有竞争，才能发挥他们的工作效能。</li>
<li>争强的欲望，自重感的欲望。</li>
</ul>
<pre>
● 提要
得人同意于你的十二种方法
第一项规则：在辩论中，获得最大利益的唯一方法，就是避免辩论。
第二项规则：尊重别人的意见，永远别指摘对方是错的。
第三项规则：如果你错了，迅速、郑重的承认下来。
第四项规则：以友善的方法开始。
第五项规则：使对方很快的回答「是！是！」。
第六项规则：尽量让对方，有多说话的机会。
第七顼规则：使对方以为这是他的意念。
第八项规则：要真诚的以他人的观点去看事情。
第九项规则：同情对方的意念和欲望。
第十项规则：激发更高尚的动机。
第十一项规则：使你的意念戏剧化。
第十二项规则：提出一个挑战。
</pre>

<hr>
<h2 id="第四篇-使人同意你的九种方法"><a href="#第四篇-使人同意你的九种方法" class="headerlink" title="第四篇　使人同意你的九种方法"></a>第四篇　使人同意你的九种方法</h2><h3 id="第一章如果你必须批评，这是开始的方法"><a href="#第一章如果你必须批评，这是开始的方法" class="headerlink" title="第一章如果你必须批评，这是开始的方法"></a>第一章如果你必须批评，这是开始的方法</h3><ul>
<li>当我们听到别人对我们的称赞后，如果再听到其它不愉快的话，就比较容易接受了。</li>
<li>不使对方难堪、反感，而改变一个人的意志</li>
<li>用称赞和真诚的欣赏作开始。</li>
</ul>
<h3 id="第二章-如何批评才不致招怨"><a href="#第二章-如何批评才不致招怨" class="headerlink" title="第二章　如何批评才不致招怨"></a>第二章　如何批评才不致招怨</h3><ul>
<li>我们要劝阻一件事，永远躲开正面的批评这是必需要记住的。如果有这个必要的话，我们不妨旁敲侧击的去暗示对方。对人正面的批评，那会毁损了他的自重，剥夺了他的自尊。如果你旁敲侧击，对方知道你用心良善，他不但接受，而且还会感激你。</li>
<li>间接的指出人们的过错。</li>
</ul>
<h3 id="第三章-先说出你自己的错误"><a href="#第三章-先说出你自己的错误" class="headerlink" title="第三章　先说出你自己的错误"></a>第三章　先说出你自己的错误</h3><ul>
<li>如果批评的人，开始先谦冲的承认自己也不是十全十美的、无可指责的，然后再指出人们的错误，这样就比较容易让人接受了。</li>
<li>在批评对方之前，不妨先谈谈你自己的错误。</li>
</ul>
<h3 id="第四章-没有人喜欢接受命令"><a href="#第四章-没有人喜欢接受命令" class="headerlink" title="第四章　没有人喜欢接受命令"></a>第四章　没有人喜欢接受命令</h3><ul>
<li>你不妨可以考虑一下。」或者是「你认为那个有效吗？」</li>
<li>运用那种方法，他保持了对方的自尊，而且使那人有了自重感。那种方法，也很容易取得对方的真诚合作，而对方不会有任何的反抗，或是拒绝。</li>
<li>发问时，别用直接的命令。</li>
</ul>
<h3 id="第五章-让对方保持他的面子"><a href="#第五章-让对方保持他的面子" class="headerlink" title="第五章　让对方保持他的面子"></a>第五章　让对方保持他的面子</h3><h3 id="第六章-如何鼓励人们成功"><a href="#第六章-如何鼓励人们成功" class="headerlink" title="第六章　如何鼓励人们成功"></a>第六章　如何鼓励人们成功</h3><ul>
<li>即使只有稍微的进步，我们也要称赞，这样可以鼓励别人继续进步。</li>
<li>我们具有各种潜在的能力，可是却惯于不会利用。这潜在的能力，其中一项，就是称赞别人、激励别人，让他们知道自己这股潜在的能力，所蕴藏的神奇效力。</li>
</ul>
<h3 id="第七章-给狗取个好名字"><a href="#第七章-给狗取个好名字" class="headerlink" title="第七章　给狗取个好名字"></a>第七章　给狗取个好名字</h3><ul>
<li>一般人，都会愿意接受指导，如果你得到他的敬重，并且对他的某种能力表示敬重的话。」<br>我们也可以这样说，如果你想改善一个人某方面的缺点，你要表示出，他已经具有这方面的优点了。</li>
<li>莎士比亚说：「如果你没有某种美德，就假定你有。」是好是「假定」对方有你所要激发的美德，给他一个美好的名誉去表现，他会尽其所能，也不愿意使你感到失望的。</li>
<li>几乎包括了富人、穷人、乞丐、盗贼，每一个人都愿意竭尽其所能，保持别人赠予他的「诚实」的美誉。</li>
<li>给人一个美名让他去保全。</li>
</ul>
<h3 id="第八章-使错误看起来容易改正"><a href="#第八章-使错误看起来容易改正" class="headerlink" title="第八章　使错误看起来容易改正"></a>第八章　使错误看起来容易改正</h3><ul>
<li>告诉一个孩子、一个丈夫，或是一个员工，他在某一件事上愚蠢至极，没有一点的天伦，他所做的完全不对。那你就破坏了他想要进取、上进的心情。可是，如果运用一种相反的技巧，多给人们一些鼓励，把事情看成很容易。使对方知道，你对他有信心，他有尚未发展出的才干，那他就会付出最大的努力，争取到这个胜利。</li>
<li>用鼓励，使你要改正的错误，看来很容易做到；使你要对方所做的事，好象很容易做到。</li>
</ul>
<h3 id="第九章-使人们乐意做你所要的事"><a href="#第九章-使人们乐意做你所要的事" class="headerlink" title="第九章　使人们乐意做你所要的事"></a>第九章　使人们乐意做你所要的事</h3><ul>
<li>人与人之间关系中，一项重要的规则，那是：「永远使人们乐意去做你所建议的事。」</li>
<li>可是就有这样一件事，发生在拿破仑身上。当他训练荣誉军时，发出一千五百枚十宇徽章给他的士兵，封他的十八位将军为「法国大将」，称他的军队为「伟大的军队」的时候，人们也说他「孩子气」，讥笑他拿玩具给那些出生入死的老军人。拿破仑回答说：「是的，有时人就是受玩具所统治。」<br>这种以名衔、或权威赠予的方法，对拿破仑有效，对你同样有效。</li>
</ul>
<pre>
●　提要
改变人而不触犯或引起反感的九种方法
第一项规则：用称赞和真诚的欣赏作开始。
第二项规则：间接的指出人们的错误。
第三项规则：在批评对方之前，不妨先谈谈你自己的过错。
第四项规则：发问时，别用直接的命令。
第五项规则：顾全对方的面子。
第六项规则：称赞最细微的进步，而且称赞每一个进步。
第七项规则：给人们一个美名让他去保全。
第八项规则：用鼓励，使你要改正的错误，看来很易做到；使你要对方所做的事，好象很易做到。
第九项规则：使人们乐意去做你所建议的事。
</pre>

<hr>
<h2 id="第五篇-创造奇迹的信件"><a href="#第五篇-创造奇迹的信件" class="headerlink" title="第五篇　创造奇迹的信件"></a>第五篇　创造奇迹的信件</h2><ul>
<li>这封信里的语气、含意，使人很愿意为发信人做一点事情，并且使对方有一种自重、高贵的感觉。因为请对方帮忙，使对方有了自尊、自重的感觉。</li>
<li>巧妙的运用这种「帮我一个忙」的心理学。</li>
<li>我们需要尽量鼓起对方的自尊心，但不是运用谄媚，或是虚伪，如果引误了这个出发点，是绝不会有效果的。<br>必需记住：我们每一个人，都是希望如何被人欣赏、如何被人重视……甚至会不顾一切的去达到这个目的。可是，没有人会接受不诚恳的、虚伪的奉承。<br>我愿意再说一遍：这书中所告诉你的原则，必需出自由衷才会有效果出现。</li>
</ul>
<p><img src="/2020/07/19/20200719-ren-xing-de-ruo-dian-zhai-yao/WULEI_Barcelona.jpg"></p>
]]></content>
      <tags>
        <tag>LIFE</tag>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>《程序员的职业素养》摘要</title>
    <url>/2020/07/21/20200721-cheng-xu-yuan-de-zhi-ye-su-yang-zhai-yao/</url>
    <content><![CDATA[<p><img src="/2020/07/21/20200721-cheng-xu-yuan-de-zhi-ye-su-yang-zhai-yao/Shanghai_Beach_3.png"></p>
<p>6年前看的书，重新整理一下</p>
<p><img src="/2020/07/21/20200721-cheng-xu-yuan-de-zhi-ye-su-yang-zhai-yao/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%81%8C%E4%B8%9A%E7%B4%A0%E5%85%BB.jpeg"></p>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p><img src="/2020/07/21/20200721-cheng-xu-yuan-de-zhi-ye-su-yang-zhai-yao/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%81%8C%E4%B8%9A%E7%B4%A0%E5%85%BB%E5%89%8D%E8%A8%80.jpeg"></p>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><h4 id="一-专业主义"><a href="#一-专业主义" class="headerlink" title="一 (专业主义)"></a>一 (专业主义)</h4><ol>
<li>专业主义的精髓就在于将公司的利益视同个人的利益。(这个呢，看情况吧)</li>
<li>不能忽略完整的测试环节，否则就交付软件是不负责任的。</li>
<li>为自己的不完美负责。代码难免出现bug，但这并不意味着你不用对它们负责。</li>
<li>让QA找不出任何问题。把自己没把握的代码发送给QA是不专业的，违背了“不行损害之事”的原则。</li>
<li>有些代码很难测试，是因为设计时就没考虑如何测试。唯一的解决办法就是要设计易于测试的代码，最好事先写测试，再写要测的代码。(前半句挺对，后半句实际上比较难操作？)</li>
<li>职业发展是你自己的事。雇主没有义务确保你在职场能够立于不败之地。<ul>
<li>雇主出了钱，你必须付出时间和精力。一周工作60个小时，前40小时给雇主，后20小时是给自己的。你应该看书，练习，学习，做一些提升职业能力的事情。</li>
<li>每天大概是3个小时是给自己提升的，你可以在路上学习，在公交学习等，利用一些时间碎片。</li>
<li>一周有168小时，给你雇主40小时，为自己的职业发展留20小时，剩下的108小时再留56小时给睡眠，那么还剩52小时可做其他的事。</li>
<li>其实这样让你免于枯竭匮乏，假设你热爱软件开发，渴望成为专业开发者，在那20个小时里，就应该做能够激发，强化你的热情的事，那20小时是充满乐趣！</li>
</ul>
</li>
<li>IT行业发展迅猛，要时常了解自己的领域，坚持广泛学习才不至于落伍，但并不意味着忘掉过去。别忘了桑塔亚纳的诅咒：“不能铭记过去的人，注定重蹈先人的覆辙”。</li>
<li>每个软件开发人员必须精通的事项：<pre>
设计模式。GOF书中的全部24种模式。
设计原则。必须了解SOLID原则，而且深刻了解组件设计原则。
方法。必须理解XP，Scrum，精益，看板，瀑布，结构化分析及结构化设计等。
实践。必须掌握测试驱动开发，面向对象设计，结构化编程，持续集成和结对编程。
工件。必须了解如何使用UML图，DFD图，结构图，Petri网络图，状态迁移图表，流程图和决策表。
</pre></li>
<li><hr>
<ul>
<li>练习。业精于勤，真正专业人士往往勤学苦干，以求得自身技能的纯属精炼。</li>
<li>合作。学习的第二个最佳方法就是与他人合作。从彼此身上学到很多东西，而且能在更短的时间内更高质量地完成更多工作。并不是要花全部时间一直和别人共事，独处的时间也更重要。</li>
<li>辅导。教学相长，想迅速牢固地掌握某些事实和观念，最好的方法就是与由你负责的人交流这些内容。传道授业中，导师也会从中受益。</li>
</ul>
</li>
<li>了解业务领域。了解自己所开发项目的业务领域，了解该领域的基本架构和基本知识，一边同客户和用户访谈。花时间与业内专家交流，了解他们的原则和价值观念。</li>
<li>雇主的问题就是你的问题。弄明白这些问题，并寻求最佳解决方案。开发系统时，站在雇主的角度思考，确保开发的功能真正满足雇主的需要。</li>
</ol>
<h4 id="二-说“不”"><a href="#二-说“不”" class="headerlink" title="二 (说“不”)"></a>二 (说“不”)</h4><ol>
<li>许诺“尝试”，就意味着你承认自己之前未尽全力，承认自己还有余力可施。<br>只要你许诺会去“尝试”，你其实是在承诺你会确保成功。<br>从本质上讲，承诺“尝试”就是一种不诚实的表现。你这么做的原因，可能是为了护住面子和避免冲突。</li>
<li>坚守专业主义精神，不能为了赶工而写出糟糕的代码，如果不能做到，当初就应该说“不”。<br>(这个吧，尽量吧，前提老板是个讲道理的人。。。。)</li>
</ol>
<h4 id="三-说“是”"><a href="#三-说“是”" class="headerlink" title="三 (说“是”)"></a>三 (说“是”)</h4><ol>
<li><p>口头上说。心里认真。付诸行动。<br>做出承诺，包含三个步骤。<br>1口头上说自己将会去做。<br>2心里认真对待做出的承诺。<br>3真正付诸行动。</p>
</li>
<li><p>没有做到自己对他人之前的承诺，会让自己难堪。言必信，行必果。<br>你只能承诺自己能完全控制的事。<br>如果你不尽早告诉别人可能的问题，就错失了让他们帮助你达成目标，兑现承诺的机会。<br>(前提是老板要讲道理啊。。。)</p>
</li>
<li><p>若为了赶工完成任务，周六日加班，那么要求周三才上班也是应该的。 (现实情况。。。)</p>
</li>
</ol>
<h4 id="四-编码"><a href="#四-编码" class="headerlink" title="四 (编码)"></a>四 (编码)</h4><ol>
<li>编码是一项颇具挑战也十分累人的智力活动。相比其他，编码要求更加聚精会神。<br>自己的代码要让其他人看得懂。(将心比心啊！)</li>
<li>如果感到疲劳或者心烦意乱，千万不要编码。<br>奉献精神和职业素养，更多意义上指要遵循纪律原则而非成为长时间工作的工作狂。<br>要确保自己已经将睡眠，健康和生活方式调整到最佳状况，这样才能做到每天的8个小时工作时间内全力以赴。 (虽然生活欺骗了你，但自己也别自暴自弃。。。。)</li>
<li>中断无法避免，总有人会打断你，消耗你的时间。发生这种情况时要记住一点，也许下次也会轮到你去打断别人请求帮助。因此，礼貌地表现出乐于助人的态度才是专业的态度。(还是将心比心！)</li>
<li>当大脑已经无法正常思考却硬逼自己在深夜还加班解决问题，你只会把自己折腾得更累，回家洗澡之类的反而会豁然开朗。<br>当碰到困难而受阻时，当你感到疲倦时，就离开一会儿，让富有创造力的潜意识接管问题。<br>精力分配得当，你将能在更短的时间内以更少的精力完成更多的事情。让自己保持好节奏，让团队保持好节奏。<br>了解你的创造力和智力运行的模式，充分发挥它们的优势而非与之背道而驰。<br>埋头忙于解决问题时，有时候可能会由于和问题贴得太近，无法看清楚所有的可选项。由于大脑中富有创造力的部分被紧张的专注力所抑制，你会错过漂亮的解决方案。<br>(适当放松一下，欲速则不达！！)</li>
<li>互相帮助是每个程序员的职责所在。作为专业人士，要以随时帮助别人为荣。<br>当然你需要独处时间，你可以直接并礼貌的告诉别人你在某个时间段不希望被人打扰。<br>(自重感啊)</li>
<li>接受他人的帮助。如果有人向你伸出援手，要诚挚接受，心怀感激地接受帮助并诚意合作。<br>不要因为自己进度压力很大，就推开伸来的援手。不妨给他半个小时的时间。如果到时那个人不能真正帮到你，再礼貌地致歉用感谢结束谈话也不迟。要记住，如同要以乐于助人为荣一样，也要以乐于接受别人的帮助为荣。<br>要学会如何求助。如果帮助唾手可得却让自己一个人堵在那儿，是很不专业的表现。<br>(透明透明！不盲目埋头苦干！)</li>
<li>辅导缺乏经验的程序员是那些经验丰富的程序员的职责。向资深导师寻求辅导也是年轻程序员的专业职责。(大家都那么菜，别不好意思！)</li>
</ol>
<h4 id="六-练习"><a href="#六-练习" class="headerlink" title="六 (练习)"></a>六 (练习)</h4><ol>
<li>保持不落伍的一种方法是为开源项目贡献代码。</li>
<li>职业程序员是用自己的时间来练习。老板的职责不包括避免你的技术落伍，也不包括为你打造一份好看的履历。<br>既然你是用自己的时间练习，就不必限制在老板规定的语言和平台。可以选择你喜欢的语言，练习你喜欢的技术。<br>(要多多学习啊！)</li>
</ol>
<h4 id="九-时间管理"><a href="#九-时间管理" class="headerlink" title="九 (时间管理)"></a>九 (时间管理)</h4><ol>
<li>受到邀请的会议没有必要全部参加。参加的会议太多，其实只能证明你不够专业。理智使用时间，谨慎选择，礼貌拒绝。<br>邀请你参加会议的人并不负责管理你的时间，为时间负责的只有你。<br>领导最重要的责任之一，就是帮你从某些会议脱身。好的领导一定会主动维护你拒绝出席的决定，因为他和你一样关心你的时间。<br>(时间宝贵，无效浪费还不如用来睡觉。。。)</li>
<li>如果会议让人厌烦，就离席。如果你发现参加某个会议是在浪费时间，就应当想个礼貌的方法退出来。<br>重要的是，你应当明白，继续呆在会议室里是浪费时间；继续参加对你没有太多意义的会议，是不专业的行为。</li>
<li>如果受到会议邀请，务必弄清楚指定的议题是什么，每个议题花多长时间没要取得什么成果。如果得不到确切的答案，你可以礼貌拒绝。</li>
<li>专业开发人员会安排好他们的睡眠，保证清晨有饱满的注意力去上班。</li>
<li>运动需要肌肉的注意力，而编程需要的是心智的注意力。肌肉注意力有助于改善心智注意力。</li>
<li>时间拆分与番茄工作法。</li>
<li>专业开发人员会评估每个任务的优先级，排除个人喜好和需要，按照真实的紧急程度来执行任务</li>
<li>选择了走不通的技术道路，你对这个决定越是坚持，浪费时间就越多。<br>专业开发人员不会执拗于某个不容放弃的主意，他们会保持开放的头脑来听取其他意见，让自己有多种选择，一旦看清楚，就会避开。</li>
</ol>
<h4 id="十-预估"><a href="#十-预估" class="headerlink" title="十(预估)"></a>十(预估)</h4><ol>
<li>专业开发人员能够清楚区分预估和承诺。只有在确切知道可以完成的前提下，他们才会给出承诺。而且会尽可能清楚说明预估的概率分布，这样主管就可以做出合适的计划。</li>
<li>大多数情况下，专业人士都不会给出确切的承诺，而是提供概率预估，来描述期望完成时间及可能的变数。</li>
</ol>
<h4 id="十一-压力"><a href="#十一-压力" class="headerlink" title="十一(压力)"></a>十一(压力)</h4><ol>
<li>即使有压力，专业人士也会冷静果断。尽管压力不断增大，他仍然会坚守所受的训练和纪律，他知道这些是他赖以战胜有最后期限和承诺所带来的压力感的最好方法。</li>
<li>快速前进确保最后期限的方法，便是保持整洁。专业人士不会为了快点前进而乱来。脏乱只会导致缓慢。</li>
<li>观察自己在危机时刻的反应，就可以了解自己的信念。如果在危机中依然遵循着你守持的纪律，就说明你确信这些纪律。<br>如果在平常时候你会注意保持代码整洁，但在危机时刻你却产出混乱的代码，就说明你并不真正相信混乱会导致速度下降。<br>如果你遵守的纪律原则是工作的最佳方式，那么即使是深度危机中，也要坚决秉持这些纪律原则。</li>
</ol>
<h4 id="十二-协作"><a href="#十二-协作" class="headerlink" title="十二(协作)"></a>十二(协作)</h4><ol>
<li><p>专业程序员最糟糕的表现就是两耳不闻窗外事，只顾一头将自己埋在技术堆里，甚至连公司业务火烧眉毛行将崩溃了也不闻不问。<br>你的工作职责就是要让业务免于陷入困顿，让公司可以长久发展下去。<br>专业程序员会花时间去理解业务。他们会和用户讨论他们正在使用的软件，会和销售人员与市场人员讨论所遭遇的问题，会和经理们沟通，明确团队的短期目标和长期目标。</p>
</li>
<li><p>不正常的团队最糟糕的症状是，每个程序员在自己代码周边筑起一道高墙，拒绝让其他程序员接触到这些代码。<br>这样会造成许多重复代码，模块间的接口完全是杂乱混淆而非正交的。<br>将代码所有权的各种隔断全部打破，由整个团队共同拥有全部代码的做法，相较于此要好得多。<br>专业开发人员不会阻止别人修改代码的。他们通过合作来达到学习的目的。</p>
</li>
</ol>
<h4 id="十四-辅导、学徒期与技艺"><a href="#十四-辅导、学徒期与技艺" class="headerlink" title="十四(辅导、学徒期与技艺)"></a>十四(辅导、学徒期与技艺)</h4><ol>
<li>计算机科班毕业生的质量一直令我颇感失望。究其原因，并不是这些毕业生不够聪明或缺乏天份，而是由于大学并没有教授真正的编程之道。</li>
<li>我们今天的做法和我所提倡的理想化的学徒制程序，这两者之间的主要差异在于技术方面的传授，培训，督导和检查。<br>观念上最大差别在于，专业主义价值观和技术敏锐度需要进行不断的传授，培育，滋养和文火慢炖，直至其深植入文化当中。<br>我们当前的做法之所以传承无力， 主要是因为其中缺少了资深人士辅导新人向其传授技艺的环节。</li>
</ol>
<p><img src="/2020/07/21/20200721-cheng-xu-yuan-de-zhi-ye-su-yang-zhai-yao/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%81%8C%E4%B8%9A%E7%B4%A0%E5%85%BB%E6%80%BB%E7%BB%93.jpeg"></p>
<hr>
<h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><pre>
编辑推荐

编程大师Bob大叔40年编程生涯心得体会
讲解成为真正专业程序员所需态度原则
业界权威好评，广受赞誉
助您职业生涯迈上更高台阶

媒体推荐

Bob大叔的这本新作又一次抬高了专业程序员的门槛，指出了他们需要在历练尚浅的软件开发职业生涯中需要不断精进的内容。
——Markus Gartner,it-agile公司资深软件开发者

有一些技术书颇具启发与教益，有一些则读来轻松喜悦且富有趣味，但很少有技术书籍能够同时兼具所有这四个特色。我感觉Martin所有的书都可归入此列。
——George Bullock，微软公司资深程序经理

如果计算机科学学位要求有“毕业后必读书单”，本书当在其列。本书描述了迈向专业程序员的修炼旅程……而且阅读起来确实异常有趣。
——Jeff Overvey，伊利诺伊大学厄本那-香槟分校

如果你期望自己能成为软件专业人士，那么本书不容错过。
——R.L.Bogetti,Baxter Healthcare公司系统主设计师

作者简介

Robert C.Martin
世界级软件开发大师，设计模式和敏捷开发先驱，敏捷联盟首任主席，C++ Report前主编，背后辈程序员尊称为“Bob大叔”。20世纪70年代初成为职业程序员，后创办Object Mentor公司并任总裁。Martin还是一名多产的作家，至今已发表数百篇文章、论文和博客，除本书外，还著有《代码整洁之道》、《敏捷软件开发：原则、模式和实践》、《UML：Java程序员指南》等。他最近创办了cleancoders.com网站，专为软件开发人员提供教育视频。

目录

目　录

第1章　专业主义　1
1.1　清楚你要什么　2
1.2　担当责任　2
1.3　首先，不行损害之事　4
1.3.1　不要破坏软件功能　4
1.3.2　不要破坏结构　7
1.4　职业道德　8
1.4.1　了解你的领域　10
1.4.2　坚持学习　11
1.4.3　练习　11
1.4.4　合作　12
1.4.5　辅导　12
1.4.6　了解业务领域　13
1.4.7　与雇主/客户保持一致　13
1.4.8　谦逊　13
1.5　参考文献　14

第2章　说“不”　15
2.1　对抗角色　17
2.2　高风险时刻　20
2.3　要有团队精神　22
2.3.1　试试看　24
2.3.2　消极对抗　25
2.4　说“是”的成本　27
2.5　如何写出好代码　34

第3章　说“是”　37
3.1　承诺用语　39
3.1.1　识别“缺乏承诺”的征兆　40
3.1.2　真正的承诺听起来是怎样的　41
3.1.3　总结　43
3.2　学习如何说“是”　43
3.2.1　“试试”的另一面　43
3.2.2　坚守原则　44
3.3　结论　47

第4章　编码　48
4.1　做好准备　49
4.1.1　凌晨3点写出的代码　50
4.1.2　焦虑时写下的代码　51
4.2　流态区　53
4.2.1　音乐　54
4.2.2　中断　55
4.3　阻塞　55
4.4　调试　57
4.5　保持节奏　60
4.5.1　知道何时应该离开一会　60
4.5.2　开车回家路上　61
4.5.3　洗澡　61
4.6　进度延迟　61
4.6.1　期望　62
4.6.2　盲目冲刺　62
4.6.3　加班加点　63
4.6.4　交付失误　63
4.6.5　定义“完成”　64
4.7　帮助　64
4.7.1　帮助他人　64
4.7.2　接受他人的帮助　65
4.7.3　辅导　66
4.8　参考文献　66

第5章　测试驱动开发　67
5.1　此事已有定论　69
5.2　TDD的三项法则　69
5.3　TDD的优势　70
5.3.1　确定性　70
5.3.2　缺陷注入率　71
5.3.3　勇气　71
5.3.4　文档　72
5.3.5　设计　72
5.3.6　专业人士的选择　73
5.4　TDD的局限　73
5.5　参考文献　74

第6章　练习　75
6.1　引子　75
6.1.1　10的22次方　76
6.1.2　转变　77
6.2　编程柔道场　79
6.2.1　卡塔　80
6.2.2　瓦萨　81
6.2.3　自由练习　81
6.3　自身经验的拓展　82
6.3.1　开源　82
6.3.2　关于练习的职业道德　82
6.4　结论　83
6.5　参考文献　83

第7章　验收测试　84
7.1　需求的沟通　84
7.1.1　过早精细化　86
7.1.2　迟来的模糊性　87
7.2　验收测试　89
7.2.1　“完成”的定义　89
7.2.2　沟通　91
7.2.3　自动化　92
7.2.4　额外工作　93
7.2.5　验收测试什么时候写，由谁来写　93
7.2.6　开发人员的角色　94
7.2.7　测试的协商与被动推进　95
7.2.8　验收测试和单元测试　96
7.2.9　图形界面及其他复杂因素　97
7.2.10　持续集成　98
7.3　结论　98

第8章　测试策略　99
8.1　QA应该找不到任何错误　100
8.1.1　QA也是团队的一部分　100
8.1.2　需求规约定义者　100
8.1.3　特性描述者　100
8.2　自动化测试金字塔　101
8.2.1　单元测试　101
8.2.2　组件测试　102
8.2.3　集成测试　103
8.2.4　系统测试　104
8.2.5　人工探索式测试　104
8.3　结论　105
8.4　参考文献　105

第9章　时间管理　106
9.1　会议　107
9.1.1　拒绝　107
9.1.2　离席　108
9.1.3　确定议程与目标　109
9.1.4　立会　109
9.1.5　迭代计划会议　109
9.1.6　迭代回顾和DEMO展示　110
9.1.7　争论/反对　110
9.2　注意力点数　111
9.2.1　睡眠　112
9.2.2　咖啡因　112
9.2.3　恢复　112
9.2.4　肌肉注意力　112
9.2.5　输入与输出　113
9.3　时间拆分和番茄工作法　113
9.4　要避免的行为　114
9.5　死胡同　115
9.6　泥潭　115
9.7　结论　116

第10章　预估　117
10.1　什么是预估　119
10.1.1　承诺　119
10.1.2　预估　120
10.1.3　暗示性承诺　121
10.2　PERT　122
10.3　预估任务　125
10.4　大数定律　127
10.5　结论　127
10.6　参考文献　128

第11章　压力　129
11.1　避免压力　131
11.1.1　承诺　131
11.1.2　保持整洁　132
11.1.3　危机中的纪律　132
11.2　应对压力　133
11.2.1　不要惊慌失措　133
11.2.2　沟通　133
11.2.3　依靠你的纪律原则　133
11.2.4　寻求帮助　134
11.3　结论　134

第12章　协作　135
12.1　程序员与人　137
12.1.1　程序员与雇主　137
12.1.2　程序员与程序员　140
12.2　小脑　142
12.3　结论　143

第13章　团队与项目　144
13.1　只是简单混合吗　144
13.1.1　有凝聚力的团队　145
13.1.2　如何管理有凝聚力的团队　146
13.1.3　项目承包人的困境　147
13.2　结论　148
13.3　参考文献　148

第14章　辅导、学徒期与技艺　149
14.1　失败的学位教育　149
14.2　辅导　150
14.2.1　DIGI-COMP I, 我的第一台计算机　150
14.2.2　高中时代的ECP-18　152
14.2.3　非常规辅导　154
14.2.4　艰难的锤炼　155
14.3　学徒期　156
14.3.1　软件学徒期　158
14.3.2　现实情况　159
14.4　技艺　160
14.5　结论　161

附录　工具　162
</pre>

]]></content>
      <tags>
        <tag>IT-BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>关于MHA_Consul_MySQL高可用方案的简单总结和思考</title>
    <url>/2020/08/31/20200831-guan-yu-mha-consul-mysql-gao-ke-yong-fang-an-de-jian-dan-zong-jie-he-si-kao/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>MHA + Consul + MySQL的高可用方案，网上已经有很多资料，这里只是做一下简要的总结和思考。文章部分文字摘自Reference中的链接。<br>直接先上一张图</p>
<p><img src="/2020/08/31/20200831-guan-yu-mha-consul-mysql-gao-ke-yong-fang-an-de-jian-dan-zong-jie-he-si-kao/MHA_Consul_MySQL%E5%88%87%E6%8D%A2.png"></p>
<ol>
<li>图中的灾备架构适用于同城主备架构的业务，比如金钱业务；</li>
<li>DB层是一主多从，主库至在其中一个机房，并在DB集群上搭建跨IDC的MHA；同样Consul也是跨IDC的集群；</li>
<li>业务的写主流量配置在主库机房的一侧，当主库故障发生DB切换产生新主库时，流量也跟从新主库一同切换；</li>
<li>主库切换通过MHA完成，并通过Consul集群和应用的SDK通知到业务服务。</li>
<li>MySQL采用默认的异步复制方式</li>
</ol>
<h3 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h3><ol>
<li>解决MySQL的单点问题。当主库发生故障时能提升从库为新的主库，且应用层能自动识别；从而缩短故障的处理时间；</li>
<li>通过Consul能支持从库的故障切换以及从库扩容或下线；</li>
</ol>
<h3 id="每个组件各自的作用"><a href="#每个组件各自的作用" class="headerlink" title="每个组件各自的作用"></a>每个组件各自的作用</h3><ol>
<li>MHA：监控主节点，可以在故障时自动或手动切换、非故障时手动主从切换。切换时会进行数据补齐，并将新的master信息更新到consul中。</li>
<li>Consul：MySQL服务注册并提供健康检查、记录最新的master；还可以提供其他配置性的服务，比如dns，可解析数据库域名。</li>
<li>SDK: sdk通过consul-api监控MySQL ip列表的变化，能连接新的库和去掉已下线的库。</li>
</ol>
<p>下面的部分将对使用到的技术逐一简要描述和总结。</p>
<h2 id="MHA"><a href="#MHA" class="headerlink" title="MHA"></a>MHA</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><pre>
MySQL MHA架构介绍：

MHA（Master High Availability）目前在MySQL高可用方面是一个相对成熟的解决方案，它由日本DeNA公司youshimaton（现就职于Facebook公司）开发，是一套优秀的作为MySQL高可用性环境下故障切换和主从提升的高可用软件。在MySQL故障切换过程中，MHA能做到在0~30秒之内自动完成数据库的故障切换操作，并且在进行故障切换的过程中，MHA能在最大程度上保证数据的一致性，以达到真正意义上的高可用。

该软件由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）。MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。

在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。

目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因为至少需要三台服务器，出于机器成本的考虑，淘宝也在该基础上进行了改造，目前淘宝TMHA已经支持一主一从。（出自：《深入浅出MySQL(第二版)》）
</pre>

<pre>
MHA工作原理总结为以下几条：
（1）从宕机崩溃的master保存二进制日志事件（binlog events）;
（2）识别含有最新更新的slave;
（3）应用差异的中继日志(relay log) 到其他slave;
（4）应用从master保存的二进制日志事件(binlog events);
（5）提升一个slave为新master;
（6）使用其他的slave连接新的master进行复制。
</pre>

<pre>
自带脚本：
自动切换脚本：/usr/local/bin/master_ip_failover
手动切换脚本：/usr/local/bin/master_ip_online_change
</pre>

<h3 id="图中的MHA阐述"><a href="#图中的MHA阐述" class="headerlink" title="图中的MHA阐述"></a>图中的MHA阐述</h3><ol>
<li>服务为主备架构，部署在IDC-A和IDC-B，其中主流量在IDC-A；MHA MANAGER则部署在IDC-C（第三个机房），这样才能保证任意一边的IDC出问题，都不影响MHA的切换；</li>
<li>为了防止来回切导致严重数据问题。可以设置，当MHA发生自动切换时，MHA MANAGER无论成功与否都会退出；</li>
<li>MHA在故障时可以进行数据补齐。</li>
</ol>
<h2 id="MySQL-半同步复制"><a href="#MySQL-半同步复制" class="headerlink" title="MySQL 半同步复制"></a>MySQL 半同步复制</h2><h3 id="主从复制的基本原理"><a href="#主从复制的基本原理" class="headerlink" title="主从复制的基本原理"></a>主从复制的基本原理</h3><ol>
<li>[master] SQL操作存入binLog中;</li>
<li>[slave] 连接master，进行数据同步;</li>
<li>[master] dump thread 把binlog数据发送到slave中;</li>
<li>[slave] 创建I&#x2F;O线程读取 master传输过来的binlog内容并写入到relay Log;</li>
<li>[slave] 创建SQL线程，从relay Log读取并执行。</li>
</ol>
<h3 id="主从复制的方式"><a href="#主从复制的方式" class="headerlink" title="主从复制的方式"></a>主从复制的方式</h3><ol>
<li><p>异步复制（Asynchronous replication）</p>
<ul>
<li>MySQL默认的复制即是异步的，主库先提交事务，然后立即响应客户端。</li>
<li>如果主库crash，且主库上已经提交的事务还没有同步到相应的从库上，那么当从库提升为主时，会导致新主上的数据不完整。</li>
<li>性能最好</li>
</ul>
</li>
<li><p>全同步复制（Fully synchronous replication）</p>
<ul>
<li>当主库执行完一个事务，且所有的从库都同步完之后才响应客户端。</li>
<li>性能差</li>
</ul>
</li>
<li><p>半同步复制（Semisynchronous replication）</p>
<ul>
<li>AFTER_COMMIT；即参数 rpl_semi_sync_master_wait_point &#x3D; after_commit</li>
<li>介于异步复制和全同步复制之间，主库提交完事务之后不立即响应客户端，而是等待至少一个从库接收到并写到relay log中才响应客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP&#x2F;IP往返的时间。所以，半同步复制最好在低延时的网络中使用。</li>
<li>等待的时间以rpl_semi_sync_master_timeout参数为准，默认为10秒。在这等待的10秒里，对其他会话该事务是可见的；所以一旦master发生宕机，对外就会产生不一致的影响</li>
<li>Slave ACK超时，将退化为异步复制模式 （所以半同步复制并不是严格意义上的半同步复制）</li>
</ul>
</li>
<li><p>增强半同步（Loss-less Semi-Synchronous）</p>
<ul>
<li>AFTER_SYNC；即参数 rpl_semi_sync_master_wait_point &#x3D; after_sync</li>
<li>after sync是MySQL5.7官方新加以解决MySQL5.6半同步缺陷的选项，也是官方推荐的方式。</li>
<li>原理：客户端发送过来一个请求，经过mysql的SQL分析，存储引擎处理，写入binlog，然后		写入从库的relaylog，存储引擎层提交，最后返回给客户端。</li>
<li>优点：主库把SQL操作先发给从库的relay log，然后再提交，再响应给客户端，这个过程即使		在storage commit之后主crash了，日志也已经写入到relay log中，从库和主库数据一致。</li>
<li>在commit之前等待Slave ACK，可以堆积事务，利于group commit，有利于提升性能。</li>
<li>在master接受到Slave ACK之前，数据的变化对其他会话时不可见的，因为此时并未提交，从	而也不会产生数据不一致的影响。</li>
<li>同样，Ack超时，也将退化为异步复制模式</li>
</ul>
</li>
<li><p>组复制 MySQL Group Replication（MGR）</p>
<ul>
<li>MGR内部实现了分布式数据一致性协议，paxos通过其来保证数据一致性。</li>
</ul>
</li>
</ol>
<h3 id="after-commit-VS-after-sync"><a href="#after-commit-VS-after-sync" class="headerlink" title="after_commit VS after_sync"></a>after_commit VS after_sync</h3><p><img src="/2020/08/31/20200831-guan-yu-mha-consul-mysql-gao-ke-yong-fang-an-de-jian-dan-zong-jie-he-si-kao/after_commit.png"><br><img src="/2020/08/31/20200831-guan-yu-mha-consul-mysql-gao-ke-yong-fang-an-de-jian-dan-zong-jie-he-si-kao/after_sync.png"></p>
<ul>
<li>after_commit：master把每一个事务写到二进制日志并保存到磁盘上，并且提交（commit）事务，再把事务发送给从库，开始等待slave的应答。响应后master返回结果给客户端，客户端才可继续。</li>
<li>after_sync  ：master把每一个事务写到二进制日志并保存磁盘上，并且把事务发送给从库，开始等待slave的应答。确认slave响应后，再提交（commit）事务到存储引擎，并返回结果给客户端，客户端才可继续。</li>
<li>半同步和增强半同步都是等待slave的ACK后才给客户端返回成功（也就是整个流程完成）</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/2020/08/31/20200831-guan-yu-mha-consul-mysql-gao-ke-yong-fang-an-de-jian-dan-zong-jie-he-si-kao/MySQL_copy.png"></p>
<ul>
<li>一致性要求高的，比如金融类的（相比其他业务TPS较低），可以考虑开启增强半同步复制</li>
</ul>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ol>
<li>MySQL 5.7新增了rpl_semi_sync_master_wait_for_slave_count系统变量，可以用来控制主库接收多少个从库写事务成功反馈，给高可用架构切换提供了灵活性。	当该变量值为2时，主库需等待两个从库的ACK。</li>
</ol>
<h2 id="Consul"><a href="#Consul" class="headerlink" title="Consul"></a>Consul</h2><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><ul>
<li>Consul is a tool for service discovery and configuration. Consul is distributed, highly available, and extremely scalable</li>
<li>Consul是一个服务管理软件。支持多数据中心下，分布式高可用的，服务发现和配置共享。采用 Raft 算法,用来保证服务的高可用。</li>
<li>Consul使用Gossip Protocol来管理成员资格并向集群广播消息。所有这些都是通过使用Serf库提供的。</li>
<li>关于raft算法原理，可以后续再讲。</li>
</ul>
<h3 id="和MHA的结合使用"><a href="#和MHA的结合使用" class="headerlink" title="和MHA的结合使用"></a>和MHA的结合使用</h3><ol>
<li>checkmysql 脚本部署到每台 consul server 中, 实现了多点检测 MySQL 是否正常;</li>
<li>checkmysql 脚本在超过半数的情况下调用 masterha_manager_consul 脚本进行主从切换;</li>
</ol>
<h4 id="主从切换"><a href="#主从切换" class="headerlink" title="主从切换"></a>主从切换</h4><ul>
<li>MHA 是切换工具，控制数据库主从切换和数据补齐；</li>
<li>MHA 进行故障检测，故障时进行切换并通知Consul下发新的主库配置到应用服务。</li>
</ul>
<h4 id="从库上下线"><a href="#从库上下线" class="headerlink" title="从库上下线"></a>从库上下线</h4><ul>
<li>Consul可以对从库进行健康检查，通过配置下发控制从库上下线。</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="CMDB"><a href="#CMDB" class="headerlink" title="CMDB"></a>CMDB</h3><ul>
<li>配置管理数据库( Configuration Management Database,CMDB)</li>
<li>自动化运维立足之本。在容灾切换管理工具中，可以直接一键从CMDB中同步所有业务系统，并能够非常灵活的定义每个业务系统的切换过程环节以及每个环节所有执行的具体操作。</li>
<li><a href="https://blog.51cto.com/031028/2426950">CMDB与容灾备份的关联</a></li>
<li><a href="https://cloud.tencent.com/developer/news/302057">好的CMDB建设，应该具备这些要素</a></li>
<li><a href="https://blog.csdn.net/weixin_42556618/article/details/107345128">【运维探讨】如何实现更加简单、高效、安全的灾备切换管理？</a></li>
</ul>
<h3 id="脑裂"><a href="#脑裂" class="headerlink" title="脑裂"></a>脑裂</h3><ul>
<li>脑裂问题是分布式多活建设必须面临的问题之一。</li>
<li>以上面的架构进行描述，当IDC-A和IDC-B、IDC-C网络不通时，其实IDC-A就是一个网络孤岛。<br>这时候时IDC-B中的从库就会提升为主库，并开始接收写操作。因为IDC-A已经是个数据孤岛，服务的主从库并未发生改变(接收不到consul下发的配置)，此时也接受外部的写操作请求，那么就会造成两边数据都有写操作，错误的双主架构导致错误的数据问题。</li>
</ul>
<h4 id="如何避免脑裂问题"><a href="#如何避免脑裂问题" class="headerlink" title="如何避免脑裂问题"></a>如何避免脑裂问题</h4><ol>
<li>如何让IDC的服务可以判断自身是否孤岛，从而拒绝服务，避免数据问题呢？</li>
<li>其中一个方案使用Consul作为选主服务来解决。后续另开文章叙述。</li>
<li>使用etcd：<a href="https://mp.weixin.qq.com/s/VFJg14JcapijOyhfJJMYUg">etcd 实现故障时主备秒级切换高可用架构</a></li>
<li>分布式锁服务Chubby（参见文献[Bur06]）集群锁服务提供一个与文件系统类似的API用来操作锁。Chubby 可以处理异地、跨机房级别的锁请求。Chubby 使用Paxos协议来提供分布式一致性（具体描述参看第23章）。Chubby 是实现主实例选举（Master-Election）过程的关键组件。例如，一个服务有5个冗余实例在同时运行，但是只有一个实例可以处理对外请求，一般的做法是通过Chubby进行自动选举，选择一个实例成为主实例。Chubby适合存放那种对一致性要求非常高的数据。—《SRE：Google运维解密》</li>
</ol>
<h4 id="结合raft的思考"><a href="#结合raft的思考" class="headerlink" title="结合raft的思考"></a>结合raft的思考</h4><ul>
<li>为了避免脑裂，需要有选主机制，一般超半数的投票才能成为leader；Consul就是基于raft是实现的；</li>
<li>在线上部署consul必须至少是三个机房，因为如果只有两个机房，其中一个机房挂了（刚好是大多数机器的机房），服务将不可用；</li>
<li>分布式存储系统，需要解决数据的一致性问题和脑裂问题。<ol>
<li>raft有实现，但是首先得基于raft协议的文件存储；</li>
<li>使用MySQL作为存储，Consul作为选主服务的业务：Consul可以解决脑裂问题<ul>
<li>MySQL的增强半同步复制机制 支持配置n个从库ack才响应客户端（其实和raft大多数结点写成功才算成功有点类似[Quorum机制]），可以很大程度的避免丢数据导致不一致。</li>
</ul>
</li>
</ol>
</li>
<li>一般金钱业务使用同城两个机房，主备架构，那么不能完全和raft三机房匹配（三机房意味着一定每个机房至少有一个结点接收到数据才算成功）。当然每个机房可以有多个DB，比如同城的两个机房A合B，A有一主一丛，B有两从。增强半同步可以根据实际情况配置rpl_semi_sync_master_wait_for_slave_count参数，指定必须多少个从库成功。<ul>
<li>MySQL使用异步复制的，一般情况下，切完机房保持数据一致性或检查监控数据一致性的方案，需要业务方自行监控和修正。</li>
<li>就算使用了增强半同步，理论上数据也只是落盘到relay log，极端情况下，从库也可以立马故障，甚至无法恢复。这种极端情况基本不考虑了，只能业务自己权衡，允不允许丢数据，有没有其他修复数据机制（日志文件或对账等），要不要继续提供服务了。</li>
</ul>
</li>
</ul>
<h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><h3 id="为什么Dump和I-x2F-O线程不能多线程？"><a href="#为什么Dump和I-x2F-O线程不能多线程？" class="headerlink" title="为什么Dump和I&#x2F;O线程不能多线程？"></a>为什么Dump和I&#x2F;O线程不能多线程？</h3><ol>
<li>dump线程和IO线程都是负责网络传输，如果将这里扩展为多线程那么会将一份Binlog日志分割为多份，并行传输，那么在slave端将会要额外的增加代码考虑如何将多份日志还原为原来的Binlog，大大增加难度。</li>
<li>性能瓶颈不在IO，扩展后也没有多大效率提升。</li>
<li>为什么Redis 6.0使用IO多线程增强性能，MySQL这里使用IO多线程却不行？<ul>
<li>Redis是多个Client节点一个Server节点（暂且这么看），IO线程需要处理多个不同Client来源的请求；MySQL主从复制，本质上是1个Client端一个Server端，增大IO线程也无济于事。</li>
</ul>
</li>
</ol>
<h3 id="增强半同步是否会导致从有数据而主却没有？"><a href="#增强半同步是否会导致从有数据而主却没有？" class="headerlink" title="增强半同步是否会导致从有数据而主却没有？"></a>增强半同步是否会导致从有数据而主却没有？</h3><ul>
<li>是。在Loss-less Semi-Synchronous模式下，master在调用binlog sync之后，engine层commit之前等待Slave ACK（需要收到至少一个Slave节点回复的ACK后）。这样只有在确认Slave收到事务events后，master事务才会提交，然后把结果返回给客户端。此时此事务才对其他事务可见。在这种模式下解决了after_commit模式带来的幻读和数据丢失问题，因为主库没有提交事务。但也会有个问题，假设主库在存储引擎提交之前挂了，那么很明显这个事务是不成功的，但由于对应的Binlog已经做了Sync操作，从库已经收到了这些Binlog，并且执行成功，相当于在从库上多了数据，也算是有问题的，但多了数据，问题一般不算严重。这个问题可以这样理解，作为MySQL，在没办法解决分布式数据一致性问题的情况下，它能保证的是不丢数据，多了数据总比丢数据要好。</li>
</ul>
<h3 id="MHA本身就支持自动切，为什么还要使用Consul？"><a href="#MHA本身就支持自动切，为什么还要使用Consul？" class="headerlink" title="MHA本身就支持自动切，为什么还要使用Consul？"></a>MHA本身就支持自动切，为什么还要使用Consul？</h3><ul>
<li>MHA本身提供了自动切换主库的功能，但是MHA本身没有提供通知应用等机制。因此采用比较成熟的方案MHA+consul，并以SDK的方式接入。</li>
</ul>
<h3 id="自动切换安全吗？"><a href="#自动切换安全吗？" class="headerlink" title="自动切换安全吗？"></a>自动切换安全吗？</h3><ol>
<li>直接启用masterha_manager 自动切换脚本并不安全，主要因为在网络抖动的情况下并不能保证数据库真的不能访问。不能仅通过一个点的检测就判断数据库不可访问。</li>
<li>通过 Consul( Consul 提供 dns 接口)集群的特性, 增加多点检测机制, 在 n 个集群的环境中, 有超过半数的检测点检测到数据库有问题, 就认为数据库不可访问, 这时调用 masterha_manager 脚本进行切换。</li>
<li>网络问题千变万化，在发生切换事件之后，需有相应的方案对主从流水数据进行对账或修正（确定基于binlog与应用日志的重要数据校验与补偿机制）。</li>
<li>发生切换事件之后，在确定数据已经无异常之前，需要防止再自动切回去，造成严重的数据异常。所以一般情况下，只能自动切一次，直到人工介入确认无异常，重新设置为自动切模式。当然，有完善的监控比对数据异常机制的情况下，可以考虑做成自动化，无需依赖人工介入。</li>
</ol>
<h3 id="MHA切换之后，主库禁写后，现有的连接是否还能继续写入"><a href="#MHA切换之后，主库禁写后，现有的连接是否还能继续写入" class="headerlink" title="MHA切换之后，主库禁写后，现有的连接是否还能继续写入?"></a>MHA切换之后，主库禁写后，现有的连接是否还能继续写入?</h3><p><img src="/2020/08/31/20200831-guan-yu-mha-consul-mysql-gao-ke-yong-fang-an-de-jian-dan-zong-jie-he-si-kao/MySQL_%E6%9D%83%E9%99%90.png"><br>mha切库禁写时，直接锁住整个实例，新操作无法写入，直接就设置read_only。</p>
<h3 id="自动切的时机如何把握？"><a href="#自动切的时机如何把握？" class="headerlink" title="自动切的时机如何把握？"></a>自动切的时机如何把握？</h3><ol>
<li>自动切的最佳时机很难人为，必须经过多种故障场景的测试，确定合适尽可能安全的切换策略和参数。</li>
<li>在实践中，初期可以先告警人工介入决定是否切换；确定好合适的切换策略和参数后，自动切在非核心业务中稳定正确运行一段时间后才在核心业务运用。</li>
</ol>
<h3 id="MHA能保证数据一定不丢吗？"><a href="#MHA能保证数据一定不丢吗？" class="headerlink" title="MHA能保证数据一定不丢吗？"></a>MHA能保证数据一定不丢吗？</h3><ul>
<li>在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失。但如上所述，网络等问题时无解的，理论上还是存在丢的可能性。一致性要求高的，比如金钱类的（相比其他业务TPS较低），可以考虑开启半同步复制，大大降低数据丢失的风险。</li>
</ul>
<h3 id="新的主库和原主库数据一致性问题如何解决？"><a href="#新的主库和原主库数据一致性问题如何解决？" class="headerlink" title="新的主库和原主库数据一致性问题如何解决？"></a>新的主库和原主库数据一致性问题如何解决？</h3><ol>
<li>MHA只能尽量保证数据补齐；</li>
<li>主从延迟较大时，切主库有风险；</li>
<li>开启半同步复制可以大大降低丢数据的风险，但也带来一定的性能损耗；</li>
<li>要做好切库后，主从日志流水对比修复方案</li>
</ol>
<h3 id="不一致如何止损？"><a href="#不一致如何止损？" class="headerlink" title="不一致如何止损？"></a>不一致如何止损？</h3><ol>
<li>根据业务情况进行实现，比如在发生切换事件的一端时间内(比如一个小时)，阻断大额交易操作，等待开发确认后再恢复；</li>
<li>具体实现可以使用redis存储数据快照，执行前和数据库的数据进行对比判断是否阻断，或其他可行方案；</li>
<li>是否应该阻断，公司的利益和用户的利益，这是个哲学问题。。。</li>
</ol>
<h3 id="扩展-1"><a href="#扩展-1" class="headerlink" title="扩展"></a>扩展</h3><ul>
<li>云数据库使用数据库代理进行连接:<a href="https://cloud.tencent.com/document/product/236/72619">读写分离扩展云数据库 MySQL 性能</a></li>
<li><a href="https://cloud.tencent.com/document/product/236/35671">切换网络</a></li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://www.cnblogs.com/arstercz/p/6963920.html">基于 consul 架构的 MHA 自动切换</a></li>
<li><a href="https://blog.csdn.net/yangjianrong1985/article/details/102479034">基于MHA+consul的MySQL高可用设计</a></li>
<li><a href="https://www.cnblogs.com/xuanzhi201111/p/4231412.html">MySQL高可用之MHA的搭建</a></li>
<li><a href="https://code.google.com/p/mysql-master-ha/">MHA官方介绍</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzYwNjQ3NA==&mid=2651297535&idx=1&sn=2138d7d09cf5294c73810b133eed67e3&chksm=84ff42dab388cbcc90d9642b6cd3ed5de8e524cc10737947ce0c46eb287e95f4bae62472fa24&mpshare=1&scene=1&srcid=0518czFAsyzFLKkM07SIauWS#rd">京东MySQL数据库主从切换自动化</a></li>
<li><a href="https://www.cnblogs.com/sunss/archive/2010/10/05/1844204.html">MySQL数据库的授权原则</a></li>
<li><a href="https://www.cnblogs.com/zhoujinyi/p/3808673.html">MySQL MHA 搭建&amp;测试</a></li>
<li><a href="https://www.cnblogs.com/ivictor/p/5735580.html">MySQL半同步复制</a></li>
<li><a href="https://blog.csdn.net/qq_33330687/article/details/107496954">MySQL - 异步复制，半同步复制，增强半同步复制，组复制，全告诉你</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1537291">mysql 半同步复制</a></li>
<li><a href="https://www.cnblogs.com/allenhu320/p/11316276.html">增强半同步复制</a></li>
<li><a href="https://www.jianshu.com/p/3bfb0bfb8b34">【MySQL】5.7增强半同步AFTER SYNC&amp;AFTER COMMIT</a></li>
</ol>
]]></content>
      <tags>
        <tag>容灾</tag>
        <tag>Consul</tag>
        <tag>MySQL</tag>
        <tag>MHA</tag>
        <tag>HA</tag>
        <tag>半同步复制</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式一致性协议概览</title>
    <url>/2020/09/12/20200912-fen-bu-shi-yi-zhi-xing-xie-yi/</url>
    <content><![CDATA[<ul>
<li>本文内容基本来源：网上资料总结</li>
</ul>
<h2 id="共识（Consensus）-和-一致性（Consistency）"><a href="#共识（Consensus）-和-一致性（Consistency）" class="headerlink" title="共识（Consensus） 和 一致性（Consistency）"></a>共识（Consensus） 和 一致性（Consistency）</h2><ul>
<li>分布式一致性（共识）协议 (consensus protocol)</li>
<li>Consensus !&#x3D; Consistency</li>
<li>CAP 定理中的 C 和数据库 ACID 的 C 才是真正的“一致性”—— consistency 问题</li>
<li>在早些的文献中，共识（consensus）也叫做协商（agreement）</li>
<li>共识（Consensus），很多时候会见到与一致性（Consistency）术语放在一起讨论。严谨地讲，两者的含义并不完全相同。</li>
<li>一致性的含义比共识宽泛，在不同场景（基于事务的数据库、分布式系统等）下意义不同。具体到分布式系统场景下，一致性指的是多个副本对外呈现的状态。如前面提到的顺序一致性、线性一致性，描述了多节点对数据状态的共同维护能力。而共识，则特指在分布式系统中多个节点之间对某个事情（例如多个事务请求，先执行谁？）达成一致意见的过程。因此，达成某种共识并不意味着就保障了一致性。</li>
<li>实践中，要保证系统满足不同程度的一致性，往往需要通过共识算法来达成。</li>
<li><a href="https://mp.weixin.qq.com/s/KKrxuVCrjlXXWMPTXQ-fvA">分布式之系统底层原理</a></li>
</ul>
<h2 id="共识问题"><a href="#共识问题" class="headerlink" title="共识问题"></a>共识问题</h2><ul>
<li>在分布式系统中，共识就是系统中的多个节点对某个值达成一致。共识问题可以用数学语言来描述：一个分布式系统包含 n 个进程 {0, 1, 2,…, n-1}，每个进程都有一个初值，进程之间互相通信，设计一种算法使得尽管出现故障，进程们仍协商出某个不可撤销的最终决定值，且每次执行都满足以下三个性质：<ul>
<li>终止性（Termination）：所有正确的进程最终都会认同某一个值。</li>
<li>协定性（Agreement）：所有正确的进程认同的值都是同一个值。</li>
<li>完整性（Integrity），也称作有效性（Validity）：如果正确的进程都提议同一个值，那么所有处于认同状态的正确进程都选择该值。</li>
</ul>
</li>
<li>完整性可以有一些变化，例如，一种较弱的完整性是认定值等于某些正确经常提议的值，而不必是所有进程提议的值。完整性也隐含了，最终被认同的值必定是某个节点提出过的。</li>
<li>算法共识&#x2F;一致性算法有两个最核心的约束：1) 安全性（Safety），2) 存活性（Liveness）：<ul>
<li>Safety：保证决议（Value）结果是对的，无歧义的，不会出现错误情况。<ul>
<li>只有是被提案者提出的提案才可能被最终批准；</li>
<li>在一次执行中，只批准（chosen）一个最终决议。被多数接受（accept）的结果成为决议；</li>
</ul>
</li>
<li>Liveness：保证决议过程能在有限时间内完成。<ul>
<li>决议总会产生，并且学习者最终能获得被批准的决议。</li>
</ul>
</li>
</ul>
</li>
<li>根据解决的场景是否允许拜占庭（Byzantine）错误，共识算法可以分为 Crash Fault Tolerance (CFT) 和 Byzantine Fault Tolerance（BFT）两类。<ul>
<li>对于非拜占庭错误的情况，已经存在不少经典的算法，包括 Paxos（1990 年）、Raft（2014 年）及其变种等。这类容错算法往往性能比较好，处理较快，容忍不超过一半的故障节点。</li>
<li>对于要能容忍拜占庭错误的情况，包括 PBFT（Practical Byzantine Fault Tolerance，1999 年）为代表的确定性系列算法、PoW（1997 年）为代表的概率算法等。确定性算法一旦达成共识就不可逆转，即共识是最终结果；而概率类算法的共识结果则是临时的，随着时间推移或某种强化，共识结果被推翻的概率越来越小，最终成为事实上结果。拜占庭类容错算法往往性能较差，容忍不超过 1&#x2F;3 的故障节点。</li>
</ul>
</li>
<li>副本控制协议可以分为两大类：“中心化(centralized)副本控制协议”和“去中心化(decentralized)副本控制协议”。</li>
</ul>
<h2 id="分布式系统的几个主要难题"><a href="#分布式系统的几个主要难题" class="headerlink" title="分布式系统的几个主要难题"></a>分布式系统的几个主要难题</h2><ol>
<li>网络问题</li>
<li>时钟问题</li>
<li>节点故障问题</li>
</ol>
<h2 id="达成共识还可以解决分布式系统中的以下经典问题"><a href="#达成共识还可以解决分布式系统中的以下经典问题" class="headerlink" title="达成共识还可以解决分布式系统中的以下经典问题"></a>达成共识还可以解决分布式系统中的以下经典问题</h2><ol>
<li>互斥（Mutual exclusion）：哪个进程进入临界区访问资源？</li>
<li>选主（Leader election）：在单主复制的数据库，需要所有节点就哪个节点是领导者达成共识。如果一些由于网络故障而无法与其他节点通信，可能会产生两个领导者，它们都会接受写入，数据就可能会产生分歧，从而导致数据不一致或丢失。</li>
<li>原子提交（Atomic commit）：跨多节点或跨多分区事务的数据库中，一个事务可能在某些节点上失败，但在其他节点上成功。如果我们想要维护这种事务的原子性，必须让所有节点对事务的结果达成共识：要么全部提交，要么全部中止&#x2F;回滚。</li>
</ol>
<ul>
<li>总而言之，在共识的帮助下，分布式系统就可以像单一节点一样工作——所以共识问题是分布式系统最基本的问题。</li>
</ul>
<h2 id="FLP-不可能（FLP-Impossibility）"><a href="#FLP-不可能（FLP-Impossibility）" class="headerlink" title="FLP 不可能（FLP Impossibility）"></a>FLP 不可能（FLP Impossibility）</h2><ul>
<li>早在 1985 年，Fischer、Lynch 和 Paterson （FLP）在 “Impossibility of Distributed Consensus with One Faulty Process[5]” 证明了：在一个异步系统中，即使只有一个进程出现了故障，也没有算法能保证达成共识。</li>
<li>简单来说，因为在一个异步系统中，进程可以随时发出响应，所以没有办法分辨一个进程是速度很慢还是已经崩溃，这不满足终止性（Termination）。</li>
<li>FLP给后来的人们提供了研究的思路——不再尝试寻找异步通信系统中共识问题完全正确的解法。FLP 不可能是指无法确保达成共识，并不是说如果有一个进程出错，就永远无法达成共识。</li>
</ul>
<h2 id="同步系统中的共识"><a href="#同步系统中的共识" class="headerlink" title="同步系统中的共识"></a>同步系统中的共识</h2><ul>
<li>Dolev 和 Strong 在论文 “Authenticated Algorithms for Byzantine Agreement[9]” 中证明了：同步系统中，如果 N 个进程中最多有 f 个会出现崩溃故障，那么经过 f + 1 轮消息传递后即可达成共识。</li>
<li>在一个有 f 个拜占庭故障节点的系统中，必须总共至少有 3f + 1 个节点才能够达成共识。即 N &gt;&#x3D; 3f + 1。</li>
<li>虽然同步系统下拜占庭将军问题的确存在解，但是代价很高，需要 O(N^f+1 ) 的信息交换量，只有在那些安全威胁很严重的地方使用（例如：航天工业）</li>
<li>PBFT(Practical Byzantine Fault Tolerance)[12] 算法顾名思义是一种实用的拜占庭容错算法，由 Miguel Castro 和 Barbara Liskov 发表于 1999 年。</li>
<li>算法的主要细节不再展开。PBFT 也是通过使用同步假设保证活性来绕过 FLP 不可能。PBFT 算法容错数量同样也是 N &gt;&#x3D; 3f + 1，但只需要 O(n^2 ) 信息交换量，即每台计算机都需要与网络中其他所有计算机通讯。</li>
</ul>
<h2 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h2><ul>
<li>一致性（Consistency）是指多副本（Replications）问题中的数据一致性。</li>
</ul>
<ol>
<li>强一致性：数据更新成功后，任意时刻所有副本中的数据都是一致的，一般采用同步的方式实现。</li>
<li>弱一致性：数据更新成功后，系统不承诺立即可以读到最新写入的值，也不承诺具体多久之后可以读到。</li>
<li>最终一致性：弱一致性的一种形式，数据更新成功后，系统不承诺立即可以返回最新写入的值，但是保证最终会返回上一次更新操作的值。</li>
</ol>
<ul>
<li>分布式中一致性是非常重要的，分为弱一致性和强一致性。现在主流的一致性协议一般都选择的是弱一致性的特殊版本：最终一致性。</li>
</ul>
<h2 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h2><ul>
<li>CAP是指在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）这三个要素最多只能同时实现两点，不可能三者兼顾。</li>
<li>CAP理论提出就是针对分布式环境的，所以，P 这个属性是必须具备的。</li>
</ul>
<ol>
<li>Consistency 一致性<br>一致性指“all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。等同于所有节点拥有数据的最新版本。<br>CAP中的C指的是强一致性。</li>
<li>Availability 可用性<br>可用性指“Reads and writes always succeed”，即服务一直可用，而且是正常响应时间。<br>对于一个可用性的分布式系统，每一个非故障的节点必须对每一个请求作出响应。如果不考虑一致性，这个是很好实现的，立即返回本地节点的数据即可，而不需要等到数据一致才返回。</li>
<li>Partition Tolerance 分区容忍性<br>Tolerance也可以翻译为容错，分区容忍性具体指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即系统容忍网络出现分区，分区之间网络不可达的情况，分区容忍性和扩展性紧密相关，Partition Tolerance特指在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。</li>
</ol>
<ul>
<li><p>传统数据库都是假设不保证P的，因为传统数据库都是单机或者很小的本地集群，假设网络不存在问题，出现问题手工修复。所以，损失分区容错(P)只保证CA相当于就是一个单体应用，根本不是分布式。</p>
</li>
<li><p>分布式是要求单个节点故障(概率太高了)系统仍能完成运行。搭建分布式就是间接要求必须保证P，即P是现实，那C和A就无法同时做到，需要在这两者之间做平衡。</p>
</li>
<li><p>像银行系统，是通过损失可用性(A)来保障CP，银行系统是内网，很少出现分区不可达故障状态，一旦出现，不可达的节点对应的ATM就没法使用，即变为不可用。同时如果数据在各分区未达到一致，ATM也是Loading状态即不可用。</p>
</li>
<li><p>在互联网实践中，可用性又是极其重要的，因此大部分是通过损失一致性(C)来保障AP，当然也非完全牺牲一致性，使用弱一致性，即一定时间后一致的弱一致性，当数据还在同步时(WRITE之后)，使用上一次的数据。</p>
</li>
<li><p>Google 2009年 在Transaction Across DataCenter 的分享中，对一致性协议在业内的实践做了一简单的总结，如下图所示，这是 CAP 理论在工业界应用的实践经验。<br><img src="/2020/09/12/20200912-fen-bu-shi-yi-zhi-xing-xie-yi/cap-sumarry.png"></p>
</li>
</ul>
<h3 id="BASE-理论"><a href="#BASE-理论" class="headerlink" title="BASE 理论"></a>BASE 理论</h3><ul>
<li>Basically Available（基本可用）</li>
<li>Soft state（软状态）</li>
<li>Eventually consistent（最终一致性）</li>
</ul>
<ul>
<li>BASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。</li>
<li>BASE理论是对大规模的互联网分布式系统实践的总结，用弱一致性来换取可用性，不同于ACID，属于AP系统。</li>
</ul>
<h3 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h3><ul>
<li>ACID（Atomicity原子性，Consistency一致性，Isolation隔离性，Durability持久性）是事务的特点，具有强一致性，一般用于单机事务，分布式事务若采用这个原则会丧失一定的可用性，属于CP系统。</li>
</ul>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><h3 id="按单主和多主进行分类"><a href="#按单主和多主进行分类" class="headerlink" title="按单主和多主进行分类"></a>按单主和多主进行分类</h3><ol>
<li>单主协议，即整个分布式集群中只存在一个主节点。主备复制、2PC、 Paxos、Raft、ZAB。<ul>
<li>（不允许数据分歧）：整个分布式系统就像一个单体系统，所有写操作都由主节点处理并且同步给其他副本。</li>
</ul>
</li>
<li>多主协议，即整个集群中不只存在一个主节点。Pow、Gossip协议。<ul>
<li>（允许数据分歧）：所有写操作可以由不同节点发起，并且同步给其他副本。</li>
</ul>
</li>
</ol>
<ul>
<li>单主协议由一个主节点发出数据，传输给其余从节点，能保证数据传输的有序性。而多主协议则是从多个主节点出发传输数据，传输顺序具有随机性，因而数据的有序性无法得到保证，只保证最终数据的一致性。这是单主协议和多主协议之间最大的区别。</li>
</ul>
<pre>
－－－单主－－主备复制、2PC、 Paxos、Raft、ZAB
｜
－－－多主－－Pow、Gossip
</pre>

<h3 id="按CAP中的P分类"><a href="#按CAP中的P分类" class="headerlink" title="按CAP中的P分类"></a>按CAP中的P分类</h3><ul>
<li>分区容忍的一致性协议跟所有的单主协议一样，它也是只有一个主节点负责写入（提供顺序一致性），但它跟 2PC 的区别在于它只需要保证大多数节点（一般是超过半数）达成一致就可以返回客户端结果，这样可以提高了性能，同时也能容忍网络分区（少数节点分区不会导致整个系统无法运行）。分区容忍的一致性算法保证大多数节点数据一致后才返回客户端，同样实现了顺序一致性。</li>
</ul>
<pre>
－－－非P－－主备复制、2PC
｜
－－－P   －－Paxos、Raft
</pre>

<h2 id="算法简介"><a href="#算法简介" class="headerlink" title="算法简介"></a>算法简介</h2><h3 id="1、主备复制"><a href="#1、主备复制" class="headerlink" title="1、主备复制"></a>1、主备复制</h3><ul>
<li>主备复制可以说是最常用的数据复制方法，也是最基础的方法，很多其他协议都是基于它的变种。 主备复制要求所有的写操作都在主节点上进行，然后将操作的日志发送给其他副本。可以发现由于主备复制是有延迟的，所以它实现的是最终一致性。</li>
<li>主备复制的实现方式：主节点处理完写操作之后立即返回结果给客户端，写操作的日志异步同步给其他副本。这样的好处是性能高，客户端不需要等待数据同步，缺点是如果主节点同步数据给副本之前数据缺失了，那么这些数据就永久丢失了。MySQL 的主备同步就是典型的异步复制。</li>
</ul>
<h3 id="2、2PC"><a href="#2、2PC" class="headerlink" title="2、2PC"></a>2、2PC</h3><ul>
<li>2PC 是典型的 CA 系统，为了保证一致性和可用性，2PC 一旦出现网络分区或者节点不可用就会被拒绝写操作，把系统变成只读的。</li>
<li>由于 2PC 容易出现节点宕机导致一直阻塞的情况，所以在数据复制的场景中不常用，一般多用于分布式事务中。</li>
<li>如果网络环境较好，该协议一般还是能很好的工作的，2PC广泛应用于关系数据库的分布式事务处理，如mysql的内部与外部XA都是基于2PC的，一般想要把多个操作打包未原子操作也可以用2PC。</li>
</ul>
<pre>
｜－－－1. Prepare(Vote Request) 
｜
｜－－－2. Global Commit (1－ return (Vote Commit)) （正常流程）
｜
｜－－－2. Global Rollback (1－ return (Vote Abort)) （异常流程）
</pre>

<ul>
<li>缺点：    <ol>
<li>性能问题(两个阶段都涉及同步等待阻塞，极大降低了吞吐量)</li>
<li>协调者单点故障问题</li>
<li>丢失消息导致的数据不一致问题</li>
</ol>
</li>
</ul>
<h3 id="3、3PC"><a href="#3、3PC" class="headerlink" title="3、3PC"></a>3、3PC</h3><ul>
<li><p>相对于2PC，3PC主要解决的单点故障问题，并减少阻塞。在2PC的基础上增加了CanCommit阶段，并引入了超时机制。一旦事务参与者迟迟没有收到协调者的Commit请求，就会自动进行本地commit，这样相对有效地解决了协调者单点故障的问题;但是性能问题和不一致问题仍然没有根本解决。</p>
</li>
<li><p>CanCommit阶段: 检查下自身状态的健康性，看有没有能力进行事务操作。</p>
</li>
<li><p>和2PC区别：</p>
<ol>
<li>相比较2PC而言，3PC对于协调者（Coordinator）和参与者（Partcipant）都设置了超时时间，而2PC只有协调者才拥有超时机制。这个优化点，主要是避免了参与者在长时间无法与协调者节点通讯（协调者挂掉了）的情况下，无法释放资源的问题，因为参与者自身拥有超时机制会在超时后，自动进行本地commit从而进行释放资源。而这种机制也侧面降低了整个事务的阻塞时间和范围。</li>
<li>通过CanCommit、PreCommit、DoCommit三个阶段的设计，相较于2PC而言，多设置了一个缓冲阶段保证了在最后提交阶段之前各参与节点的状态是一致的。</li>
</ol>
</li>
<li><p>无论是2PC还是3PC都无法彻底解决分布式的一致性问题。Google Chubby的作者Mike Burrows说过， there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos。意即世上只有一种一致性算法，那就是Paxos，所有其他一致性算法都是Paxos算法的不完整版。</p>
</li>
</ul>
<h3 id="4、MVCC"><a href="#4、MVCC" class="headerlink" title="4、MVCC"></a>4、MVCC</h3><ul>
<li>MVCC(Multi-version Cocurrent Control，多版本并发控制)技术。MVCC 技术最初也是在数据库系统中被提出，但这种思想并不局限于单机的分布式系统，在分布式系统中同样有效。</li>
</ul>
<h3 id="5、Paxos协议"><a href="#5、Paxos协议" class="headerlink" title="5、Paxos协议"></a>5、Paxos协议</h3><ul>
<li>2PC、3PC 两个协议的协调者都需要人为设置而无法自动生成，是不完整的分布式协议，而Paxos 就是一个真正的完整的分布式算法。系统一共有几个角色：Proposer（提出提案）、Acceptor（参与决策）、Learner（不参与提案，只负责接收已确定的提案，一般用于提高集群对外提供读服务的能力），实践中一个节点可以同时充当多个角色。</li>
<li>作者在描述Paxos时，列举了希腊城邦选举的例子，所以该算法又被称为希腊城邦算法。</li>
<li>Paxos是非常经典的一致性协议，但是因为过于理论化，难以直接工程化，因此工业界出现了诸多基于Paxos思想出发的变种。虽然这些变种最终很多都和原始的Paxos有比较大的差距，甚至完全演变成了新的协议，但是作为奠基者的Paxos在分布式一致性协议中依然持有不可撼动的地位。</li>
<li>Paxos协议的容错性很好，只要有超过半数的节点可用，整个集群就可以自己进行Leader选举，也可以对外服务，通常用来保证一份数据的多个副本之间的一致性，适用于构建一个分布式的一致性状态机。</li>
<li>Google的分布式锁服务Chubby就是用了Paxos协议，而开源的ZooKeeper使用的是Paxos的变种ZAB协议。</li>
</ul>
<h3 id="6、Raft协议"><a href="#6、Raft协议" class="headerlink" title="6、Raft协议"></a>6、Raft协议</h3><ul>
<li>Raft协议是斯坦福的Diego Ongaro、John Ousterhout两人于2013年提出，作者表示流行的Paxos算法难以理解，且其过于理论化致使直接应用于工程实现时出现很多困难，因此作者希望提出一个能被大众比较容易地理解接受，且易于工程实现的协议。Raft由此应运而生。不得不说，Raft作为一种易于理解，且工程上能够快速实现一个较完整的原型的算法，受到业界的广泛追捧。</li>
<li>Raft协议对标Paxos，容错性和性能都是一致的，但是Raft比Paxos更易理解和实施。系统分为几种角色：Leader（发出提案）、Follower（参与决策）、Candidate（Leader选举中的临时角色）。</li>
<li>在Raft协议出来之前，Paxos是分布式领域的事实标准，但是Raft的出现打破了这一个现状（raft作者也是这么想的，请看论文），Raft协议把Leader选举、日志复制、安全性等功能分离并模块化，使其更易理解和工程实现，将来发展怎样我们拭目以待（挺看好）。</li>
<li>Raft协议目前被用于 cockrouchDB，TiKV等项目中</li>
<li>Raft 算法实际上是 Multi-Paxos 的一个变种，通过新增两个约束：<ul>
<li>追加日志约束：Raft 中追加节点的日志必须是串行连续的，而 Multi-Paxos 中则可以并发追加日志（实际上 Multi-Paxos 的并发也只是针对日志追加，最后应用到内部 State Machine 的时候还是必须保证顺序）。</li>
<li>选主限制：Raft 中只有那些拥有最新、最全日志的节点才能当选 Leader 节点，而 Multi-Paxos 由于允许并发写日志，因此无法确定一个拥有最新、最全日志的节点，因此可以选择任意一个节点作为 Leader，但是选主之后必须要把 Leader 节点的日志补全。</li>
<li>基于这两个限制，Raft 算法的实现比 Multi-Paxos 更加简单易懂，不过由于 Multi-Paxos 的并发度更高，因此从理论上来说 Multi-Paxos 的性能会更好一些，但是到现在为止业界也没有一份权威的测试报告来支撑这一观点。</li>
</ul>
</li>
</ul>
<h3 id="Paxos和Raft的对比"><a href="#Paxos和Raft的对比" class="headerlink" title="Paxos和Raft的对比"></a>Paxos和Raft的对比</h3><ul>
<li>Paxos算法和Raft算法有显而易见的相同点和不同点。二者的共同点在于，它们本质上都是单主的一致性算法，且都以不存在拜占庭将军问题作为前提条件。二者的不同点在于，Paxos算法相对于Raft，更加理论化，原理上理解比较抽象，仅仅提供了一套理论原型，这导致很多人在工业上实现Paxos时，不得已需要做很多针对性的优化和改进，但是改进完却发现算法整体和Paxos相去甚远，无法从原理上保证新算法的正确性，这一点是Paxos难以工程化的一个很大原因。相比之下Raft描述清晰，作者将算法原型的实现步骤完整地列在论文里，极大地方便了业界的工程师实现该算法，因而能够受到更广泛的应用。</li>
<li>从根本上来看，Raft的核心思想和Paxos是非常一致的，甚至可以说，Raft是基于Paxos的一种具体化实现和改进，它让一致性算法更容易为人所接受，更容易得到实现。由此亦可见，Paxos在一致性算法中的奠基地位是不可撼动的。</li>
</ul>
<h3 id="7、Gossip算法"><a href="#7、Gossip算法" class="headerlink" title="7、Gossip算法"></a>7、Gossip算法</h3><ul>
<li>Gossip又被称为流行病算法，它与流行病毒在人群中传播的性质类似，由初始的几个节点向周围互相传播，到后期的大规模互相传播，最终达到一致性。</li>
<li>Gossip协议与上述所有协议最大的区别就是它是去中心化的，上面所有的协议都有一个类似于Leader的角色来统筹安排事务的响应、提交与中断，但是Gossip协议中就没有Leader，每个节点都是平等的。</li>
<li>Gossip协议被广泛应用于P2P网络，同时一些分布式的数据库，如Redis集群的消息同步使用的也是Gossip协议，另一个重大应用是被用于比特币的交易信息和区块信息的传播。</li>
<li>去中心化的Gossip看起来很美好：没有单点故障，看似无上限的对外服务能力……本来随着Cassandra火了一把，但是现在Cassandra也被抛弃了，去中心化的架构貌似难以真正应用起来。归根到底我觉得还是因为去中心化本身管理太复杂，节点之间沟通成本高，最终一致等待时间较长……往更高处看，一个企业（甚至整个社会）不也是需要中心化的领导（或者制度）来管理吗，如果没有领导（或者制度）管理，大家就是一盘散沙，难成大事啊。</li>
<li>事实上现代互联网架构只要把单点做得足够强大，再加上若干个强一致的热备，一般问题都不大。</li>
<li>应用：数据同步；缺点：节点之间沟通成本高，最终一致等待时间较长</li>
</ul>
<h3 id="8、Pow（Proof-of-work）"><a href="#8、Pow（Proof-of-work）" class="headerlink" title="8、Pow（Proof of work）"></a>8、Pow（Proof of work）</h3><ul>
<li>Proof-of-work算法又被称为Pow算法。工作量证明算法。</li>
<li>Pow最为人所熟知的应用是比特币。代表者是比特币（BTC），区块链1.0</li>
<li>PoW（Proof of Work，工作量证明）的字面意思是谁干的活多，谁的话语权就大，在一定层面上类似于现实生活中“多劳多得”的概念。以比特币为例，比特币挖矿就是通过计算符合某一个比特币区块头的哈希散列值争夺记账权。这个过程需要通过大量的计算实现，简单理解就是挖矿者进行的计算量越大（工作量大），它尝试解答问题的次数也就变得越多，解出正确答案的概率自然越高，从而就有大概率获得记账权，即该矿工所挖出的区块被串接入主链。</li>
<li>基于PoW节点网络的安全性令人堪忧。大于51%算力的攻击。</li>
<li>51%算力攻击目前仅在“PoW”共识机制中存在，因为“PoW”共识机制依赖算力计算获胜，也就是谁算得快，谁的胜率就高。在使用了“PoW”共识机制的区块链网络中，我们称参与计算哈希的所有计算机资源为算力，那么全网络的算力就是100%，当超过51%的算力掌握在同一阵营中时，这个阵营的计算哈希胜出的概率将会大幅提高。为什么是51%？50.1%不行吗？当然也是可以的，之所以取51%是为了取一个最接近50%，且比50%大的整数百分比，这样当算力值达到51%后的效果将会比50.1%的计算效果更明显。举个例子，如果诚实节点的算力值是50.1%，那么坏节点的算力值就是49.9%。两者的差距不算太大，这样容易导致最终的区块竞争你来我往、长期不分上下。如果算力资源分散，不是高度集中的，那么整个区块链网络是可信的。然而，当算力资源集中于某一阵营的时候，算力的拥有者就能使用算力资源去逆转区块，导致区块链分叉严重，</li>
</ul>
<h3 id="9、PoS（Proof-of-Stake）"><a href="#9、PoS（Proof-of-Stake）" class="headerlink" title="9、PoS（Proof of Stake）"></a>9、PoS（Proof of Stake）</h3><ul>
<li>代表者是以太坊（ETH），以太坊正在从PoW过渡到PoS，区块链2.0</li>
<li>PoS（Proof of Stake，股权证明）是由点点币（PPCoin）首先应用的。该算法没有挖矿过程，而是在创世区块内写明股权分配比例，之后通过转让、交易的方式，也就是我们说的IPO（Initial Public Offerings）公开募股方式，逐渐分散到用户钱包地址中去，并通过“利息”的方式新增货币，实现对节点地址的奖励。PoS的意思是股份制。也就是说，谁的股份多，谁的话语权就大，这和现实生活中股份制公司的股东差不多。但是，在区块链的应用中，我们不可能真实地给链中的节点分配股份，取而代之的是另外一些东西，例如代币，让这些东西来充当股份，再将这些东西分配给链中的各节点。</li>
<li>PoS共识算法具有下面的优缺点：（1）优点•缩短了共识达成的时间，链中共识块的速度更快。•不再需要大量消耗能源挖矿，节能。•作弊得不偿失。如果一名持有多于50%以上股权的人（节点）作弊，相当于他坑了自己，因为他是拥有股权最多的人，作弊导致的结果往往是拥有股权越多的人损失越多。（2）缺点•攻击成本低，只要节点有物品数量，例如代币数量，就能发起脏数据的区块攻击。•初始的代币分配是通过IPO方式发行的，这就导致“少数人”（通常是开发者）获得了大量成本极低的加密货币，在利益面前，很难保证这些人不会大量抛售。•拥有代币数量大的节点获得记账权的概率会更大，使得网络共识受少数富裕账户支配，从而失去公正性。</li>
<li>区块链2.0仍存在性能上的缺陷，难以支持大规模的商业应用开发。与支付宝在“双十一”时26.5万笔交易&#x2F;秒的性能相比，像以太坊这样的区块链系统只能做到几百笔交易&#x2F;秒的水平。交易需由多个参与方确认，是影响区块链性能的主要原因。</li>
</ul>
<h3 id="10、DPoS"><a href="#10、DPoS" class="headerlink" title="10、DPoS"></a>10、DPoS</h3><ul>
<li>代表者是柚子（EOS），区块链3.0</li>
</ul>
<h3 id="11、"><a href="#11、" class="headerlink" title="11、"></a>11、</h3><ul>
<li>PBFT拜占庭容错，联盟链中常用。</li>
</ul>
<h3 id="Gossip算法和Pow算法对比"><a href="#Gossip算法和Pow算法对比" class="headerlink" title="Gossip算法和Pow算法对比"></a>Gossip算法和Pow算法对比</h3><ul>
<li>同为去中心化算法，Gossip算法和Pow算法都能实现超大集群的一致性，但是它们的特性可谓有天壤之别。Gossip算法往往应用于超大集群快速达成一致性的目的。它的特性是如流感一般超强的传播速度，以及自身能够管理的数量可观的节点数。但是对于流传的消息没有特别的管控，无法辨别其中的虚假信息，并且只关注与最终的一致性，不关心消息的顺序性。而Pow算法则完全专注于尽可能地解决”拜占庭将军”问题，防止消息的篡改。它可以不计代价地去要求各个节点参与竞选，以付出巨大算力为代价保证平台的安全性。</li>
</ul>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><ul>
<li>区块链：PoW、PoS、Gossip</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="2PC和TCC什么关系"><a href="#2PC和TCC什么关系" class="headerlink" title="2PC和TCC什么关系"></a>2PC和TCC什么关系</h3><ol>
<li><p>2PC在“分布式一致性协议“的范畴，属于CA层面的一个协议，一般作为和其他协议(PAXOS，Raft)进行对比的形式出现。</p>
</li>
<li><p>2PC在“分布式事务“的范畴，属于数据库层面，XA协议的基础。TCC算是一种特殊的2PC。TCC事务的处理流程与2PC两阶段提交类似，不过2PC通常都是在跨库的DB层面，而TCC本质上就是一个应用层面的2PC，需要通过业务逻辑来实现。</p>
</li>
<li><p>TCC是分布式事务的范畴，但其本质也是分布式一致性的一种协议，只是特指业务上的协议。而一般情况下我们所说的分布式一致性协议，一般是指底层系统实现上的，偏向基础服务上的。如果以后有人对TCC进行改造，描述出底层系统(非业务)的TCC，那么它也属于这篇文章所包含的其中一种分布式一致性协议。对于其他分布式事务的实现方案同理。</p>
</li>
</ol>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul>
<li>从Paxos到Raft再到EPaxos：<a href="https://mp.weixin.qq.com/s/ex7CgJTbxbd5FA2F-BvSVQ">一文总结：分布式一致性技术是如何演进的？</a></li>
<li>众所周知，Paxos是出了名的晦涩难懂，不仅难以理解，更难以实现。而Raft则以可理解性和易于实现为目标，Raft的提出大大降低了使用分布式一致性的门槛，将分布式一致性变的大众化、平民化，因此当Raft提出之后，迅速得到青睐，极大地推动了分布式一致性的工程应用。</li>
<li>EPaxos的提出比Raft还早，但却长期无人问津，很大一个原因就是EPaxos实在是难以理解。EPaxos基于Paxos，但却比Paxos更难以理解，大大地阻碍了EPaxos的工程应用。不过，是金子总会发光的，EPaxos因着它独特的优势，终于被人们发现，具有广阔的前景。</li>
<li>EPaxos更适用于跨AZ跨地域场景，对可用性要求极高的场景，Leader容易形成瓶颈的场景。Multi-Paxos和Raft本身非常相似，适用场景也类似，适用于内网场景，一般的高可用场景，Leader不容易形成瓶颈的场景。</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/130974371">分布式一致性协议概述</a></li>
<li><a href="https://www.jianshu.com/p/558acf897628">分布式系统：一致性协议</a></li>
<li><a href="https://blog.csdn.net/demon7552003/article/details/86657767">分布式一致性协议</a></li>
<li><a href="https://mp.weixin.qq.com/s/jQrPSmPhC_yNbIRcufR8KQ">分布式事务：深入理解什么是2PC、3PC及TCC协议</a></li>
<li><a href="https://mp.weixin.qq.com/s/UfbMFXxJqRhLDXUntKVE8A">详解分布式一致性机制</a></li>
<li><a href="https://mp.weixin.qq.com/s/qxaR832GsXQBpc6YxgX63Q">漫谈分布式共识问题</a>！！</li>
<li><a href="https://mp.weixin.qq.com/s/KKrxuVCrjlXXWMPTXQ-fvA">分布式之系统底层原理</a>！！！！</li>
<li><a href="https://mp.weixin.qq.com/s/IbBC38rhhQ-mEfw3yf9AVA">深度介绍分布式系统原理与设计</a></li>
<li>[区块链：以太坊DApp开发实战]</li>
<li>[区块链：分布式商业与智数未来]</li>
</ul>
]]></content>
      <tags>
        <tag>分布式技术</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL笔记</title>
    <url>/2020/10/03/20201003-mysql-bi-ji/</url>
    <content><![CDATA[<h2 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h2><p><img src="/2020/10/03/20201003-mysql-bi-ji/MySQL.png"></p>
<h2 id="InnoDB-事务隔离级别"><a href="#InnoDB-事务隔离级别" class="headerlink" title="InnoDB 事务隔离级别"></a>InnoDB 事务隔离级别</h2><table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody><tr>
<td>未提交读(RUC)</td>
<td>NO</td>
<td>NO</td>
<td>NO</td>
</tr>
<tr>
<td>已提交读(RC)</td>
<td>YES</td>
<td>NO</td>
<td>NO</td>
</tr>
<tr>
<td>可重复读(RR)</td>
<td>YES</td>
<td>YES</td>
<td>NO</td>
</tr>
<tr>
<td>可串行化</td>
<td>YES</td>
<td>YES</td>
<td>YES</td>
</tr>
</tbody></table>
<h2 id="InnoDB-锁类型"><a href="#InnoDB-锁类型" class="headerlink" title="InnoDB 锁类型"></a>InnoDB 锁类型</h2><h3 id="共享-x2F-排它锁-Shared-and-Exclusive-Locks"><a href="#共享-x2F-排它锁-Shared-and-Exclusive-Locks" class="headerlink" title="共享&#x2F;排它锁(Shared and Exclusive Locks)"></a>共享&#x2F;排它锁(Shared and Exclusive Locks)</h3><p>在InnoDb中实现了两个标准的行级锁，可以简单的看为两个读写锁:</p>
<ol>
<li>S-共享锁：又叫读锁，其他事务可以继续加共享锁，但是不能继续加排他锁。</li>
<li>X-排他锁: 又叫写锁，一旦加了写锁之后，其他事务就不能加锁了。</li>
</ol>
<ul>
<li><p>兼容性:是指事务A获得一个某行某种锁之后，事务B同样的在这个行上尝试获取某种锁，如果能立即获取，则称锁兼容，反之叫冲突。</p>
</li>
<li><p>纵轴是代表已有的锁，横轴是代表尝试获取的锁。</p>
<table>
<thead>
<tr>
<th>.</th>
<th>X（行级）</th>
<th>S（行级）</th>
</tr>
</thead>
<tbody><tr>
<td>X（行级）</td>
<td>冲突</td>
<td>冲突</td>
</tr>
<tr>
<td>S（行级）</td>
<td>冲突</td>
<td>兼容</td>
</tr>
</tbody></table>
</li>
</ul>
<h3 id="意向锁-Intention-Locks"><a href="#意向锁-Intention-Locks" class="headerlink" title="意向锁(Intention Locks)"></a>意向锁(Intention Locks)</h3><ul>
<li>InnoDB为了支持多粒度锁机制(multiple granularity locking)，即允许行级锁与表级锁共存，而引入了意向锁(intention locks)。意向锁是指，未来的某个时刻，事务可能要加共享&#x2F;排它锁了，先提前声明一个意向。</li>
</ul>
<ol>
<li>意向共享锁:表达一个事务想要获取一张表中某几行的共享锁。</li>
<li>意向排他锁:表达一个事务想要获取一张表中某几行的排他锁。</li>
</ol>
<ul>
<li>事务要获得某些行的S&#x2F;X锁，必须先获得表对应的IS&#x2F;IX锁，意向锁仅仅表明意向，意向锁之间相互兼容;虽然意向锁之间互相兼容，但是它与共享锁&#x2F;排它锁互斥</li>
<li>如果请求事务与当前存在的锁兼容，则授予锁。如果冲突则不会授予，事务会进行等待，直到冲突的锁被释放。永远不会在冲突情况下授予锁，因为会导致数据库的死锁</li>
<li>意向共享锁&#x2F;意向排他锁属于表锁，且取得意向共享锁&#x2F;意向排他锁是取得共享锁&#x2F;排他锁的前置条件。</li>
</ul>
<table>
<thead>
<tr>
<th>.</th>
<th>IX</th>
<th>IS</th>
<th>X（表级）</th>
<th>S（表级）</th>
</tr>
</thead>
<tbody><tr>
<td>IX</td>
<td>兼容</td>
<td>兼容</td>
<td>冲突</td>
<td>冲突</td>
</tr>
<tr>
<td>IS</td>
<td>兼容</td>
<td>兼容</td>
<td>冲突</td>
<td>兼容</td>
</tr>
<tr>
<td>X（表级）</td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
</tr>
<tr>
<td>S（表级）</td>
<td>冲突</td>
<td>兼容</td>
<td>冲突</td>
<td>兼容</td>
</tr>
</tbody></table>
<h4 id="意向锁的意义在哪里？"><a href="#意向锁的意义在哪里？" class="headerlink" title="意向锁的意义在哪里？"></a>意向锁的意义在哪里？</h4><ol>
<li>IX，IS是表级锁，不会和行级的X，S锁发生冲突。只会和表级的X，S发生冲突</li>
<li>意向锁是在添加行锁之前添加。</li>
<li>如果没有意向锁，当向一个表添加表级X锁时，就需要遍历整张表来判断是否存行锁，以免发生冲突</li>
<li>如果有了意向锁，只需要判断该意向锁与表级锁是否兼容即可。</li>
</ol>
<h2 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h2><ul>
<li>MVCC，多版本并发控制技术。在InnoDB中，在每一行记录的后面增加两个隐藏列，记录创建版本号和删除版本号。通过版本号和行锁，从而提高数据库系统并发性能。</li>
</ul>
<h2 id="InnoDB-索引"><a href="#InnoDB-索引" class="headerlink" title="InnoDB 索引"></a>InnoDB 索引</h2><ul>
<li>InnoDB的主键索引与行记录是存储在一起的，故叫做聚集索引（Clustered Index）：</li>
</ul>
<h3 id="InnoDB的表必须要有聚集索引"><a href="#InnoDB的表必须要有聚集索引" class="headerlink" title="InnoDB的表必须要有聚集索引"></a>InnoDB的表必须要有聚集索引</h3><ol>
<li>如果表定义了PK，则PK就是聚集索引；</li>
<li>如果表没有定义PK，则第一个非空unique列是聚集索引；</li>
<li>否则，InnoDB会创建一个隐藏的row-id作为聚集索引；</li>
</ol>
<ul>
<li><p>聚集索引，也只能够有一个，因为数据行在物理磁盘上只能有一份聚集存储。</p>
</li>
<li><p>InnoDB的普通索引可以有多个，它与聚集索引是不同的：普通索引的叶子节点，存储主键（也不是指针）</p>
</li>
</ul>
<h3 id="索引使用"><a href="#索引使用" class="headerlink" title="索引使用"></a>索引使用</h3><ul>
<li>where条件中的and前后的顺序，不会影响索引的命中</li>
<li>负向查询肯定不可以命中索引</li>
</ul>
<h2 id="InnoDB-log"><a href="#InnoDB-log" class="headerlink" title="InnoDB log"></a>InnoDB log</h2><ul>
<li>binlog 可以给备库使用，也可以保存起来用于恢复数据库历史数据。它是实现在 server 层的，所有引擎可以共用。redo log 是 InnoDB 特有的日志，用来支持 crash-safe 能力。</li>
</ul>
<h2 id="MySQL-EXPLAIN"><a href="#MySQL-EXPLAIN" class="headerlink" title="MySQL EXPLAIN"></a>MySQL EXPLAIN</h2><h3 id="Extra"><a href="#Extra" class="headerlink" title="Extra"></a>Extra</h3><p>该列包含MySQL解决查询的详细信息,有以下几种情况：</p>
<ol>
<li>Using where:列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤</li>
<li>Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询</li>
<li>Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序”</li>
<li>Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。</li>
<li>Impossible where：这个值强调了where语句会导致没有符合条件的行。</li>
<li>Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行</li>
</ol>
<h3 id="type"><a href="#type" class="headerlink" title="type"></a>type</h3><p>找到所需行的方式</p>
<ol>
<li>ALL: 扫描全表</li>
<li>index: 扫描全部索引树</li>
<li>range: 索引范围扫描</li>
<li>ref: 非唯一性索引扫描</li>
<li>eq_ref：唯一性索引扫描</li>
<li>const：常量扫描，比如主键。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>Using filesort：当Query 中包含order by 操作，而且无法利用索引完成排序操作的时候，MySQL Query Optimizer 不得不选择相应的排序算法来实现。</li>
<li>Using temporary：在某些操作中必须使用临时表时，在 Extra 信息中就会出现Using temporary ,主要常见于 GROUP BY 和 ORDER BY 等操作中</li>
</ul>
<h2 id="主要命令"><a href="#主要命令" class="headerlink" title="主要命令"></a>主要命令</h2><ol>
<li><code>SHOW ENGINES;</code> 命令查看 MySQL 支持的存储引擎。</li>
<li><code>SHOW TABLE STATUS;</code> 命令查看当前库中的表使用的是什么存储引擎。</li>
<li><code>select * from information_schema.INNODB_LOCKS</code> TODO</li>
<li><code>show variables like &#39;%tx_isolation%&#39;;</code>查看事务隔离级别</li>
<li><code>show engine innodb status</code> 输出innodb监控可以查看到意向锁的信息</li>
<li><code>show status like &#39;innodb_row_lock%&#39;;</code>查看锁情况</li>
</ol>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol>
<li>在 MySQL 数据库中，Database 和 Schema 是一对一的，所以 Database 和 Schema 是一个概念。</li>
<li>唯一索引会降级记录锁，这么做的理由是:非唯一索引加next-key锁由于不能确定明确的行数有可能其他事务在你查询的过程中，再次添加这个索引的数据，导致隔离性遭到破坏，也就是幻读。唯一索引由于明确了唯一的数据行，所以不需要添加间隙锁解决幻读。</li>
<li>间隙锁之间是兼容的。插入意向锁（IX）和间隙锁冲突。间隙锁 属于S锁？？？这样才符合表格的描述。</li>
<li>删除记录时，先查询出需要删除的记录主键，通过主键索引进行删除，可以避免产生间隙锁（唯一索引会降级记录锁）。</li>
<li>间隙锁(gap lock)与临键锁(next-key lock) 只在RR以上的级别生效，RC下会失效</li>
</ol>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol>
<li>以固定的顺序访问表和行。交叉访问更容易造成事务等待回路。</li>
<li>尽量避免大事务，占有的资源锁越多，越容易出现死锁。建议拆成小事务。</li>
<li>降低隔离级别。如果业务允许(上面4.3也分析了，某些业务并不能允许)，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。</li>
<li>为表添加合理的索引。防止没有索引出现表锁，出现的死锁的概率会突增。</li>
<li>在删除之前，可以通过快照查询(不加锁)，如果查询没有结果，则直接插入，如果有通过主键进行删除。如果查询的索引不含有唯一属性，不会降级成记录锁，而是间隙锁，插入时容易死锁。</li>
</ol>
<h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><h3 id="InnoDB选择什么列作为主键"><a href="#InnoDB选择什么列作为主键" class="headerlink" title="InnoDB选择什么列作为主键"></a>InnoDB选择什么列作为主键</h3><ol>
<li>不能为空的列；</li>
<li>不能重复的列；</li>
<li>很少改变的列；(行是按照聚集索引物理排序的，如果主键频繁改变，物理顺序会改变，性能会急剧降低。)</li>
<li>经常被检索(where key&#x3D;XXX)的列； (被检索的列上要建立索引，如果该索引是聚集索引，能够避免回表，性能提升几乎一倍。)</li>
<li>不是太长的列;(普通索引叶子节点会存储主键值，如果主键值太长，会增加普通索引的大小。)</li>
</ol>
<h3 id="为什么-MySQL-索引选择了-B-树而不是-B-树？"><a href="#为什么-MySQL-索引选择了-B-树而不是-B-树？" class="headerlink" title="为什么 MySQL 索引选择了 B+树而不是 B 树？"></a>为什么 MySQL 索引选择了 B+树而不是 B 树？</h3><ol>
<li>B+树更适合外部存储（一般指磁盘存储），由于内节点（非叶子节点）不存储 data，所以一个节点可以存储更多的内节点，每个节点能索引的范围更大更精确。也就是说使用 B+树单次磁盘 I&#x2F;O 的信息量相比较 B 树更大，I&#x2F;O 效率更高。</li>
<li>MySQL 是关系型数据库，经常会按照区间来访问某个索引列，B+树的叶子节点间按顺序建立了链指针，加强了区间访问性，所以 B+树对索引列上的区间范围查询很友好。而 B 树每个节点的 key 和 data 在一起，无法进行区间查找。</li>
</ol>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="InnoDB一棵B-树可以存放多少行数据"><a href="#InnoDB一棵B-树可以存放多少行数据" class="headerlink" title="InnoDB一棵B+树可以存放多少行数据?"></a>InnoDB一棵B+树可以存放多少行数据?</h3><ul>
<li><a href="https://www.cnblogs.com/leefreeman/p/8315844.html">https://www.cnblogs.com/leefreeman/p/8315844.html</a></li>
<li>约2千万。(高度为3的B+树)；一个高度为 3 的 B+ 树大概可以存放 1170 × 1170 × 16 &#x3D; 21902400 行数据，已经是千万级别的数据量了。</li>
<li>InnoDB存储引擎最小储存单元——页（Page），一个页的大小默认是16K。<ul>
<li><code>show variables like &#39;innodb_page_size&#39;;</code></li>
<li>innodb的所有数据文件（后缀为ibd的文件），他的大小始终都是16384（16k）的整数倍</li>
</ul>
</li>
<li>假设一行记录的数据大小为1k，实际上现在很多互联网业务数据记录大小通常就是1K左右</li>
<li>非叶子节点能存放多少指针：假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即16384&#x2F;14&#x3D;1170。那么可以算出一棵高度为2的B+树，能存放1170  × 16&#x3D;18720条这样的数据记录。</li>
<li>根据同样的原理我们可以算出一个高度为3的B+树可以存放：1170<em>1170</em>16&#x3D;21902400条这样的记录。所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索引查询通常只需要1-3次IO操作即可查找到数据。</li>
<li>在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索引查询通常只需要1-3次IO操作即可查找到数据。</li>
<li>怎么得到InnoDB主键索引B+树的高度？<ul>
<li>在实际操作之前，你可以通过InnoDB元数据表确认主键索引根页的page number为3，你也可以从《InnoDB存储引擎》这本书中得到确认。</li>
<li><code>SELECT   b.name, a.name, index_id, type, a.space, a.PAGE_NO   FROM   information_schema.INNODB_SYS_INDEXES a,   information_schema.INNODB_SYS_TABLES b   WHERE   a.table_id = b.table_id AND a.space &lt;&gt; 0;</code></li>
</ul>
</li>
<li>基于现有表的总大小和总行数，算出每一行占用的大概大小<ul>
<li>每行大概大小 ≈ total_size &#x2F; total_rows</li>
<li>对于InnoDB存储引擎，可以通过执行以下SQL查询来获取表的大小  <pre>
  SELECT
  table_name AS `Table`,
  ROUND(((data_length + index_length) / 1024 / 1024), 2) AS `Size (MB)`
  FROM
  information_schema.tables
  WHERE
  table_schema = 'your_database_name' -- 替换为实际的数据库名
  AND table_name = 'your_table_name'; -- 替换为实际的表名        
  </pre></li>
<li>通过查看InnoDB存储引擎的.ibd文件来获取表的大小。每个InnoDB表都有一个对应的.ibd文件，其中包含了该表的数据和索引。</li>
<li>3层B+树，每行大小1k（1个页16k，则可以存16条数据）：可以记录的总大小大概为1170<em>1170</em>16</li>
</ul>
</li>
</ul>
<h3 id="MySQL-InnoDB-引擎-RR-隔离级别是否解决了幻读"><a href="#MySQL-InnoDB-引擎-RR-隔离级别是否解决了幻读" class="headerlink" title="MySQL InnoDB 引擎 RR 隔离级别是否解决了幻读?"></a>MySQL InnoDB 引擎 RR 隔离级别是否解决了幻读?</h3><ul>
<li><p><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247489575&amp;idx=2&amp;sn=410aa5a43cb2cdc265dcd39e31128f17&amp;chksm=eb539d11dc24140743b6b6f1369e958417cbe86b9f53809afe2744872f86675e753d9884f9e3&amp;xtrack=1&amp;scene=90&amp;subscene=93&amp;sessionid=1559142508&amp;clicktime=1559142541&amp;ascene=56&amp;devicetype=android-26&amp;version=2700043b&amp;nettype=WIFI&amp;abtest_cookie=BQABAAoACwASABMAFQAHACOXHgBWmR4AyJkeANyZHgDzmR4AA5oeAAyaHgAAAA==&amp;lang=zh_CN&amp;pass_ticket=W5ig5maP6tmaLevaqwsMcnXl28LHoqSmvBuqMPbg7dOQBytHnUWtVKFBwtS2hFz6&amp;wx_header=1">https://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247489575&amp;idx=2&amp;sn=410aa5a43cb2cdc265dcd39e31128f17&amp;chksm=eb539d11dc24140743b6b6f1369e958417cbe86b9f53809afe2744872f86675e753d9884f9e3&amp;xtrack=1&amp;scene=90&amp;subscene=93&amp;sessionid=1559142508&amp;clicktime=1559142541&amp;ascene=56&amp;devicetype=android-26&amp;version=2700043b&amp;nettype=WIFI&amp;abtest_cookie=BQABAAoACwASABMAFQAHACOXHgBWmR4AyJkeANyZHgDzmR4AA5oeAAyaHgAAAA%3D%3D&amp;lang=zh_CN&amp;pass_ticket=W5ig5maP6tmaLevaqwsMcnXl28LHoqSmvBuqMPbg7dOQBytHnUWtVKFBwtS2hFz6&amp;wx_header=1</a></p>
</li>
<li><p>Mysql官方给出的幻读解释是：只要在一个事务中，第二次select多出了row就算幻读。</p>
</li>
<li><p>a事务先select，b事务insert确实会加一个gap锁，但是如果b事务commit，这个gap锁就会释放（释放后a事务可以随意dml操作），a事务再select出来的结果在MVCC下还和第一次select一样，接着a事务不加条件地update，这个update会作用在所有行上（包括b事务新加的），a事务再次select就会出现b事务中的新行，并且这个新行已经被update修改了，实测在RR级别下确实如此。<br>如果这样理解的话，Mysql的RR级别确实防不住幻读。</p>
</li>
<li><p>在快照读读情况下，mysql通过mvcc来避免幻读。<br>在当前读读情况下，mysql通过next-key来避免幻读。<br>select * from t where a&#x3D;1;属于快照读<br>select * from t where a&#x3D;1 lock in share mode;属于当前读</p>
</li>
</ul>
<p>不能把快照读和当前读得到的结果不一样这种情况认为是幻读，这是两种不同的使用。所以MySQL 存储引擎 InnoDB 隔离级别 RR 解决了幻读问题。</p>
<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><ol>
<li>MySQL 存储引擎 InnoDB 隔离级别 RR 解决了幻读问题。</li>
<li>不能把快照读和当前读得到的结果不一样这种情况认为是幻读，这是两种不同的使用。</li>
<li>如果要update，不能出现幻读的情况，之前应该加上for update查询；不需要update，只是读，快照读已经使用mvcc解决幻读问题。</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.yuque.com/yinjianwei/vyrvkf/bq2ib3">MySQL 体系结构-概述</a></li>
<li><a href="https://www.yuque.com/yinjianwei/vyrvkf/miwe1h">MySQL 体系结构-主要文件</a></li>
<li><a href="https://www.cnblogs.com/wt645631686/p/8258070.html">MySQL 参数- Innodb_File_Per_Table（独立表空间）</a></li>
<li><a href="https://mp.weixin.qq.com/s/yzXbbutzVJ1hIZgVszIBgw">为什么开发人员必须要了解数据库锁？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962952&idx=1&sn=aa1d3aaa3a61a811a8656cbfaa45c0a0&chksm=bd2d0b948a5a82822c8a87c2b154a2fb3bdd76a21288db2e1ac97cbb35fd08b43dd5f69c0b58&mpshare=1&scene=1&srcid=&sharer_sharetime=1572482536085&sharer_shareid=dcfe0eae58d1da3d4cc1d60a98c3905c#rd">主键，不少人以为自己懂了，却不透彻…</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962609&idx=1&sn=46e59691257188d33a91648640bcffa5&chksm=bd2d092d8a5a803baea59510259b28f0669dbb72b6a5e90a465205e9497e5173d13e3bb51b19&scene=21#wechat_redirect">如何避免回表查询？什么是索引覆盖？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962899&idx=1&sn=a7f2458680c8f6d295e8c324c7e86cc7&chksm=bd2d0bcf8a5a82d9ac8cc016d21a34b5e3b3be9e235dae29393c6670244dbd53c57ed3b1df16&mpshare=1&scene=1&srcid=&sharer_sharetime=1571143294900&sharer_shareid=dcfe0eae58d1da3d4cc1d60a98c3905c#rd">InnoDB架构，一幅图秒懂！</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962887&idx=1&sn=4806f481448b1c3ddfbbd53e732a7bb5&chksm=bd2d0bdb8a5a82cd50bc155ed2ba57f105bfd76ff78992823ed85214b5c767eef17e691a2255&scene=21#wechat_redirect">事务已提交，数据却丢了，赶紧检查下这个配置</a></li>
<li><a href="https://mp.weixin.qq.com/s/JAzbWvHK6qsb5-NsIftnXQ">丁奇：MySQL 中 6 个常见的日志问题</a></li>
<li><a href="https://xie.infoq.cn/article/e870100a489edb0224a318b62">再深入一点|binlog 和 relay-log 到底长啥样？</a></li>
<li><a href="https://www.jianshu.com/p/61933a9ca85f">MySQL InnoDB 引擎中的 7 种锁类型，你都知道吗？</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1485755">锁机制与 InnoDB 锁算法</a></li>
<li><a href="https://blog.csdn.net/Saintyyu/article/details/91269087">MySQL常见的七种锁详细介绍</a> !!</li>
<li><a href="https://juejin.im/post/6844903856560668680">MySQL中InnoDB的锁分类</a></li>
<li><a href="https://yq.aliyun.com/articles/646976">浅谈MySQL的七种锁</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961508&idx=1&sn=9f31a95e5b8ec16fa0edc7de6087d2a1&chksm=bd2d0d788a5a846e3bf16d300fb9723047bd109fd22682c39bdf7ed4e77b167e333460f6987c&scene=21#wechat_redirect">别废话，各种SQL到底加了什么锁？</a></li>
<li><a href="https://www.cnblogs.com/xuanzhi201111/p/4175635.html">MySQL Explain详解</a></li>
<li><a href="https://mp.weixin.qq.com/s/has0jQ3FCqHZHEw2U2VLuA">记一次 MySQL 性能优化过程</a></li>
<li><a href="https://mp.weixin.qq.com/s/1ZWOLPV4fCqi2EebU_C9YA">MySQL索引前世今生</a></li>
</ul>
]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>《我的第一本金融入门书》-笔记</title>
    <url>/2020/11/03/20201103-wo-de-di-yi-ben-jin-rong-ru-men-shu-bi-ji/</url>
    <content><![CDATA[<h3 id="银行的生财之道——存款与贷款"><a href="#银行的生财之道——存款与贷款" class="headerlink" title="银行的生财之道——存款与贷款"></a>银行的生财之道——存款与贷款</h3><ul>
<li>银行的存款不可能全部贷放出去，按照法律规定，银行必须要留存一定比例的存款作为应对储户提款的准备金，并且贷款在很多时候存在不能及时收回的情况，甚至会出现坏账，这会对银行造成损失，此外，这笔钱还没有扣除税收等因素</li>
</ul>
<h3 id="货币创造的秘密——商业银行的派生存款"><a href="#货币创造的秘密——商业银行的派生存款" class="headerlink" title="货币创造的秘密——商业银行的派生存款"></a>货币创造的秘密——商业银行的派生存款</h3><ul>
<li>我们时常听到财经新闻报道说，中央银行上调法定存款准备金率0.5个百分点，冻结了约3000万元的银行存款货币。在我国，这是当市场流动性泛滥、通货膨胀严重的时候政府所采用的紧缩货币供给的手段。银行存款也是货币，并且银行账户上的存款数量远远大于现金，那么这些多出来的没有现金支撑的存款货币是怎么创造出来的呢？为什么法定存款准备金率的上调就能冻结那么多的存款货币呢？</li>
<li>我们知道，现在人们使用的货币都是信用货币，而信用货币最早的形式是商业银行的银行券。后来，银行券的发行逐渐集中到了一国的中央银行。也就是说，现在人们手中的所有现金货币都是由中央银行发出来的，而商业银行能够创造的只是存款货币。存款货币的创造与银行以支票存款为依据组织的转账结算有直接的联系。一般来说，人们把现金存入银行之后，并不一定再把现金全数提出；从银行取得贷款的客户通常也并不要求银行支付现金，而是要求把贷款记在自己的存款账户中。当客户的存款账户上存有款项时，既可以在必要的时候提取现金，又可以开出支票履行支付义务；当一位客户取得支票时，他往往也不是到付款银行提取现金，而是委托自己开有存款账户的往来银行代收并把收来的款项记入存款账户。对银行来说，客户开出支票，因此有应该付出的款项，同时客户交来支票委托收款，因此有应该收入的款项</li>
<li>银行对现金货币的需要归结为两类：一是客户从存款中提取现金用于发放工资、小额零星支付等；二是结清支票结算中应收应付的差额。在长期经营中，银行发现，相对于存款，现金只是一小部分，而且两者的比例关系相对稳定。也就是说，只要按存款的一定百分比保持现金库存即可应对客户对于现金的需要。</li>
<li>在这样的现代银行支付体系下，存款货币就产生出来，或者说是派生出来了。</li>
<li>假如有一位客户甲，他持有10000元的现金，并将其存入开立了活期存款账户的A银行。从而，A银行负债业务中的存款一项就多了10000元。根据经验，保存相当于90％的现金就足以应对客户日常提取现金的需要，那么A银行可以把9000元贷出。假如这时候正好有一位客户乙要从A银行贷款9000元，那么此时A银行的资产账户上就多出来9000元的贷款，以及剩余的1000元用于应对取现的准备金，实际上，这1000元的准备金是按照法律要求要存到中央银行的账户上的。</li>
<li>如果客户乙将这9000元的贷款用签发支票的方式支付给与自己有业务往来的客户丙，客户丙在B银行开立了账户，于是这9000元则由A银行转到了B银行，B银行的存款就多了9000元。同样的道理，B银行将这9000元中的10％留作准备金，将其余的90％（8100元）贷放出去。如果这时正好有客户丁要从B银行贷款8100元，那么B银行的资产账户就多出来8100元的贷款，同时B银行将900元的准备金上缴中央银行。</li>
<li>以此类推，B银行的客户丁向C银行的客户戊用支票支付8100元的应付款，于是C银行就又多了8100元的存款，在这8100元中，90％用于C银行的贷款，10％用作准备金，无限地循环下去，最终我们可以得到一个总的存款数量和准备金数量。</li>
<li>将A、B、C……银行的存款数量相加，得到10000＋9000＋8100＋7290＋…＝100000（元），准备金数量为1000＋900＋810＋729＋…＝10000（元），从中我们可以看出最初的10000元原始存款最终变成了100000元派生存款，扩大了10倍。经过简单归纳，我们发现这个倍数正好是准备金率的倒数，也就是1&#x2F;10％＝10。</li>
<li>至此，我们就明白了商业银行派生货币的秘密，在银行之间的非现金转账制度和不完全准备金制度下，这样的存款货币派生机制就是有效的。在这一制度下，某单位的现金经过多次存款转账支付，可以创造出（1&#x2F;准备金率）倍的存款。我们也能够回答中央银行调整存款准备金率对存款货币数量影响巨大的原因了。假如存款准备金率由10％调整到20％，那么存款的最终创造数量就变为1&#x2F;20％，扩大了5倍，即10000元的现金只能创造出50000元的存款，这个影响相当巨大。</li>
<li>在非现金转账制度和不完全准备金制度的条件下，商业银行可以创造出数倍于现金数量的存款，而这个倍数就是存款准备金率的倒数。</li>
</ul>
<h3 id="利率是怎样调整的——固定利率与浮动利率"><a href="#利率是怎样调整的——固定利率与浮动利率" class="headerlink" title="利率是怎样调整的——固定利率与浮动利率"></a>利率是怎样调整的——固定利率与浮动利率</h3><ul>
<li>根据在借贷期内利率是否会发生变化，我们又可以将利率分为固定利率和浮动利率。</li>
<li>浮动利率是一种在借贷期内可定期调整的利率。</li>
<li>浮动利率尽管可以为债权人减少损失，但也因手续复杂、计算依据多样而增加费用开支。因此，浮动利率多用于3年以上的国际金融市场的借贷。</li>
<li>固定利率和浮动利率是利率的两种设置方式。采用固定利率可以使计算简单方便，而采用浮动利率可以使长期借贷行为更加公平。</li>
</ul>
<h3 id="为什么会有负利率——名义利率与实际利率"><a href="#为什么会有负利率——名义利率与实际利率" class="headerlink" title="为什么会有负利率——名义利率与实际利率"></a>为什么会有负利率——名义利率与实际利率</h3><ul>
<li>实际利率是指物价水平不变，从而货币购买力保持不变条件下得到的利息率。</li>
<li>为了避免通货膨胀的损失，假设仍然要取得3％的利息，那么粗略地计算，乙必须把贷款利率提高到8％，这样才能保证收回的本金和利息之和与以前的物价水平相当，并且保证购买力不变。其中，这个8％就是名义利率。从这个例子我们可以看出，名义利率是包括物价水平变化情况的利率，实际利率和名义利率之间的关系可以大致表示为：名义利率＝实际利率＋通货膨胀率。市场上各种利率都是名义利率，实际利率却不容易观察到。而利用上述公式，就可以根据已知的名义利率和通货膨胀率推出实际利率。例如考察我国现在的银行存款，1年期定期储蓄存款的利率是3.25％，这是名义利率。而2011年3月的消费物价指数为4.9％，这可以代替通货膨胀率，这样我们可以算出1年期储蓄存款的实际利率为－1.65％，也就是说，我们年初把钱存进银行，年末取出后按购买力计算还亏了1.65％。所以，有些人不愿意把钱存进银行，而是去炒股或者买房，因为一般认为股市和房市是可以实现保值的市场。</li>
<li>实际利率是物价水平不变条件下的利率，而名义利率是包括了物价变化水平的利率，两者的关系为：名义利率＝实际利率＋通货膨胀率</li>
</ul>
<h3 id="没有风险的利率——基准利率"><a href="#没有风险的利率——基准利率" class="headerlink" title="没有风险的利率——基准利率"></a>没有风险的利率——基准利率</h3><ul>
<li>生活中，我们经常听到所谓基准利率的说法，比如，在国内，老百姓习惯上把银行的1年期定期储蓄存款的利率作为基准利率；而银行从业人员则把银行间隔夜拆借利率作为基准利率；在国外，基准利率又成了中央银行的再贴现率。那么，到底什么是基准利率呢？顾名思义，基准利率是指在多种利率并存的条件下起决定作用的利率，也就是说这种利率发生了变动，其他利率也会相应变动。因此，了解了这种关键性的利率水平的变化趋势，也就可以了解全部利率体系的变化趋势</li>
</ul>
<h3 id="什么是有价证券的价值——票面价值、内在价值、市场价格"><a href="#什么是有价证券的价值——票面价值、内在价值、市场价格" class="headerlink" title="什么是有价证券的价值——票面价值、内在价值、市场价格"></a>什么是有价证券的价值——票面价值、内在价值、市场价格</h3><ul>
<li>票面价值也称面值，是在有价证券票面上标明的金额数值</li>
<li>内在价值就是一种有价证券未来收益的现值，它是对有价证券进行价值评估的核心。</li>
<li>对于债券，其本身并没有对应的实物资产。股票，有其对应的实物资产，但具有同样估值金额的实物资产绝不等于对应的股票有同等的内在价值。</li>
<li>市场价格也称市值，它的形成是以其内在价值为准的</li>
<li>票面价值、内在价值、市场价格是三个不同的概念。票面价值是标明在有价证券票面上的金额数量，内在价值是有价证券未来收益的现值，而市场价格是围绕有价证券内在价值上下波动而形成的。</li>
</ul>
<h3 id="怎样评估有价证券的价值——净现值"><a href="#怎样评估有价证券的价值——净现值" class="headerlink" title="怎样评估有价证券的价值——净现值"></a>怎样评估有价证券的价值——净现值</h3><ul>
<li>现值发行的债券票面价格为1000元，每年按8％付息，即利息为80元，每年付息一次，10年还本。如果市场利率达到9％，那么这张债券的现值，或者说内在价值实际只有935元，如果这张债券的定价超过935元，则将不具有投资价值，如果定价低于935元，则可以买入。</li>
<li>净现值是将有价证券未来可预期到的收益折现到当前所得到的金额再减去投资的成本。</li>
</ul>
<h3 id="一个简单的股票价值评价指标——市盈率"><a href="#一个简单的股票价值评价指标——市盈率" class="headerlink" title="一个简单的股票价值评价指标——市盈率"></a>一个简单的股票价值评价指标——市盈率</h3><ul>
<li>所谓市盈率，就是股票的市场价格与每股盈利的比值。</li>
<li>市盈率＝每股市场价格&#x2F;每股盈利</li>
<li>如果市盈率太高，则可能意味着股票的价格高于价值，在这种情况下，投资者需要卖出手中的股票或不购买这种股票。如果市盈率太低，则可能意味着股票的价值被低估，此时正是投资的好时机</li>
<li>从理论上来说，股票的市盈率愈低，愈值得投资</li>
<li>只有比较同类股票的市盈率才会有实用价值</li>
<li>市盈率的高低也不能作为投资选择的绝对标准。因为高市盈率还可能意味着股票的收益有很大的增长潜力，投资者对股票特别看好；低市盈率可能是因为股票未来的收益前景不好，投资人对股票不那么看好导致的。</li>
<li>证券业监管部门也十分关注市盈率的高低。如果市场的平均市盈率太高，那么，政府可能得出市场泡沫过大的判断，然后采取一定的措施帮助消除泡沫。</li>
<li>市盈率是判断股票价值的一种十分简便的方法，它的数值等于股票的市场价格与每股盈利的比值，含义是，每得到1元的收益需要付出多少元的投资。</li>
</ul>
<h3 id="实际收益的损失——通货膨胀风险"><a href="#实际收益的损失——通货膨胀风险" class="headerlink" title="实际收益的损失——通货膨胀风险"></a>实际收益的损失——通货膨胀风险</h3><ul>
<li>通货膨胀风险也称为购买力风险。它是由于通货膨胀、货币贬值给投资者带来的实际收益下降的风险</li>
<li>因为通货膨胀的增长，居民的收入或工资可能会出现上涨。大部分民众对通货膨胀不敏感，但是对自己的工资上涨很敏感。人们的收入增加，大多数的人会选择增加消费，这种现象就是货币幻觉</li>
<li>股票的通货膨胀风险相对较小。</li>
<li>当一国的股票市场完全瘫痪，不可以保证人们财富的安全时，人们就会放弃股票和本国货币，大量持有有信用的外币和黄金等贵金属。</li>
</ul>
<h3 id="购买金融资产就是投资吗——投资与投机"><a href="#购买金融资产就是投资吗——投资与投机" class="headerlink" title="购买金融资产就是投资吗——投资与投机"></a>购买金融资产就是投资吗——投资与投机</h3><ul>
<li>交易者根据交易手段、交易结果、交易目的的不同应该被分成两类：投资者与投机者。</li>
<li>拥有安全性、盈利性、研究性特征的是投资者，反之则是投机者。</li>
<li>投资者深入分析金融资产的价值，他们寻找价值被低估的金融产品并长期持有以获得稳定的收入。投机者关注行情指标，他们购买金融资产的目的就是为了在短期内获得暴利。</li>
</ul>
<h3 id="行为金融学典型现象——羊群效应"><a href="#行为金融学典型现象——羊群效应" class="headerlink" title="行为金融学典型现象——羊群效应"></a>行为金融学典型现象——羊群效应</h3><ul>
<li>羊群效应是行为金融学的经典内容。羊群是一种比较散乱的动物组织，如果有一只羊躁动起来，那么其余的羊会跟随着这只羊一起躁动起来。羊群效应说的是一种从众心理。</li>
<li>羊群效应的教训告诫我们，做任何事都要有自己的判断。总是跟着别人投资，也不会得到多大的收益</li>
<li>投资者应该相信自己的判断，千万不要盲目跟风投资。</li>
</ul>
<h3 id="股票的生财之道——分红与价差"><a href="#股票的生财之道——分红与价差" class="headerlink" title="股票的生财之道——分红与价差"></a>股票的生财之道——分红与价差</h3><ul>
<li>股票的获利方式有两种，一种是通过股价的变动获利，另一种是通过股票的分红获利。</li>
<li>在长期中获得合理的收益，而不是短期内的一夜暴富，这是我们股票的一个重要原则。</li>
<li>只有坚定这一个原则，我们在投资股票时，才能够以一个平和的心态去面对股市带来的波动与股价的涨涨落落。</li>
</ul>
<h3 id="未来标准化的商品买卖——期货合约"><a href="#未来标准化的商品买卖——期货合约" class="headerlink" title="未来标准化的商品买卖——期货合约"></a>未来标准化的商品买卖——期货合约</h3><ul>
<li>之前讲到远期合约的优势是规避未来的风险，其实远期合约也存在一些不足，那就是远期合约往往是买卖双方商议好就可以达成的一种合约，而如果第三方甚至其他各方想要介入这份合约或者买卖双方想要将合约中的金融产品卖给其他人的话，则会比较麻烦。比如双方规定好要交的货是一等大豆1000吨，但是第三方只想要200吨，或者第三方只想要二等大豆等，这样就不能转卖这个远期合约。为了避免这种麻烦，使交易更为顺畅地进行，人们又发明了标准化的远期合约，即期货合约。</li>
<li>期货是现在进行买卖，但是在将来进行交收或交割的标的物，这个标的物可以是某种商品（如黄金、原油、农产品），也可以是金融工具，还可以是金融指标。</li>
<li>期货实际上是一种可以反复转让、反复买卖的标准化合同。</li>
<li>交易这些“将运到”合约比交易谷物本身要更为有用</li>
<li>期货市场的两类关键参与人就是套期保值者与投机者。期货市场建立的目的是出于对保值的需要。</li>
<li>所谓套期保值，就是以现在的价格卖出未来生产的产品，或是以现在的价格买入未来所需要的原料。</li>
<li>套期保值者一般是产品的生产商或者是需要原料的加工商。他们进入期货市场购买或卖出期货合约的目的是为了避免未来的损失。举例来说，棉花生产商为了避免在棉花收获时因棉花丰收而引起的价格下跌中受到损失，在收获期前三个月就在期货市场卖出期货合约，或者做空该种类的期货。而到了棉花收获期，他们再买入期货合约，也就是进行平仓。由于期货合约越到履约期越接近现货价格，如果三个月后棉花价格下跌，那么棉花生产商便在期货市场盈利，从而弥补在现货市场的亏损；如果三个月后棉花价格上涨，那么棉花生产商便在现货市场盈利，从而弥补在期货市场的亏损，即将利润在三个月前就锁定。</li>
<li>而投机者在期货交易中则是扮演着“价格发现者”的角色。投机者进入期货市场购买或卖出期货合约的目的只有一个——就是获利。因此，在期货市场中时刻关注价格的波动与走向，如果发现期货市场价格与现货市场价格出现偏离，那么就会毫不犹豫地利用价差进行套利交易。但是同时，他们的不断套利也使得期货市场与现货市场的价格不会出现扭曲。</li>
<li>期货采用保证金制度，即只需要付部分货款就可以订购全部的商品</li>
<li>期货市场更适合专业的投资者进行投资。</li>
<li>中国有上海期货交易所、郑州商品交易所、大连商品交易所、中国金融期货交易所四大交易所</li>
<li>期货合约是将要买卖的东西的单位、品质、样式等在合约中事先规定好，在规定的日期进行交割的一种远期合约。期货的出现有助于保障原材料供应商与需求商的利益不会因原材料价格波动而受损。期货交易中使用保证金制度，属于杠杆交易，风险较大。</li>
</ul>
<h3 id="金融政策的神奇魔力"><a href="#金融政策的神奇魔力" class="headerlink" title="金融政策的神奇魔力"></a>金融政策的神奇魔力</h3><ul>
<li>政府调节经济的目的是为了预防由于单纯依靠市场力量所出现的种种市场失灵的情况。无论是由于人们的盲目乐观而产生的经济泡沫，还是由于人们信心不足而出现的经济衰退，政府都可以通过运用金融政策使经济重回正轨</li>
</ul>
<h3 id="市场失灵的历史表现——1929年美国经济危机回顾"><a href="#市场失灵的历史表现——1929年美国经济危机回顾" class="headerlink" title="市场失灵的历史表现——1929年美国经济危机回顾"></a>市场失灵的历史表现——1929年美国经济危机回顾</h3><ul>
<li>经济学家凯恩斯认为经济危机的根源在于有效需求不足。</li>
<li>劳动者工资率的上升却慢于劳动生产率的增长。其结果是，生产商品的能力大大超过了购买力，“消费不足”带来了“生产过剩”的必然后果。</li>
</ul>
<h3 id="金融政策魔力的源泉——货币、利率与汇率"><a href="#金融政策魔力的源泉——货币、利率与汇率" class="headerlink" title="金融政策魔力的源泉——货币、利率与汇率"></a>金融政策魔力的源泉——货币、利率与汇率</h3><ul>
<li>一个国家的宏观金融政策应主要包括三大政策：货币政策、利率政策和汇率政策。</li>
<li>政府的目标是确保三个市场的均衡，即保证国内的商品市场的均衡、货币市场的均衡以及国际收支的均衡。</li>
<li>对于商品市场的均衡，从总体上说，就是国内商品的总供给与总需求的均衡，让所供给的商品满足所产生的需求，这样一方面可以不出现供过于求的局面，不至于产生商品积压，引起通货紧缩，使得经济发展陷入停滞的局面；另一方面可以防范供不应求的局面，不至于出现需求旺盛而供给不足，产生物价上涨，人民的需求难以得到有效保障的困境。政府可以运用财政政策对市场加以调整。在货币市场的均衡方面，就是要使一国对于货币的需求等于货币的供给。就货币的需求而言，根据凯恩斯的理论，人们有三种倾向去持有货币，即预防动机、交易动机与投机动机。这三方面的因素使得人们对货币有相应的需求。而中央银行作为货币的发行机构，可以通过控制货币的供给引导货币市场的均衡。在国际收支方面，如果一国的出口大于进口，则会出现顺差局面，会对本国的货币产生升值压力，进而影响本国的出口行业，并同时容易造成输入型通货膨胀，对国内经济产生影响；而如果进口大于出口，则会产生贸易赤字，使得本国货币不断走弱，进而影响本国的国际购买力水平与经济发展前景。因此，政府应该通过有效的汇率政策等调控方式引导国际收支平衡。</li>
</ul>
<h3 id="是痛苦的根源还是繁荣的表象——通货膨胀"><a href="#是痛苦的根源还是繁荣的表象——通货膨胀" class="headerlink" title="是痛苦的根源还是繁荣的表象——通货膨胀"></a>是痛苦的根源还是繁荣的表象——通货膨胀</h3><ul>
<li>如果通货膨胀保持在一个比较低的水平，那么就说明市场上对于各种产品的需求比较旺盛，至少是供不应求。这样的话，整个经济的流转就会比较顺畅，企业生产的产品不会因为卖不出去而滞销；企业可以继续生产，生产过程中也会雇佣一定的劳动者，因此也不会有人失业。劳动者有了工作，也就有了收入，有了收入，也就有了消费的基础。</li>
<li>一般而言，国际上通常认为通货膨胀率（一般用消费者物价指数CPI进行衡量）在2％以下是可以接受的范围，而在3％以上就认为已存在问题。如果通货膨胀率高于5％，则认为存在着比较严重的问题。而通货膨胀率如果达到20％，就认为这个国家面临着经济崩溃的风险。</li>
<li>通货膨胀是指一个经济体在一段时间内货币数量增速大于实物数量增速，普遍物价水平上涨，单位货币的购买力下降的状况。较低水平的通货膨胀反映经济的蓬勃发展，但较高水平的通货膨胀就是经济痛苦的根源</li>
</ul>
<h3 id="一个艰难的抉择——失业与通货膨胀的跷跷板"><a href="#一个艰难的抉择——失业与通货膨胀的跷跷板" class="headerlink" title="一个艰难的抉择——失业与通货膨胀的跷跷板"></a>一个艰难的抉择——失业与通货膨胀的跷跷板</h3><ul>
<li>失业率的存在是让人苦恼的，通货膨胀的爆发是让人忧愁的，西方一些学者甚至将两者的数值进行加总，创造出一个“痛苦指数”来反映人们对于现行经济状况的担忧。而更让一国政府与中央银行郁闷的是，往往他们通过相应的金融政策调整，在解决其中一个问题的时候，会引发另一个问题的产生。就如同跷跷板一样，压下了这一头，那一头又升了起来。</li>
<li>事实正是如此，当中央银行通过宽松的货币政策甚至是降息对不景气的经济进行刺激以消除失业压力的同时，会引发投资的加速，使得原材料的成本大幅度提高，进而引发一般商品价格上涨，并促使工资上涨，形成成本推动的通货膨胀。相反，当中央银行通过提高利率或收紧货币为一个过热的经济体降温时，常常会让投资者犹豫不决，导致投资不足，进而使企业不能进行有效的扩大再生产，并开始裁员，导致失业人数增加。</li>
<li>上述这种情况正好反映了金融政策制定者所处的两难境地。金融政策的调整既要保证老百姓不会因为物价的快速上涨而怨声载道，又要避免老百姓因找不到工作或失业而痛苦不堪。所以说，对一国政府与中央银行而言，如何让通货膨胀与失业的跷跷板在一个能够接受的范围内达到平衡，是一个十分艰难的抉择。小贴士根据经济学家的研究，一国的失业率与通货膨胀率常常存在着此消彼长的替代关系。这种现象使得政府在制定相应的宏观经济政策时常常面临着两难的抉择，往往只能就重避轻，而难以全部满足。</li>
</ul>
<h3 id="来自全球化的挑战——输入型通货膨胀与汇率变动的压力"><a href="#来自全球化的挑战——输入型通货膨胀与汇率变动的压力" class="headerlink" title="来自全球化的挑战——输入型通货膨胀与汇率变动的压力"></a>来自全球化的挑战——输入型通货膨胀与汇率变动的压力</h3><ul>
<li>当今世界市场的发展使得各国的联系更为紧密，因此单单考虑本国的情况显然难以完全把握经济的命脉。因此，政府在进行相应的金融政策调整时，还要考虑外部因素，也就是考虑国际市场带来的压力。而这种压力也来自两个相对应的方面，或者说，来自汇率的两种调整方式的压力。一种方式是实行固定汇率制，也就是保持汇率稳定。保持汇率稳定可以预防经济的波动，但是相应地，由于本国货币的升值或贬值压力，一国的中央银行必须动用其外汇储备进行汇率干预以保持汇率的稳定，这就对一国的外汇储备状况提出了很高的要求。如果一个国家的货币有贬值压力，那么中央银行就需要不断地用本国的外汇储备换回本国货币以保持市场上对本国货币的需求，从而稳定本国汇率。这样做对本国的外汇储备是极大的消耗。而另一方面，如果本国货币有升值压力，那么中央银行必须不断地在国际市场中供给本国货币以换回外汇储备，这样做的话会使本国的外汇储备不断膨胀，而当外汇储备贬值时，就会造成本国外汇储备的巨大损失。另一种方式是实行浮动汇率制，是指政府允许市场作为调节汇率的手段，允许汇率进行波动。这样，政府就可以不动用外汇储备对汇率市场进行干预，使汇率可以较为自由地变动。然而，在这种方式下，汇率的波动会对经济产生很大的影响。如果本国货币升值，那么会使本国的相关出口行业面临着巨大的汇率压力，因为出口企业在国内用本国货币购买原材料、雇佣劳动力，而出口到国外的产品却是用外币进行结算，本国货币升值会造成产品的成本上升，对利润产生冲击。如果本国货币贬值，那么会引发进口产品的价格上升，进而形成输入型通货膨胀。也就是说，我们购买同样的国外原材料或产品时，需要付出更多的本国货币，就如同通货膨胀一样，同样的产品需要更多的钱才能买到，表现为进口原材料与商品的价格普遍提高，对于对外依赖度很高的国家，这将会严重干扰该国的经济生产过程。因此，无论采用哪种汇率制度，汇率的波动或者汇率的变化压力都会对经济造成一定的冲击。而对汇率的调节机构来说，制定相应的汇率政策是一个取舍的过程。汇率政策对一国汇率的影响可以分为三种，即有计划的升值、保持汇率不变以及有计划的贬值。有计划的升值可以防止输入型通货膨胀，使本国的进口商品、原材料价格趋于稳定，进而使一般商品价格不至于出现较大的波动，但是，这是以牺牲出口行业的利益为代价的。而有计划的贬值则恰恰相反，一国政府为了推动出口企业的快速发展，通过实施一定程度的货币贬值手段对外贸行业进行刺激，使外贸企业由于能够更为便宜的使用国内资源而获得一定的成本优势。但是，贬值手段所带来的可能后果是输入型通货膨胀的压力，会对本国的一般性生产行业造成一定的冲击，同时也会影响本国的一般商品价格。保持汇率稳定不变则如前文所述，会促使中央银行动用大量的外汇储备进行干预，这样会对一国的外汇储备造成一定的压力。</li>
</ul>
<h3 id="对魔法的质疑——金融政策是否是万能的"><a href="#对魔法的质疑——金融政策是否是万能的" class="headerlink" title="对魔法的质疑——金融政策是否是万能的"></a>对魔法的质疑——金融政策是否是万能的</h3><ul>
<li>金融政策在实行中往往存在着滞后性与信息不完全的问题。</li>
<li>金融政策的调整不是立竿见影的，而是有一定的滞后性。这就对金融政策的制定者提出了较高的要求，需要他们对未来的趋势有明确的判断，不能为了解决短期的问题而影响长期的发展。</li>
<li>经济的波动往往呈现出复苏—繁荣—衰退—萧条—再复苏的周期性特征，这是因为，在繁荣阶段，企业往往增加投资并且成本较高，形成泡沫，在随后的衰退期中很可能会遭受损失。如果金融政策的制定者能够把握这种经济周期规律，合理运用金融政策，那么就可以获得良好的效果</li>
<li>逆周期政策就是一种金融调控的合理手段。简单地说，逆周期政策就如同开车一般，在经济向着繁荣方向发展时就踩下经济的刹车，而在经济向着衰退方向发展时就踩下经济的油门。具体而言，当经济进入复苏阶段，企业重新开始走上扩张道路时，政府不应继续通过宽松的金融政策对其进行刺激，而是应该适当紧缩货币与信贷。这样，由于金融政策有滞后性，当经济走向高涨时期时，货币与信贷政策正好可以发挥作用，避免经济过热。而当经济增长比较平缓但并未出现下滑趋势时，政府就应对其进行刺激。逆周期政策可以避免由于滞后性造成的调控不当的问题，是金融政策制定中一个比较好的调控思路。</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="美国国债"><a href="#美国国债" class="headerlink" title="美国国债"></a>美国国债</h3><ul>
<li>中国为什么要购买美国国债？<a href="https://www.zhihu.com/question/23117022">https://www.zhihu.com/question/23117022</a></li>
<li>根本原因是中国是实行外汇管制和人民币汇率控制。也就是说钞票进出中国都要经过一个机构，更换对应的货币，这个机构叫央行。</li>
<li>中国是世界工厂，生产很多东西卖到全世界；同时中国的经济发展和巨大的市场规模，很多外国公司到中国投资。所以中国现在每年的贸易都是顺差（进来的钱多，出去的钱少），这样一年一年累计，中国银行就聚集了一大笔美元。</li>
</ul>
<h3 id="买美国国债"><a href="#买美国国债" class="headerlink" title="买美国国债"></a>买美国国债</h3><ol>
<li>钱太多，花不掉。<br>中国的外汇也不全是买美国国债，也有部分是做其他的，比如买黄金，投资等。但是这么一笔巨额的资金，只做这些是消化不了的。</li>
<li>选来选去，只有买美国国债比较合适：1，有保障（美国后台，安全），2，用的掉（美国国债发行量大），3，回报率尚可。</li>
<li>购买美国国债是稳赚不赔的吗？<br>不是，比如美元贬值可能导致缩水</li>
<li>那么大笔的重要的资金，安全是第一位的；回报率是第二位的</li>
</ol>
<h3 id="中国的外汇储备并不都是中国人赚的"><a href="#中国的外汇储备并不都是中国人赚的" class="headerlink" title="中国的外汇储备并不都是中国人赚的"></a>中国的外汇储备并不都是中国人赚的</h3><ul>
<li>中国的外汇储备并不全部都是中国人自己赚的，里面有一部分，而且是很大一部分，是外国投资引来的外汇，这笔美元只是暂存在央行，其所有权并不归属于中国。中国每年的巨额出口顺差，赚的钱也并不全是中国的，相当大一部分，都是属于外国资方的，但是我们不能因此排斥外国资方，相反还要拼命引资，没有这些外国投资，中国不可能发展到今天这个高度。</li>
<li>所以，为了在外汇储备激增的前提下尽可能的保护中国的利益，买美国国债，是保护中国外汇储备最佳的选择。</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>《复盘网飞》-笔记</title>
    <url>/2021/08/09/20210809-fu-pan-wang-fei-bi-ji/</url>
    <content><![CDATA[<h3 id="网飞的创意来源"><a href="#网飞的创意来源" class="headerlink" title="网飞的创意来源"></a>网飞的创意来源</h3><ul>
<li>顿悟是极其罕见的。出现在创业故事中的所谓的顿悟往往是被过分简化的，甚至是伪造的。我们之所以爱听这些故事，是因为它们契合了有关灵感和天才的浪漫想象。我们想让我们这个时代的“牛顿们”在苹果掉下来的时候坐在苹果树下；我们想要这个时代的“阿基米德们”坐在浴缸里。但真相往往比这复杂许多。真相是，每一个好主意背后，都有上千个馊主意。这两者有时很难区分。</li>
</ul>
<h3 id="最初的股权模式"><a href="#最初的股权模式" class="headerlink" title="最初的股权模式"></a>最初的股权模式</h3><ul>
<li>我的风险是我投入的时间。里德的风险是他投入的金钱。</li>
</ul>
<h3 id="OPM很难"><a href="#OPM很难" class="headerlink" title="OPM很难"></a>OPM很难</h3><ul>
<li>OPM到底是什么呢？它其实只是创业界的一个俚语。它意为“别人的钱”（Other People’s Money，首字母缩写为OPM）。当企业家们恳求你记住OPM时，他们真正要表达的意思是：一旦涉及为你的梦想融资，你就只花别人的钱。创业有风险，你唯一的投资只能是时间，不要把真金白银砸进去。你反正会把一生都奉献给自己的创意，那就让别人贡献金钱吧。</li>
</ul>
<h3 id="企业文化不是说出来的"><a href="#企业文化不是说出来的" class="headerlink" title="企业文化不是说出来的"></a>企业文化不是说出来的</h3><ul>
<li>企业文化就是我们做事的方式。我们上班不用打卡，没有强制的工作时间，想来的时候就来，想走的时候就走。评判你的唯一标准就是结果。只要你在解决问题、完成任务，我就不在乎你究竟身处何地，工作有多努力，或者你每天在办公室里待多久。</li>
</ul>
<h3 id="企业文化是做出来的"><a href="#企业文化是做出来的" class="headerlink" title="企业文化是做出来的"></a>企业文化是做出来的</h3><ul>
<li><p>事实上，我们的企业文化不是通过会议或者圆桌讨论制定的，也不是精心规划的产物。因为团队成员都在初创公司、大型企业，以及介于两者之间的很多公司有过丰富的工作经验，所以我们的文化实际上是在大家共同的价值观基础之上自然而然地衍生的。</p>
</li>
<li><p>作为领导者，你的工作就是让他们明白这一点。你之所以选择这群人参加如此艰苦的越野旅行，大概率就是因为你相信他们的判断力，因为他们明白自己要做的工作。所以作为一个领导者，确保每个人都能到达营地的最好方法，是告诉他们去哪里，而不是告诉他们怎么去那里。给他们明确的坐标，让他们自己想办法。</p>
</li>
<li><p>在一家公司规模还很小的时候，信任和效率是息息相关的。如果你给团队招到了合适的人选，你就不需要确切地告诉他们你希望他们以什么方式来做事——事实上，你甚至不需要告诉他们你想让他们做什么。你唯一要做的就是明确你想要达到的目标，以及这个目标背后的重要意义。如果你雇用了合适的人选，找到了聪明、能干、值得信赖的人，他们自己就会弄清楚自己需要做什么，也会勇往直前。他们会在你意识到问题存在之前就独立地加以解决。</p>
</li>
<li><p>网飞的早期文化完全脱胎于我和里德对待彼此的方式。我们不会给对方一张我们期望对方完成的任务清单，然后频繁“查岗”以确保所有事情都完成了。我们只是确保每个人都了解公司的目标，以及我们各自负责的是哪些事。我们必须自己设法弄清楚需要做些什么才能实现目标。我们要对彼此开诚布公——绝对地坦诚。</p>
</li>
<li><p>绝对的坦诚，以及自由与责任。这些都是非凡的理想，但在我们建立公司最初的几年里，它们并没有真正被确定。我们都是具体事情具体对待的。举个例子。1999年的某一天，我们的一位经理带着一个特殊的要求来找我。他的女朋友搬到了圣迭戈市，他想努力维持他们的恋爱关系。“如果我星期五提前下班，飞到圣迭戈去，您觉得可以吗？”他问道。他解释说，他星期一会在那边办公，星期一晚上飞回来，星期二早上能回到办公室。我的回答可能让他大吃一惊。“我不在乎你在哪里工作，也不在乎你工作多长时间。你就算在火星上工作，我也不管。如果你问的只是工作时间和地点的问题，那答案很简单：对我来说无所谓。”我话锋一转，接着说：“但是，如果你真正想问我的是，我是否愿意降低对你和你团队的期望，这样你就可以和你的女朋友待在一起？那这个问题的答案也很简单：不可能。”他犹豫地看着我。我可以看到他在圣迭戈过周末的梦想破灭了。“听着，工作地点和工作时间完全取决于你自己。如果你每周在办公室里只待3天半，还能有效地管理你的团队，那么所有的权力都属于你。你就去吧——那我就只能羡慕你，但愿我也能像你一样能干。不过你要记住：你是经理。你的部分工作就是确保你的团队知道你想要他们完成什么，知道这些任务为什么很重要。你觉得如果你不待在办公室里，他们也能做到吗？”不用说，他的女朋友在那之后不久就单身了。我给了那位经理选择的自由，但同时也提醒了他对团队的责任。我对他做到了绝对的坦诚，虽然我怀疑如果他每周提前下班去圣迭戈，他是否还能履行承诺、尽职尽责，但我最终还是把决定权交给了他。那位经理觉得自己被赋予了权力，可以自由地选择自己的生活方式，而公司最终也从他重新集中的精力中受益。每一方都是赢家。或者，应该说几乎是每一方。他在圣迭戈的那个前女友可能并不像我这么看。自由与责任也不仅仅属于管理者。</p>
</li>
<li><p>拥有自由与责任的文化，加上绝对的坦诚，就仿佛有魔力一般所向披靡。我们不仅取得了很好的效果，员工们也很喜欢这种文化。具备判断力来做出负责任决定的人都喜欢他们有这样做的自由。</p>
</li>
<li><p>他们喜欢被信任的感觉。</p>
</li>
<li><p>这是有道理的，对吧？如果你的公司里到处都是缺乏敏锐判断力的人，那么你就必须制定各种各样的防范措施，让他们循规蹈矩。你必须为他们规定好每一件事：他们可以在办公用品上花多少钱，他们可以休多少天假，他们什么时候应该待在办公桌前。大多数公司最终都建立了这样的体系，来保护自己免受缺乏判断力的人的伤害。这只会让拥有判断力的人感到沮丧。</p>
</li>
</ul>
<h3 id="投公司就是跟对人"><a href="#投公司就是跟对人" class="headerlink" title="投公司就是跟对人"></a>投公司就是跟对人</h3><ul>
<li><p>当机会来敲门时，你不一定非得开门。但你至少应该透过钥匙孔朝外面看一眼。这就是我们在面对亚马逊时所做的。</p>
</li>
<li><p>机构风险合伙公司资助我们，不是因为我们的预测结果很好，也不是因为我们的路演很完美，更不是因为我用幻灯片和热情打动了他们。机构风险合伙公司资助我们，是因为尽管这一切看起来那么不切实际，但里德是一个可以创造奇迹的人，而他入伙了。</p>
</li>
</ul>
<h3 id="成功会带来问题"><a href="#成功会带来问题" class="headerlink" title="成功会带来问题"></a>成功会带来问题</h3><ul>
<li>其实，大多数事情都是这样的。当你忙着把梦想变为现实的时候，在目标实现以前，掌声和鲜花都不属于你——而真的到了那个时刻，你也早已把注意力转移到解决其他问题上去了。</li>
<li>但我在网飞创业的第一年中学到的一件事就是，成功会带来问题。增长当然很好，但伴随增长而来的将是一系列全新的复杂问题。你的团队有新成员之后，你如何让他们有身份认同感？如何平衡持续扩张与一贯的身份认同？在可能会有所失的情况下，你又如何确保自己能够继续冒险？</li>
<li>这就是创业初期的典型运作方式：你雇用一群才华横溢的员工，让他们成为万事通。对于每件事，每个人都会做一点儿。你雇用的是一支团队，而不是一组职位。</li>
<li>一旦创始团队开始适当放手，不再凡事亲力亲为，我们就需要把很多事情编成规定，以确保我们的业务继续平稳运转。</li>
</ul>
<h3 id="里德的坦诚"><a href="#里德的坦诚" class="headerlink" title="里德的坦诚"></a>里德的坦诚</h3><ul>
<li>在商业中有一种说话的策略，这种策略对传递坏消息很有用。这种策略名叫“狗屎三明治”。你用一连串的赞美开头，赞扬人们工作做得不错。这是你的第一片面包。结束了这段话以后，你就在上面堆上屎：坏消息，不够乐观的业绩报告，你的受众不那么喜欢听到的内容。接着你再用一片面包来收尾：未来的宏伟蓝图，以及一份着手处理所有糟糕情况的计划。</li>
<li>“所以我认为最好的结果是，我全职加入公司，我们一起来运营。我做首席执行官，你做总裁。”</li>
<li>我敢肯定里德一定在想，为什么我没有像他那样清楚地、合乎逻辑地看待公司的情况。我知道里德没有——也不能——理解我在想些什么。那可谢天谢地了，因为我脑子里冒出来的词语并不礼貌。</li>
</ul>
<h3 id="放弃首席执行官头衔"><a href="#放弃首席执行官头衔" class="headerlink" title="放弃首席执行官头衔"></a>放弃首席执行官头衔</h3><ul>
<li>这是绝对的坦诚，这和我们一开始驾着沃尔沃开在17号公路上练习过的坦诚是一样的。里德既没有私心，也没有其他用心，他的动机就是为了公司的利益。</li>
<li>我成功地组建了一支团队，打造了一种企业文化，把一个想法从一张信封的背面发展成为一家公司，一个办公室，一款真实存在于世界上的产品。但我们正在走出最初的阶段，现在我们必须快速发展壮大，而这个阶段需要的是一套完全不同的技能。</li>
<li>我不得不扪心自问：看到我的梦想成真到底有多重要？甚至，它此刻还仅仅只是我的梦想吗？我们现在有了40个员工，每个人都像我一样渴望网飞大获成功。他们每天工作到很晚，周末也要加班，工作占用了他们本应与朋友和家人相处的时间，所有努力都是为了实现那个原本只是我一个人的梦想，但他们却早已把这个梦想当成了自己的梦想。为了他们，难道我不应该尽我所能确保公司生存吗？即便这意味着我扮演的角色将不再是我当初想象的那个角色。我的头衔与他们的工作，哪一个更重要？</li>
<li>当你的梦想成真时，它就不再仅仅属于你了。它属于那些帮助过你的人——你的家人、你的朋友、你的同事。它属于全世界。</li>
<li>为了我的员工、我的投资者，还有我自己，我应该确保公司在未来继续取得成功，即使这意味着我要辞去首席执行官一职。</li>
</ul>
<h3 id="重新定义团队"><a href="#重新定义团队" class="headerlink" title="重新定义团队"></a>重新定义团队</h3><ul>
<li><p>通常，在创业初期适合这份工作的人，到了中期阶段就无法继续胜任了。有时，引进具有数十年经验和专业知识的人员是必要的。</p>
</li>
<li><p>巴里的到来宣告了吉姆·库克在网飞职业生涯的结束。吉姆从一开始就想成为公司的首席财务官，而随着巴里的正式加入，他的梦想显然从此破灭了。吉姆的离开也算不上突然，这类事情基本都不能算是突然，但它凸显了那年春夏两季正在发生的事情：创业团队开始分崩离析，下一个阶段就是用新的人选取代他们。</p>
</li>
<li><p>这是创业中的一个事实：变革。当你白手起家时，你仰仗的是才华横溢、热情澎湃的多面手：他们什么事情都会做一点儿，他们相信团队的使命，而你愿意把时间、金钱和想法都托付给他们。但是一旦你从0发展到1，你播下的种子开始茁壮成长，你就必须启动洗牌重组。通常，在创业初期适合这份工作的人，到了中期阶段就无法继续胜任了。有时，引进具有数十年经验和专业知识的人员是必要的。</p>
</li>
</ul>
<h3 id="订阅模式初见雏形"><a href="#订阅模式初见雏形" class="headerlink" title="订阅模式初见雏形"></a>订阅模式初见雏形</h3><ul>
<li><p>如果这是一个馊主意，那么不管我们多关注测试中的细节问题，它也不会成为一个好主意。但如果这是一个好主意，那么不管有多少障碍或者我们这边的工作做得多马虎，大家都会争相涌入享用这项服务。</p>
</li>
<li><p>我们一直试图避免落入创业的头号陷阱：在脑海里筑造想象中的城堡，精心设计好一切，包括塔楼、吊桥和护城河。过度的计划和过度的设计往往只是过度的思考，或者只是普通的拖延症而已。在创意方面，测试10个糟糕的想法要比花上好几天时间想出完美的创意更有效。</p>
</li>
</ul>
<h3 id="关键创新：订阅与算法推荐"><a href="#关键创新：订阅与算法推荐" class="headerlink" title="关键创新：订阅与算法推荐"></a>关键创新：订阅与算法推荐</h3><ul>
<li>整件事给我们上了宝贵的一课：相信你的直觉，但也要检验它。在做任何具体的事情之前，数据必须先行。</li>
<li>如果在网飞上线的那天，你让我描述一下网飞最终会是什么样子的，我可能永远也想不到包月订阅的服务模式。</li>
<li>但威廉·戈德曼最著名的是他写下了3个词语：无人、知晓、一切。</li>
<li>因为如果“无人知晓一切”——如果真的不可能事先知道哪些想法是好的，哪些不是，如果不可能知道谁会成功，而谁又不会——那么任何想法都有可能是成功的。如果“无人知晓一切”，那么你就必须相信你自己，你必须进行自我测试，你必须愿意承担失败的风险。</li>
<li>硅谷的头脑风暴会议，通常会以一句“天下没有馊主意”开头。我始终无法苟同。肯定是有馊主意的。但如果你不去尝试一下，你永远都不会知道这个想法到底是好还是坏。</li>
<li>订阅模式不但拯救了网飞，也迅速成了网飞最典型的特征。但这并不是我们从一开始就制定好的发展方向，也不是任何人可以事先预测的。这需要很多努力、很多思考。</li>
<li>这也需要机缘巧合。其他人称之为幸运，我管它叫“无人知晓一切”。</li>
</ul>
<h3 id="为潜力付费"><a href="#为潜力付费" class="headerlink" title="为潜力付费"></a>为潜力付费</h3><ul>
<li>消极选项的问题要更棘手一些。“你不能连问都不问一声就从别人的信用卡里扣费，”里德说，“这是完全不道德的。”</li>
</ul>
<h3 id="专注与放弃"><a href="#专注与放弃" class="headerlink" title="专注与放弃"></a>专注与放弃</h3><ul>
<li><p>最主要的原因其实更简单。如果我们把开辟加拿大市场所需要的精力、人力和脑力应用到业务的其他方面，我们最终得到的回报要远远高于10%。拓展市场只是一个短期举措，它仅仅具有短期的效益，而且会分散我们的注意力。</p>
</li>
<li><p>专注，这就是企业家的秘密武器，它在网飞的故事里出现了一次又一次——放弃DVD销售业务，放弃按件计价的租赁模式，以及最终放弃了网飞初创团队的众多成员——为了公司的未来，我们不得不抛弃一部分过去。有时候，这种极度的专注似乎有些冷酷无情——确实有点儿残酷。但这又绝不仅仅是残酷，它更是一种勇气。</p>
</li>
</ul>
<h3 id="数据先行"><a href="#数据先行" class="headerlink" title="数据先行"></a>数据先行</h3><ul>
<li><p>次日送达对取消订阅率没有产生太大的影响，真正发生变化的是新用户注册率。</p>
</li>
<li><p>我们运行测试的时间越长，就越能明显看出，次日送达能真正颠覆这个行业——只不过不是以我们预想的方式罢了。它不会影响用户留存率，它真正影响的是注册率。次日送达激发了真正的用户忠诚度，正是这种用户忠诚度让你自发地把自己正在使用的这项新服务告诉你所有的朋友。</p>
</li>
<li><p>整件事给我们上了宝贵的一课：相信你的直觉，但也要检验它。在做任何具体的事情之前，数据必须先行。</p>
</li>
<li><p>我们虽然猜测次日送达很重要，但是在分析测试结果时目光太过短浅，所以一直想不明白为什么会产生这样的结果。因此，需要进行一项额外的测试，一次真正跳脱定势思维的测试，来理解我们凭直觉认为是正确的事情。一旦理解了它背后的原因，我们就可以进一步完善这个想法，最大限度地发挥它的潜力——巨大的潜力。</p>
</li>
</ul>
<h3 id="开创算法匹配服务"><a href="#开创算法匹配服务" class="headerlink" title="开创算法匹配服务"></a>开创算法匹配服务</h3><ul>
<li><p>我们想要提供个性化的服务，但问题是，如果全部由人工完成这些工作，成本就会非常高昂，更不用说费时了。当我们只有900部电影时，创建匹配的内容还可行，但到1999年年底，我们已经有了近5000部电影。除了工作进度很难跟上，浏览甚至也会变得更加不方便。里德又以他的一贯的风格坚持推进自动化。</p>
</li>
<li><p>最后我们才意识到，要想为用户提供他们想要的东西，最好的方法就是通过用户自身进行数据众包。</p>
</li>
<li><p>我们决定让用户给每部电影打分，从1星到5星不等。让他们给喜欢的电影打5颗星，觉得观看纯粹是浪费时间的就打1颗星。事实证明，大家喜欢被征求意见。人人都是评论家。</p>
</li>
<li><p>我创建的团队不断迸发着各种创意，致力于增进与用户的良好关系，而里德的团队则专注于简化我们的设想，提升效率。里德的高度专注帮助我们聚焦于未来，而我的目标则是确保无论我们发展得多快，无论我们变得多么高效，在根本上，我们始终寻求与用户建立良好的关系。</p>
</li>
</ul>
<h3 id="危机下的盈利计划"><a href="#危机下的盈利计划" class="headerlink" title="危机下的盈利计划"></a>危机下的盈利计划</h3><ul>
<li>网飞内部都有一个共同的期待，那就是一旦得出了显而易见的正确结论，就该着手实施了。争论是为了更好地合作，而不是为了自己的面子。谁是对的并不重要，重要的是我们做对了。</li>
</ul>
<h3 id="泡沫危机"><a href="#泡沫危机" class="headerlink" title="泡沫危机"></a>泡沫危机</h3><ul>
<li>登上顶峰是可选的，安全下山是必须的</li>
<li>我们花时间进行自我评估，然后毫不留情地剔除了所有不再有贡献价值的计划、测试、附加功能和增强功能。</li>
<li>过去，我们主要关注的是等式的一边：获取更多的用户。而此刻，越来越明显的一点是，我们必须开始关注等式的另一边：减少经营企业的成本。</li>
</ul>
<h3 id="只关注棘手之事"><a href="#只关注棘手之事" class="headerlink" title="只关注棘手之事"></a>只关注棘手之事</h3><ul>
<li>这是创业圈的一句格言：你肯定会犯错，但是你不能连犯两次同样的错。</li>
</ul>
<h3 id="裁员计划"><a href="#裁员计划" class="headerlink" title="裁员计划"></a>裁员计划</h3><ul>
<li>一名主要员工已经离开了：埃里克·迈耶，他在前一天就被劝退了。虽然他天赋异禀，但他的才干已不再适合应对我们面临的挑战。</li>
<li>“我们的一些朋友和同事将会离开这里。但这并不是因为他们做错了什么，这纯粹是因为要让公司变得更强大，我们别无他路。</li>
<li>这一切结束后不久，我就把我分管的几个部门剩余的员工召集在了一起。我发表了一次简短的讲话，主要内容是我们要继续前进，我们有责任向我们自己，也向其他每一个人证明，这次裁员不是任性的、残忍的，裁员唯一的目标就是为了确保网飞能够挺过去。为了所有人，我们有责任保证实现这一目标。</li>
</ul>
<h3 id="上市"><a href="#上市" class="headerlink" title="上市"></a>上市</h3><ul>
<li>这不是金钱的问题。这是一个人是否有用的问题，是价值观所带来的快乐的问题。对我来说，工作从来就不是为了发家致富。于我而言，工作是为了完成任务时的激动，是为了解决问题时的乐趣。在网飞，这些问题都非常复杂，而快乐就来自和优秀的人围坐在一起，努力解决这些问题。</li>
</ul>
<h3 id="明星团队"><a href="#明星团队" class="headerlink" title="明星团队"></a>明星团队</h3><ul>
<li><p>在经历了9月痛苦的裁员之后，过了几周，乃至几个月，我们开始注意到一种变化。我们变得更好了。我们变得更高效、更有创造力，也更果断了。筛选员工让人员变得更精简，也更专注。我们没时间可以浪费了，所以我们没有浪费时间。虽然我们不得不解雇一些非常有天赋的员工，但留下的全部是超级明星选手。有了这些超级明星选手负责完成所有的工作，难怪我们的工作质量如此之高。这在成功的创业企业中颇为常见。公司能够起步，得益于一小群敬业奉献的人，得益于他们的专注、投入和创造力。公司不断招人、发展壮大，接着又进行收缩。它开始重新致力于自己的使命，而这往往依赖于其最宝贵的成员重新集中的注意力和精力。</p>
</li>
<li><p>然而，雇用和留下超级明星选手远不只是工作质量的问题。这是文化问题。当你仅仅保留超级明星选手时，你就打造了一种“竞争、卓越”的文化。当你知道自己属于百里挑一的精英团队之后，每天上班就会变得更有意思。此外，如果你已经有了超级明星人才队伍的名声在外，那么吸引其他精英加入你的团队也会容易得多。</p>
</li>
</ul>
<h3 id="将“不”变成“是”"><a href="#将“不”变成“是”" class="headerlink" title="将“不”变成“是”"></a>将“不”变成“是”</h3><ul>
<li><p>我们挺了过来，正朝着目标稳步前进。但此时一切都变了，创始团队的很多成员都已经离开了。吉姆当时去了亚马逊旗下一家名为“葡萄酒买家”（WineShopper）的公司工作。特在一家互联网安全初创公司“地带实验室”（Zone Labs）工作。维塔和埃里克在9月被解雇了。克里斯蒂娜在1999年因为身体原因休假，后来便再也没有以全职身份回来工作过。最初那一批技术娴熟的多面手，如今已被超级明星专家取代。我当然很高兴能与全硅谷最杰出的人才共事，但作为与创始团队最后的纽带，我开始怀疑自己未来在公司的角色。我适合什么角色？更重要的是，我希望自己扮演什么样的角色？</p>
</li>
<li><p>我知道我们的想法很好，即便现在或许无法实现，但总有一天能够实现。以下是我总结的经验：在实现梦想的道路上，你拥有的最强大的武器就是坚持不懈、义无反顾。坚决不接受“不”这个回答，绝对是值得的，因为在商界，“不”并不总是意味着“不”。</p>
</li>
<li><p>我完全相信网飞一定会大获成功。我从未像现在这般确信，我们创建的这家公司注定会取得长期的成功。我只是想要有选择卖出的权利。</p>
</li>
<li><p>要实现这一点，我就需要大大降低自己在投行和投资者面前的存在感。我不能以“总裁”的身份出现在我们的S-1申请表上。这意味着两件事：第一，我需要一个低调的头衔，以免让我看起来像是公司的负责人；第二，我需要放弃我在网飞董事会的席位。</p>
</li>
<li><p>不过，离开董事会有点儿难。我为那个席位努力奋斗了很久，有一次还差点儿丢了席位。里德在担任首席执行官后不久，就要求我把董事会席位让给一位投资者。我坚决拒绝了。我告诉他，我可以放弃首席执行官的头衔，甚至可以放弃一些股权，但我绝不会放弃我在董事会的席位——那太过分了。我想要对公司的发展方向有一定的控制权，我同时也认为，由公司的一位创始成员留在董事会里制衡风险投资人的利益是很重要的。</p>
</li>
<li><p>“董事会上的每个人都说，他们只会为了公司的成功着想，”我告诉里德，“但你我都知道，在风险投资人和公司创始人的词典里，‘成功’这个词的含义并不完全相同。”顺便说一下，这句话是真的。我现在经常这么告诉创业者。风险投资人总是说他们与你的使命一致，他们想要的都是对公司最有利的。但他们真正想要的，其实是对他们的投资最有利的。这两者并不总是等同的。顺风顺水时，大家的方向都是一致的。只有当暴风雨来临时，你才会发现原来大家的目标其实各不相同。</p>
</li>
</ul>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li><p>创业是一次孤独的旅程，你在做一件没人愿意相信的事情，你一次又一次地被告知：那永远不会成功。是你在对抗全世界。但事实是，光靠自己是行不通的。你需要寻求帮助，说服别人接受你的想法，让他们也心怀如你一般的热情。给他们戴上神奇的眼镜，让他们也能看到你对未来的憧憬。</p>
</li>
<li><p>大多数公司在寻求进入新业务领域的机会的时候，都会进行一项“自制或外购分析”。在分析的过程中，公司会衡量从头开始打造一项新业务的成本、时机和难度，再评估直接买下一家已经在从事这项业务的公司是否成本更低且更快、更好。</p>
</li>
<li><p>我在网飞学到的一条重要经验就是，仅仅有创造性的想法，或者有合适的人在你身边工作还不够，你还需要保持专注。在一家初创公司，能把一件事情做好就已经够难了，更不用说要把一大堆事情都做好了。尤其是当你想做的那些事情不仅截然不同，而且会互相阻碍的时候。</p>
</li>
</ul>
<h3 id="后记-伦道夫的成功法则"><a href="#后记-伦道夫的成功法则" class="headerlink" title="后记 伦道夫的成功法则"></a>后记 伦道夫的成功法则</h3><ul>
<li><p>1.至少比要求的多做10%。2.在你不了解的领域永远不要把自己的观点当成事实说给别人听。要非常小心，严格自律。3.始终保持礼貌和体贴，对上对下都一样。4.不要非难，不要抱怨，而是坚持提出建设性的、严肃认真的批评意见。5.当你有事实依据时，不要害怕据此做出决定。6.一切尽可能量化。7.思想要开明，但也要保持怀疑。8.别迟到。</p>
</li>
<li><p>随着年龄的增长，如果你有那么一点儿自知之明，你就会了解关于自己的两件重要的事情：第一，你喜欢什么；第二，你擅长做什么。每天能同时做这两件事情的人都是幸运儿。</p>
</li>
<li><p>但这个故事太混乱了。当你和媒体、投资者或者商业伙伴交谈时，大家真的不愿意听你讲这些。他们想要的是一个干净整洁的版本，上面打着一个精巧的蝴蝶结。里德几乎立刻就意识到了这一点，所以他想出了一个故事。这是一个伟大的故事：简单、清晰，令人难忘。这个故事抓住了网飞的精髓，为我们解决了一个大问题。</p>
</li>
<li><p>但随着季度业绩报告机械地反反复复，年复一年，我慢慢意识到，虽然我热爱这家公司，但我已经不再热爱在这里的工作了。</p>
</li>
<li><p>这是真的：里德经常和我谈论我的感受。他太聪明了，肯定已经注意到我身上的技能不是网飞未来几年发展所需要的；他也太诚实了，瞒不了我多长时间。</p>
</li>
<li><p>不过此刻，他看上去倒是松了一口气。在这样的安排下，他就不必主动找我进行一次不愉快的谈话了。他不必再做幻灯片，再做一块“狗屎三明治”——因为这个决定不是他做的。我在做最后一个项目。如果失败了，我就会离开——按照我自己选择的方式。</p>
</li>
<li><p>那些艰难困苦的日子也一去不复返了。我想念那段日子；我想念那些深夜和清晨，草坪椅和折叠桌；我想念所有人同舟共济的那种感觉，那种对于每天都要处理一个与自己的职位描述无甚关联的问题的期待。</p>
</li>
<li><p>有时候，你必须从你的梦想中后退一步，抽离出来，尤其是当你认为你已经实现了梦想的时候。那时你才能真正地看清它。就我而言，离开网飞是因为我意识到已经锻造为成品的网飞并不是我的梦想。我的梦想是打造事物，是创建网飞的过程。</p>
</li>
<li><p>我真的为我们在网飞取得的成就而感到骄傲，它的成功已经远远超出了我的期望。但我逐渐意识到，成功不是由一家公司的成就来定义的。我有一个不同的定义：成功是你自己的成就。成功是你能做自己喜欢的事，做你最擅长的事，追求对你来说重要的事。</p>
</li>
<li><p>从这个定义来看，我做得不错。但是成功也可以被定义得更加宽泛一点儿：你拥有一个梦想，你通过时间、天赋和毅力，见证梦想变为现实。我也完全符合这个定义，为此我很自豪。</p>
</li>
<li><p>这就是伦道夫法则所指向的那种成功，是父亲一直期望我实现的那种成功：实现你的目标，让你的梦想成为现实，同时享受来自家庭的爱的滋养。不要总想着金钱，不要总想着股票期权。这才是成功。</p>
</li>
<li><p>说句公道话，最初的设想确实是无法成功的。我们花了数年时间调整、改变策略，想出新点子，再加上运气好，才最终找到了一个可行的版本。</p>
</li>
<li><p>要将梦想变为现实，任何人所能采取的最有力的一步都很简单：你只需要开始。要想知道你的想法到底好不好，唯一的方法就是去试试。你花一个小时去做一件事，学到的东西会比花一辈子去思考它还多。</p>
</li>
<li><p>你必须学会热爱问题，而不是热爱解决方案。当事情耗费的时间比你预期的久时，这就是你保持专注的方式。相信我，事情耗费的时间绝对比你预期的久。如果你已经读到了这里，你就会发现，把梦想变成现实的过程有一个戏剧式结构，这个过程不会很快，也绝不容易，在整个过程中，你会遇到许多问题和困难。</p>
</li>
<li><p>雅达利（Atari）的联合创始人诺兰·布什内尔说过一句话，这句话直到现在都能引起我的共鸣：“每个冲过澡的人都有过一个想法，但真正与众不同的是那些从浴室出来，用毛巾把自己擦干，然后采取行动的人。”</p>
</li>
</ul>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>顿悟</li>
<li>股权稀释过程</li>
<li>OPM创业</li>
<li>作为领导者，给他们明确的坐标，让他们自己想办法</li>
<li>团队壮大，编成规定</li>
<li>“狗屎三明治”</li>
<li>绝对的坦诚</li>
<li>不同阶段的需要</li>
<li>重新定义团队</li>
<li>绝对的坦诚，以及自由与责任</li>
<li>具备判断力来做出负责任决定的人</li>
<li>他们喜欢被信任的感觉</li>
<li>充分快速试错</li>
<li>数据必须先行</li>
<li>无人、知晓、一切</li>
<li>专注与放弃</li>
<li>坚持推进自动化</li>
<li>争论是为了更好地合作</li>
<li>不连续犯同样的错误</li>
<li>明星团队、“竞争、卓越”的文化</li>
<li>制衡风险投资人</li>
<li>你喜欢什么；擅长做什么</li>
<li>整洁的讲故事</li>
<li>从梦想中抽离</li>
<li>有想法，更重要的是开始</li>
<li>学会热爱问题，而不是热爱解决方案</li>
</ul>
<hr>
<ul>
<li>评论：想起了达维多定律：一家企业要在市场中总是占据主导地位，那么它就要永远做到第一个开发出新一代产品，第一个淘汰自己的产品</li>
<li>不被替换，足够的股权，或匹配能力</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>《小狗钱钱》-笔记</title>
    <url>/2021/08/13/20210813-xiao-gou-qian-qian-bi-ji/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><ul>
<li><p>财务自由是今天每个人都可能实现的目标，当然这需要我们拥有追求自己真正想要的生活的勇气。正如一句名言所说：“并非困难使我们放弃，而是因为我们放弃，才显得如此困难。</p>
</li>
<li><p>什么都无法阻挡你将金钱的规律铭记在心，你就会发现自己的财务状况在日益改善。没有任何东西能够阻挡一个顺应时势的想法。这一点也适用于每一个人的生活。什么都无法阻挡你享受自己与生俱来的权利——富裕。富有尊严、财务上游刃有余的生活符合我们的自然法则。只要你不放弃，那就没有任何东西可以阻碍你达到这个目标。就是现在，马上行动起来吧。我们的生活是一次旅行。如果我们掌握了金钱的规律，那么这次旅行就可以为我们开创机遇，并将我们引向那个自己从未想过的方向。</p>
</li>
</ul>
<h3 id="第一章-白色的拉布拉多犬"><a href="#第一章-白色的拉布拉多犬" class="headerlink" title="第一章 白色的拉布拉多犬"></a>第一章 白色的拉布拉多犬</h3><ul>
<li>中国的智者老子说过：‘天下难事，必作于易；天下大事，必作于细。</li>
</ul>
<h3 id="第二章-梦想储蓄罐和梦想相册"><a href="#第二章-梦想储蓄罐和梦想相册" class="headerlink" title="第二章 梦想储蓄罐和梦想相册"></a>第二章 梦想储蓄罐和梦想相册</h3><ul>
<li><p>学习就是认识新观念和新想法的过程。假如人们始终以同一种思维方式来考虑问题的话，那么始终只会得到同样的结果。因为我对你讲述的许多内容是你以前从未接触过的，所以我建议你，在你还没有做之前，不要轻易下结论。没有想象力的人是很难成就大事的。我们对一件事投入的精力越多，成功的可能性也越大。可是大多数人把精力放在自己并不喜欢的事情上，而不去想象自己希望得到的东西。</p>
</li>
<li><p>看看你的爸爸妈妈，他们拥有的钱比你零花钱的10倍还要多得多，也许是你的100倍。尽管如此，他们的情况也并不好。钱的数目并不是决定性因素，更重要的是我们怎么来使用它。我们首先必须学会量入为出，只有这样，我们才有能力获得更多的钱。</p>
</li>
</ul>
<h3 id="第三章-达瑞，一个很会挣钱的男孩"><a href="#第三章-达瑞，一个很会挣钱的男孩" class="headerlink" title="第三章 达瑞，一个很会挣钱的男孩"></a>第三章 达瑞，一个很会挣钱的男孩</h3><ul>
<li>第一，为别人解决一个难题，那么你就能赚到许多钱；第二，把精力集中在你知道的、能做的和拥有的东西上。</li>
</ul>
<h3 id="第四章-堂兄的挣钱之道"><a href="#第四章-堂兄的挣钱之道" class="headerlink" title="第四章 堂兄的挣钱之道"></a>第四章 堂兄的挣钱之道</h3><ul>
<li><p>你最好想清楚你喜欢做什么，然后再考虑你怎么用它来挣钱。我就是这样想出派送面包这项服务的。</p>
</li>
<li><p>“但是，我想提醒你两件重要的事情。”我听见马塞尔说，“第一，无论在什么时候都不能把希望只寄托在一份工作上，它持续的时间不会像你设想的那么长，所以你要立即寻找另一份替代的工作。”</p>
</li>
<li><p>这些困难是你现在还难以预料的。到那时候就能看出来，你到底是一个洋娃娃似的胆小鬼呢，还是一个像我一样能挣很多钱的人。情况顺利的时候，人人都能挣到钱。只有在逆境中，一切才能见分晓。”</p>
</li>
</ul>
<h3 id="第五章-钱钱以前的主人"><a href="#第五章-钱钱以前的主人" class="headerlink" title="第五章 钱钱以前的主人"></a>第五章 钱钱以前的主人</h3><ul>
<li>72小时规定！”“72小时规定？”我紧接着问钱钱。“很简单。当你决定做一件事情的时候，你必须在72小时之内完成，否则你很可能永远不会再做了。</li>
</ul>
<h3 id="第六章-爸爸妈妈犯下的错误"><a href="#第六章-爸爸妈妈犯下的错误" class="headerlink" title="第六章 爸爸妈妈犯下的错误"></a>第六章 爸爸妈妈犯下的错误</h3><ul>
<li><p>“大多数人都认为工作肯定是一件艰苦而令人不愉快的事情，”他向我解释道，“其实只有做自己喜欢的事情的人，才能真正获得成功。”</p>
</li>
<li><p>钱钱接着说：“第二个忠告是，应当尽可能少地偿还贷款——也就是大人们说的分期付款。</p>
</li>
<li><p>如果每年偿还1%，虽然需要支付的利息逐年减少，但最后总共支付的利息数额仍会达到贷款数额的3倍左右。为了能快一点儿还清1万马克贷款，人们当然选择每年付较高的分期付款。许多人和银行约定的分期付款数额刚好在他们承受能力的上限，因此他们手里的钱一直很紧张。</p>
</li>
<li><p>第三个忠告是针对消费贷款的。消费贷款是与住房无关的贷款。假如人们为了购置新的汽车、家具、电视机或其他用于生活的商品而贷款，就是消费贷款。这时候贷款的人应当遵守的一个原则，就是将不用于生活的那部分钱的一半存起来，另一半用于偿还贷款。”“可是我奶奶常说，债务应当尽快还清，”我想起奶奶的话，“所以应该把所有不用于生活的钱都用来还债。”“当你还清了债务的时候，又达到了什么目标呢？”钱钱问我。“爸爸妈妈总是说，那时候他们肩上的一个重担就可以卸下来了。”我试着给钱钱解释。“他们是这么以为的。”钱钱赞同地点点头，“可是事实上，当他们还清了债务的时候，他们拥有的财产为零，也就是一无所有。一无所有可不是目标呀。”我吃了一惊，问道：“那么目标该是什么呢？”“去美国旅行，买笔记本电脑——这些才是目标，”钱钱耐心地解释给我听，“或者把不花的钱都积攒起来。”</p>
</li>
<li><p>所有的消费贷款都是不明智的。聪明的做法是只把以前积攒起来的财富用于支出。</p>
</li>
<li><p>将扣除生活费后剩下的钱的一半存起来，剩下的一半用于支付消费贷款。最好根本不申请消费贷款。</p>
</li>
</ul>
<h3 id="第七章-在金先生家"><a href="#第七章-在金先生家" class="headerlink" title="第七章 在金先生家"></a>第七章 在金先生家</h3><ul>
<li><p>你当然也应该得到一点儿什么……让我想想。你照顾钱钱很长一段时间了，确切地说，是一年多。如果我一天付你10马克，你觉得怎么样？”我一点儿都不高兴。我气呼呼地说：“我愿意照顾钱钱是因为我一见到它就喜欢上了它，而不是为了挣什么钱。”金先生笑了，但我并不觉得他是在嘲笑我——这两者之间还是有一点儿细微差别的。他向我解释道：“吉娅，大多数人都是这么想的，我曾经也这么想。可是请你告诉我，你为什么不能因为做了一件自己喜欢的事情而挣到钱呢？”类似的话我已经听过许多次了。的确如此，马塞尔对我说过，汉内坎普先生也说过。尽管如此，我还是觉得心里有些不安。“我要告诉你一件事，”金先生接着说，“恰恰是因为你喜欢我的钱钱，我才要每天付你10马克，因为由此我知道，它在你身边过得很舒服，你也会继续好好地照顾它。正是你的真情实意才让你的劳动显得那样珍贵。”</p>
</li>
<li><p>“鹅代表你的钱。如果你存钱，你就会得到利息。利息就相当于金蛋。”我不敢肯定自己是不是真的懂了。金先生接着说：“大多数人生来并没有‘鹅’。这就是说，他们的钱不足以让他们依靠利息来生活。”“可是要靠利息生活的话，这个人肯定得有很多很多的钱才行，是这样吗？”我不解地打断了金先生的话。“你需要的钱其实比你想象的要少得多。”金先生答道，“如果你有2.5万马克，能得到12%的利息的话，那每年就有3000马克。”</p>
</li>
<li><p>那么2.5万马克就是你的‘鹅’，而你是不会‘杀’它的。</p>
</li>
<li><p>“你必须作出选择！”金先生点点头，“你可以马上拿出你的钱，用在任何一个地方——比如一旦你有了3000马克，你可以马上飞往加利福尼亚——可是那样的话，你也就‘杀死’了你的‘鹅’；你也可以选择将一部分钱存起来，那样过了一段时间之后，仅靠每年的利息，你就可以飞往加利福尼亚了。”</p>
</li>
<li><p>我已经想好该怎么分配我的钱了，我也要把50%的收入变成我的‘鹅’，40%放入我的梦想储蓄罐，剩下的10%用来花。”金先生看着我，眼光中充满了赞许。</p>
</li>
<li><p>越是把注意力放在疼痛上，我就越会觉得疼。谈论疼痛就像给植物施肥一样。所以我很多年以前就改掉了抱怨的习惯。</p>
</li>
</ul>
<h3 id="第十一章-爸爸妈妈不明白"><a href="#第十一章-爸爸妈妈不明白" class="headerlink" title="第十一章 爸爸妈妈不明白"></a>第十一章 爸爸妈妈不明白</h3><ul>
<li><p>幸运其实只是充分准备加上努力工作的结果。</p>
</li>
<li><p>你干的活最多只值报酬的一半，另一半报酬源于你的想法和实施这个想法的勇气。</p>
</li>
</ul>
<h3 id="第十二章-陶穆太太归来"><a href="#第十二章-陶穆太太归来" class="headerlink" title="第十二章 陶穆太太归来"></a>第十二章 陶穆太太归来</h3><ul>
<li><p>要想过更幸福、更满意的生活，人就得改变自身。这和钱无关，金钱本身既不会使人幸福，也不会带来不幸。金钱是中性的，既不好，也不坏。只有当钱属于某一个人的时候，它才会对这个人产生好的影响或者坏的影响。钱可以被用于好的用途，也可以被用于坏的用途。一个幸福的人有了钱会更幸福；而一个悲观忧虑的人，钱越多，烦恼就越多。</p>
</li>
<li><p>“我妈妈总说，金钱会使人的本性变坏。”我反驳道。“金钱会暴露一个人的本性，”陶穆太太解释说，“金钱就像一个放大镜，它帮你更充分地展现出你本来的样子。好人可以用钱做很多好事。而如果你是盗贼，那你很可能会把钱挥霍在一些蠢事上。”</p>
</li>
</ul>
<h3 id="第十三章-巨大的危机"><a href="#第十三章-巨大的危机" class="headerlink" title="第十三章 巨大的危机"></a>第十三章 巨大的危机</h3><ul>
<li>“我想，你刚刚又找到了一个做有钱人的很好的理由。”钱钱提示我。我疑惑地望着它。“你可以做一个有能力帮助别人的人，而别人也会相信你，愿意接受你的帮助。”钱钱解释说。</li>
</ul>
<h3 id="第十四章-投资俱乐部"><a href="#第十四章-投资俱乐部" class="headerlink" title="第十四章 投资俱乐部"></a>第十四章 投资俱乐部</h3><p>1．确定自己希望获得财务上的成功。<br>2．自信，有想法，做自己喜欢做的事。<br>3．把钱分成日常开销、梦想目标和金鹅账户三部分。<br>4．进行明智的投资。<br>5．享受生活。</p>
<h3 id="第十五章-演讲"><a href="#第十五章-演讲" class="headerlink" title="第十五章 演讲"></a>第十五章 演讲</h3><ul>
<li>如果你没有做今天这件事情，你就永远不会知道，给自己一些压力之后，你能够做到些什么。一个人觉得最引以为自豪的事情，往往是那些做起来最艰难的事情。这一点你千万不要忘记。</li>
</ul>
<h3 id="第十六章-俱乐部的投资行动"><a href="#第十六章-俱乐部的投资行动" class="headerlink" title="第十六章 俱乐部的投资行动"></a>第十六章 俱乐部的投资行动</h3><ul>
<li><p>基金就像一口大锅，许多没有时间、没有相关的知识或者没有兴趣亲自去买股票的投资人都会把钱投进这口锅里，这些钱由金融界的专家——也就是所谓的基金经理人——去投资买股票。国家对此进行严格的监督，基金经理人必须遵守一定的规定。比如，他们至少必须购买20种不同的股票。</p>
</li>
<li><p>如果我们打算投资买基金，就要准备把自己的钱在里面放上5～10年。对于那些能等这么长时间的人来说，基金几乎是一种零风险的投资。”</p>
</li>
<li><p>挑选基金时的注意事项：1．基金应该至少有10年历史。假如它在这么长时间内一直有丰厚的利润，那我们可以认为，未来它也会运作良好。2．应该选择大型的跨国股票基金。这种基金在世界各地购买股票，以此分散风险，所以十分安全。3．对基金的走势图进行比较。我们应该观察在过去10年间哪些基金的年终利润最好。</p>
</li>
<li><p>“有一个相当简单的公式，如果你们运用这个公式的话，可以不用去看那些又复杂又麻烦的表格。它的名字叫72公式。”老太太讲解说，“你们直接用72除以你们投资的年利润百分比，得出的数字就是这笔钱翻一倍所要的年数。”“啊？”莫尼卡嘟哝了一声。“72除以12是多少？”陶穆太太问。“6。”马塞尔飞快地算了出来。“对！这就是说，如果你们每年能得到12%的利润，6年以后你们的钱就会翻一倍。”马塞尔一边思考，一边说：“要想知道15%的时候会怎么样，那我就必须用72除以15，等于4.8年。”</p>
</li>
<li><p>“简单地说，如果你们投资的收益率是15%，差不多5年以后，钱就会翻一倍。</p>
</li>
<li><p>”陶穆太太说道，“也就是说，如果将来我们也能得到15%，那5年以后我们的2万马克就会涨到4万马克，10年以后就会是8万，15年后是16万，而20年后是32万。”</p>
</li>
</ul>
<h3 id="第十七章-爷爷奶奶害怕风险"><a href="#第十七章-爷爷奶奶害怕风险" class="headerlink" title="第十七章 爷爷奶奶害怕风险"></a>第十七章 爷爷奶奶害怕风险</h3><ul>
<li><p>只有当我们把它卖出的时候，才会有亏损。可是我们并没有这么做。</p>
</li>
<li><p>现在我们可以用比实际价值低的价钱购买股票和基金。不久以后，又有人会愿意付出相当于它们实际价值的钱，把它们买进。这样我们就会大赚一笔。</p>
</li>
<li><p>银行存折肯定不是保存钱的最合适的地方，金先生总是把银行存折叫作“吞钱机器”。</p>
</li>
<li><p>你要理解你的爷爷奶奶，他们是为你好。他们只是想让你免受损失，想尽他们所知来帮助你。</p>
</li>
<li><p>到了他们这个年纪，很可能有过几次吃亏的经历。现在他们想保护自己，也保护你。这是可以理解的。不过说真的，你应该多谢你的爷爷奶奶，因为他们可能帮你避免了一个错误。”“避免了什么错误？”“我觉得，你们现在用2万马克再次买进基金不是一个好主意。我认为最多1万马克就够了。”</p>
</li>
<li><p>可是如果行情继续下跌怎么办呢？所以你最好不要投入太多的钱。而且如果行情真的继续下跌，那时要是你手头还有钱用来再一次买进的话，不是更好吗？”“但我们并不知道，行情是不是真的还会继续下跌。”“没错，我们是不知道。没有人能知道，所有试图预测未来走势的专家总是计算失误，意想不到的情况很多。正因为如此，你应该始终储备一些现金。决不能把你全部的钱都投资在股票或者基金上面。”</p>
</li>
<li><p>我怎么知道通货膨胀率有多高，会吃掉我多少钱呢？”“目前是3%左右。如果你现在想计算具体的数目，我可以告诉你一个相当简单的公式，就是72公式。这个公式很实用，我们可以通过它计算出自己的钱翻一倍需要多少年，也可以用来帮助我们计算通货膨胀。它可以告诉我们，在一定通货膨胀率下，我们的钱在多长时间后会贬值一半。按72除以3%的通货膨胀率计算，得到24，就是说24年以后，你的钱只值现在的一半。”</p>
</li>
<li><p>没错！所以我把存折叫作‘吞钱机器’。因为你从这里得到的利息连通货膨胀带来的损失都抵消不了</p>
</li>
<li><p>但是我们几乎没有别的选择。你总不能把你所有的钱都投资买股票。就算你还很年轻，也该留一些现金做储备。只有这样才能达到分散风险的最佳效果。”</p>
</li>
<li><p>当然也有一些储蓄种类的利率比较高，可是你必须把钱放在银行里存很长一段时间。这种方式的坏处是，碰上再次买进的合适时机，你不能马上采取行动。”“那么，我该拿百分之几的钱投资日拆呢？”“这要根据你的具体情况而定。你还小，20%就够了。”</p>
</li>
<li><p>我决定向金钱魔法师们建议，每人只拿出2500马克用来再次买进基金，剩下840马克，可以投资在日拆上。</p>
</li>
</ul>
<h3 id="第十八章-大冒险的结局"><a href="#第十八章-大冒险的结局" class="headerlink" title="第十八章 大冒险的结局"></a>第十八章 大冒险的结局</h3><ul>
<li><p>而自从他买了一辆新车之后，甚至比往常提早一个小时就起床了。当一个人不需要再为钱的问题烦心之后，竟然会发生如此巨大的变化，真令人难以置信。</p>
</li>
<li><p>我们买的第一只基金的行情虽然持续下跌了7个月，但我们并没有卖出，所以没有亏损。这以后行情开始爬升，如果我们卖出的话，可以获取不少利润。不过我们没有理由这样做，我们想要的是让我们的鹅不断地长大。马塞尔曾经想过卖出手里的基金，他说这叫提取利润。陶穆太太却问他准备怎样处置这笔钱，怎样让它继续增长。我们得出的结论是：再次选择同样的基金进行投资。于是马塞尔立即意识到现在卖出基金毫无意义。</p>
</li>
<li><p>我想起了金先生对我说过的一句话：不要为失去的东西而忧伤，而要对拥有它的时光心存感激。对我来说，这句话的意思是：从现在开始，我再也得不到钱钱的建议了，但我还是必须应对各种情况。</p>
</li>
</ul>
<h3 id="自力更生——写给成年人的后记"><a href="#自力更生——写给成年人的后记" class="headerlink" title="自力更生——写给成年人的后记"></a>自力更生——写给成年人的后记</h3><ul>
<li><p>钱钱拆除了偏见的围墙，让人眼前豁然开朗，它告诉我们：经营活动并不是童工劳动，而是一种能激发人的热情的游戏；赚钱并不枯燥，相反会带来激动人心的时刻，释放人的发明创造的才能。</p>
</li>
<li><p>我们推崇一种聪明的、简朴的生活方式。也就是说，宁愿购买一件一流产品，也不要不停地买许多的二流产品。而且，不要仅仅因为一件产品的外观不再时髦而新产品正在流行，就不断追逐新鲜的东西。生活质量不是由越来越多的高科技产品堆砌而成的，而体现在一些别的方面，比如悠闲地享受一下生活，增进邻里关系，</p>
</li>
<li><p>表达感情或者从事艺术性和创造性的活动。</p>
</li>
</ul>
<h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><ul>
<li>股票是一家公司的股权证明——你可以购买这家公司的一份或若干份股权。每一份股权就是一张股票。如果公司赢利（赚钱），你就可以根据自己所拥有的股份数量，从公司的利润中分得一部分。你的股份越少，分到的利润就越少；股份越多，分到的利润就越多。如果公司亏损，那么你所持有的股票就会贬值。在这种情况下，你不应该急于卖出股票，而应该等待公司重新赢利。在第十六章中，陶穆太太对此有详细说明。</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>并非困难使我们放弃，而是因为我们放弃，才显得如此困难。</li>
<li>无论在什么时候都不能把希望只寄托在一份工作上，它持续的时间不会像你设想的那么长，所以你要立即寻找另一份替代的工作。</li>
<li>72小时规定</li>
<li>尽可能少地偿还贷款</li>
<li>消费贷款是不明智的</li>
<li>基金</li>
</ul>
<hr>
<ul>
<li>评论：转：聪明理财五大定律<br>4321定律：家庭资产合理配置比例是家庭收入的40%用于供房及其他方面投资，30%用于家庭生活开支，20%用于银行存款以备应急之需，10%用于保险。<br>72定律：不拿回利息利滚利存款，本金增值一倍所需要的时间等于72除以年收益率。比如，如果在银行存10万元，年利率是2%，每年利滚利，多少年能变20万元？答案是36年。<br>80定律：股票占总资产的合理比重等于80减去年龄的得数添上一个百分号(%)。比如，30岁时股票可占总资产50%，50岁时则占30%为宜。<br>家庭保险双十定律：家庭保险设定的恰当额度应为家庭年收入的10倍，保费支出的恰当比重应为家庭年收入的10%。</li>
<li>评论：转<br>吞钱机器：储蓄利息永远跑不赢通货膨胀。把钱存在银行，你的存款金额看起来是在增加，然而它的实际购买力是在不断降低的。所以，真正富有的人，钱都不会存在银行，而是通过理财投资，跑赢通货膨胀。</li>
<li>评论：投短线叫投机，投长线才叫投资。价格终会回归价值，长期投资价值，才有相对稳定的收益。</li>
<li>评论：转：<ul>
<li>关于基金的三原则：<ol>
<li>基金就像一口大锅，许多没有时间、没有相关的知识或者没有兴趣亲自去买股票的投资人都会把钱投进这口锅里，这些钱由金融界的专家——也就是所谓的基金经理人——去投资买股票。国家对此进行严格的监督，基金经理人必须遵守一定的规定。比如，他们至少必须购买20种不同的股票。</li>
<li>基金符合投资的一切要求。由于它的这些特点，它也非常适合儿童和青少年。如果能够在5～10年内不动用这些钱，基金投资是很保险的，它会带来丰厚的利润……</li>
<li>基金也符合第三条原则，它很容易操作，几乎就像在银行开一个普通的账户一样简单。</li>
</ol>
</li>
<li>挑选基金时的注意事项：<br>  1．基金应该至少有10年历史。假如它在这么长时间内一直有丰厚的利润，那我们可以认为，未来它也会运作良好。<br>  2．应该选择大型的跨国股票基金。这种基金在世界各地购买股票，以此分散风险，所以十分安全。<br>  3．对基金的走势图进行比较。我们应该观察在过去10年间哪些基金的年终利润最好。</li>
</ul>
<p>	</p>
</li>
<li>评论：比特币不跌50%以上不入手，入手拿5年！等第5年比特币牛市，比特币不赚10倍不出货！</li>
</ul>
<p>		</p>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>个人管理经验总结</title>
    <url>/2021/08/13/20210813-ge-ren-guan-li-jing-yan-zong-jie/</url>
    <content><![CDATA[<ul>
<li>情商、基于别人的角度思考</li>
</ul>
<hr>
<ol>
<li>以身作则</li>
<li>技术功底，才能令人信服</li>
<li>保证成员 免干扰、休息时间如无必要不打扰</li>
<li>情商，基于别人角度考虑</li>
<li>真诚、谦虚、透明</li>
</ol>
<hr>
<ol>
<li>避免用“以为”作为借口，基于“对方角度”、“将心比心”的方式，思考问题；</li>
<li>“将心比心”的方式不奏效？一般大公司都追求一定的人才密集性，基本不会出现这个问题；</li>
<li>注重沟通的有效性（阐述事情的上下文），避免浪费双方的时间；</li>
<li>真正靠谱的人，当离职的时候，基本不需要什么交接，现有的文档修修补补即可，因为平时善于同步团队信息和分享。做到了可替代性很强，同时“不可替代性”很强。</li>
</ol>
<hr>
<h3 id="《技术领导力：程序员如何才能带团队-》-周明耀-总结"><a href="#《技术领导力：程序员如何才能带团队-》-周明耀-总结" class="headerlink" title="《技术领导力：程序员如何才能带团队 》- 周明耀 - 总结"></a>《技术领导力：程序员如何才能带团队 》- 周明耀 - 总结</h3><ol>
<li>技术管理，技术在前，管理在后。一个技术从业者，核心竞争力是技术能力。技术管理最大的特性是表率，是感染力。</li>
<li>管理看起来套路很多，其实最终都是人性和策略，理解人性，善用策略，就能做好管理。对于聪明人来说，有实践机会，管理可以在短时间内达到一个不错的水准，但技术永远需要长时间积累。</li>
<li>很多技术领导带团队取得了一点成绩，就开始沾沾自喜，以为这事离了自己不行，其实是团队作战的功劳。大部分情况下，不是团队离不开领导，而是你离不开你的团队！</li>
<li>作为技术管理者，需要持续保持自己的技术能力，需要不断强化自己的管理能力和方方面面的综合性能力</li>
<li>只有做好当前的事情，你才有资格谈技术理想</li>
<li>在软件行业，没有在专业上的持续学习和成长，是不会成功的。技术变革如此迅速，如果不坚持学习，可能大学毕业几年后就被淘汰了。在不断更新的软件开发行业中，这并不意味着你不需要使用大学里学习的知识，而是除此外还需要不断地增加对新的技术、工具、方法、框架的深度认识和理解。</li>
<li>做好自己。- And now, as I lie on my deathbed, I suddenly realize:If I had only changed myself first, then by example I would have changed my family.From their inspiration and encouragement, I would then have been able to better my country, and who knows, I may have even changed the world.如果一开始我仅仅去改变我自己，然后作为一个榜样，我可能改变我的家庭；在家人的帮助和鼓励下，我可能为国家做一些事情。然后谁知道呢？我甚至可能改变这个世界。</li>
<li>在做这些决定之前，有没有做足充分的技术调研、产品调研工作，能不能尽量详细地说清楚已有框架、产品的实现原理、优缺点、是否适用于你的产品场景等，这些都是前期技术调研的工作，也是体现我们脚踏实地做事的一个环节。</li>
<li>一个人的逻辑能力属于软实力，它是决定你是否可以承担团队领导职责的关键因素。</li>
<li>举事以为人者，众助之；举事以自为者，众去之。</li>
<li>“平时的艰苦训练是战时胜利的保证，这才是对士兵的最大仁慈。我是一个很坏的家伙。我要让他们尝试每一分钟的地狱生活，然后我又为他们痛哭！”</li>
<li>为了公司、自身的形象，我们需要无比庄敬自强，公平待人，不可欺负弱势的人，也不可以做损及他人或自己的事。同时，我们需要一个谦卑的团队负责人，谦卑的人不会固执己见，而是会虚怀若谷地聆听他人的言论。</li>
<li>有了真诚，才会有虚心，有了虚心，才肯丢开自己去了解别人，也才能放下虚伪的自尊心去了解自己。建筑在了解自己了解别人上面的爱，才不是盲目的爱。</li>
<li>我在生活中也是一个很仔细的人，也喜欢仔细的人。仔细的人一般做事都比较负责，愿意承担责任，也懂得抓细节。抓细节是作为一名技术团队管理者必须做到的。所谓的管理浮于表面，一般都是说管理者不关注细节，例如不参与设计、不参与代码审核，而只是高喊要注意开发设计、注意开发质量，这样的领导对于技术团队来说，尤其是一线技术团队经理来说，是不合格的，也是不能服众的。我觉得一个仔细的人，他一定也是一个善于观察的人，而善于观察、思考其实也是一个团队领导者所必须具备的品质，否则他的团队一定会在某一阶段或者一直处于混乱状态。</li>
<li>一个人一生如果想要获得过人的成就，就注定与读书和终生学习形影不离。功利性的学习是非常狭隘的，收获也是非常有限的，但是终生学习的回报却是不可估量的。</li>
<li>“钱能买到一切有价的东西，独独换不回健康，也唯有生命才是无价的。”我们经常会听说有人得癌症了，有人又猝死了，这些例子数不胜数。虽然我能理解健康的重要性，但经常无可奈何。一个现场问题出现了，我们要一直忙到凌晨，可能偶尔还需要通宵应对。但是空下来以后，一定记得好好睡一觉，把睡眠补回来。因为只有保持身体健康，才能更好地带领团队。</li>
<li>回到技术管理工作。一直有同仁问我，什么时候可以转为技术管理？如果在军队里面，一个士兵说我杀敌本领不行，是不是可以升为将军？同样的道理，最好是技术能力比较强之后再转管理，水到渠成，技术不行的人即使转了管理，也难使人信服。</li>
<li>从技术转管理本身就是一个很大的转变，一旦跳进去，就很难爬出来了。我认为最大的差异就是，技术面对的是系统性问题，需要的是逻辑思维能力，是智商，而管理需要面对的很多是非逻辑思维能力，是情商。系统问题需要智商，而人是活的，你要理解人，就需要情商，情商是什么？我个人理解，情商就是如何站在别人的角度看问题。</li>
<li>作为技术团队管理者，你也需要有一定的技术功底，能够让“英雄”觉得可以从你这里学到一些知识，这样才能合作愉快。最后，需要对“英雄”的薪资、福利有所倾斜，并且多和他们沟通，让他们自己选择技术方向，为他们指明职业发展方向，并把他们放入关键项目里。</li>
<li>大多数公司内部都是垂直组织结构，所以管理团队、管理自己的团队领导岗位，大致上可以分为向下管理、向上管理、对外管理、自我管理这四个方面，管理的最终目标是：“不要让你的下属陷入困境，不要让你的同事陷入困境，尤其是在任何情况下，都不要让你的上级陷入困境”。</li>
<li>成功地管理程序员最重要、最关键的因素，是在技术层面得到他们的尊重。</li>
<li>你所选择的这位空降管理者，你需要充分考虑他是否有良好、可以被证明的履历，这样才能让他获得团队的尊重。所以说，一般情况下技术团队是不会空降高管的。（真实！）</li>
<li>我们要学会保护团队成员，让他们免受组织中的各种问题、争议和“机会”的干扰。</li>
<li>公司内部非重要部门组织的会议，尽量不要放在周五的晚上和休息日进行。利用这种休息时间，看起来很有效率，其实是在过度使用研发资源，过度消费员工对公司的满意度。周五晚上和休息日可以打扰研发人员的事情是：（1）现场问题，必须立即处理（不处理会损害公司未来利益）；（2）重要客户提出需求，要求立即做出回复（不处理会损害公司当前利益）；（3）特别重大的突发事件（对你和公司都很重要）。</li>
<li>“信任但要核实”，这是里根总统经常引用的一句谚语，也是列宁的口头语。</li>
<li>记住，没有记录的会议，相当于没有开过。每一个重要会议，都需要有完整的会议记录，包括参加人员、讨论议题（逐一写下来）、讨论过程大体描述、每一个议题的最终结论（包含流程图）、遗留问题、下一次会议时间及议题等。</li>
<li>你老板的级别越高，你的报告就越要精简，越要注重大局，细节更少、局面更大、文字更少、项目符号更多。</li>
<li>另外，你还要避免只把问题带给领导的情况，最好是拿着几套潜在的解决方案和问题一起交给他。即使你没有特别好的解决方案，或者没有找到最好的解决方案，也会让领导觉得你已经做好了自己的功课，过来找他是为了寻求他的建议和忠告，而不是直接把问题抛给他。</li>
<li>公平、公正，是做事、做人的基本原则。</li>
<li>如果程序员觉得没有前途，不思进取，而资质较好的程序员很快又被提拔为管理者，那我们的软件开发将很难有技术和人才的积累。</li>
<li>作为一名团队管理者，有一点是需要做到：“不要作恶！”</li>
<li>程序员都是些无拘无束的人，常见的激励方法往往没什么用。除了进行必要的技术监督并把开发实践和过程落实到位之外，善于利用程序员的自我意识和改变世界的欲望也很关键。这就需要一类既能理解程序员的工作方式，又能理解工作本身的技术管理者，他们不仅能有效地激励程序员超常发挥，而且能按时交付结果。</li>
<li>杰出的程序员偏爱能够满足他们更高理想或要求的公司和项目，他们非常在意自己所做的事情，常常为了想要的结果而超负荷工作，而不会在某种压力下自愿做低技术含量的重复劳动。</li>
<li>大公司可能会采用“矩阵管理”方式组建团队，这意味着团队成员都有各自隶属的职能领域，但为了完成某个指定的项目，被“临时”分配到了一个矩阵型的团队中。这样能够在项目人事配备方面获得最大的灵活性，但是也带来了考核的难题。如果团队成员很优秀，这不会是一个问题。但是当团队成员表现不佳时，则可能成为“临时”团队负责人的烦心事。这个问题通常被称为有责任但没有权力。（真实！）</li>
<li>不要小看了这两个词的力量，正是这两个词决定了OKR和KPI的本质差异：OKR关注的是目标，KPI关注的是指标。当我们关注“目标”的时候，我们会思考接下来我要做的事情是什么；而我们关注“指标”的时候，我们会思考自己的工作如何评价。</li>
<li>彼得·德鲁克在《管理的实践》中说：“并不是有了工作才有目标，而是相反，有了目标才能确定每个人的工作。所以企业的使命和任务，必须转化为目标。”</li>
<li>OKR让我们做正确的事情，KPI让我们正确地做事情！</li>
<li>软件的主要目的就是把人类生活的非核心生命周期软件化、虚拟化，以提供更低的成本和更高效率的新生活，让核心生命周期的运行能够更加容易，让非核心生命周期的处理更少地占用人类的时间，变相地延长人类生命。</li>
<li>一个合格的开发经理必须同时做到“按预期交付成果”“让客户满意”“让员工满意”</li>
<li>从这些工作任务的性质来看，开发经理是项目的推动者、技术的输出者，也是关系的协调者。总的来说，开发经理往往是决定一个项目成败的关键人物，要求其职业素养高、技术能力强、综合能力强、职责范围广。也正是因为要求太高，所以很多公司将开发经理、项目经理区分开，即项目经理可以不用管技术，专心做协调、进度把控工作。</li>
<li>软件开始开发前需要确定投入与产出的比值，也就是ROI（Return On Investment，投资回报率），一旦确定需要创建，就需要安排一系列的资源来支撑这个软件的生存，这是需求的最原始描述。</li>
<li>在需求评审阶段，邀请产品、开发、测试相关人员进行需求评审，产品需求评审主要针对以下几个方面进行：❑ WHY：为什么做这个需求？❑ WHAT：需求的价值是什么？❑ WHEN：需求期望什么时候上线？截止日期？❑ HOW：需求是否完整？正常场景是什么？异常场景是什么？技术上分别怎么应对？</li>
<li>对于还未上线运营的新系统，一般会让应用的产品经理或负责人给出一个预估的比例，但是这个预估需要我们进行评估，不是随意的。对于已上线运营的应用，一般会分析实际的交易数据来确定交易比例，这样会更加精准。</li>
<li>当你去问一个老人很多问题的时候，虽然可能很快得到解答，但当有一天，有很多新人来问你问题的时候，你就能体会到什么问题该问，什么问题不该问。</li>
<li>总结项目经验教训的目的在于总结问题、分析原因，避免以后犯同样的错误，而不是追究谁的责任。再重申一句，复盘会不要太严肃，它不是“批斗会”，而是为了总结经验，不断优化，不再犯同样的错误。</li>
<li>在项目中发生需求变更是难免的，我们不能抵制变更，但是一定要用切实有效的办法控制变更。需求发生变更后一定要认真仔细修改相关的文件，如需求文档、项目计划、设计文档等，并通过书面方式通知团队成员，不能在会议上一笔带过，并且要确保团队成员都准确地知道了变更的内容以及下一步的计划。注意，再小的变更都会给项目带来影响，多次微小的变更可能引发连锁变化，所以不能因为变更影响小而疏忽怠慢。</li>
<li>向进度落后的项目中增加人手，只会使进度更加落后”，这句话摘自《人月神话》。（实际还是看具体情况）</li>
<li>根据时间管理的经验，安排工作的原则顺序为：重要&#x2F;紧急工作&gt;重要&#x2F;不紧急&gt;不重要&#x2F;紧急&gt;不重要&#x2F;不紧急。</li>
<li>缺少强有力项目管理能力的技术领导，很容易让团队的部分成员陷入迷茫。提出的命题很大，但是落实到每位技术人员身上，一部分人会迷茫，不知道每天应该干点什么，所以最好的方式是对工作进行拆分，每天的工作要能说清楚它的具体目标、要求标准等，这样才能让大家有存在感和参与感。</li>
<li>为了更好地设计系统、理解技术，你一定要组织调研项目和预研项目，这是因为你或者团队不可能什么技术、框架都懂，更何况技术发展非常快，只有针对技术进行调研、预研，才能够真正跟上技术发展的潮流，否则终有一天你会被技术岗位淘汰。</li>
<li>业务、架构和技术之间是共生的关系，而不是互斥的关系。先有业务问题，才会有技术来解决业务问题。而业务的长大要求，提高了对技术的要求，导致了对业务生命周期的拆分，以并行的方式提升效率，形成了架构，也形成了新的技术。所以在这三者的关系里：业务是核心，技术是解决业务问题的工作，而架构是让业务长大的组织方法。架构需要用技术来实现拆分，技术需要架构来合理组织，以提升效率。软件和业务最终是要合体的。</li>
</ol>
<hr>
<ul>
<li>正如很多管理环节，领导交代工作，喜欢你够聪明，自己去领悟。奉行的是好话不说第二遍，这样好像显得彼此的效率都很高，实际上这是很模糊的，下属极易做错做偏，不仅成功率低，往往还需要大量的成本去弥补。</li>
<li>在日本的管理中有一个问五次原则，1告诉你去做什么。2让你复述一次。3做这件事的目的是什么。4你觉得行动过程中会有哪些问题，哪些你能自己搞定，哪些需要我来协助。5如果全权交给你来做，你会有什么想法和创意。</li>
<li>看似好像很啰嗦繁杂，却实在地提高了沟通的效率和质量，有效避免了理解偏差和权责不清导致的错误和矛盾。</li>
</ul>
<hr>
<ul>
<li>有些人身上的光环是自己有本事，有些人身上的光环完全是公司的，一定要分清楚。</li>
<li>Leadership并不是当领导和经理，而是一种特征，这种特征有如下两个简单的表象：<ul>
<li>帮人解问题。团队或身边中大多数人都在问：“这问题怎么办？”，而总是你能站出来告诉大家这事该怎么办？</li>
<li>被人所依赖。团队或身边中大多数人在做比较关键的决定时，都会来找你咨询你的意见和想法。</li>
</ul>
</li>
</ul>
<hr>
<pre>
摘自陈皓

技术领导力是：

尊重技术，追求核心基础技术。
追逐自动化的高效率的工具和技术，同时避免无效率的组织架构和管理。
解放生产力，追逐人效的提高。
开发抽象和高质量的可以重用的技术组件。
坚持高于社会主流的技术标准和要求。

那么作为一个软件工程师怎样才算是拥有“技术领导力”呢？我个人认为，是有下面的这些特质。

能够发现问题。能够发现现有方案的问题。
能够提供解决问题的思路和方案，并能比较这些方案的优缺点。
能够做出正确的技术决定。用什么样的技术、什么解决方案、怎样实现来完成一个项目。
能够用更优雅，更简单，更容易的方式来解决问题。
能够提高代码或软件的扩展性、重用性和可维护性。
能够用正确的方式管理团队。所谓正确的方式，一方面是，让正确的人做正确的事，并发挥每个人的潜力；另一方面是，可以提高团队的生产力和人效，找到最有价值的需求，用最少的成本实现之。并且，可以不断地提高自身和团队的标准。
创新能力。能够使用新的方法新的方式解决问题，追逐新的工具和技术。

Leader 和 Boss 的不同
再或者用通俗的话说，Leader 是大家跟我一起上，而 Boss 则是大家给我上，一个在团队的前面，一个在团队的后面。

如何成为众人愿意追随的 Leader
说白了，要成为一个大家愿意追随的人，那么你需要有以下这些“征兆”。

帮人解决问题。团队或身边大多数人都在问：“这个问题怎么办？”，而你总是能站出来告诉大家该怎么办。

被人依赖。团队或身边大多数人在做比较关键的决定时，都会来找你咨询意见和想法。
</pre>

<hr>
<p>《清单革命》</p>
<hr>
]]></content>
      <tags>
        <tag>团队管理</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式理论相关整理</title>
    <url>/2021/10/12/20211012-fen-bu-shi-li-lun-xiang-guan-zheng-li/</url>
    <content><![CDATA[<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li>分布式存储系统通常通过维护多个副本来进行容错，提高系统的可用性。要实现此目标，就必须要解决分布式存储系统的最核心问题：维护多个副本的一致性。</li>
<li>一致性（consensus）,它是构建具有容错性（fault-tolerant）的分布式系统的基础。 在一个具有一致性的性质的集群里面，同一时刻所有的结点对存储在其中的某个值都有相同的结果，即对其共享的存储保持一致。集群具有自动恢复的性质，当少数结点失效的时候不影响集群的正常工作，当大多数集群中的结点失效的时候，集群则会停止服务（不会返回一个错误的结果）。</li>
<li>一致性协议就是用来保证即使在部分(确切地说是小部分)副本宕机的情况下，系统仍然能正常对外提供服务。一致性协议通常基于replicated state machines，即所有结点都从同一个state出发，都经过同样的一些操作序列（log），最后到达同样的state。</li>
</ul>
<h3 id="分布式架构"><a href="#分布式架构" class="headerlink" title="分布式架构"></a>分布式架构</h3><ul>
<li>[分布式架构的套路](&lt;<a href="https://mp.weixin.qq.com/s/vJJWpIZ-bTzVl9E3wPLlEw">https://mp.weixin.qq.com/s/vJJWpIZ-bTzVl9E3wPLlEw</a>)<ul>
<li>1、纯负载均衡形式。<br>硬件层面的 F5、软件层面的 nginx</li>
<li>2、领导选举型<br>整个集群的消息都会转发到集群的领导这里，是一种 master-slavers，区别只是这个 master 是被临时选举出来的，一旦 master 宕机，集群会立刻选举出一个新的领导，继续对外提供服务。<br>ElasticSearch，zookeeper、Raft</li>
<li>3、区块链型<br>整个集群的每一个节点都可以进行记录，但是记录的内容要得到整个集群 N 个机器的认可才是合法的。典型的应用有 Bit Coin，以及 Hyperledger。</li>
<li>4、master-slaver型<br>整个集群以某台 master 为中枢，进行集群的调度。交互是这样，一般会把所有的管理类型的数据放到 master 上，而把具体的数据放到 slaver 上，实际进行调用的时候，client 先调用 master 获取数据所存放的 server 的 信息，再自行跟 slave 进行交互。典型的系统有 Hadoop。集群，HBase 集群，Redis 集群等。</li>
<li>5、规则型一致性Hash<br>这种架构类型一般出现在数据库分库分表的设计中。按照规则进行分库分表，在查询之前使用规则引擎进行库和表的确认，再对具体的应用进行访问。为什么要用一致性 Hash ？其实用什么都可以，只是对于这类应用来说一致性 Hash 比较常见而已。</li>
</ul>
</li>
</ul>
<h3 id="副本一致性"><a href="#副本一致性" class="headerlink" title="副本一致性"></a>副本一致性</h3><ol>
<li>强一致性(strong consistency)</li>
<li>单调一致性(monotonic consistency):任何时刻,任何用户一旦读到某个数据在某次更新后的值, 这个用户不会再读到比这个值更旧的值。</li>
<li>会话一致性(session consistency)：在同一个会话内，系统保证读己所写的一致性。</li>
<li>最终一致性(eventual consistency):如果没有更新，最终系统会返回最后更新的值。换句话说，如果系统在持续更新，则永远无法达到一致性。</li>
<li>弱一致性(week consistency)：系统并不保证后续读操作获得更新值的时间点;弱一致性系统 一般很难在实际中使用,使用弱一致性系统需要应用方做更多的工作从而使得系统可用。</li>
<li>因果一致性：和写进程具有因果关系的进程将会读取到更新的数据，写进程保证取代上次更更新。</li>
<li>读己所写一致性：进程永远读取自己上次更新写入的最新值，而不可能读取到任何历史数据。这是传统操作系统默认的一致性行为。</li>
</ol>
<h3 id="分布式系统中的一致性模型"><a href="#分布式系统中的一致性模型" class="headerlink" title="分布式系统中的一致性模型"></a>分布式系统中的一致性模型</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/_yJqXUIQ7ka8f46j3VCbuQ">分布式系统中的一致性模型</a></li>
<li>一致性模型是所有被允许的操作记录的集合。当我们运行一个程序，经过一系列集合中允许的操作，特定的执行结果总是一致的。如果程序意外地执行了非集合中的操作，我们就称执行记录是非一致的。如果任意可能的执行操作都在这个被允许的操作集合内，那么系统就满足一致性模型。</li>
<li>现实往往没有那么理想化：在几乎每个实际的系统中，进程之间都有一定的距离。一个没有被缓存的值（指没有被CPU的local cache缓存），通常在距离CPU30厘米的DIMM内存条上。光需要整整一个纳秒来传播这么长的距离，实际的内存访问会比光速慢得多。位于不同数据中心某台计算机上的值可以相距几千公里——意味着需要几百毫秒的传播时间。我们没有更快传播数据的方法，否则就违反了物理定律。（物理定律都违反了，就更别谈什么现代计算机体系了。）</li>
<li>这意味着我们的操作不再是瞬时的。某些操作也许快到可以被近乎认为是瞬时的，但是通常来说，操作是耗时的。我们调用对一个变量的写操作；写操作传播到内存，或其他计算机，或月球；内存改变状态；一个确认信息回传；这样我们才知道这个操作真实的发生了。</li>
<li>在分布式系统中，操作的耗时被放大了，我们必须使一致性模型更宽松：允许这些有歧义的顺序发生。</li>
<li>我们该如何确定宽松的程度？我们必须允许所有可能的顺序吗？或许我们还是应该强加一些合理性约束？</li>
</ul>
<ol>
<li>线性一致性（Linearizability）<ul>
<li>线性一致性模型提供了这样的保证：1.对于观察者来说，所有的读和写都在一个单调递增的时间线上串行地向前推进。2.所有的读总能返回最近的写操作的值。</li>
</ul>
</li>
<li>顺序一致性（Sequential consistency）<ul>
<li>如果我们允许进程在时间维度发生偏移，从而它们的操作可能会在调用之前或是完成之后生效，但仍然保证一个约束——任意进程中的操作必须按照进程中定义的顺序（即编程的定义的逻辑顺序）发生。这样我们就得到了一个稍弱的一致性模型：顺序一致性。</li>
<li>顺序一致性放松了对一致性的要求：1. 不要求操作按照真实的时间序发生。2. 不同进程间的操作执行先后顺序也没有强制要求，但必须是原子的。3. 单个进程内的操作顺序必须和编码时的顺序一致。</li>
<li>如果我在Twitter上写了一条推文，或是在Facebook发布了一篇帖子，都会耗费一定的时间渗透进一层层的缓存系统。不同的用户将在不同的时间看到我的信息，但每个用户都以同一个顺序看到我的操作。一旦看到，这篇帖子便不会消失。如果我写了多条评论，其他人也会按顺序的看见，而非乱序。</li>
</ul>
</li>
<li>因果一致性（Casual consistency）<ul>
<li>我们不必对一个进程中的每个操作都施加顺序约束。只有因果相关的操作必须按顺序发生。同样拿帖子举例子：一篇帖子下的所有评论必须以同样的顺序展示给所有人，并且只有帖子可见后，帖子下的回复才可见（也就是说帖子和帖子下的评论有因果关系）。如果我们将这些因果关系编码成类似“我依赖于操作X”的形式，作为每个操作明确的一部分，数据库就可以将这些操作延迟直到它们的依赖都就绪后才可见。</li>
<li>因果一致性比同一进程下对每个操作严格排序的一致性（即顺序一致性）来的更宽松——属于同一进程但不同因果关系链的操作能以相对的顺序执行（也就是说按因果关系隔离，无因果关系的操作可以并发执行），这能防止许多不直观的行为发生。</li>
</ul>
</li>
<li>串行一致性（Serializable consistency）<ul>
<li>如果我们说操作记录的发生等效于某些单一的原子序，但和调用时间与完成时间无关，那么我们就得到了名为串行一致性的一致性模型。这一模型比你想象的更强大同时也更脆弱。</li>
<li>因为串行一致性允许对操作顺序执行任意的重排（只要操作顺序是原子序的）， 它在实际的场景中并不是十分有用。大多数宣称提供了串行一致性的数据库实际上提供的是强串行一致性，它有着和线性一致性一样的时间边界。让事情更复杂的是，大多数SQL数据库宣称的串行一致性等级比实际的更弱，比如可重复读，游标稳定性，或是快照隔离性。</li>
<li>关于线性一致性和串行一致性，看似十分相似，其实不然。串行一致性是数据库领域的概念，是针对事务而言的，描述对一组事务的执行效果等同于某种串行的执行，没有ordering的概念，而线性一致性来自并行计算领域，描述了针对某种数据结构的操作所表现出的顺序特征。串行一致性是对多操作，多对象的保证，对总体的操作顺序无要求；线性一致性是对单操作，单对象的保证，所有操作遵循真实时间序</li>
</ul>
</li>
<li>FIFO 一致性（FIFO consistency, 又称 PRAM consistency, pipelined RAM consistency）。<ul>
<li>FIFO 一致性不会考虑多个进程之间的操作排序。对任意一个进程的写操作 1 与写操作 2，若写操作 1 先于写操作 2 完成，那么任何进程不可以先读到写操作 2 的值，再读到写操作 1 的值。</li>
</ul>
</li>
</ol>
<ul>
<li>强一致（strict consistency），通常是指线性一致性或顺序一致性。线性一致性与顺序一致性之间的区别，也可以被理解为系统模型的区别，即系统中是否存在绝对时间。弱于顺序一致性的一致性级别都可被称为弱一致，而最终一致性是弱一致性的一种形式。</li>
</ul>
<h3 id="衡量分布式系统的指标"><a href="#衡量分布式系统的指标" class="headerlink" title="衡量分布式系统的指标"></a>衡量分布式系统的指标</h3><ul>
<li>性能</li>
<li>可用性</li>
<li>可扩展性</li>
<li>一致性</li>
</ul>
<h3 id="基本副本协议"><a href="#基本副本协议" class="headerlink" title="基本副本协议"></a>基本副本协议</h3><ul>
<li>副本控制协议分为两大类:“中心化(centralized)副本控制协议”和“去中心化(decentralized) 副本控制协议”。</li>
</ul>
<ol>
<li>中心化副本控制协议<ul>
<li>primary-secondary 协议</li>
</ul>
</li>
<li>去中心化副本控制协议(去中心化协议没有因为中心化节点异常而带来的停服务等问题。)</li>
</ol>
<h3 id="NWR-机制"><a href="#NWR-机制" class="headerlink" title="NWR 机制"></a>NWR 机制</h3><ul>
<li>首先看看这三个字母在分布式系统中的含义：<ul>
<li>N：有多少份数据副本；</li>
<li>W：一次成功的写操作至少有w份数据写入成功；</li>
<li>R：一次成功的读操作至少有R份数据读取成功。</li>
</ul>
</li>
<li>NWR值的不同组合会产生不同的一致性效果，当W+R&gt;N的时候，读取操作和写入操作成功的数据一定会有交集，这样就可以保证一定能够读取到最新版本的更新数据，数据的强一致性得到了保证，如果R+W&lt;&#x3D;N，则无法保证数据的强一致性，因为成功写和成功读集合可能不存在交集，这样读操作无法读取到最新的更新数值，也就无法保证数据的强一致性。</li>
<li>版本的新旧需要版本控制算法来判别，比如向量时钟。</li>
<li>当然R或者W不能太大，因为越大需要操作的副本越多，耗时越长。</li>
</ul>
<h3 id="Quorum-机制"><a href="#Quorum-机制" class="headerlink" title="Quorum 机制"></a>Quorum 机制</h3><ul>
<li>Quorum机制其实就是NWR机制。</li>
</ul>
<ol>
<li>Write-all-read-one(简称 WARO).<ul>
<li>WARO 读服务的可用性较高,但更新服务的可用性不高,甚至虽然使用了 副本,但更新服务的可用性等效于没有副本。WARO 牺牲了更新服务的可用性,最大程度的增强读服务的可用性。</li>
</ul>
</li>
<li>Quorum 机制</li>
</ol>
<ul>
<li>将 WARO 的条件进行松弛,从而使得可以在读写服务可用性之间做折中,得出 Quorum 机制。</li>
<li>在 Quorum 机制下,当某次更新操作 wi 一旦在所有 N 个副本中的 W 个副本上都成功,则就称 该更新操作为“成功提交的更新操作”,称对应的数据为“成功提交的数据”。</li>
<li>仅仅依赖 quorum 机制是无法保证强一致性的。因为仅有 quorum 机制时无法确 定最新已成功提交的版本号,除非将最新已提交的版本号作为元数据由特定的元数据服务器或元数 据集群管理,否则很难确定最新成功提交的版本号。</li>
<li>Quorum 机制的三个系统参数 N、W、R 控制了系统的可用性,也是系统对用户的服务承诺:数 据最多有 N 个副本,但数据更新成功 W 个副本即返回用户成功。对于一致性要求较高的 Quorum 系 统,系统还应该承诺任何时候不读取未成功提交的数据,即读取到的数据都是曾经在 W 个副本上成 功的数据。</li>
</ul>
<hr>
<ul>
<li><p><a href="https://www.cnblogs.com/hapjin/p/5626889.html">分布式系统理论之Quorum机制</a></p>
</li>
<li><p>在分布式系统中有个CAP理论，对于P（分区容忍性）而言，是实际存在 从而无法避免的。因为，分布系统中的处理不是在本机，而是网络中的许多机器相互通信，故网络分区、网络通信故障问题无法避免。<br>因此，只能尽量地在C 和 A 之间寻求平衡。对于数据存储而言，为了提高可用性（Availability），采用了副本备份，比如对于HDFS，默认每块数据存三份。某数据块所在的机器宕机了，就去该数据块副本所在的机器上读取（从这可以看出，数据分布方式是按“数据块”为单位分布的）</p>
</li>
<li><p>但是，问题来了，当需要修改数据时，就需要更新所有的副本数据，这样才能保证数据的一致性（Consistency）。因此，就需要在 C(Consistency) 和 A(Availability) 之间权衡。</p>
</li>
<li><p>Quorum机制，就是这样的一种权衡机制，一种将“读写转化”的模型。在介绍Quorum之前，先看一个极端的情况：WARO机制。<br>WARO(Write All Read one)是一种简单的副本控制协议，当Client请求向某副本写数据时(更新数据)，只有当所有的副本都更新成功之后，这次写操作才算成功，否则视为失败。</p>
<ul>
<li>①写操作很脆弱，因为只要有一个副本更新失败，此次写操作就视为失败了。②读操作很简单，因为，所有的副本更新成功，才视为更新成功，从而保证所有的副本一致。<br>  这样，只需要读任何一个副本上的数据即可。假设有N个副本，N-1个都宕机了，剩下的那个副本仍能提供读服务；但是只要有一个副本宕机了，写服务就不会成功。</li>
<li>WARO牺牲了更新服务的可用性，最大程度地增强了读服务的可用性。而Quorum就是更新服务和读服务之间进行一个折衷。</li>
<li>Quorum机制是“抽屉原理”的一个应用。定义如下：假设有N个副本，更新操作wi 在W个副本中更新成功之后，才认为此次更新操作wi 成功。称成功提交的更新操作对应的数据为：“成功提交的数据”。对于读操作而言，至少需要读R个副本才能读到此次更新的数据。其中，W+R&gt;N ，即W和R有重叠。一般，W+R&#x3D;N+1</li>
<li>5(3+3,5+1);7(4+4,5+3,7+1);9(5+5,7+3,9+1)</li>
</ul>
</li>
<li><p>1）如何读取最新的数据？—在已经知道最近成功提交的数据版本号的前提下，最多读R个副本就可以读到最新的数据了。<br>2）如何确定 最高版本号 的数据是一个成功提交的数据？—继续读其他的副本，直到读到的 最高版本号副本 出现了W次。</p>
</li>
<li><p>一般一个Quorum的节点数目不大于9个，故无法简单地将一致性系统节点直接部署在多个地域，系统需要能持续地水平拓展，来满足服务、资源的拓展需求</p>
</li>
</ul>
<h3 id="CAP-理论"><a href="#CAP-理论" class="headerlink" title="CAP 理论"></a>CAP 理论</h3><ul>
<li>Consistency (一致性):CAP 理论中的副本一致性特指强一致性(1.3.4 );</li>
<li>Availiablity(可用性):指系统在出现异常时已经可以提供服务;</li>
<li>Tolerance to the partition of network (分区容忍):指系统可以对网络分区(1.1.4.2 )这种异常情 况进行容错处理;</li>
<li>协议分析<br>1. Lease 机制牺牲了部分异常情况下的 A,从而获得了完全的 C 与很好的 P。<br>2. Quorum 机制,在 CAP 三大因素中都各做了折中,有一定的 C,有较好 的 A,也有较好的 P,是一种较为平衡的分布式协议。<br>3. 两阶段提交系统具有完全的 C,很糟糕的 A,很糟糕的 P。<br>4. Paxos 协议 ,在 CAP 三方面较之两阶段提交协议要优秀得多。Paxos 协议具有 完全的 C,较好的 A,较好的 P。Paxos 的 A 与 P 的属性与 Quorum 机制类似,因为 Paxos 的协议本 身就具有 Quorum 机制的因素。</li>
<li>CAP中的三个因素并不对等，P是基础，CA之间需要tradeoff。系统设计不是三选二的取舍。</li>
<li>延迟作为可用性的指标和体现，系统设计通常需要在C和延迟之间tradeoff。</li>
<li>总结：P是一个自然的事实，CA是强需求。三者并不对等。</li>
<li>在数据库领域，CAP也正是ACID和BASE长期博弈(tradeoff)的结果。</li>
<li>ACID伴随数据库的诞生定义了系统基本设计思路，所谓先入为主。2000年左右，随着互联网的发展，高可用的话题被摆上桌面，所以提出了BASE。从此C和A的取舍消长此起彼伏，其结晶就是CAP理论。</li>
<li>从ACID和BASE来说，ACID是为了保证一致性而诞生，因而侧重一致性；BASE是为了高可用系统的设计而诞生，因而侧重可用性。在分解C和A的情况时，肯定要涉及P，所以CAP理论统一了这一切。如果非要说酸碱，或者说酸碱平衡，那就是平衡于CAP理论。</li>
<li>CAP并不与ACID中的A（原子性）冲突，值得讨论的是ACID中的C（一致性）和I（隔离性）。ACID的C指的是事务不能破坏任何数据库规则，如键的唯一性。与之相比，CAP的C仅指单一副本这个意义上的一致性，因此只是ACID一致性约束的一个严格的子集。如果系统要求ACID中的I（隔离性），那么它在分区期间最多可以在分区一侧维持操作。事务的可串行性（serializability）要求全局的通信，因此在分区的情况下不能成立。</li>
<li>CA系统才是真正的难点。宣称是CA系统的，目前有两家：一家是Google的Spanner，一家是Alibaba的OceanBase。</li>
<li>对P的分解需要从网络开始。网络包含了基础设施，光速限制以及软件配置与升级等。Google通过建设自己广域网获得高可靠的基础设施支撑，对于Google Spanner的CA系统，CAP之父曾总结说网络才是根本。</li>
<li>CAP理论：一致性与性能之间的trade-off</li>
</ul>
<h3 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/V1sJcSjff1wbAoQVpLgUMA">请不要再称数据库是CP或者AP</a></li>
<li>一致性（Consistency）在CAP中是可线性化的意思（linearizability）。而这个是非常特殊（而且非常强）的一致性。尤其是虽然ACID中的C也是一致性（Consistency），但是和这里的一致性没有任何关系。</li>
<li>Alice还有Bob，他们在同一个房间，都在看他们的手机查2014年世界杯的决赛结果。就在最终结果刚发布之后，Alice刷新了页面，看到了宣布冠军，而且很兴奋地告诉了Bob。Bob马上也重新加载了他手机上的页面，但是他的请求被送到了一个数据库的拷贝，还没有拿到最新的数据，结果他的手机上显示决赛还正在进行。</li>
<li>如果Alice和Bob同时刷新，拿到了不一样的结果，并不会太让人意外。因为他们不知道具体服务器到底是先处理了他们中哪一个请求。但是Bob知道他刷新页面是在Alice告诉了他最终结果_之后_的。所以他预期他查询的结果一定比Alice的更新。事实是，他却拿到了旧的结果。这就违反了可线性化。</li>
<li>ZooKeeper默认设置既不是一致的（CP）也不是可用的（AP），只是“P”。但是你有选择通过用sync命令来让它成为CP。并且在正确的设置下，读操作（不包括写）其实是CAP可用的。</li>
</ul>
<h3 id="Lease-机制"><a href="#Lease-机制" class="headerlink" title="Lease 机制"></a>Lease 机制</h3><ul>
<li>Lease 是由颁发者授予的在某一有效期内的承诺。颁发者一旦发 出 lease,则无论接受方是否收到,也无论后续接收方处于何种状态,只要 lease 不过期,颁发者一 定严守承诺;另一方面,接收方在 lease 的有效期内可以使用颁发者的承诺,但一旦 lease 过期,接 收方一定不能继续使用颁发者的承诺。</li>
<li>Lease 机制依赖于有效期,这就要求颁发者和接收者的时钟是同步的。对于这种时钟不同步,实践中的通常做法是 将颁发者的有效期设置得比接收者的略大,只需大过时钟误差就可以避免对 lease 的有效性的影响。</li>
</ul>
<hr>
<ul>
<li>master给各个slave分配不同的数据，每个节点的数据都具有有效时间比如1小时，在lease时间内，客户端可以直接向slave请求数据，如果超过时间客户端就去master请求数据。一般而言，slave可以定时主动向master要求续租并更新数据，master在数据发生变化时也可以主动通知slave，不同方式的选择也在于可用性与一致性之间进行权衡。</li>
<li>租约机制也可以解决主备之间网络不通导致的双主脑裂问题，亦即：主备之间本来心跳连线的，但是突然之间网络不通或者暂停又恢复了或者太繁忙无法回复，这时备机开始接管服务，但是主机依然存活能对外服务，这是就发生争夺与分区，但是引入lease的话，老主机颁发给具体server的lease必然较旧，请求就失效了，老主机自动退出对外服务，备机完全接管服务。</li>
</ul>
<h3 id="Split-Brain"><a href="#Split-Brain" class="headerlink" title="Split Brain"></a>Split Brain</h3><ul>
<li>如何避免“Split Brain”(脑裂)问题？<ul>
<li>Split Brain 是指在同一时刻有两个认为自己处于 Active 状态的 NameNode。</li>
</ul>
</li>
<li>Raft是一种一致性算法， gossip是广播协议</li>
<li>为 Raft 引入 leader lease 机制解决集群脑裂时的 stale read 问题：<a href="https://www.jianshu.com/p/072380e12657">https://www.jianshu.com/p/072380e12657</a><ul>
<li>这种方法牺牲了一定的可用性（在脑裂时部分客户端的可用性）换取了一致性的保证。</li>
<li>多数派的网络分区挂了，岂不是直接不可写？</li>
</ul>
</li>
</ul>
<h3 id="拜占庭将军问题"><a href="#拜占庭将军问题" class="headerlink" title="拜占庭将军问题"></a>拜占庭将军问题</h3><ul>
<li>拜占庭将军问题提供了对分布式共识问题的一种情景化描述，是分布式系统领域最复杂的模型。此外, 它也为我们理解和分类现有的众多分布式一致性协议和算法提供了框架。现有的分布式一致性协议和算法主要可分为两类：<br>  1. 一类是故障容错算法(Crash Fault Tolerance, CFT)， 即非拜占庭容错算法，解决的是分布式系统中存在故障，但不存在恶意攻击的场景下的共识问题。也就是说，在该场景下可能存在消息丢失，消息重复，但不存在消息被篡改或伪造的场景。一般用于局域网场景下的分布式系统，如分布式数据库。属于此类的常见算法有Paxos算法、Raft算法、ZAB协议等。<br>  2. 一类是拜占庭容错算法，可以解决分布式系统中既存在故障，又存在恶意攻击场景下的共识问题。一般用于互联网场景下的分布式系统，如在数字货币的区块链技术中。属于此类的常见算法有PBFT算法、PoW算法。</li>
</ul>
<h3 id="CAP软件分类"><a href="#CAP软件分类" class="headerlink" title="CAP软件分类"></a>CAP软件分类</h3><ul>
<li>CP: MongoDB、HBase、Zookeeper; (paxos、raft、zab、2PC协议)</li>
<li>AP: Eureka、Couch DB、Cassandra、Amazon Dynamo</li>
<li>Raft (etcd)、ZAB(Zookeeper)</li>
</ul>
<h3 id="故障处理如何做？有以下模型可以考虑"><a href="#故障处理如何做？有以下模型可以考虑" class="headerlink" title="故障处理如何做？有以下模型可以考虑"></a>故障处理如何做？有以下模型可以考虑</h3><ul>
<li><p>Fail-Fast：从字面含义看就是“快速失败”，尽可能的发现系统中的错误，使系统能够按照事先设定好的错误的流程执行，对应的方式是“fault-tolerant（容错）”。只发起一次调用，失败立即报错,通常用于非幂等性的写操作。 如果有机器正在重启，可能会出现调用失败 。</p>
</li>
<li><p>Fail-Over：含义为“失效转移”，是一种备份操作模式，当主要组件异常时，其功能转移到备份组件。其要点在于有主有备，且主故障时备可启用，并设置为主。如Mysql的双Master模式，当正在使用的Master出现故障时，可以拿备Master做主使用。阿里同学认为这里可以指失败自动切换。当出现失败，重试其它服务器，通常用于读操作（推荐使用）。 重试会带来更长延迟。</p>
</li>
<li><p>Fail-Safe：含义为“失效安全”，即使在故障的情况下也不会造成伤害或者尽量减少伤害。维基百科上一个形象的例子是红绿灯的“冲突监测模块”当监测到错误或者冲突的信号时会将十字路口的红绿灯变为闪烁错误模式，而不是全部显示为绿灯。有时候来指代“自动功能降级” (Auto-Degrade)。阿里的同学认为失败安全，出现异常时，直接忽略，通常用于写入审计日志等操作。调用信息丢失 可用于生产环境Monitor。</p>
</li>
<li><p>Fail-Back：Fail-over之后的自动恢复，在簇网络系统（有两台或多台服务器互联的网络）中，由于要某台服务器进行维修，需要网络资源和服务暂时重定向到备用系统。在此之后将网络资源和服务器恢复为由原始主机提供的过程，称为自动恢复。阿里的同学认为失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作 不可靠，重启丢失。可用于生产环境 Registry。</p>
</li>
<li><p>Forking  并行调用多个服务器，只要一个成功即返回，通常用于实时性要求较高的读操作。 需要浪费更多服务资源 。</p>
</li>
<li><p>Broadcast广播调用，所有提供逐个调用，任意一台报错则报错。通常用于更新提供方本地状态速度慢，任意一台报错则报错。</p>
</li>
<li><p>上述故障模型是从系统设计的角度出发的，根据不同的需要设计不同故障处理方案。现在看来，系统的外延已经扩大。系统的容错性，或者分区容错能力，不能仅仅使用事先和事中的方案解决，系统的容错性还包括事后处理。</p>
</li>
<li><p>分布式系统(Distributed System)资料:<a href="https://github.com/ty4z2008/Qix/blob/master/ds.md">https://github.com/ty4z2008/Qix/blob/master/ds.md</a></p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.cnblogs.com/foreach-break/p/notes_about_distributed_system_and_The_log.html">学习笔记：The Log（我所读过的最好的一篇分布式技术文章）</a></li>
<li>《分布式系统原理介绍刘杰》</li>
<li><a href="https://www.cnblogs.com/hapjin/p/5626889.html">分布式系统理论之Quorum机制</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&mid=2650738983&idx=4&sn=6d59ee01f70f2bff3df373dd9381e31f&chksm=bea760f489d0e9e">一文读懂拜占庭将军问题</a></li>
<li><a href="https://mp.weixin.qq.com/s/UfbMFXxJqRhLDXUntKVE8A">详解分布式一致性机制</a></li>
<li><a href="https://mp.weixin.qq.com/s/90RAmLZcTshlm-MBjTlP0A">CAP理论与分布式系统设计</a></li>
<li><a href="https://mp.weixin.qq.com/s/IbBC38rhhQ-mEfw3yf9AVA">深度介绍分布式系统原理与设计</a>!!</li>
<li><a href="https://mp.weixin.qq.com/s/05-ko4KyeHOTkrAbl8dQwQ">跨地域场景下，如何解决分布式系统的一致性？</a></li>
<li><a href="https://mp.weixin.qq.com/s/KbNNU246BAeJmLoWbKie6g">左耳朵耗子：分布式系统架构经典资料</a></li>
<li><a href="https://mp.weixin.qq.com/s/L7Zjbbub2D6pWto0TZ2qug">如何系统性的学习分布式系统？</a></li>
</ul>
]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>NIO总结笔记</title>
    <url>/2022/01/17/20220117-nio-zong-jie-bi-ji/</url>
    <content><![CDATA[<h2 id="Java-I-x2F-O"><a href="#Java-I-x2F-O" class="headerlink" title="Java I&#x2F;O"></a>Java I&#x2F;O</h2><table>
<thead>
<tr>
<th>I&#x2F;O</th>
<th>NIO</th>
</tr>
</thead>
<tbody><tr>
<td>面向流</td>
<td>面向缓冲</td>
</tr>
<tr>
<td>阻塞IO</td>
<td>非阻塞IO</td>
</tr>
<tr>
<td>无</td>
<td>选择器</td>
</tr>
</tbody></table>
<ul>
<li>I&#x2F;O 与 NIO 一个比较重要的区别是我们使用 I&#x2F;O 的时候往往会引入多线程，每个连接使用一个单独的线程，而 NIO 则是使用单线程或者只使用少量的多线程，每个连接共用一个线程。而由于 NIO 的非阻塞需要一直轮询，比较消耗系统资源，所以异步非阻塞模式 AIO 就诞生了。</li>
</ul>
<h3 id="5-种-I-x2F-O模型"><a href="#5-种-I-x2F-O模型" class="headerlink" title="5 种 I&#x2F;O模型"></a>5 种 I&#x2F;O模型</h3><ol>
<li>blocking I&#x2F;O</li>
<li>nonblocking I&#x2F;O</li>
<li>I&#x2F;O multiplexing (select and poll)</li>
<li>signal driven I&#x2F;O (SIGIO)</li>
<li>asynchronous I&#x2F;O (the POSIX aio_functions)。</li>
</ol>
<ul>
<li>不同的操作系统对上述模型支持不同，UNIX 支持 IO 多路复用。不同系统叫法不同，freebsd 里面叫 kqueue，Linux 叫 epoll。而 Windows2000 的时候就诞生了 IOCP 用以支持 asynchronous I&#x2F;O。</li>
<li>Java 是一种跨平台语言，为了支持异步 I&#x2F;O，诞生了 NIO，Java1.4 引入的 NIO1.0 是基于 I&#x2F;O 复用的，它在各个平台上会选择不同的复用方式。Linux 用的 epoll，BSD 上用 kqueue，Windows 上是重叠 I&#x2F;O。</li>
<li>IO多路复用，Java NIO的核心类库多路复用器Selector就是基于epoll的多路复用技术实现。</li>
<li>IO复用的系统调用方式：select，pselect，poll，epoll（IO复用属于同步IO）</li>
<li>同步阻塞BIO，同步非阻塞NIO，异步非阻塞AIO<br> 同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞！<br>阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回！</li>
</ul>
<h3 id="Java-I-x2F-O-的相关方法"><a href="#Java-I-x2F-O-的相关方法" class="headerlink" title="Java I&#x2F;O 的相关方法"></a>Java I&#x2F;O 的相关方法</h3><ol>
<li>同步并阻塞 (I&#x2F;O 方法)：服务器实现模式为一个连接启动一个线程，每个线程亲自处理 I&#x2F;O 并且一直等待 I&#x2F;O 直到完成，即客户端有连接请求时服务器端就需要启动一个线程进行处理。但是如果这个连接不做任何事情就会造成不必要的线程开销，当然可以通过线程池机制改善这个缺点。I&#x2F;O 的局限是它是面向流的、阻塞式的、串行的一个过程。对每一个客户端的 Socket 连接 I&#x2F;O 都需要一个线程来处理，而且在此期间，这个线程一直被占用，直到 Socket 关闭。在这期间，TCP 的连接、数据的读取、数据的返回都是被阻塞的。也就是说这期间大量浪费了 CPU 的时间片和线程占用的内存资源。此外，每建立一个 Socket 连接时，同时创建一个新线程对该 Socket 进行单独通信 (采用阻塞的方式通信)。这种方式具有很快的响应速度，并且控制起来也很简单。在连接数较少的时候非常有效，但是如果对每一个连接都产生一个线程无疑是对系统资源的一种浪费，如果连接数较多将会出现资源不足的情况；</li>
<li>同步非阻塞 (NIO 方法)：服务器实现模式为一个请求启动一个线程，每个线程亲自处理 I&#x2F;O，但是另外的线程轮询检查是否 I&#x2F;O 准备完毕，不必等待 I&#x2F;O 完成，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有 I&#x2F;O 请求时才启动一个线程进行处理。NIO 则是面向缓冲区，非阻塞式的，基于选择器的，用一个线程来轮询监控多个数据传输通道，哪个通道准备好了 (即有一组可以处理的数据) 就处理哪个通道。服务器端保存一个 Socket 连接列表，然后对这个列表进行轮询，如果发现某个 Socket 端口上有数据可读时，则调用该 Socket 连接的相应读操作；如果发现某个 Socket 端口上有数据可写时，则调用该 Socket 连接的相应写操作；如果某个端口的 Socket 连接已经中断，则调用相应的析构方法关闭该端口。这样能充分利用服务器资源，效率得到大幅度提高；</li>
<li>异步非阻塞 (AIO 方法，JDK7 发布)：服务器实现模式为一个有效请求启动一个线程，客户端的 I&#x2F;O 请求都是由操作系统先完成了再通知服务器应用去启动线程进行处理，每个线程不必亲自处理 I&#x2F;O，而是委派操作系统来处理，并且也不需要等待 I&#x2F;O 完成，如果完成了操作系统会另行通知的。该模式采用了 Linux 的 epoll 模型。</li>
</ol>
<ul>
<li>在连接数不多的情况下，传统 I&#x2F;O 模式编写较为容易，使用上也较为简单。但是随着连接数的不断增多，传统 I&#x2F;O 处理每个连接都需要消耗一个线程，而程序的效率，当线程数不多时是随着线程数的增加而增加，但是到一定的数量之后，是随着线程数的增加而减少的。所以传统阻塞式 I&#x2F;O 的瓶颈在于不能处理过多的连接。非阻塞式 I&#x2F;O 出现的目的就是为了解决这个瓶颈。非阻塞 IO 处理连接的线程数和连接数没有联系，例如系统处理 10000 个连接，非阻塞 I&#x2F;O 不需要启动 10000 个线程，你可以用 1000 个，也可以用 2000 个线程来处理。因为非阻塞 IO 处理连接是异步的，当某个连接发送请求到服务器，服务器把这个连接请求当作一个请求“事件”，并把这个“事件”分配给相应的函数处理。我们可以把这个处理函数放到线程中去执行，执行完就把线程归还，这样一个线程就可以异步的处理多个事件。而阻塞式 I&#x2F;O 的线程的大部分时间都被浪费在等待请求上了。</li>
</ul>
<h3 id="AIO-相关的类和接口"><a href="#AIO-相关的类和接口" class="headerlink" title="AIO 相关的类和接口"></a>AIO 相关的类和接口</h3><ul>
<li><code>java.nio.channels.AsynchronousChannel</code>：标记一个 Channel 支持异步 IO 操作；</li>
<li><code>java.nio.channels.AsynchronousServerSocketChannel</code>：ServerSocket 的 AIO 版本，创建 TCP 服务端，绑定地址，监听端口等；</li>
<li><code>java.nio.channels.AsynchronousSocketChannel</code>：面向流的异步 Socket Channel，表示一个连接；</li>
<li><code>java.nio.channels.AsynchronousChannelGroup</code>：异步 Channel 的分组管理，目的是为了资源共享。一个 AsynchronousChannelGroup 绑定一个线程池，这个线程池执行两个任务：处理 IO 事件和派发 CompletionHandler。AsynchronousServerSocketChannel 创建的时候可以传入一个 AsynchronousChannelGroup，那么通过 AsynchronousServerSocketChannel 创建的 AsynchronousSocketChannel 将同属于一个组，共享资源；</li>
<li><code>java.nio.channels.CompletionHandler</code>：异步 IO 操作结果的回调接口，用于定义在 IO 操作完成后所作的回调工作。AIO 的 API 允许两种方式来处理异步操作的结果：返回的 Future 模式或者注册 CompletionHandler，推荐用 CompletionHandler 的方式，这些 handler 的调用是由 AsynchronousChannelGroup 的线程池派发的。这里线程池的大小是性能的关键因素。</li>
</ul>
<h3 id="Reactor线程模型"><a href="#Reactor线程模型" class="headerlink" title="Reactor线程模型"></a>Reactor线程模型</h3><p>常用的Reactor线程模型有三种，分别如下：</p>
<ol>
<li>Reactor单线程模型；</li>
<li>Reactor多线程模型；</li>
<li>主从Reactor多线程模型    <ul>
<li>Netty的线程模型并非固定不变，通过在启动辅助类中创建不同的EventLoopGroup实例并通过适当的参数配置，就可以支持上述三种Reactor线程模型。</li>
</ul>
</li>
</ol>
<h3 id="Netty线程模型"><a href="#Netty线程模型" class="headerlink" title="Netty线程模型"></a>Netty线程模型</h3><ul>
<li><a href="http://www.infoq.com/cn/articles/netty-threading-model">http://www.infoq.com/cn/articles/netty-threading-model</a></li>
<li>主从Reactor线程模型</li>
<li>Netty线程开发最佳实践<ul>
<li>2.4.1. 时间可控的简单业务直接在IO线程上处理<br>  如果业务非常简单，执行时间非常短，不需要与外部网元交互、访问数据库和磁盘，不需要等待其它资源，则建议直接在业务ChannelHandler中执行，不需要再启业务的线程或者线程池。避免线程上下文切换，也不存在线程并发问题。</li>
<li>2.4.2. 复杂和时间不可控业务建议投递到后端业务线程池统一处理<br>  对于此类业务，不建议直接在业务ChannelHandler中启动线程或者线程池处理，建议将不同的业务统一封装成Task，统一投递到后端的业务线程池中进行处理。<br>  过多的业务ChannelHandler会带来开发效率和可维护性问题，不要把Netty当作业务容器，对于大多数复杂的业务产品，仍然需要集成或者开发自己的业务容器，做好和Netty的架构分层。</li>
<li>2.4.3. 业务线程避免直接操作ChannelHandler<br>  对于ChannelHandler，IO线程和业务线程都可能会操作，因为业务通常是多线程模型，这样就会存在多线程操作ChannelHandler。为了尽量避免多线程并发问题，建议按照Netty自身的做法，通过将操作封装成独立的Task由NioEventLoop统一执行，而不是业务线程直接操作<br>  <code>ctx.executor().execute(new Runnable()&#123;&#125;)</code><br>  如果你确认并发访问的数据或者并发操作是安全的，则无需多此一举，这个需要根据具体的业务场景进行判断，灵活处理。</li>
</ul>
</li>
</ul>
<h3 id="Netty的“零拷贝”"><a href="#Netty的“零拷贝”" class="headerlink" title="Netty的“零拷贝”"></a>Netty的“零拷贝”</h3><ul>
<li>Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。</li>
<li>Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。</li>
<li>Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。</li>
</ul>
<h3 id="Netty-灵活的TCP参数配置能力"><a href="#Netty-灵活的TCP参数配置能力" class="headerlink" title="Netty - 灵活的TCP参数配置能力"></a>Netty - 灵活的TCP参数配置能力</h3><ul>
<li>SO_RCVBUF和SO_SNDBUF：通常建议值为128K或者256K；</li>
<li>SO_TCPNODELAY：NAGLE算法通过将缓冲区内的小封包自动相连，组成较大的封包，阻止大量小封包的发送阻塞网络，从而提高网络应用效率。但是对于时延敏感的应用场景需要关闭该优化算法；</li>
<li>软中断：如果Linux内核版本支持RPS（2.6.35以上版本），开启RPS后可以实现软中断，提升网络吞吐量。RPS根据数据包的源地址，目的地址以及目的和源端口，计算出一个hash值，然后根据这个hash值来选择软中断运行的cpu，从上层来看，也就是说将每个连接和cpu绑定，并通过这个hash值，来均衡软中断在多个cpu上，提升网络并行处理性能。</li>
</ul>
<h3 id="心跳实现"><a href="#心跳实现" class="headerlink" title="心跳实现"></a>心跳实现</h3><ul>
<li>使用TCP协议层的Keeplive机制，但是该机制默认的心跳时间是2小时，依赖操作系统实现不够灵活</li>
<li>应用层实现自定义心跳机制，比如Netty实现心跳机制<ul>
<li>服务端添加IdleStateHandler心跳检测处理器，并添加自定义处理Handler类实现userEventTriggered()方法作为超时事件的逻辑处理</li>
</ul>
</li>
</ul>
<h3 id="Netty中比较常用的帧解码器"><a href="#Netty中比较常用的帧解码器" class="headerlink" title="Netty中比较常用的帧解码器"></a>Netty中比较常用的帧解码器</h3><ol>
<li>固定长度帧解码器 - FixedLengthFrameDecoder<ul>
<li>适用场景：每个上层数据包的长度，都是固定的，比如 100。在这种场景下，只需要把这个解码器加到 pipeline 中，Netty 会把底层帧，拆分成一个个长度为 100 的数据包 (ByteBuf)，发送到下一个 channelHandler入站处理器。</li>
</ul>
</li>
<li>行分割帧解码器 - LineBasedFrameDecoder<ul>
<li>适用场景：每个上层数据包，使用换行符或者回车换行符做为边界分割符。发送端发送的时候，每个数据包之间以换行符&#x2F;回车换行符作为分隔。在这种场景下，只需要把这个解码器加到 pipeline 中，Netty 会使用换行分隔符，把底层帧分割成一个一个完整的应用层数据包，发送到下一站。前面的例子，已经对这个解码器进行了演示。</li>
</ul>
</li>
<li>自定义分隔符帧解码器 - DelimiterBasedFrameDecoder<ul>
<li>DelimiterBasedFrameDecoder 是LineBasedFrameDecoder的通用版本。不同之处在于，这个解码器，可以自定义分隔符，而不是局限于换行符。如果使用这个解码器，在发送的时候，末尾必须带上对应的分隔符。</li>
</ul>
</li>
<li>自定义长度帧解码器 - LengthFieldBasedFrameDecoder<ul>
<li>这是一种基于灵活长度的解码器。在数据包中，加了一个长度字段（长度域），保存上层包的长度。解码的时候，会按照这个长度，进行上层ByteBuf应用包的提取。</li>
<li>LengthFieldPrepender(编码)：如果协议中的第一个字段为长度字段，netty提供了LengthFieldPrepender编码器，它可以计算当前待发送消息的二进制字节长度，将该长度添加到ByteBuf的缓冲区头中</li>
</ul>
</li>
</ol>
<h3 id="Netty-API"><a href="#Netty-API" class="headerlink" title="Netty API"></a>Netty API</h3><h4 id="JDK-ByteBuffer-VS-Netty-ByteBuf"><a href="#JDK-ByteBuffer-VS-Netty-ByteBuf" class="headerlink" title="JDK ByteBuffer VS Netty ByteBuf"></a>JDK ByteBuffer VS Netty ByteBuf</h4><ul>
<li><a href="https://blog.csdn.net/u013828625/article/details/79845512">https://blog.csdn.net/u013828625/article/details/79845512</a></li>
<li>Netty中的ByteBuf则完全对JDK中的ByteBuffer的缺点进行了改进</li>
<li>网络数据的基本单位永远是 byte(字节)。Java NIO 提供 ByteBuffer 作为字节的容器，但该类过于复杂，有点难用。ByteBuf是Netty当中的最重要的工具类，它与JDK的ByteBuffer原理基本上相同，也分为堆内与堆外俩种类型，但是ByteBuf做了极大的优化，具有更简单的API，更多的工具方法和优秀的内存池设计。</li>
<li>ByteBuf 维护俩不同索引：一个用于读取，一个用于写入：从 ByteBuf 读取时，其 readerIndex 将会被递增已经被读取的字节数；当写入 ByteBuf 时，writerIndex 也会被递增</li>
</ul>
<h4 id="SimpleChannelInboundHandler"><a href="#SimpleChannelInboundHandler" class="headerlink" title="SimpleChannelInboundHandler"></a>SimpleChannelInboundHandler</h4><ul>
<li><a href="https://www.cnblogs.com/ffaiss/p/9843442.html">SimpleChannelInboundHandler与ChannelInboundHandlerAdapter</a></li>
<li><a href="https://developer.aliyun.com/article/97235">Netty随记之ChannelInboundHandlerAdapter、SimpleChannelInboundHandler</a></li>
<li><a href="https://www.cnblogs.com/lemon-flm/p/7813914.html">Netty——高级发送和接收数据handler处理器</a></li>
<li>每一个Handler都一定会处理出站或者入站（也可能两者都处理）数据，例如对于入站的Handler可能会继承SimpleChannelInboundHandler或者ChannelInboundHandlerAdapter，而SimpleChannelInboundHandler又是继承于ChannelInboundHandlerAdapter，最大的区别在于SimpleChannelInboundHandler会对没有外界引用的资源进行一定的清理，并且入站的消息可以通过泛型来规定。</li>
<li>对于两者关系：<br><code>public abstract class SimpleChannelInboundHandler&lt;I&gt; extends ChannelInboundHandlerAdapter</code></li>
<li><code>public void channelRead(ChannelHandlerContext ctx, Object msg) </code> , msg 是ByteBuf类型（未decode转化类型的情况），使用 SimpleChannelInboundHandler 会被自动释放</li>
</ul>
<ol>
<li>ChannelInboundHandlerAdapter<ul>
<li>ChannelInboundHandlerAdapter是ChannelInboundHandler的一个简单实现，默认情况下不会做任何处理，只是简单的将操作通过fire*方法传递到ChannelPipeline中的下一个ChannelHandler中让链中的下一个ChannelHandler去处理。</li>
<li>需要注意的是信息经过channelRead方法处理之后不会自动释放（因为信息不会被自动释放所以能将消息传递给下一个ChannelHandler处理）。</li>
</ul>
</li>
<li>SimpleChannelInboundHandler<ul>
<li>SimpleChannelInboundHandler支持泛型的消息处理，默认情况下消息处理完将会被自动释放，无法提供fire*方法传递给ChannelPipeline中的下一个ChannelHandler,如果想要传递给下一个ChannelHandler需要调用ReferenceCountUtil#retain方法。</li>
<li>channelRead0方法在将来将会重命名为messageReceived</li>
</ul>
</li>
</ol>
<h4 id="channelRead-和channelReadComplete"><a href="#channelRead-和channelReadComplete" class="headerlink" title="channelRead()和channelReadComplete()"></a>channelRead()和channelReadComplete()</h4><ul>
<li><a href="https://segmentfault.com/q/1010000018753423">channelRead()和channelReadComplete() 方法的区别是什么？</a></li>
<li>channelRead表示接收消息，可以看到msg转换成了ByteBuf，然后打印，也就是把Client传过来的消息打印了一下，你会发现每次打印完后，channelReadComplete也会调用，如果你试着传一个超长的字符串过来，超过1024个字母长度，你会发现channelRead会调用多次，而channelReadComplete只调用一次。</li>
</ul>
<h4 id="ctx-write-vd-ctx-channel-write"><a href="#ctx-write-vd-ctx-channel-write" class="headerlink" title="ctx.write() vd ctx.channel().write()"></a>ctx.write() vd ctx.channel().write()</h4><ul>
<li>Any difference between ctx.write() and ctx.channel().write() in netty?:<a href="https://stackoverflow.com/questions/20366418/any-difference-between-ctx-write-and-ctx-channel-write-in-netty">https://stackoverflow.com/questions/20366418/any-difference-between-ctx-write-and-ctx-channel-write-in-netty</a></li>
<li>Yes there is… Channel.write(..) always start from the tail of the ChannelPipeline and so pass through all the ChannelOutboundHandlers. ChannelHandlerContext.write(…) starts from the current position of the ChannelHandler which is bound to the ChannelHandlerContext and so only pass those ChannelOutboundHandlers that are in front of it.</li>
</ul>
<h4 id="自定义消息协议"><a href="#自定义消息协议" class="headerlink" title="自定义消息协议"></a>自定义消息协议</h4><ul>
<li><p>len : 表示消息的长度,通常用4个字节保存</p>
</li>
<li><p>head : 消息头部</p>
</li>
<li><p>body : 消息内容</p>
</li>
<li><p>在实际的项目中,消息格式可能会增加一些标志,例如,开始标记,结束标志,消息序列号,消息的协议类型(json或者二进制等)</p>
</li>
</ul>
<h3 id="Netty-没用JDK1-7的AIO"><a href="#Netty-没用JDK1-7的AIO" class="headerlink" title="Netty 没用JDK1.7的AIO"></a>Netty 没用JDK1.7的AIO</h3><ul>
<li>为什么Netty不用AIO而用NIO?</li>
</ul>
<pre>
According to the book the main reasons were:
1. Not faster than NIO (epoll) on unix systems (which is true)
There is no daragram suppport
2. Unnecessary threading model (too much abstraction without usage)
3. I agree that AIO will not easily replace NIO, but it is useful for windows developers nonetheless.
<https: 2515 github.com netty issues>
We obviously did not consider Windows as a serious platform so far, and that's why we were neglecting NIO.2 AIO API which was implemented using IOCP on Windows. (On Linux, it wasn't any faster because it was using the same OS facility - epoll.)
</https:></pre>

<h3 id="Netty-Epoll"><a href="#Netty-Epoll" class="headerlink" title="Netty-Epoll"></a>Netty-Epoll</h3><ul>
<li>Selector 实现原理:<a href="http://www.jianshu.com/p/2b71ea919d49">http://www.jianshu.com/p/2b71ea919d49</a></li>
</ul>
<ul>
<li>epoll的两种工作模式：<ul>
<li>LT：level-trigger，水平触发模式，只要某个socket处于readable&#x2F;writable状态，无论什么时候进行epoll_wait都会返回该socket。<br>  当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。</li>
<li>ET：edge-trigger，边缘触发模式，只有某个socket从unreadable变为readable或从unwritable变为writable时，epoll_wait才会返回该socket。<br>  当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。<br>  ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读&#x2F;阻塞写操作把处理多个文件描述符的任务饿死。</li>
</ul>
</li>
<li>在Linux系统中JDK NIO使用的是 LT ，而Netty epoll使用的是 ET。</li>
</ul>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li>JDK中有自带的ByteBuffer类，但是netty中的 ByteBuf 算是对Byte Buffer的重新实现。他们没有关联关系。</li>
<li>netty推荐使用<code>io.netty.buffer.Unpooled</code>来进行Buff的创建工作。Unpooled是一个工具类，可以为ByteBuf分配空间、拷贝或者封装操作</li>
<li>DirectBuffer：使用 DirectBuffer 是一种更加接近系统底层的方法，所以，它的速度比普通的 ByteBuffer 更快。DirectBuffer 相对于 ByteBuffer 而言，读写访问速度快很多，但是创建和销毁 DirectBuffer 的花费却比 ByteBuffer 高。</li>
<li>Netty的并发处理能力主要体现在两个方面：<ol>
<li>利用Java语言自身的多线程机制实现消息的并行处理；</li>
<li>利用Java NIO类库的Selector实现多路复用，一个NIO线程可以同时并发处理成百上千个通信链路，实现海量客户端的并发接入和处理。</li>
</ol>
</li>
<li>netty.pipeline执行顺序：在给定的示例配置中，当事件进入到入站时，处理程序计算顺序为(代码行：从上到下)。当一个事件出站时，顺序是(代码行：从下到上)。</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a href="http://www.infoq.com/cn/articles/netty-high-performance">Netty系列之Netty高性能之道</a>  </li>
<li><a href="http://blog.csdn.net/linsongbin1/article/details/77915686">Netty实战-自定义解码器处理半包消息</a></li>
<li>TODO nio-demo&#x2F;docs</li>
<li>TODO nio_demo&#x2F;netty-definitive-guide&#x2F;netty-definitive-guide-notes.md</li>
</ul>
]]></content>
      <tags>
        <tag>NIO</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title>Java代码段查阅</title>
    <url>/2022/04/01/20220401-java-dai-ma-duan-cha-yue/</url>
    <content><![CDATA[<h2 id="集合处理"><a href="#集合处理" class="headerlink" title="集合处理"></a>集合处理</h2><h3 id="List集合拼接成以逗号分隔的字符串"><a href="#List集合拼接成以逗号分隔的字符串" class="headerlink" title="List集合拼接成以逗号分隔的字符串"></a>List集合拼接成以逗号分隔的字符串</h3><ol>
<li><code>list.stream().collect(Collectors.joining(&quot;,&quot;));</code></li>
<li><code>String.join(&quot;,&quot;, list)</code></li>
</ol>
<h3 id="两个List集合取交集"><a href="#两个List集合取交集" class="headerlink" title="两个List集合取交集"></a>两个List集合取交集</h3><ul>
<li><code>list1.retainAll(list2)</code></li>
</ul>
<h3 id="交集、并集、差集"><a href="#交集、并集、差集" class="headerlink" title="交集、并集、差集"></a>交集、并集、差集</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*交集*/</span></span><br><span class="line">List&lt;AClass&gt; intersectResult = aClassList1.stream().filter(aClassList2::contains).collect(Collectors.toList());</span><br><span class="line"><span class="comment">/*并集*/</span></span><br><span class="line">Stream.of(list1, list2).flatMap(Collection::stream).collect(Collectors.toList());</span><br><span class="line"><span class="comment">/*差集*/</span></span><br><span class="line">List&lt;AClass&gt; differenceResult = aClassList1.stream().filter(x -&gt; !aClassList2.contains(x)).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>

<h3 id="使用parallelStream时要注意线程安全问题"><a href="#使用parallelStream时要注意线程安全问题" class="headerlink" title="使用parallelStream时要注意线程安全问题"></a>使用parallelStream时要注意线程安全问题</h3><ul>
<li>在并发时使用HashMap和ArrayList等非线程安全的类是会存在问题的</li>
<li>应使用<ol>
<li>list合并：  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Stream.of().parallel()</span><br><span class="line">           .mapToObj(index -&gt; &#123;</span><br><span class="line">               <span class="keyword">return</span> Collections.&lt;T&gt;emptyList();</span><br><span class="line">           &#125;).flatMap(Collection::stream).collect(Collectors.toList());</span><br></pre></td></tr></table></figure></li>
<li>map合并：  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Stream.of().parallel()</span><br><span class="line">           .mapToObj(index -&gt; &#123;</span><br><span class="line">               <span class="keyword">return</span> Collections.&lt;K, V&gt;emptyMap();</span><br><span class="line">           &#125;)</span><br><span class="line">					.flatMap(x -&gt; x.entrySet().stream())</span><br><span class="line">					.collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, (v1, v2) -&gt; v1));</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><ul>
<li><code>list.sort(Comparator.comparing(XXX::getXX, Comparator.reverseOrder()).thenComparing(XXX::getXXX))</code></li>
<li><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">list.sort(</span><br><span class="line">            Comparator.comparing((Function&lt;XXXBO, Integer&gt;)xxxBO -&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> (ids.contains(xxxBO.getId())) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">            &#125;).thenComparing(xxxBO -&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> (ptIds.contains(xxxBO.getTId())) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">            &#125;)</span><br><span class="line">                .thenComparing(XXXBO::getAddTime, Comparator.reverseOrder())</span><br><span class="line">                    .thenComparing(XXXBO::getId, Comparator.reverseOrder()));</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><h3 id="首字母转成大写"><a href="#首字母转成大写" class="headerlink" title="首字母转成大写"></a>首字母转成大写</h3><ul>
<li><code>StringUtils.capitalize(str);</code></li>
</ul>
<h3 id="重复拼接字符串"><a href="#重复拼接字符串" class="headerlink" title="重复拼接字符串"></a>重复拼接字符串</h3><ul>
<li><code>StringUtils.repeat(&quot;ab&quot;, 2);</code></li>
</ul>
<h3 id="字符串分割"><a href="#字符串分割" class="headerlink" title="字符串分割"></a>字符串分割</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Iterable&lt;String&gt; split = Splitter.on(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">							 .trimResults()</span><br><span class="line">							 .omitEmptyStrings()</span><br><span class="line">							 .split(sourceStr);</span><br><span class="line">			 <span class="keyword">return</span> Sets.newHashSet(split)</span><br><span class="line"></span><br><span class="line">Sets.newHashSet(Splitter.on(<span class="string">&quot;,&quot;</span>).omitEmptyStrings().trimResults().splitToList(topics));</span><br></pre></td></tr></table></figure>

<h2 id="日期"><a href="#日期" class="headerlink" title="日期"></a>日期</h2><h3 id="Date类型转String类型"><a href="#Date类型转String类型" class="headerlink" title="Date类型转String类型"></a>Date类型转String类型</h3><ul>
<li><code>String date = DateFormatUtils.format(new Date(), &quot;yyyy-MM-dd HH:mm:ss&quot;);</code></li>
</ul>
<h3 id="String类型转Date类型"><a href="#String类型转Date类型" class="headerlink" title="String类型转Date类型"></a>String类型转Date类型</h3><ul>
<li><code>Date date = DateUtils.parseDate(&quot;2021-05-01 01:01:01&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;);</code></li>
</ul>
<h3 id="计算一个小时后的日期"><a href="#计算一个小时后的日期" class="headerlink" title="计算一个小时后的日期"></a>计算一个小时后的日期</h3><ul>
<li><code>Date date = DateUtils.addHours(new Date(), 1);</code></li>
</ul>
<h3 id="java8"><a href="#java8" class="headerlink" title="java8"></a>java8</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">long</span> <span class="variable">tomorrowZeroTime</span> <span class="operator">=</span> LocalDate.now().plusDays(<span class="number">1</span>).atTime(LocalTime.MIN).atZone(ZoneId.systemDefault()).toEpochSecond();</span><br><span class="line"> <span class="type">long</span> <span class="variable">days</span> <span class="operator">=</span> (expireZeroTime - nowZeroTime) / SECONDS_PER_DAY;</span><br><span class="line"> <span class="type">long</span> <span class="variable">beginTime</span> <span class="operator">=</span> LocalDateTime.now().plusHours(-<span class="number">2</span>).atZone(ZoneId.systemDefault()).toInstant().toEpochMilli();</span><br><span class="line"> <span class="type">long</span> <span class="variable">endTime</span> <span class="operator">=</span> LocalDateTime.now().plusHours(-<span class="number">1</span>).atZone(ZoneId.systemDefault()).toInstant().toEpochMilli();</span><br><span class="line"> <span class="type">long</span> <span class="variable">exportStartTime</span> <span class="operator">=</span> LocalDateTime.of(LocalDate.now(), LocalTime.MIN).minusDays(<span class="number">1</span>).atZone(ZoneId.systemDefault()).toEpochSecond();</span><br><span class="line"> <span class="type">long</span> <span class="variable">exportStartTime</span> <span class="operator">=</span>LocalDateTime.now().withHours(<span class="number">0</span>).plusHours(-<span class="number">1</span>).atZone(ZoneId.systemDefault()).toInstant().toEpochMilli();</span><br><span class="line"> <span class="type">Long</span> <span class="variable">millisecond</span> <span class="operator">=</span> Instant.now().toEpochMilli();  <span class="comment">// 精确到毫秒</span></span><br><span class="line"> <span class="type">Long</span> <span class="variable">second</span> <span class="operator">=</span> Instant.now().getEpochSecond();<span class="comment">// 精确到秒</span></span><br><span class="line"> LocalDateTime.ofInstant(Instant.ofEpochMilli(time),ZoneId.systemDefault())</span><br><span class="line">  <span class="type">DateTimeFormatter</span> <span class="variable">formatter</span> <span class="operator">=</span> DateTimeFormatter.ofPattern(<span class="string">&quot;yyyyMMdd&quot;</span>);</span><br><span class="line">             <span class="type">LocalDate</span> <span class="variable">dt</span> <span class="operator">=</span> LocalDate.parse(<span class="string">&quot;20191020&quot;</span>, formatter);</span><br><span class="line">             dt.plusDays(<span class="number">1</span>);</span><br><span class="line">             <span class="type">String</span> <span class="variable">day</span> <span class="operator">=</span> dt.format(formatter);</span><br><span class="line">  <span class="comment">//Java8的DateTimeFormatter是线程安全的，而SimpleDateFormat并不是线程安全。    </span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="开源库"><a href="#开源库" class="headerlink" title="开源库"></a>开源库</h2><h3 id="commons-collections4"><a href="#commons-collections4" class="headerlink" title="commons-collections4"></a>commons-collections4</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 两个集合取交集</span></span><br><span class="line">Collection&lt;String&gt; collection = CollectionUtils.retainAll(listA, listB);</span><br><span class="line"><span class="comment">// 两个集合取并集</span></span><br><span class="line">Collection&lt;String&gt; collection = CollectionUtils.union(listA, listB);</span><br><span class="line"><span class="comment">// 两个集合取差集</span></span><br><span class="line">Collection&lt;String&gt; collection = CollectionUtils.subtract(listA, listB);</span><br></pre></td></tr></table></figure>

<h3 id="common-beanutils-操作对象"><a href="#common-beanutils-操作对象" class="headerlink" title="common-beanutils 操作对象"></a>common-beanutils 操作对象</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">BeanUtils.setProperty(user, <span class="string">&quot;id&quot;</span>, <span class="number">1</span>);</span><br><span class="line">BeanUtils.setProperty(user, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;yideng&quot;</span>);</span><br><span class="line">System.out.println(BeanUtils.getProperty(user, <span class="string">&quot;name&quot;</span>)); <span class="comment">// 输出 yideng</span></span><br><span class="line">System.out.println(user); <span class="comment">// 输出 &#123;&quot;id&quot;:1,&quot;name&quot;:&quot;yideng&quot;&#125;</span></span><br><span class="line">对象和map互转</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对象转map</span></span><br><span class="line">Map&lt;String, String&gt; map = BeanUtils.describe(user);</span><br><span class="line">System.out.println(map); <span class="comment">// 输出 &#123;&quot;id&quot;:&quot;1&quot;,&quot;name&quot;:&quot;yideng&quot;&#125;</span></span><br><span class="line"><span class="comment">// map转对象</span></span><br><span class="line"><span class="type">User</span> <span class="variable">newUser</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">BeanUtils.populate(newUser, map);</span><br><span class="line">System.out.println(newUser); <span class="comment">// 输出 &#123;&quot;id&quot;:1,&quot;name&quot;:&quot;yideng&quot;&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="commons-io-文件流处理"><a href="#commons-io-文件流处理" class="headerlink" title="commons-io 文件流处理"></a>commons-io 文件流处理</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">File</span> <span class="variable">file</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;demo1.txt&quot;</span>);</span><br><span class="line"><span class="comment">// 读取文件</span></span><br><span class="line">List&lt;String&gt; lines = FileUtils.readLines(file, Charset.defaultCharset());</span><br><span class="line"></span><br><span class="line">FileUtils.readFileToString(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;xxx&quot;</span>));</span><br><span class="line"><span class="comment">// 写入文件</span></span><br><span class="line">FileUtils.writeLines(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;demo2.txt&quot;</span>), lines);</span><br><span class="line"><span class="comment">// 复制文件</span></span><br><span class="line">FileUtils.copyFile(srcFile, destFile);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Google-Guava-工具类库"><a href="#Google-Guava-工具类库" class="headerlink" title="Google Guava 工具类库"></a>Google Guava 工具类库</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建集合</span></span><br><span class="line">List&lt;String&gt; list = Lists.newArrayList();</span><br><span class="line">List&lt;Integer&gt; list = Lists.newArrayList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">// 反转list</span></span><br><span class="line">List&lt;Integer&gt; reverse = Lists.reverse(list);</span><br><span class="line">System.out.println(reverse); <span class="comment">// 输出 [3, 2, 1]</span></span><br><span class="line"><span class="comment">// list集合元素太多，可以分成若干个集合，每个集合10个元素</span></span><br><span class="line">List&lt;List&lt;Integer&gt;&gt; partition = Lists.partition(list, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">Map&lt;String, String&gt; map = Maps.newHashMap();</span><br><span class="line">Set&lt;String&gt; set = Sets.newHashSet();</span><br><span class="line"></span><br><span class="line"><span class="comment">//Multimap 一个key可以映射多个value的HashMap</span></span><br><span class="line">Multimap&lt;String, Integer&gt; map = ArrayListMultimap.create();</span><br><span class="line">map.put(<span class="string">&quot;key&quot;</span>, <span class="number">1</span>);</span><br><span class="line">map.put(<span class="string">&quot;key&quot;</span>, <span class="number">2</span>);</span><br><span class="line">Collection&lt;Integer&gt; values = map.get(<span class="string">&quot;key&quot;</span>);</span><br><span class="line">System.out.println(map); <span class="comment">// 输出 &#123;&quot;key&quot;:[1,2]&#125;</span></span><br><span class="line"><span class="comment">// 还能返回你以前使用的臃肿的Map</span></span><br><span class="line">Map&lt;String, Collection&lt;Integer&gt;&gt; collectionMap = map.asMap();</span><br><span class="line"></span><br><span class="line"><span class="comment">//BiMap 一种连value也不能重复的HashMap</span></span><br><span class="line">BiMap&lt;String, String&gt; biMap = HashBiMap.create();</span><br><span class="line"><span class="comment">// 如果value重复，put方法会抛异常，除非用forcePut方法</span></span><br><span class="line">biMap.put(<span class="string">&quot;key&quot;</span>,<span class="string">&quot;value&quot;</span>);</span><br><span class="line">System.out.println(biMap); <span class="comment">// 输出 &#123;&quot;key&quot;:&quot;value&quot;&#125;</span></span><br><span class="line"><span class="comment">// 既然value不能重复，何不实现个翻转key/value的方法，已经有了</span></span><br><span class="line">BiMap&lt;String, String&gt; inverse = biMap.inverse();</span><br><span class="line">System.out.println(inverse); <span class="comment">// 输出 &#123;&quot;value&quot;:&quot;key&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Table 一种有两个key的HashMap</span></span><br><span class="line"><span class="comment">// 一批用户，同时按年龄和性别分组</span></span><br><span class="line">Table&lt;Integer, String, String&gt; table = HashBasedTable.create();</span><br><span class="line">table.put(<span class="number">18</span>, <span class="string">&quot;男&quot;</span>, <span class="string">&quot;yideng&quot;</span>);</span><br><span class="line">table.put(<span class="number">18</span>, <span class="string">&quot;女&quot;</span>, <span class="string">&quot;Lily&quot;</span>);</span><br><span class="line">System.out.println(table.get(<span class="number">18</span>, <span class="string">&quot;男&quot;</span>)); <span class="comment">// 输出 yideng</span></span><br><span class="line"><span class="comment">// 这其实是一个二维的Map，可以查看行数据</span></span><br><span class="line">Map&lt;String, String&gt; row = table.row(<span class="number">18</span>);</span><br><span class="line">System.out.println(row); <span class="comment">// 输出 &#123;&quot;男&quot;:&quot;yideng&quot;,&quot;女&quot;:&quot;Lily&quot;&#125;</span></span><br><span class="line"><span class="comment">// 查看列数据</span></span><br><span class="line">Map&lt;Integer, String&gt; column = table.column(<span class="string">&quot;男&quot;</span>);</span><br><span class="line">System.out.println(column); <span class="comment">// 输出 &#123;18:&quot;yideng&quot;&#125;</span></span><br><span class="line"><span class="comment">// Multiset 一种用来计数的Set</span></span><br><span class="line">Multiset&lt;String&gt; multiset = HashMultiset.create();</span><br><span class="line">multiset.add(<span class="string">&quot;apple&quot;</span>);</span><br><span class="line">multiset.add(<span class="string">&quot;apple&quot;</span>);</span><br><span class="line">multiset.add(<span class="string">&quot;orange&quot;</span>);</span><br><span class="line">System.out.println(multiset.count(<span class="string">&quot;apple&quot;</span>)); <span class="comment">// 输出 2</span></span><br><span class="line"><span class="comment">// 查看去重的元素</span></span><br><span class="line">Set&lt;String&gt; set = multiset.elementSet();</span><br><span class="line">System.out.println(set); <span class="comment">// 输出 [&quot;orange&quot;,&quot;apple&quot;]</span></span><br><span class="line"><span class="comment">// 还能查看没有去重的元素</span></span><br><span class="line">Iterator&lt;String&gt; iterator = multiset.iterator();</span><br><span class="line"><span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">    System.out.println(iterator.next());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 还能手动设置某个元素出现的次数</span></span><br><span class="line">multiset.setCount(<span class="string">&quot;apple&quot;</span>, <span class="number">5</span>);</span><br></pre></td></tr></table></figure>

<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="比较两个对象是否相等"><a href="#比较两个对象是否相等" class="headerlink" title="比较两个对象是否相等"></a>比较两个对象是否相等</h3><ul>
<li><code>Objects.equals(strA, strB);</code> (防止空指针)</li>
</ul>
<h3 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h3><p>1. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CompletableFuture.supplyAsync(</span><br><span class="line">                  () -&gt; &#123;</span><br><span class="line">                  &#125;);</span><br></pre></td></tr></table></figure>

<p>2. </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line">		&#125;);</span><br></pre></td></tr></table></figure>

<h3 id="重写toString"><a href="#重写toString" class="headerlink" title="重写toString"></a>重写toString</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">  		<span class="keyword">return</span> ReflectionToStringBuilder.toString(<span class="built_in">this</span>,</span><br><span class="line">  				ToStringStyle.SHORT_PREFIX_STYLE);</span><br><span class="line">&#125;</span><br><span class="line">  	</span><br><span class="line"> <span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">          <span class="type">ReflectionToStringBuilder</span> <span class="variable">builder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReflectionToStringBuilder</span>(</span><br><span class="line">                  <span class="built_in">this</span>, ToStringStyle.SHORT_PREFIX_STYLE) &#123;</span><br><span class="line">              <span class="meta">@Override</span></span><br><span class="line">              <span class="keyword">protected</span> <span class="type">boolean</span> <span class="title function_">accept</span><span class="params">(Field field)</span> &#123;</span><br><span class="line">                  <span class="keyword">return</span> !<span class="string">&quot;createTime&quot;</span>.equals(field.getName()) &amp;&amp;</span><br><span class="line">                          !field.getName().equals(<span class="string">&quot;updateTime&quot;</span>) &amp;&amp;</span><br><span class="line">                          !field.getName().equals(<span class="string">&quot;xxx&quot;</span>);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;;</span><br><span class="line">          <span class="keyword">return</span> builder.toString();</span><br><span class="line">&#125; 	</span><br></pre></td></tr></table></figure>

<h3 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map&lt;String, String&gt; requestMap =</span><br><span class="line">            request.getParameterMap().entrySet().stream().collect(</span><br><span class="line">                Collectors.toMap(Map.Entry::getKey, entry -&gt; entry.getValue()[<span class="number">0</span>], (v1, v2) -&gt; &#123;</span><br><span class="line">                        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(String.format(<span class="string">&quot;Duplicate key for values %s and %s&quot;</span>, v1, v2));</span><br><span class="line">                    &#125;,</span><br><span class="line">                    TreeMap::<span class="keyword">new</span>));</span><br></pre></td></tr></table></figure>

<h3 id="Optional"><a href="#Optional" class="headerlink" title="Optional"></a>Optional</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">.orElseThrow(() -&gt; <span class="keyword">new</span> <span class="title class_">ContextedRuntimeException</span>(<span class="string">&quot;notExist&quot;</span>).addContextValue(<span class="string">&quot;id&quot;</span>, id));</span><br></pre></td></tr></table></figure>

<h4 id="Optional中map和flatMap"><a href="#Optional中map和flatMap" class="headerlink" title="Optional中map和flatMap"></a>Optional中map和flatMap</h4><ul>
<li><a href="https://blog.csdn.net/qq_28988969/article/details/80995927">https://blog.csdn.net/qq_28988969/article/details/80995927</a></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FlightTicketInfo</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String orderNumber;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getOrderNumber</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> orderNumber;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * desc :</span></span><br><span class="line"><span class="comment"> * create_user : cheng</span></span><br><span class="line"><span class="comment"> * create_date : 2018/7/4 11:21</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OptionalTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testMap</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">FlightTicketInfo</span> <span class="variable">flightTicketInfo</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">        Optional&lt;Optional&lt;String&gt;&gt; s1 = Optional.ofNullable(flightTicketInfo).map(OptionalTest::getOrderNumber);</span><br><span class="line"></span><br><span class="line">        Optional&lt;String&gt; s2 = Optional.ofNullable(flightTicketInfo).map(FlightTicketInfo::getOrderNumber);</span><br><span class="line"></span><br><span class="line">        Optional&lt;String&gt; s3 = Optional.ofNullable(flightTicketInfo).flatMap(OptionalTest::getOrderNumber);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Optional&lt;String&gt; <span class="title function_">getOrderNumber</span><span class="params">(FlightTicketInfo flightTicketInfo)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Optional.ofNullable(flightTicketInfo).map(f -&gt; f.getOrderNumber());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>1.9新增 or()方法是作为orElse()和orElseGet()方法的改进而出现的，使用方法一致，但后两个方法在执行完成后返回的并非包装值。如果需要执行一些逻辑并返回Optional时，可以使用or()方法。该方法传入Supplier接口的实例，当value有值时直接返回自身Optional，当为空时，自动执行suuplier的get()方法，并包装成Optional返回，其源码中包装的语句如下：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Optional&lt;T&gt; r = (Optional&lt;T&gt;) supplier.get();</span><br><span class="line"><span class="keyword">return</span> Objects.requireNonNull(r);</span><br></pre></td></tr></table></figure>
<ul>
<li>stream()方法则不用多说，是一个提供给流式编程使用的方法，功能上是一个适配器，将Optional转换成Stream：没有值返回一个空的stream，或者包含一个Optional的stream。其源码如下：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!isPresent()) &#123;</span><br><span class="line"><span class="keyword">return</span> Stream.empty();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> Stream.of(value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>其原因是orElseGet()的参数是Supplier目标类型的函数，简单来说，Suppiler接口类似Spring的懒加载，声明之后并不会占用内存，只有执行了get()方法之后，才会调用构造方法创建出对象，而orElse()是快加载，即使没有调用，也会实际的运行。<br>这个特性在一些简单的方法上差距不大，但是当方法是一些执行密集型的调用时，比如远程调用，计算类或者查询类方法时，会损耗一定的性能。<br>orElseThrow()方法与orElseGet()方法的参数都是Supplier参数都是函数类型的，这意味着这两种方法都是懒加载，但针对于必须要使用异常控制流程的场景，orElseThrow()会更加合适，因为可以控制异常类型，使得相比NPE会有更丰富的语义。</li>
</ul>
<h3 id="BigDecimal"><a href="#BigDecimal" class="headerlink" title="BigDecimal"></a>BigDecimal</h3><ul>
<li><code>user.getMoney().stripTrailingZeros().toPlainString()</code></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> BigDecimal <span class="title function_">sum</span><span class="params">(Function&lt;XXX, BigDecimal&gt; get, List&lt;XXX&gt; list)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> list.stream().map(get).reduce((acc, item) -&gt; &#123;</span><br><span class="line">            acc = acc.add(item);</span><br><span class="line">            <span class="keyword">return</span> acc;</span><br><span class="line">        &#125;).get().divide(BigDecimal.valueOf(<span class="number">100</span>));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="包装临时对象"><a href="#包装临时对象" class="headerlink" title="包装临时对象"></a>包装临时对象</h3><ul>
<li>当一个方法需要返回两个及以上字段时，可以使用Pair和Triple</li>
<li>返回两个字段<br><code>ImmutablePair&lt;Integer, String&gt; pair = ImmutablePair.of(1, &quot;yideng&quot;);</code></li>
<li>返回三个字段<br><code>ImmutableTriple&lt;Integer, String, Date&gt; triple = ImmutableTriple.of(1, &quot;yideng&quot;, new Date());</code></li>
</ul>
<h3 id="临时文件返回"><a href="#临时文件返回" class="headerlink" title="临时文件返回"></a>临时文件返回</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">XXXController</span> &#123;</span><br><span class="line"></span><br><span class="line">     <span class="meta">@GetMapping(value = &quot;/xxdata.txt&quot;)</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">bidata</span><span class="params">(HttpServletResponse response)</span> &#123;</span><br><span class="line"></span><br><span class="line">            <span class="type">String</span> <span class="variable">content</span> <span class="operator">=</span> <span class="string">&quot;success|=|333\nsuccess|=|333&quot;</span>;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                response.setHeader(<span class="string">&quot;Content-Type&quot;</span>, <span class="string">&quot;text/plain;charset=utf-8&quot;</span>);</span><br><span class="line">                response.addHeader(<span class="string">&quot;Content-Disposition&quot;</span>,<span class="string">&quot;attachment;filename=xxdata.txt&quot;</span>);</span><br><span class="line">                <span class="type">OutputStream</span> <span class="variable">output</span> <span class="operator">=</span> response.getOutputStream();</span><br><span class="line">                output.write(content.getBytes(Charset.forName(<span class="string">&quot;UTF-8&quot;</span>)));</span><br><span class="line">                output.flush();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">               e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">     <span class="meta">@GetMapping(value = &quot;/xxdata.txt&quot;)</span></span><br><span class="line">     <span class="keyword">public</span> String <span class="title function_">bidata</span><span class="params">(HttpServletResponse response)</span> &#123;</span><br><span class="line"></span><br><span class="line">                response.setHeader(<span class="string">&quot;Content-Type&quot;</span>, <span class="string">&quot;text/plain;charset=utf-8&quot;</span>);</span><br><span class="line">                response.addHeader(<span class="string">&quot;Content-Disposition&quot;</span>,<span class="string">&quot;attachment;filename=xxdata.txt&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span>  <span class="string">&quot;success|=|333\nsuccess|=|333&quot;</span>;</span><br><span class="line"></span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping(value = &quot;/xxvideo/&#123;uri&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">proxy</span><span class="params">(<span class="meta">@PathVariable(&quot;uri&quot;)</span> String uri, HttpServletResponse response)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">            response.setHeader(<span class="string">&quot;Access-Control-Allow-Origin&quot;</span>, <span class="string">&quot;*.xx.cn, *.xx.xx.com&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="type">OutputStream</span> <span class="variable">output</span> <span class="operator">=</span> response.getOutputStream();</span><br><span class="line">            <span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> xxxService.getRealUrl(uri);</span><br><span class="line">    </span><br><span class="line">            <span class="keyword">if</span> (StringUtils.isBlank(url)) &#123;</span><br><span class="line">                response.setStatus(HttpStatus.NOT_FOUND_404);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">Proxy</span> <span class="variable">proxy</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Proxy</span>(Proxy.Type.HTTP, <span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(forwardProxyHost, forwardProxyPort));</span><br><span class="line">            <span class="keyword">try</span> (<span class="type">InputStream</span> <span class="variable">input</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">URL</span>(url).openConnection(proxy).getInputStream()) &#123;</span><br><span class="line">                IOUtils.copy(input, output);</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            LOGGER.error(<span class="string">&quot;error，uri:&#123;&#125;&quot;</span>, uri, e);</span><br><span class="line">            response.setStatus(HttpStatus.INTERNAL_SERVER_ERROR_500);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">ExecutorService</span> <span class="variable">executor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ScheduledThreadPoolExecutor</span>(Runtime.getRuntime().availableProcessors() * <span class="number">2</span>, <span class="keyword">new</span> <span class="title class_">BasicThreadFactory</span>.Builder().namingPattern(<span class="string">&quot;common-schedule-pool-%d&quot;</span>).daemon(<span class="literal">true</span>).build()); </span><br></pre></td></tr></table></figure>

<ul>
<li>Java线程池中三种方式创建 ThreadFactory 设置线程名称: <a href="https://blog.csdn.net/u010648555/article/details/106137206">https://blog.csdn.net/u010648555/article/details/106137206</a></li>
</ul>
<h3 id="扫描注解"><a href="#扫描注解" class="headerlink" title="扫描注解"></a>扫描注解</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="type">Reflections</span> <span class="variable">reflections</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Reflections</span>(<span class="keyword">new</span> <span class="title class_">ConfigurationBuilder</span>()</span><br><span class="line">               .addUrls(ClasspathHelper.forPackage(<span class="string">&quot;com.xxx&quot;</span>))</span><br><span class="line">               .setScanners(<span class="keyword">new</span> <span class="title class_">MethodAnnotationsScanner</span>()));</span><br><span class="line"></span><br><span class="line"> <span class="keyword">for</span> (<span class="keyword">final</span> Method method : reflections.getMethodsAnnotatedWith(xxxxx.class)) &#123;</span><br><span class="line">           Class&lt;?&gt; clazz = method.getDeclaringClass();</span><br><span class="line">           Collection&lt;?&gt; beans = applicationContext.getBeansOfType(clazz).values();</span><br><span class="line">           <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> beans.size();</span><br><span class="line">          &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.reflections<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>reflections<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9.11<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> CompletableFuture&lt;Boolean&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;);</span><br><span class="line">CompletableFuture&lt;Boolean&gt; future2 = CompletableFuture.supplyAsync(() -&gt; <span class="literal">true</span>);</span><br><span class="line">CompletableFuture&lt;Boolean&gt; future3 = CompletableFuture.supplyAsync(() -&gt; <span class="literal">true</span>);</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Supplier&lt;Boolean&gt;&gt; tasks = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(<span class="number">2</span>);</span><br><span class="line">        tasks.add(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        tasks.add(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">        tasks.stream().parallel().forEach(Supplier::get);</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CompletableFuture&lt;CallResult&gt; future1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> CallResult.FAIL;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">CompletableFuture&lt;CallResult&gt; future2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> CallResult.FAIL;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">List&lt;CallResult&gt; resultList = Stream.of(future1, future2).map(CompletableFuture::join).collect(</span><br><span class="line">            Collectors.toList());</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (resultList.stream().filter(v -&gt; CallResult.FAIL.equals(v)).count() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Exception</span>(<span class="string">&quot; call exception&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> IntStream.range(<span class="number">0</span>, DBTableConfig.SIZE).parallel()</span><br><span class="line">  .mapToObj(index -&gt; mapper.selectAllList(index, Date.from(Instant.ofEpochSecond(startTime)),</span><br><span class="line">    Date.from(Instant.ofEpochSecond(endTime)), xxx, Arrays.asList(xx, xx), limit)).flatMap(Collection::stream).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CompletableFuture&lt;Void&gt; cf6 = CompletableFuture.allOf(cf3, cf4, cf5);</span><br><span class="line">CompletableFuture&lt;String&gt; result = cf6.thenApply(v -&gt; &#123;</span><br><span class="line">  <span class="comment">//这里的join并不会阻塞，因为传给thenApply的函数是在CF3、CF4、CF5全部完成时，才会执行 。</span></span><br><span class="line">  result3 = cf3.join();</span><br><span class="line">  result4 = cf4.join();</span><br><span class="line">  result5 = cf5.join();</span><br><span class="line">  <span class="comment">//根据result3、result4、result5组装最终result;</span></span><br><span class="line">  <span class="keyword">return</span> <span class="string">&quot;result&quot;</span>;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h2 id="开源类库"><a href="#开源类库" class="headerlink" title="开源类库"></a>开源类库</h2><ul>
<li>apache commons</li>
<li>commons-lang3</li>
<li>commons-collections</li>
</ul>
<h2 id="Web"><a href="#Web" class="headerlink" title="Web"></a>Web</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">RequestAttributes</span> <span class="variable">requestAttributes</span> <span class="operator">=</span> RequestContextHolder.getRequestAttributes();</span><br><span class="line">        <span class="keyword">if</span> (requestAttributes <span class="keyword">instanceof</span> ServletRequestAttributes) &#123;</span><br><span class="line">            <span class="type">HttpServletRequest</span> <span class="variable">request</span> <span class="operator">=</span> ((ServletRequestAttributes)requestAttributes).getRequest();</span><br><span class="line">           </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * curl -XPOST -F &quot;materialFile=@/D:/Downloads/5c1.FBX&quot; &quot;http://127.0.0.1:19201/addMaterial&quot;</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> materialFile</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@CheckToken(false)</span></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/addMaterial&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> ApplicationResponse <span class="title function_">addMaterial</span><span class="params">(<span class="meta">@RequestParam(&quot;materialFile&quot;)</span> MultipartFile materialFile</span></span><br><span class="line"><span class="params">            )</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> ApplicationResponse.ok().build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">spring.http.multipart.maxFileSize=10MB</span><br><span class="line">spring.http.multipart.maxRequestSize=10MB</span><br></pre></td></tr></table></figure>

<ul>
<li>long 前端失精问题<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean(&quot;jackson2ObjectMapperBuilderCustomizer&quot;)</span></span><br><span class="line"><span class="meta">@ConditionalOnProperty(name = &quot;config.long2string&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)</span></span><br><span class="line"><span class="keyword">public</span> Jackson2ObjectMapperBuilderCustomizer <span class="title function_">jackson2ObjectMapperBuilderCustomizer</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">Jackson2ObjectMapperBuilderCustomizer</span> <span class="variable">customizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Jackson2ObjectMapperBuilderCustomizer</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">customize</span><span class="params">(Jackson2ObjectMapperBuilder jacksonObjectMapperBuilder)</span> &#123;</span><br><span class="line">            jacksonObjectMapperBuilder.serializerByType(Long.class, ToStringSerializer.instance)</span><br><span class="line">                    .serializerByType(Long.TYPE, ToStringSerializer.instance);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">return</span> customizer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="MyBatis"><a href="#MyBatis" class="headerlink" title="MyBatis"></a>MyBatis</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;queryBookInfo&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;com.tjt.platform.entity.BookInfo&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;java.lang.Integer&quot;</span>&gt;</span></span><br><span class="line">select count(*) from t_rule_BookInfo t</span><br><span class="line"><span class="tag">&lt;<span class="name">where</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;title !=null and title !=&#x27;&#x27; &quot;</span>&gt;</span></span><br><span class="line">title = #&#123;title&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;author !=null and author !=&#x27;&#x27; &quot;</span>&gt;</span></span><br><span class="line">AND author = #&#123;author&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">where</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line">UPDATE 操作也一样，可以用标记代替 1=1。</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">@Select(&#123;</span><br><span class="line">               &quot;<span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-handlebars"><span class="language-xml">&quot;,</span></span></span><br><span class="line"><span class="language-xml"><span class="language-handlebars">               &quot;SELECT &quot; +  FIELDS,</span></span></span><br><span class="line"><span class="language-xml"><span class="language-handlebars">               &quot;FROM  `t_xxxx_task` t&quot;,</span></span></span><br><span class="line"><span class="language-xml"><span class="language-handlebars">               &quot;WHERE createTime <span class="symbol">&amp;gt;</span>= #&#123;startTime&#125; AND createTime <span class="symbol">&amp;lt;</span> #&#123;endTime&#125; &quot;,</span></span></span><br><span class="line"><span class="language-xml"><span class="language-handlebars">               &quot;<span class="tag">&lt;<span class="name">when</span> <span class="attr">test</span> = <span class="string">&#x27;statusList != null and statusList.size &gt; 0&#x27;</span>&gt;</span>&quot;,</span></span></span><br><span class="line"><span class="language-xml"><span class="language-handlebars">               &quot;AND `status` in (<span class="tag">&lt;<span class="name">foreach</span> <span class="attr">collection</span> = <span class="string">&#x27;statusList&#x27;</span> <span class="attr">item</span> = <span class="string">&#x27;status&#x27;</span> <span class="attr">index</span>=<span class="string">&#x27;index&#x27;</span> <span class="attr">open</span>=<span class="string">&#x27;&#x27;</span> <span class="attr">close</span>=<span class="string">&#x27;&#x27;</span> <span class="attr">separator</span>=<span class="string">&#x27;,&#x27;</span>&gt;</span>#&#123;status&#125;<span class="tag">&lt;/<span class="name">foreach</span>&gt;</span>)&quot;,</span></span></span><br><span class="line"><span class="language-xml"><span class="language-handlebars">               &quot;<span class="tag">&lt;/<span class="name">when</span>&gt;</span>&quot;,</span></span></span><br><span class="line"><span class="language-xml"><span class="language-handlebars">               &quot;LIMIT #&#123;limit&#125;&quot;,</span></span></span><br><span class="line"><span class="language-xml"><span class="language-handlebars">               &quot;</span></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span>&quot;</span><br><span class="line">       &#125;)</span><br><span class="line">       List<span class="tag">&lt;<span class="name">TxxxxTask</span>&gt;</span> selectList(@Param(&quot;startTime&quot;)Date startTime, @Param(&quot;endTime&quot;)Date endTime, @Param(&quot;statusList&quot;) List<span class="tag">&lt;<span class="name">Integer</span>&gt;</span> statusList, @Param(&quot;limit&quot;) int limit);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.toutiao.com/i6943239541448917512">实现同样逻辑，代码量减少90%，Java程序员必会的工具库</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/515993095">CompletableFuture原理与实践-外卖商家端API的异步化</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>直播相关技术梳理总结</title>
    <url>/2022/05/04/20220504-zhi-bo-xiang-guan-ji-zhu-shu-li-zong-jie/</url>
    <content><![CDATA[<h1 id="视频直播的实现原理"><a href="#视频直播的实现原理" class="headerlink" title="视频直播的实现原理"></a>视频直播的实现原理</h1><ul>
<li><a href="https://www.cnblogs.com/stringarray/p/13027230.html">网络协议-流媒体协议 </a></li>
<li>首先，网络协议将编码好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的服务端来接收这些网络包，从而得到里面的视频流，这个过程称为接流。</li>
<li>服务端接到视频流之后，可以对视频流进行一定的处理，例如转码，也即从一个编码格式，转成另一种格式。因为观众使用的客户端千差万别，要保证他们都能看到直播。流处理完毕之后，就可以等待观众的客户端来请求这些视频流，观众的客户端请求的过程称为拉流。</li>
<li>如果有非常多的观众，同时看一个视频直播，那都从一个服务器上拉流，压力太大了，因而需要一个视频的分发网络（CDN），将视频预先加载到就近的边缘节点，这样大部分观众看的视频，是从边缘节点拉取的，就能降低服务器的压力。</li>
<li>当观众的客户端将视频流拉下来之后，就需要进行解码，也即通过上述过程的逆过程，将一串串看不懂的二进制代码，再转变成一帧帧生动的图片，在客户端播放出来，这样你就能看到直播视频啦。</li>
</ul>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><ul>
<li><a href="https://cloud.tencent.com/document/product/267/43393">https://cloud.tencent.com/document/product/267/43393</a></li>
</ul>
<h2 id="转码"><a href="#转码" class="headerlink" title="转码"></a>转码</h2><ul>
<li>转码是将视频码流转换成另一个视频码流的过程，是一种离线任务。通过转码，可以改变原始码流的编码格式、分辨率和码率等参数，从而适应不同终端和网络环境的播放。使用转码功能可以实现：<ul>
<li>适配更多终端：将原始视频转码成拥有更强终端适配能力的格式，使视频资源能够在更多设备上播放。</li>
<li>适配不同带宽：将视频转换成流畅、标清、高清或超清输出，用户可根据当前网络环境选择合适码率的视频播放。</li>
<li>节省带宽：采用更先进的编码方式转码，在不损失原始画质的情况下显著降低码率，节省播放带宽。</li>
</ul>
</li>
</ul>
<h2 id="视频编码"><a href="#视频编码" class="headerlink" title="视频编码"></a>视频编码</h2><ul>
<li>H.265是新的编码协议，也即是H.264的升级版。H.265标准保留H.264原来的某些技术，同时对一些相关的技术加以改进。</li>
<li>视频编码：指通过特定的压缩技术，将某个视频格式的文件转换成另一种视频格式文件的方式。常见的音频视频编码有MPEG系列与H.26X系列。</li>
</ul>
<h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><ul>
<li><a href="https://blog.csdn.net/lxc1014/article/details/45666281">https://blog.csdn.net/lxc1014/article/details/45666281</a></li>
<li>mp4,rmvb,mkv,avi从形式上来说首先都是视频文件的扩展名，其次它们也是视频文件的封装格式（即容器）， mp4是MPEG-4标准的第14部分所制定的容器标准。所谓容器，就是把编码器生成的多媒体内容（视频，音频，字幕，章节信息等）混合封装在一起的标准。容器使得不同多媒体内容同步播放变得很简单，而容器的另一个作用就是为多媒体内容提供索引，也就是说如果没有容器存在的话一部影片你只能从一开始看到最后，不能拖动进度条（当然这种情况下有的播放器会话比较长的时间临时创建索引），而且如果你不自己去手动另外载入音频就没有声音。</li>
</ul>
<h1 id="普通直播"><a href="#普通直播" class="headerlink" title="普通直播"></a>普通直播</h1><ul>
<li>直播类应用在产品功能上基本是这两类：<ul>
<li>1、直播的基础功能：连麦互动直播（支持多码率、多协议）等非功能性需求。— 流相关服务</li>
<li>2、应用本身的个性化功能：比如答题场景中的发题目、作答、公布答案等。— 长连接相关服务</li>
</ul>
</li>
</ul>
<h1 id="多人连麦-x2F-PK-x2F-聊天"><a href="#多人连麦-x2F-PK-x2F-聊天" class="headerlink" title="多人连麦&#x2F;PK&#x2F;聊天"></a>多人连麦&#x2F;PK&#x2F;聊天</h1><ul>
<li><a href="https://juejin.im/post/6844903777837776910">直播多人连麦技术简介</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/43629518">直播连麦技术对比-互动直播调研必看</a><ul>
<li>基于WebRTC和RTMP结合的方案</li>
<li>基于RTC的方案(声网、即构)</li>
<li>anyRTC直播方案</li>
</ul>
</li>
<li><a href="https://zhuanlan.zhihu.com/p/27086190">直播连麦技术方案对比及测试方法</a><ul>
<li>SD-RTN™:这是声网的连麦架构，直播连麦的鼻祖。基于UDP，主播端、连麦端、观众端都在基于SD-RTN™进行实时通信，大大降低延时。主播端和连麦端也可以转码到CDN推流。</li>
<li>RTMP改进方案:基于TCP协议，基本思路是：主播接受连麦嘉宾的视频，在本地合图；主播和连麦嘉宾的视频同时传到服务端合图，然后通过CDN推到观众端。</li>
<li>WebRTC改进:主播和连麦嘉宾，基于WebRTC进行“视频会议”，将“视频会议”在服务端合图后推到CDN进行分发。</li>
</ul>
</li>
</ul>
<h2 id="传统直播形式"><a href="#传统直播形式" class="headerlink" title="传统直播形式"></a>传统直播形式</h2><ul>
<li>一个主播推流，广播给直播间所有的观众。一个直播间对应一个主播，并且仅有一路推拉流。</li>
<li>基于协议RTMP做的单路直播互动。该模式下主播一个人表演，其他观众根据IM系统跟主播进行文字互动。</li>
<li>总结：主播端推一路流，观众端CDN拉一路流。</li>
</ul>
<h2 id="连麦直播形式"><a href="#连麦直播形式" class="headerlink" title="连麦直播形式"></a>连麦直播形式</h2><ul>
<li>两个主播（另一个主播可能是观众）推流，广播给直播间所有观众。</li>
<li>基于UDP做的多路实时互动直播。该模式下主播跟观众除了基于IM系统沟通外，还可以进行音视频互动，极大的方便了观众，互动效果更直观，更能有效吸引用户。</li>
</ul>
<h3 id="1基于RTMP协议优化方案"><a href="#1基于RTMP协议优化方案" class="headerlink" title="1基于RTMP协议优化方案"></a>1基于RTMP协议优化方案</h3><ul>
<li>主播A和主播B之间通过原有的推拉流路径去拉取对方的流内容。也就是说，主播A在推流同时，拉取主播B的流，主播B推流的同时拉取主播A的流。对于两个主播来说互为对方的观众。此时对于直播间内的其他观众而言，是分别拉取主播A和主播B的流，并展示出来。</li>
<li>在此基础上可以进一步对主播两路流做混流，这样观众端只需要拉一路流。</li>
<li>混流：可以在服务端做，也可以在其中一个主播的客户端做混流再推流（对主播设备性能有一定要求）</li>
</ul>
<h3 id="2基于P2P协议方案"><a href="#2基于P2P协议方案" class="headerlink" title="2基于P2P协议方案"></a>2基于P2P协议方案</h3><ul>
<li>此方案的实现方式是，主播A和主播B之间通过P2P协议进行音视频连接，正常情况下能够保证较低的延迟，保证主播A和主播B之间的互动。主播A在自己的流内容基础上加入主播B的流内容，统一推向服务端。此时直播间内仅有一路流，并且其他观众也只需要拉取这一路流内容。</li>
<li>此方案的优点是显而易见的，主播AB之间的延迟降低，交互体验好，观众保持原有逻辑不变，拉取直播间固定流地址。但是缺点是：主播A在连麦过程中需要承担两路推流一路拉流的压力，即拉取主播B的流内容，将自己的流内容推给主播B，将主播A和主播B的流内容推给服务端；主播A的网速压力和性能压力将会巨大，同时主播AB之间一对一的连接也导致扩展性较差，无法满足2人以上的业务场景需求。</li>
</ul>
<h3 id="3基于多人视频通话系统方案-（目前主流）"><a href="#3基于多人视频通话系统方案-（目前主流）" class="headerlink" title="3基于多人视频通话系统方案 （目前主流）"></a>3基于多人视频通话系统方案 （目前主流）</h3><ul>
<li>此方案的实现方式是将主播A和主播B的视频交互交由第三方处理，目前比较成熟的技术有视频会议系统和Google开源的WebRTC系统。在此架构下，主播A与主播B的流合成处理上传都是由这个交互系统完成。此方案对于方案2来说减轻了主播端的压力，并且采用UDP协议传输方式降低延迟。同时也兼容多人连接交互。</li>
<li>此方案缺点是对服务端开发量大，要求高。</li>
</ul>
<h3 id="第三方支持"><a href="#第三方支持" class="headerlink" title="第三方支持"></a>第三方支持</h3><ul>
<li>语音连麦聊天室集成介绍:<a href="http://docs-im.easemob.com/rtc/scenario/tc">http://docs-im.easemob.com/rtc/scenario/tc</a></li>
<li>腾讯音视频技术平台：<a href="https://cloud.tencent.com/document/product/267/44710">https://cloud.tencent.com/document/product/267/44710</a></li>
</ul>
<hr>
<h2 id="推流"><a href="#推流" class="headerlink" title="推流"></a>推流</h2><ul>
<li><p>使用ffmpeg推流到rtmp服务</p>
<ul>
<li><code>ffmpeg -re -i 1.mp4 -c copy -f flv rtmp://127.0.0.1:1935/live/movie</code></li>
<li><a href="https://juejin.cn/post/6909479346646286343">如何开发一款H5小程序直播</a></li>
</ul>
</li>
<li><p>OBS 推流:<a href="https://cloud.tencent.com/document/product/267/32726">https://cloud.tencent.com/document/product/267/32726</a></p>
</li>
<li><p>VLC播放器：<a href="https://www.videolan.org/vlc/index.zh.html">https://www.videolan.org/vlc/index.zh.html</a>,<br><a href="https://cloud.tencent.com/document/product/267/32727">https://cloud.tencent.com/document/product/267/32727</a></p>
</li>
</ul>
<h2 id="混流"><a href="#混流" class="headerlink" title="混流"></a>混流</h2><ul>
<li>混流就是把多路音视频流合成单流。准确的说，混流应该叫做混音（音频流）混画（视频流）混流的过程包括解码、混流、编码和推流四个部分。混流这个环节包括做动冲，目的是把多路流进行画面对齐和音画同步，同时通过缓冲对抗网络抖动，以便混合成一路流以后能够达到良好的效果。在混流的过程中，难点是如何对抗网络抖动等不确定因素。</li>
</ul>
<h3 id="不混流的优势和劣势"><a href="#不混流的优势和劣势" class="headerlink" title="不混流的优势和劣势"></a>不混流的优势和劣势</h3><ul>
<li><p>不混流的优势</p>
<ul>
<li>延迟低：不用混流，节省了混流消耗的时间，显著地降低了延迟</li>
<li>成本低： 如果是在服务端进行混流，将会耗费计算资源。考虑到服务端计算资源比较昂贵，如果不用混流，将会节省宝贵的计算资源，显著地降低成本。虽然拉多流比起拉单流会消耗更多的带宽成本，但是拉多流节省计算资源成本，整体而言，成本是降低了。</li>
<li>灵活性:在观众端，业务侧可以比较灵活的操控多路流，来满足多样化的业务需求。比如画中画大小画面相互切换，和对半分屏画面左右调换等效果，来提高观众端的用户体验。</li>
</ul>
</li>
<li><p>不混流的劣势</p>
<ul>
<li>拉多流会消耗更多的带宽。多路流被从服务端推到CDN, 然后观众端从CDN拉多流，都会耗费比较多的带宽成本。对于带宽成本占了运营成本显著，的确是需要慎重考量的。</li>
</ul>
</li>
<li><p>混流的优势</p>
<ul>
<li>成本：可以分为计算资源成本和带宽成本。由于预先做混流，因此计算资源成本会上去，但是由于只拉单流，因此带宽成本会下来。</li>
<li>可录制：如果业务上有录制音视频流的需求，以备监管抽查或者观众回放的话，那么需要进行混流。如果不进行混流的话，录制的时候只能录制到其中一个路音视频流，也就是只能看到其中一个主播的画面。要录制全画面的话，必须要进行混流。</li>
<li>易传播：如果业务上有通过音视频流地址链接(HLS)进行转发传播的需求，那么也需要进行混流，因为地址链接只会指向一路音视频流。如果不混流，使用转发的地址链接就只会播放出一个主播的音视频流。</li>
</ul>
</li>
<li><p>混流的劣势</p>
<ul>
<li>高延迟：由于在做混流的过程中，需要做抖动缓冲和实时转码等计算处理，将会耗费时间，从而造成额外的延迟。</li>
<li>不灵活：由于观众端拉单流观看，多路音视频流已经被混合成单流，所以观众端无法再灵活地对多流进行操控，比如切换画中画的主次画面。</li>
<li>服务器计算成本高：由于混流需要额外的计算资源，这里会导致额外的运营成本。</li>
</ul>
</li>
<li><p>服务端混流的优势</p>
<ul>
<li>低延迟</li>
<li>计算资源可控</li>
<li>网络带宽资源可控</li>
<li>可控可扩展</li>
</ul>
</li>
<li><p>服务端混流的劣势</p>
<ul>
<li>服务器计算成本高</li>
<li>服务端压力大</li>
</ul>
</li>
<li><p>混流工具: FFmpeg</p>
<ul>
<li>混流命令: <code>./ffmpeg -i “背景图” -i “rtmp://输入流1” -i “rtmp://输入流2” -filter_complex “nullsrc=size=1600x720 [base];[0:v] scale=1600x720 [main]; [1:v] crop=320:180:0:0 [photo1];[2:v] crop=320:180:0:0 [photo2];[base][main] overlay=x=0:y=0 [temp];[temp][photo1] overlay=x=1280:y=0 [temp1];[temp1][photo2] overlay=x=1280:y=180 [temp2]” -c:v libx264 -r 50 -bufsize 10M -f flv “rtmp://推流地址”</code></li>
<li>录制命令: <code>./ffmpeg -i rtmp://混流地址 test.mp4</code></li>
</ul>
</li>
<li><p><a href="https://blog.csdn.net/Peng__Chao/article/details/107716008">基于FFmpeg混流及录制rtmp直播流</a></p>
</li>
</ul>
<h2 id="混音"><a href="#混音" class="headerlink" title="混音"></a>混音</h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/121010029">实时音频的混音在视频直播中的技术原理和实践总结</a></li>
<li>混音，顾名思义，就是把两路或者多路音频流混合在一起，形成一路音频流。实时音频混音，指的只是音频流的混合。</li>
<li>混音的逻辑可以在终端设备上实现，也可以在服务器上实现，因此可以分为终端混音和云端混音。终端混音一般应用于背景配音，音乐伴奏等场景。云端混音可以是云端混流的一部分，主要目的是利用云端的计算能力去做多路音视频流的音画对齐，还有降低下行带宽成本；也可以做纯粹的云端混音，来实现合唱直播等场景的需求。</li>
</ul>
<hr>
<h1 id="实现例子1"><a href="#实现例子1" class="headerlink" title="实现例子1"></a>实现例子1</h1><ul>
<li>火爆的直播应用，你了解背后的技术架构吗？:<a href="https://mp.weixin.qq.com/s/2ucFww9MEdsKbMO8Wepg1A">https://mp.weixin.qq.com/s/2ucFww9MEdsKbMO8Wepg1A</a></li>
<li>音视频流采用了腾讯云的直播解决方案，而业务数据流（活动、题目、答案、弹幕、红包等）则采用了自研的长连接方案。</li>
</ul>
<h2 id="产品功能"><a href="#产品功能" class="headerlink" title="产品功能"></a>产品功能</h2><ul>
<li>直播类应用在产品功能上基本是这两类：<ul>
<li>1、直播的基础功能：连麦互动直播（支持多码率、多协议，多主播同框）、美颜特效、弹幕、IM聊天、点赞、屏幕共享等功能性需求，以及防盗链、涉黄涉政鉴别等非功能性需求。</li>
<li>2、应用本身的个性化功能：比如答题场景中的发题目、作答、公布答案，电商场景中的商品展示、一键下单购买，网红直播场景中的礼物打赏。</li>
</ul>
</li>
</ul>
<h2 id="面临的技术挑战"><a href="#面临的技术挑战" class="headerlink" title="面临的技术挑战"></a>面临的技术挑战</h2><ul>
<li>音视频处理及传输：涉及音视频编码、实时美颜、视频推流、CDN加速分发、终端适配和播放，流量统计等诸多技术点</li>
<li>高带宽压力：按照标清视频的标准，观看直播的码流至少为1Mbps，如果100W用户在线，光视频流的出口带宽能达到976.56G bps。1条弹幕可达到130字节，1秒要滚屏20条弹幕，如果需要同时推送给100W用户，弹幕的出口带宽也将达到19.37G bps.  </li>
<li>低延迟性要求：直播场景下如何整合视频流和业务数据流，做到声音、主播画面和题目同步，以保证用户体验</li>
</ul>
<h2 id="音视频处理及传输的方案选型"><a href="#音视频处理及传输的方案选型" class="headerlink" title="音视频处理及传输的方案选型"></a>音视频处理及传输的方案选型</h2><ul>
<li>第三方支持方案：音视频处理及传输，可以使用腾讯云的直播解决方案。主持人侧：通过演播室的专业摄像设备，搭载腾讯云提供的obs推流软件，即可进行视频录制和推流。用户侧：APP端集成腾讯云的SDK，动态拿到推流地址后即可观看直播。</li>
</ul>
<h2 id="业务数据流的方案选型"><a href="#业务数据流的方案选型" class="headerlink" title="业务数据流的方案选型"></a>业务数据流的方案选型</h2><ul>
<li>业务数据是指除音视频以外的，和答题应用场景相关的数据（比如题目、答案、弹幕、红包等）。腾讯云提供了两种可选方案：<ul>
<li>1、题目预先设置好，直接由腾讯云的SDK通过音视频通道下发，打入直播流中。</li>
<li>2、让题目先通过腾讯云的IM通道快速送达观众端APP，在观众端先缓存下来，等待播放器通知了预期的 NTP 时间戳之后，再把题目显示出来。</li>
</ul>
</li>
<li>自研业务数据流通道。这样视频流和业务数据流会分两个通道下发，因为业务流相对视频流的数据量很小，只要能保证业务逻辑的处理速度和业务数据的下行速度，“音-画-题”的延迟是可以接受的。毕竟当时已经是4G时代，如果用户侧的网速不行，视频流可能都无法正常观看了。</li>
</ul>
<h3 id="长连接、高性能的网关服务器"><a href="#长连接、高性能的网关服务器" class="headerlink" title="长连接、高性能的网关服务器"></a>长连接、高性能的网关服务器</h3><ul>
<li>（支持100W用户同时在线，20W并发答题，弹幕实时推送等要求），我们的技术选型是：Netty、ProtoBuf、WebSocket，选型理由：</li>
<li>1、Netty：Netty是当时最流行的高性能和异步NIO框架，直播答题的业务场景中，涉及到题目下发、弹幕、下红包雨等非常多的推送场景，而且一场答题活动中，客户端和服务端的通信频繁，长连接比短连接在性能上更优。</li>
<li>2、ProtoBuf：作为客户端和服务端的数据交换格式，PB是一种效率和兼容性都很优秀的二进制数据传输格式，在码流和序列化速度上明显优于JSON、XML、hessian等主流格式，同时支持向前向后兼容以及各种主流语言。</li>
<li>3、WebSocket：是 HTML5 一种新的协议，用来实现客户端与服务器端的长连接通讯。<ul>
<li>为什么使用WebSocket不使用TCP呢？TODO</li>
</ul>
</li>
</ul>
<h3 id="基于TCP长连接的通信架构"><a href="#基于TCP长连接的通信架构" class="headerlink" title="基于TCP长连接的通信架构"></a>基于TCP长连接的通信架构</h3><p><img src="/2022/05/04/20220504-zhi-bo-xiang-guan-ji-zhu-shu-li-zong-jie/%E5%9F%BA%E4%BA%8ETCP%E9%95%BF%E8%BF%9E%E6%8E%A5%E7%9A%84%E9%80%9A%E4%BF%A1%E6%9E%B6%E6%9E%84.png"></p>
<ul>
<li>上面的通信架构用于业务数据流的传输，流程如下：<ul>
<li>1、客户端使用websocket与服务端进行通讯，用户进入答题直播间时建立连接，退出直播间时断开连接。</li>
<li>2、Nginx对websocket做负载均衡。</li>
<li>3、TCP网关基于netty实现，用于维持长连接和转发业务请求，不负责具体的业务逻辑，它和下层业务系统（答题系统）通过RPC接口进行交互，主要考虑后续其他业务可以复用TCP网关层，所以将业务下沉。客户端和网关之间通过心跳机制保证连接的有效性以及检测僵尸连接。</li>
<li>4、消息推送（比如弹幕、下发题目、公布答案等诸多场景）由下层业务（答题系统）通过MQ通知TCP网关，再由TCP网关推送给客户端。</li>
</ul>
</li>
</ul>
<h3 id="长连接通信中的数据传输格式定义"><a href="#长连接通信中的数据传输格式定义" class="headerlink" title="长连接通信中的数据传输格式定义"></a>长连接通信中的数据传输格式定义</h3><ul>
<li>客户端请求消息的格式</li>
<li>客户端响应消息的格式</li>
</ul>
<h2 id="直播架构简单总结"><a href="#直播架构简单总结" class="headerlink" title="直播架构简单总结:"></a>直播架构简单总结:</h2><ul>
<li>1、音视频编码和传输，这些基础性的直播功能，除非公司有钱有实力，否则建议直接用腾讯云或者阿里云的解决方案（斗鱼、蘑菇街这些知名的直播应用都还用的腾讯云）。</li>
<li>2、架构设计重点放在应用本身，根据直播应用的用户量级和业务特性先确定通信架构（长连接还是短链接，或者两者混用）。</li>
</ul>
<h1 id="实现例子2"><a href="#实现例子2" class="headerlink" title="实现例子2"></a>实现例子2</h1><ul>
<li>视频相亲背后的音视频方案 （多人连麦）</li>
<li><a href="https://cloud.tencent.com/developer/article/1579968">https://cloud.tencent.com/developer/article/1579968</a></li>
<li>[互动直播相亲交友源码低成本开发搭建如何处理音视频技术难点](<a href="https://www.bilibili.com/read/cv7985514/">https://www.bilibili.com/read/cv7985514/</a> 出处：bilibili)</li>
</ul>
<ol>
<li>开发成本高、周期长<ul>
<li>实时音视频技术栈包含音视频编解码、音视频前后处理、信令、网络传输、高并发、高可用、系统监控、多个平台的终端开发，技术储备和开发成本是非常大的挑战。</li>
</ul>
</li>
<li>弱网环境下的音视频质量<ul>
<li>现实的网络环境非常复杂、用户使用中小网络运营商的服务，存在着非常多的不确定性，或多或少的丢包、不确定的网络延时和抖动。</li>
</ul>
</li>
<li>终端极致的性能要求<ul>
<li>多人同屏视频连麦的直播间，面对终端有限的算力、内存，实时音视频终端软件架构的设计会对通信的质量、时延都带来影响。</li>
</ul>
</li>
</ol>
<ul>
<li><p>一套互动直播相亲交友程序源码主播端到观众端有下面几个步骤：</p>
<ul>
<li>1、视音频信号实时采集；</li>
<li>2、经过预处理和音视频编码；</li>
<li>3、封装发送到CDN源站；</li>
<li>4、播放端从CDN边缘拉到数据；</li>
<li>5、然后进行解码；</li>
<li>6、经过音视频同步之后；</li>
<li>7、给观众展现出来。</li>
</ul>
</li>
<li><p>互动直播相亲交友系统的主要技术难点在于：</p>
<ul>
<li>1）低延迟互动：保证主播和互动观众之间能够实时互动，两者之间就像电话沟通，因此必须保证两者能在秒级以内听到对方的声音，看到对方的视频；</li>
<li>2）音画同步：互动直播中对音画同步的需求和单向直播中类似，只不过互动直播中的延迟要求更高，必须保证在音视频秒级传输情况下的秒级同步。</li>
<li>3）音视频实时合成：其他观众需要实时观看到对话结果，因此需要在客户端或者服务端将画面和声音实时合成，然后以低成本高品质的方式传输观众端。</li>
</ul>
</li>
</ul>
<h1 id="实现实例3"><a href="#实现实例3" class="headerlink" title="实现实例3"></a>实现实例3</h1><ul>
<li><p>会议系统</p>
</li>
<li><p><a href="https://www.juhe.cn/news/index/id/1568">https://www.juhe.cn/news/index/id/1568</a></p>
</li>
<li><p>缺点：</p>
<ul>
<li>会议系统很大程度上依赖专线服务，成本过高；</li>
<li>会议系统很多不能在服务器做转码合成视频，对主播设备依赖过大。因为合图视频主要是由主播端编码、推送到CDN，一部分需要主播设备比较高端，另外需要主播网络比较好，否则依然解决不了连麦问题</li>
</ul>
</li>
<li><p>RTC技术（WebRTC）</p>
</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul>
<li><a href="https://www.zhihu.com/answer/2121203968">为何一直推荐WebRTC？</a></li>
</ul>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul>
<li>播放网络视频，通常解析库我们可以有多个选择，如FFMPEG，Daniulive SDK 或者 vitamio。</li>
<li>[H5 直播流播放器 Jessibuca]</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>火爆的直播应用，你了解背后的技术架构吗？:<a href="https://mp.weixin.qq.com/s/2ucFww9MEdsKbMO8Wepg1A">https://mp.weixin.qq.com/s/2ucFww9MEdsKbMO8Wepg1A</a></li>
<li>直播新红海，狼人杀火爆背后的语音视频技术:<a href="https://zhuanlan.zhihu.com/p/33092831">https://zhuanlan.zhihu.com/p/33092831</a></li>
<li>实时视频通话超低延迟架构的思考与实践：<a href="https://blog.csdn.net/zego_0616/article/details/79651875">https://blog.csdn.net/zego_0616/article/details/79651875</a></li>
</ul>
]]></content>
      <tags>
        <tag>直播</tag>
        <tag>流媒体</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务简要总结</title>
    <url>/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul>
<li>本文涉及一些理论基础</li>
<li>业界目前的分布式事务的解决方案</li>
<li>简单的分类和总结</li>
<li>基本内容都来源网上</li>
</ul>
<h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><ol>
<li>事务：事务是由一组操作构成的可靠的独立的工作单元，事务具备ACID的特性，即原子性、一致性、隔离性和持久性。</li>
<li>本地事务：当事务由资源管理器本地管理时被称作本地事务。本地事务的优点就是支持严格的ACID特性，高效，可靠，状态可以只在资源管理器中维护，而且应用编程模型简单。但是本地事务不具备分布式事务的处理能力，隔离的最小单位受限于资源管理器。</li>
<li>全局事务：当事务由全局事务管理器进行全局管理时成为全局事务，事务管理器负责管理全局的事务状态和参与的资源，协同资源的一致提交回滚。</li>
</ol>
<h3 id="ACID-数据库事务4个特性"><a href="#ACID-数据库事务4个特性" class="headerlink" title="ACID(数据库事务4个特性)"></a>ACID(数据库事务4个特性)</h3><ol>
<li>Atomicity（原子性）</li>
<li>Consistency（一致性)</li>
<li>Isolation（隔离性）</li>
<li>Durablity（持久性）</li>
</ol>
<h3 id="分布式事务-Distributed-Transaction"><a href="#分布式事务-Distributed-Transaction" class="headerlink" title="分布式事务 (Distributed Transaction)"></a>分布式事务 (Distributed Transaction)</h3><ol>
<li>在互联网技术里面，强调追求最终一致性。异地多活就是围绕这一点来做的。</li>
<li>分布式事务从实质上看与数据库事务的概念是一致的，既然是事务也就需要满足事务的基本特性（ACID），只是分布式事务相对于本地事务而言其表现形式有很大的不同。</li>
</ol>
<h3 id="分布式一致性协议-consensus-protocol"><a href="#分布式一致性协议-consensus-protocol" class="headerlink" title="分布式一致性协议 (consensus protocol)"></a>分布式一致性协议 (consensus protocol)</h3><ol>
<li>两阶段提交协议（The two-phase commit protocol，2PC）</li>
<li>3PC</li>
<li>PAXOS</li>
<li>Raft 等</li>
</ol>
<ul>
<li><p>无论是2PC还是3PC都无法彻底解决分布式的一致性问题。Google Chubby的作者Mike Burrows说过， ”there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos。意即世上只有一种一致性算法，那就是Paxos，所有其他一致性算法都是Paxos算法的不完整版。</p>
</li>
<li><p>详情看：<a href="https://kingson4wu.gitee.io/2020/09/12/20200912-%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE/">分布式一致性协议概览</a></p>
</li>
</ul>
<h3 id="DTP-Distributed-Transaction-Processing"><a href="#DTP-Distributed-Transaction-Processing" class="headerlink" title="DTP(Distributed Transaction Processing)"></a>DTP(Distributed Transaction Processing)</h3><ul>
<li><p>DTP（Distributed Transaction Processing Reference Model）：分布式事务处理模型。TM、RM、AP等角色的分布式事务的模型。<br><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/DTP.png"></p>
</li>
<li><p>AP（Application Program，应用程序）</p>
</li>
<li><p>TM（Transaction Manager，事务管理器）</p>
</li>
<li><p>RM（Resource Manager，资源管理器）</p>
</li>
<li><p>DTP规范中主要包含了AP、RM、TM三个部分，其中AP是应用程序，是事务发起和结束的地方；RM是资源管理器，主要负责管理每个数据库的连接数据源；TM是事务管理器，负责事务的全局管理，包括事务的生命周期管理和资源的分配协调等。</p>
</li>
<li><p>XA是DTP的一部分接口规范。</p>
</li>
</ul>
<h3 id="分布式事务框架"><a href="#分布式事务框架" class="headerlink" title="分布式事务框架"></a>分布式事务框架</h3><ul>
<li><p>大多数分布式事务框架，也多借鉴了DTP（Distributed Transaction Processing）模型</p>
</li>
<li><p>RM负责本地事务的提交，同时完成分支事务的注册、锁的判定，扮演事务参与者角色。</p>
</li>
<li><p>TM负责整体事务的提交与回滚的指令的触发，扮演事务的总体协调者角色。</p>
</li>
<li><p>不同框架在实现时，各组件角色的功能、部署形态会根据需求进行调整，例如TM有的是以jar包形式与应用部署在一起，有的则剥离出来需要单独部署（例如Seata中将TM的主要功能放到一个逻辑上集中的Server上，叫做TC( Transaction Coordinator )）</p>
</li>
<li><p>一个好的分布式事务框架应用尽可能满足以下特性：<br>业务改造成本低；1<br>性能损耗低；2<br>隔离性保证完整。3<br>但如同CAP，这三个特性是相互制衡</p>
</li>
<li><p>基于业务补偿的Saga满足1.2；TCC满足2.3；Seata（AT模式）满足1.3</p>
</li>
</ul>
<p><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/Saga_TCC_AT.png"></p>
<h3 id="分布式事务的4种模式"><a href="#分布式事务的4种模式" class="headerlink" title="分布式事务的4种模式"></a>分布式事务的4种模式</h3><ol>
<li>AT - (无侵入的分布式事务解决方案)</li>
<li>TCC (业务层的2PC)</li>
<li>Saga (一种补偿协议，长事务解决方案)</li>
<li>XA (DB层的2PC)</li>
</ol>
<ul>
<li>阿里seata框架 实现了这四种模式。</li>
<li><a href="https://zhuanlan.zhihu.com/p/78599954">分布式事务的4种模式</a></li>
</ul>
<p><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/Seata.jpg"></p>
<ul>
<li>性能最高的是Saga，其次是TCC。</li>
<li>隔离性最好的是XA（资源层），最差的是Saga。</li>
<li>除了XA，其他三个为柔性事务，补偿式事务。</li>
</ul>
<h3 id="补偿型事务"><a href="#补偿型事务" class="headerlink" title="补偿型事务"></a>补偿型事务</h3><p>补偿型事务处理机制构建在 事务资源 之上（要么在中间件层面，要么在应用层面），事务资源 本身对分布式事务是无感知的。<br><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/%E8%A1%A5%E5%81%BF%E5%9E%8B%E4%BA%8B%E5%8A%A1.png"></p>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul>
<li>分布式事务实现方案从ACID的角度上，分刚性事务、柔型事务。</li>
<li>刚性事务：通常无业务改造，强一致性，原生支持回滚&#x2F;隔离性，低并发，适合短事务;<br>柔性事务：有业务改造，最终一致性，实现补偿接口，实现资源锁定接口，高并发，适合长事务。</li>
<li>刚性事务满足ACID理论；柔性事务满足BASE理论（基本可用，最终一致）</li>
<li>刚性事务：XA 协议（2PC、JTA、JTS）、3PC；<br>柔型事务：TCC&#x2F;FMT、Saga（状态机模式、Aop模式）、本地事务消息、消息事务（半消息）。</li>
</ul>
<h3 id="柔性事务"><a href="#柔性事务" class="headerlink" title="柔性事务"></a>柔性事务</h3><ul>
<li>柔性事务（如分布式事务）为了满足可用性、性能与降级服务的需要，降低一致性（Consistency）与隔离性（Isolation）的要求，遵循 BASE 理论。</li>
<li>柔性事务也部分遵循 ACID 规范：<ol>
<li>原子性：严格遵循</li>
<li>一致性：事务完成后的一致性严格遵循；事务中的一致性可适当放宽</li>
<li>隔离性：并行事务间不可影响；事务中间结果可见性允许安全放宽</li>
<li>持久性：严格遵循</li>
</ol>
</li>
</ul>
<h3 id="柔性事务的分类"><a href="#柔性事务的分类" class="headerlink" title="柔性事务的分类"></a>柔性事务的分类</h3><p>柔性事务分为：两阶段型、补偿型、异步确保型、最大努力通知型。</p>
<ol>
<li>两阶段型 (这个并不算柔性事务，资源层，强一致性！)<br>分布式事务二阶段提交，对应技术上的 XA、JTA&#x2F;JTS，这是分布式环境下事务处理的典型模式。</li>
<li>补偿型<br>TCC 型事务（Try-Confirm-Cancel）可以归为补偿型。在 Try 成功的情况下，如果事务要回滚，Cancel 将作为一个补偿机制，回滚 Try 操作；TCC 各操作事务本地化，且尽早提交（没有两阶段约束）；当全局事务要求回滚时，通过另一个本地事务实现“补偿”行为。<br>TCC 是将资源层的二阶段提交协议转换到业务层，成为业务模型中的一部分。</li>
<li>异步确保型<br>将一些有同步冲突的事务操作变为异步操作，避免对数据库事务的争用，如消息事务机制。</li>
<li>最大努力通知型<br>通过通知服务器（消息通知）进行，允许失败，有补充机制。</li>
</ol>
<ul>
<li>针对不同的分布式场景业界常见的解决方案有2PC、TCC、可靠消息最终一致性、最大努力通知这几种。</li>
</ul>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li>JTA（Java Transaction API）：分布式事务的编程API，按照XA、DTP的模型和规范实现，在J2EE中，单库事务通过JDBC事务来支持，跨库事务通过JTA API来支持，通过JTA API可以协调和管理横跨多个数据库的分布式事务，一般来说会结合JNDI。</li>
</ul>
<h2 id="分布式事务解决方案"><a href="#分布式事务解决方案" class="headerlink" title="分布式事务解决方案"></a>分布式事务解决方案</h2><h3 id="本地消息服务方案-ebay"><a href="#本地消息服务方案-ebay" class="headerlink" title="本地消息服务方案(ebay)"></a>本地消息服务方案(ebay)</h3><ul>
<li><p>eBay 事件队列方案——最终一致性</p>
</li>
<li><p>eBay 的架构师Dan Pritchett，曾在一篇解释BASE 原理的论文《Base：An Acid Alternative》中提到一个eBay 分布式系统一致性问题的解决方案。它的核心思想是将需要分布式处理的任务通过消息或者日志的方式来异步执行，消息或日志可以存到本地文件、数据库或消息队列，再通过业务规则进行失败重试，它要求各服务的接口是幂等的。</p>
</li>
<li><p>(任务表，定时任务或人工自动重试)。</p>
</li>
<li><p>优点：</p>
<ul>
<li>消息的时效性比较高；</li>
<li>从应用设计的角度实现了消息数据的可靠性，消息数据的可靠性不依赖于MQ中间件，弱化了对MQ中间件特性的依赖；</li>
<li>方案轻量级，容易实现。</li>
</ul>
</li>
<li><p>缺点：</p>
<ul>
<li>与具体的业务场景绑定，耦合性强，不可以共用；</li>
<li>消息数据与业务数据同步，占用业务系统资源；</li>
<li>业务系统在使用关系型数据库的情况下消息服务性能会受到关系型数据库的并发性能限制。</li>
</ul>
</li>
<li><p>本地消息表:一种非常经典的实现，基本避免了分布式事务，实现了“最终一致性”。但是，关系型数据库的吞吐量和性能方面存在瓶颈，频繁的读写消息会给数据库造成压力。所以，在真正的高并发场景下，该方案也会有瓶颈和限制的。</p>
</li>
<li><p>其他类似方案：<a href="https://www.infoq.cn/article/b4VPvP3m8DA-PM7ZqMGZ">去哪儿网消息队列设计与实现</a></p>
</li>
<li><p><a href="https://insights.thoughtworks.cn/backend-development-eda/">事件驱动架构(EDA)编码实践</a> (事件表方式)</p>
</li>
</ul>
<h3 id="消息队列MQ事务"><a href="#消息队列MQ事务" class="headerlink" title="消息队列MQ事务"></a>消息队列MQ事务</h3><ul>
<li>2PC、3PC的时候我们说没有根本解决性能问题，而如果通过MQ的事务消息来进行异步解耦，并实现系统的数据的最终一致性的话会不会好很多呢？实际上这就是我们下一篇文章要继续讲述的《分布式事务之如何基于RocketMQ的事务消息特性实现分布式系统的最终一致性？:<a href="https://blog.csdn.net/u014532775/article/details/100830995">https://blog.csdn.net/u014532775/article/details/100830995</a></li>
</ul>
<h4 id="以支付系统为例"><a href="#以支付系统为例" class="headerlink" title="以支付系统为例"></a>以支付系统为例</h4><ol>
<li>上游服务（支付系统）如何确保完成自身支付成功状态更新后消息100%的能够投递到下游服务（用户余额系统）指定的Topic中？<br>1)在这个流程中上游服务在进行本地数据库事务操作前，会先发送一个状态为“待确认”的消息至可靠消息服务，而不是直接将消息投递到MQ服务的指定Topic。<br>2)之后上游服务就会开启本地数据库事务执行业务逻辑操作，这里支付系统就会将该笔支付订单状态更新为“已成功”。<br>3)如果上游服务本地数据库事务执行成功，则继续向可靠消息服务发送消息确认消息，此时可靠消息服务就会正式将消息投递到MQ服务，并且同时更新消息数据库中的消息状态为“已发送”。<br>4)相反，如果上游本地数据库事务执行失败，则需要向可靠消息服务发送消息删除消息，可靠消息服务此时就会将消息删除，这样就意味着事务在上游消息投递过程中就被回滚了，而流程也就此结束了<pre>
实现数据一致性是一个复杂的活。在这个方案中可靠消息服务作为基础性的服务除了执行正常的逻辑外，还得处理复杂的异常场景。在实现过程中可靠消息服务需要启动相应的后台线程，不断轮训消息的状态，这里会轮训消息状态为“待确认”的消息，并判断该消息的状态的持续时间是否超过了规定的时间，如果超过规定时间的消息还处于“待确认”的状态，就会触发上游服务状态询问机制。</pre></li>
</ol>
<p>可靠消息服务就会调用上游服务提供的相关借口，询问这笔消息的处理情况，如果这笔消息在上游服务处理成功，则后台线程就会继续触发上图中的步骤5，更新消息状态为“已发送”并投递消息至MQ服务；反之如果这笔消息上游服务处理失败，可靠消息服务则会进行消息删除。通过这样以上机制就确保了“上游服务本地事务成功处理+消息成功投递”处于一个原子操作了。<br><br>2. 下游服务（用户余额系统）如何确保对MQ服务Topic消息的消费100%都能处理成功？</p>
<pre>
在正常的流程中，下游服务等待消费Topic的消息并进行自身本地数据库事务的处理，如果处理成功则会主动通知可靠消息服务，可靠消息服务此时就会将消息的状态更新为“已完成”；反之，处理失败下游服务就无法再主动向可靠消息服务发送通知消息了。

此时，与消息投递过程中的异常逻辑一样，可靠消息服务也会启动相应的后台线程，轮询一直处于“已发送”状态的消息，判断状态持续时间是否超过了规定时间，如果超时，可靠消息服务就会再次向MQ服务投递此消息，从而确保消息能被再次消费处理。（注意，也可能出现下游服务处理成功，但是通知消息发送失败的情况，所以为了确保幂等，下游服务也需要在业务逻辑上做好相应的防重处理）。
</pre>

<ul>
<li><p>事实上，支付系统的数据一致性是一个复杂的问题，原因在于支付流程的各个环节都存在异步的不确定性，例如支付系统需要跟第三方渠道进行交互，不同的支付渠道交互流程存在差异，并且有异步支付结果回调的情况。</p>
</li>
<li><p>除此以外，支付系统内部本身又是由多个不同子系统组成，除核心支付系统外，还有账务系统、商户通知系统等等，而核心支付系统本身也会被拆分为多个不同的服务模块，如风控、路由等用以实现不同的功能逻辑。某些场景我们无法通过分布式事务来实现数据一致性，只能通过额外的业务补偿手段，如二次轮训、支付对账等来实现数据最终一致性。</p>
</li>
<li><p>综上所述，支付系统是一个复杂的系统，要完全实现数据的一致性单靠某一种手段是无法实现的，大部分情况下我们可以通过额外的业务补偿逻辑来实现数据最终一致性，只是这样补偿逻辑需要以更多的业务开发逻辑为代价，并且在时效性上会存在延迟的问题。</p>
</li>
<li><p>MQ（事务消息）(notify-两阶段提交加回调机制)－ RocketMQ</p>
</li>
</ul>
<p><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/%E6%AD%A3%E5%B8%B8%E6%83%85%E5%86%B5_%E4%BA%8B%E5%8A%A1%E4%B8%BB%E5%8A%A8%E6%96%B9%E5%8F%91%E6%B6%88%E6%81%AF.png"><br><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/%E5%BC%82%E5%B8%B8%E6%83%85%E5%86%B5_%E4%BA%8B%E5%8A%A1%E4%B8%BB%E5%8A%A8%E6%96%B9%E6%B6%88%E6%81%AF%E6%81%A2%E5%A4%8D.jpeg"></p>
<h4 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h4><ul>
<li><p>很像阿里的notify</p>
</li>
<li><p>事务发起方首先发送 prepare 消息到 MQ。<br>在发送 prepare 消息成功后执行本地事务。<br>根据本地事务执行结果返回 commit 或者是 rollback。<br>如果消息是 rollback，MQ 将删除该 prepare 消息不进行下发，如果是 commit 消息，MQ 将会把这个消息发送给 consumer 端。<br>如果执行本地事务过程中，执行端挂掉，或者超时，MQ 将会不停的询问其同组的其他 producer 来获取状态。<br>Consumer 端的消费成功机制有 MQ 保证。</p>
</li>
<li><p>从用户侧来说，用户需要分别实现本地事务执行以及本地事务回查方法，因此只需关注本地事务的执行状态即可；而在 service 层，则对事务消息的两阶段提交进行了抽象，同时针对超时事务实现了回查逻辑，通过不断扫描当前事务推进状态，来不断反向请求 Producer 端获取超时事务的执行状态，在避免事务挂起的同时，也避免了 Producer 端的单点故障。而在存储层，RocketMQ 通过 Bridge 封装了与底层队列存储的相关操作，用以操作两个对应的内部队列，用户也可以依赖其他存储介质实现自己的 service，RocketMQ 会通过 ServiceProvider 加载进来。<br>从上述事务消息设计中可以看到，RocketMQ 事务消息较好的解决了事务的最终一致性问题，事务发起方仅需要关注本地事务执行以及实现回查接口给出事务状态判定等实现，而且在上游事务峰值高时，可以通过消息队列，避免对下游服务产生过大压力。<br>事务消息不仅适用于上游事务对下游事务无依赖的场景，还可以与一些传统分布式事务架构相结合，而 MQ 的服务端作为天生的具有高可用能力的协调者，使得我们未来可以基于 RocketMQ 提供一站式轻量级分布式事务解决方案，用以满足各种场景下的分布式事务需求。</p>
</li>
<li><p>RocketMQ 阿里开源的消息中间件,原来叫做MetaQ; RocketMQ的各个环节,包括生产者,消费者,broker都是分布式的,所以基本可以保障由于网络原因丢掉,且RocketMQ存在重复消费的问题,所以文档明确表明了应该业务方自己实现幂等性.</p>
</li>
</ul>
<p><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/RocketMQ.png"></p>
<ul>
<li>Pulsar、RocketMQ、NSQ、RabbitMQ、Kafka TODO</li>
</ul>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><ul>
<li>如果由于上游程序bug，下游程序又有二次校验，会导致消息迟迟没消费成功而堆积。（如上游出仓，下游加分成等）</li>
</ul>
<h3 id="AT-自动模式"><a href="#AT-自动模式" class="headerlink" title="AT (自动模式)"></a>AT (自动模式)</h3><ul>
<li><p>AT 模式是一种无侵入的分布式事务解决方案。下面以Seata为例。</p>
</li>
<li><p>Seata实现了AT模式：<a href="http://seata.io/zh-cn/docs/dev/mode/at-mode.html">Seata AT 模式</a></p>
</li>
<li><p>在 AT 模式下，用户只需关注自己的“业务 SQL”，用户的 “业务 SQL” 作为一阶段，Seata 框架会自动生成事务的二阶段提交和回滚操作。</p>
</li>
<li><p>一阶段：Seata 会拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。</p>
</li>
<li><p>二阶段提交：因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。</p>
</li>
<li><p>二阶段回滚：Seata 需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就可能需要转人工处理。</p>
</li>
<li><p>写隔离<br>一阶段本地事务提交前，需要确保先拿到 全局锁 。<br>拿不到 全局锁 ，不能提交本地事务。<br>拿 全局锁 的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁。</p>
</li>
<li><p>读隔离<br>在数据库本地事务隔离级别 读已提交（Read Committed） 或以上的基础上，Seata（AT 模式）的默认全局隔离级别是 读未提交（Read Uncommitted） 。<br>如果应用在特定场景下，必需要求全局的 读已提交 ，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。</p>
</li>
</ul>
<h4 id="回滚"><a href="#回滚" class="headerlink" title="回滚"></a>回滚</h4><ul>
<li>如果要人工处理。不太适合金钱业务，因为“after image”基本都是在变的。</li>
<li>官方回答：<pre>
Q: 5.脏数据回滚失败如何处理?
A:
1.脏数据需手动处理，根据日志提示修正数据或者将对应undo删除（可自定义实现FailureHandler做邮件通知或其他）
2.关闭回滚时undo镜像校验，不推荐该方案。</pre></li>
</ul>
<p>注：建议事前做好隔离保证无脏数据<br></p>
<ul>
<li>实践验证：TODO</li>
</ul>
<h3 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h3><ul>
<li>TCC（Try-Confirm-Cancel）的概念来源于 Pat Helland 发表的一篇名为“Life beyond Distributed Transactions:an Apostate’s Opinion”的论文。</li>
<li>TCC 提出了一种新的事务模型，基于业务层面的事务定义，锁粒度完全由业务自己控制，目的是解决复杂业务中，跨表跨库等大颗粒度资源锁定的问题。TCC 把事务运行过程分成 Try、Confirm &#x2F; Cancel 两个阶段，每个阶段的逻辑由业务代码控制。</li>
<li>Try 阶段失败可以 Cancel，如果 Confirm 和 Cancel 阶段失败了怎么办？<ul>
<li>TCC 中会添加事务日志，如果 Confirm 或者 Cancel 阶段出错，则会进行重试，所以这两个阶段需要支持幂等；如果重试失败，则需要人工介入进行恢复和处理等。</li>
</ul>
</li>
<li>相对于 AT 模式，TCC 模式对业务代码有一定的侵入性，但是 TCC 模式无 AT 模式的全局行锁，TCC 性能会比 AT 模式高很多。</li>
<li>关键属性：应用层面的两阶段操作(应用的侵入性非常强，实现成本高), 强隔离性（预提交校验），性能并非最佳。</li>
</ul>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol>
<li>解决了跨服务的业务操作原子性问题，例如组合支付、下订单减库存等场景非常实用</li>
<li>TCC的本质原理是把数据库的二阶段提交上升到微服务来实现，从而避免数据库二阶段中锁冲突的长事务引起的低性能风险</li>
<li>TCC异步高性能，它采用了try先检查，然后异步实现confirm，真正提交是在confirm方法中。</li>
</ol>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol>
<li>对微服务的侵入性强，微服务的每个事务都必须实现try、confirm、cancel等3个方法，开发成本高，今后维护改造的成本也高</li>
<li>为了达到事务的一致性要求，try、confirm、cancel接口必须实现幂等性操作</li>
<li>由于事务管理器要记录事务日志，必定会损耗一定的性能，并使得整个TCC事务时间拉长，可以考虑采用Redis的方式来记录事务日志</li>
</ol>
<h4 id="实践经验"><a href="#实践经验" class="headerlink" title="实践经验"></a>实践经验</h4><ul>
<li>蚂蚁金服TCC实践,总结以下注意事项:<pre>
➢业务模型分2阶段设计
➢并发控制
➢允许空回滚
➢防悬挂控制
➢幂等控制
</pre></li>
</ul>
<ol>
<li>允许空回滚<ul>
<li>Cancel 接口设计时需要允许空回滚。在 Try 接口因为丢包时没有收到，事务管理器会触发回滚，这时会触发 Cancel 接口，这时 Cancel 执行时发现没有对应的事务 xid 或主键时，需要返回回滚成功。让事务服务管理器认为已回滚，否则会不断重试，而 Cancel 又没有对应的业务数据可以进行回滚。</li>
</ul>
</li>
</ol>
<p><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/%E5%85%81%E8%AE%B8%E7%A9%BA%E5%9B%9E%E6%BB%9A.png"></p>
<ol start="2">
<li>防悬挂控制<ul>
<li>悬挂的意思是：Cancel 比 Try 接口先执行，出现的原因是 Try 由于网络拥堵而超时，事务管理器生成回滚，触发 Cancel 接口，而最终又收到了 Try 接口调用，但是 Cancel 比 Try 先到。按照前面允许空回滚的逻辑，回滚会返回成功，事务管理器认为事务已回滚成功，则此时的 Try 接口不应该执行，否则会产生数据不一致，所以我们在 Cancel 空回滚返回成功之前先记录该条事务 xid 或业务主键，标识这条记录已经回滚过，Try 接口先检查这条事务xid或业务主键如果已经标记为回滚成功过，则不执行 Try 的业务操作。</li>
</ul>
</li>
</ol>
<p><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/%E9%98%B2%E6%82%AC%E6%8C%82%E6%8E%A7%E5%88%B6.png"></p>
<h3 id="Saga-‘sɑɡə"><a href="#Saga-‘sɑɡə" class="headerlink" title="Saga [‘sɑɡə]"></a>Saga [‘sɑɡə]</h3><ul>
<li><p>Saga 理论出自 Hector &amp; Kenneth 1987发表的论文 Sagas。Saga 模式是一种长事务解决方案。</p>
</li>
<li><p>Saga 是一种补偿协议，在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。</p>
</li>
<li><p>分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。</p>
</li>
<li><p>Saga 正向服务与补偿服务也需要业务开发者实现。因此是业务入侵的。</p>
</li>
<li><p>Saga可以看做一个异步的、利用队列实现的补偿事务。Saga 模式下分布式事务通常是由事件驱动的，各个参与者之间是异步执行。</p>
</li>
<li><p>使用 Saga 模式开发分布式事务时，有两种协调不同服务的方式，一种是协同（Choreography），另一种是编排（Orchestration）</p>
<ol>
<li>选择使用协同的方式处理事务时，服务之间的通信其实就是通过事件进行的，每一个本的事务最终都会向服务的下游发送一个新的事件，既可以是消息队列中的消息，也可以是 RPC 的请求，只是下游提供的接口需要保证幂等和重入</li>
<li>编排的方式引入了中心化的协调器节点，我们通过一个 Saga 对象来追踪所有的子任务的调用情况，根据任务的调用情况决定是否需要调用对应的补偿方案，并在网络请求出现超时时进行重试</li>
</ol>
<ul>
<li>(下游约束)使用 Saga 对分布式事务进行开发时，会对分布式事务的参与者有一定的约束，每一个事务的参与者都需要保证：<ol>
<li>提供接口和补偿副作用的接口；</li>
<li>接口支持重入并通过全局唯一的 ID 保证幂等</li>
</ol>
</li>
</ul>
</li>
<li><p>Saga定义了两种恢复策略：</p>
<ol>
<li>向后恢复，对整个Saga的执行结果撤销。</li>
<li>向前恢复，适用于必须要成功的场景。</li>
</ol>
</li>
<li><p>使用 Saga 实现分布式事务的优点有：</p>
<ul>
<li><strong>微服务架构：</strong>通过对一些基础服务进行组合 &#x2F; 编排来完成各种业务需求。</li>
<li><strong>数据库兼容性高：</strong>对每个服务使用何种数据库技术没有任何要求，服务甚至可以不使用数据库。</li>
</ul>
</li>
<li><p>使用 Saga 实现分布式事务的缺点有：</p>
<ul>
<li><strong>要求服务提供补偿接口：</strong>增加了开发和维护的成本。</li>
<li><strong>不符合 ACID：</strong>没有涉及 Isolation 和 Durability。</li>
</ul>
</li>
<li><p>Saga 从流程上，还可分为两种模式：Orchestration（交响乐）和 Choreography（齐舞）。</p>
</li>
<li><p>关键：每一个参与者都是一个冲正补偿服务、异步。</p>
</li>
<li><p>关键定义：补偿式事务的 Saga</p>
</li>
<li><p>关键属性：性能较好，隔离性较差</p>
</li>
</ul>
<h4 id="方案例子"><a href="#方案例子" class="headerlink" title="方案例子"></a>方案例子</h4><ol>
<li>Ebay提出的基于消息表，即可靠消息最终一致模型，但本质上这也属于Saga模式的一种特定实现。</li>
<li>消息队列MQ事务(可靠消息)(支持事务的消息中间件) <ul>
<li>Apache开源的RocketMQ中间件能够支持一种事务消息机制，确保本地操作和发送消息的异步处理达到本地事务的结果一致。</li>
</ul>
</li>
<li>Saga Orchestration（引入了类似 XA 中的协调者的角色，来驱动整个流程）；基于 Saga Orchestration 和 Kafka 的分布式事务：<a href="https://mp.weixin.qq.com/s/o11kXLV94hUn9YylcQ2ayA">微服务中台技术解析之分布式事务方案和实践</a></li>
</ol>
<h4 id="Saga详细说明"><a href="#Saga详细说明" class="headerlink" title="Saga详细说明"></a>Saga详细说明</h4><ul>
<li>最直接的方法就是按照逻辑依次调用服务，但出现异常怎么办?那就对那些已经成功的进行补偿，补偿成功就一致了，这种朴素的模型就是Saga。但Saga这种方式并不能保证隔离性，于是出现了TCC。在实际交易逻辑前先做业务检查、对涉及到的业务资源进行“预留”，或者说是一种“中间状态”，如果都预留成功则完成这些预留资源的真正业务处理，典型的如票务座位等场景。</li>
<li>当然还有像Ebay提出的基于消息表，即可靠消息最终一致模型，但本质上这也属于Saga模式的一种特定实现，它的关键点有两个：<br>基于应用共享事务记录执行轨迹；<br>然后通过异步重试确保交易最终一致（这也使得这种方式不适用那些业务上允许补偿回滚的场景）。</li>
<li>仔细对比这些方案与XA，会发现这些方案本质上都是将两阶段提交从资源层提升到了应用层。</li>
</ul>
<ol>
<li>Saga的核心就是补偿，一阶段就是服务的正常顺序调用（数据库事务正常提交），如果都执行成功，则第二阶段则什么都不做；但如果其中有执行发生异常，则依次调用其补偿服务（一般多逆序调用未已执行服务的反交易）来保证整个交易的一致性。应用实施成本一般。</li>
<li>TCC的特点在于业务资源检查与加锁，一阶段进行校验，资源锁定，如果第一阶段都成功，二阶段对锁定资源进行交易逻辑，否则，对锁定资源进行释放。应用实施成本较高。</li>
<li>基于可靠消息最终一致，一阶段服务正常调用，同时同事务记录消息表，二阶段则进行消息的投递，消费。应用实施成本较低。</li>
</ol>
<h4 id="Saga-模式使用场景"><a href="#Saga-模式使用场景" class="headerlink" title="Saga 模式使用场景"></a>Saga 模式使用场景</h4><ul>
<li>Saga 模式适用于业务流程长且需要保证事务最终一致性的业务系统，Saga 模式一阶段就会提交本地事务，无锁、长流程情况下可以保证性能。</li>
<li>事务参与者可能是其它公司的服务或者是遗留系统的服务，无法进行改造和提供 TCC 要求的接口，可以使用 Saga 模式。</li>
</ul>
<h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><ul>
<li>一阶段提交本地数据库事务，无锁，高性能；</li>
<li>参与者可以采用事务驱动异步执行，高吞吐；</li>
<li>补偿服务即正向服务的“反向”，易于理解，易于实现；</li>
</ul>
<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>Saga 模式由于一阶段已经提交本地数据库事务，且没有进行“预留”动作，所以不能保证隔离性。</li>
</ul>
<h4 id="实践经验-1"><a href="#实践经验-1" class="headerlink" title="实践经验"></a>实践经验</h4><ul>
<li>与TCC实践经验相同的是，Saga 模式中，每个事务参与者的冲正、逆向操作，需要支持：<ul>
<li>空补偿：逆向操作早于正向操作时；</li>
<li>防悬挂控制：空补偿后要拒绝正向操作</li>
<li>幂等</li>
</ul>
</li>
</ul>
<h4 id="注意-1"><a href="#注意-1" class="headerlink" title="注意"></a>注意</h4><ul>
<li>这里要注意的是，在Saga模式中不能保证隔离性，因为没有锁住资源，其他事务依然可以覆盖或者影响当前事务。隔离性导致在金钱业务的情景中，可能出现”不够扣”的情况（给用户加钱之后，无法撤销，因为被用户花完了）。</li>
</ul>
<h3 id="XA-eXtended-Architecture"><a href="#XA-eXtended-Architecture" class="headerlink" title="XA (eXtended Architecture)"></a>XA (eXtended Architecture)</h3><ul>
<li>XA 规范 是 X&#x2F;Open 组织定义的分布式事务处理（DTP，Distributed Transaction Processing）标准。</li>
<li>XA协议由Tuxedo首先提出的，并交给X&#x2F;Open组织，作为资源管理器（数据库）与事务管理器的接口标准。XA 规范主要定义了事务协调者（Transaction Manager）和资源管理器（Resource Manager）之间的接口。</li>
<li>XA则规范了TM与RM之间的通信接口，在TM与多个RM之间形成一个双向通信桥梁，从而在多个数据库资源下保证ACID四个特性。</li>
<li>TM和RM之间使用2PC协议。在XA规范的描述中，2PC是TM协调RM们完成已定义的全局事务的方法，AP找TM申请&#x2F;注册全局事务的动作并不是二阶段提交的保障内容。</li>
<li>目前MySQL中只有InnoDB存储引擎支持XA协议。<ul>
<li><a href="https://dev.mysql.com/doc/refman/5.7/en/xa.html">https://dev.mysql.com/doc/refman/5.7/en/xa.html</a></li>
</ul>
</li>
<li>XA模式下的 开源框架有atomikos，其开发公司也有商业版本。</li>
<li>优点：<ul>
<li><strong>强一致性：</strong>实现了数据在多个数据库上的强一致提交。</li>
<li><strong>业务侵入性小：</strong>完全靠数据库本身的支持实现分布式事务，不需要改动业务逻辑。</li>
</ul>
</li>
<li>缺点：<ul>
<li><strong>单点故障：</strong>协调者或者任意一个 XA 数据库都是能引起故障的单点（Single point of failure)。</li>
<li><strong>低性能：</strong>支持 XA 特性的数据库在设计上有大量的阻塞和资源占位操作， 数据体量和吞吐量扩展性差。</li>
<li><strong>数据库选型限制：</strong>对于服务的数据库选型引入了支持 XA 协议这个限制。</li>
</ul>
</li>
<li>XA 在设计上没有考虑到分布式系统的特点，事实上是一个强一致、低可用的设计方案，对网络分隔的容忍度较差。</li>
<li>XA模式缺点：事务粒度大。高并发下，系统可用性低。因此很少使用。</li>
<li>关键属性：DB层面（资源层）</li>
</ul>
<h4 id="Seata-的XA模式"><a href="#Seata-的XA模式" class="headerlink" title="Seata 的XA模式"></a>Seata 的XA模式</h4><ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/163335038">分布式事务如何实现？深入解读 Seata 的 XA 模式</a></p>
</li>
<li><p>Seata 已经支持的 3 大事务模式：AT、TCC、Saga 都是 补偿型 的。</p>
</li>
<li><p>补偿型 事务处理机制构建在 事务资源 之上（要么在中间件层面，要么在应用层面），事务资源 本身对分布式事务是无感知的。</p>
</li>
<li><p>事务资源 对分布式事务的无感知存在一个根本性的问题：无法做到真正的 全局一致性 。</p>
</li>
<li><p>Seata 1.2.0 版本重磅发布新的事务模式：XA 模式，实现对 XA 协议的支持。</p>
</li>
<li><p>XA 的价值：与 补偿型 不同，XA 协议 要求 事务资源 本身提供对规范和协议的支持。因为 事务资源 感知并参与分布式事务处理过程，所以 事务资源（如数据库）可以保障从任意视角对数据的访问有效隔离，满足全局数据一致性。</p>
</li>
<li><p>除了 全局一致性 这个根本性的价值外，支持 XA 还有如下几个方面的好处：</p>
<ol>
<li>业务无侵入：和 AT 一样，XA 模式将是业务无侵入的，不给应用设计和开发带来额外负担。</li>
<li>数据库的支持广泛：XA 协议被主流关系型数据库广泛支持，不需要额外的适配即可使用。</li>
<li>多语言支持容易：因为不涉及 SQL 解析，XA 模式对 Seata 的 RM 的要求比较少，为不同语言开发 SDK 较之 AT 模式将更 薄，更容易。</li>
<li>传统基于 XA 应用的迁移：传统的，基于 XA 协议的应用，迁移到 Seata 平台，使用 XA 模式将更平滑。</li>
</ol>
</li>
<li><p>从编程模型上，XA 模式与 AT 模式保持完全一致。上层编程模型与 AT 模式完全相同。只需要修改数据源代理，即可实现 XA 模式与 AT 模式之间的切换。</p>
</li>
</ul>
<p><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/Seata.jpg"></p>
<h3 id="最大努力通知型"><a href="#最大努力通知型" class="headerlink" title="最大努力通知型"></a>最大努力通知型</h3><ul>
<li>回调客户端确认：支付宝会每间隔一段时间后，再向客户方发起回调请求，直到输出成功标识为止。</li>
</ul>
<h3 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h3><ol>
<li>为了交易系统更可靠，我们一般会在类似交易这种高级别的服务代码中，加入详细日志记录的，一旦系统内部引发类似致命异常（如超时情况），会有邮件通知。同时，后台会有定时任务扫描和分析此类日志，检查出这种特殊的情况，会尝试通过程序来补偿并邮件通知相关人员。</li>
<li>在某些特殊的情况下，还会有“人工补偿”的，这也是最后一道屏障。</li>
</ol>
<h2 id="Seata"><a href="#Seata" class="headerlink" title="Seata"></a>Seata</h2><ul>
<li>阿里开源分布式事务解决方案 Fescar:<a href="https://mp.weixin.qq.com/s/TFGRcHV6EgeLB45OEJPRXw">https://mp.weixin.qq.com/s/TFGRcHV6EgeLB45OEJPRXw</a></li>
<li><a href="https://github.com/seata/seata">https://github.com/seata/seata</a></li>
<li><a href="https://seata.io/zh-cn/docs/overview/what-is-seata.html">https://seata.io/zh-cn/docs/overview/what-is-seata.html</a></li>
</ul>
<h3 id="四种模式分析"><a href="#四种模式分析" class="headerlink" title="四种模式分析"></a>四种模式分析</h3><p>四种分布式事务模式，分别在不同的时间被提出，每种模式都有它的适用场景</p>
<ol>
<li>AT 模式是无侵入的分布式事务解决方案，适用于不希望对业务进行改造的场景，几乎0学习成本。</li>
<li>TCC 模式是高性能分布式事务解决方案，适用于核心系统等对性能有很高要求的场景。</li>
<li>Saga 模式是长事务解决方案，适用于业务流程长且需要保证事务最终一致性的业务系统，Saga 模式一阶段就会提交本地事务，无锁，长流程情况下可以保证性能，多用于渠道层、集成层业务系统。事务参与者可能是其它公司的服务或者是遗留系统的服务，无法进行改造和提供 TCC 要求的接口，也可以使用 Saga 模式。</li>
<li>XA模式是分布式强一致性的解决方案，但性能低而使用较少。</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>金钱业务的冻结&amp;结算 接口，其实就是TCC模式，而消费&amp;退款 就是Saga模式。</li>
<li>数据库事务对应刚性事务，以XA模式为例；业务事务对应柔性事务，以TCC，Saga，AT模式为例。</li>
<li>2PC一般是分布式事务的基础协议，具有普适性。</li>
<li>要多考虑“防悬挂控制“、”允许空回滚“。</li>
</ol>
<h3 id="分类归纳"><a href="#分类归纳" class="headerlink" title="分类归纳"></a>分类归纳</h3><ol>
<li><p>分布式事务两种大分类</p>
<ol>
<li>按模式分类：XA、AT、TCC、Saga。</li>
<li>按柔性事务分类：补偿型、异步确保型、最大努力通知型。</li>
</ol>
</li>
<li><p>补偿型(资源之上－业务层或中间件)：AT、TCC、Saga。</p>
</li>
<li><p>业务无侵入：XA、AT；业务侵入：TCC、Saga。</p>
</li>
<li><p>性能：Saga &gt; TCC&gt; XA、AT。</p>
</li>
<li><p>隔离型：XA&gt;TCC、AT&gt;Saga。</p>
</li>
<li><p>刚性事务满足ACID理论；柔性事务满足BASE理论（基本可用，最终一致）。</p>
</li>
<li><p>刚性事务：XA；柔性事务：AT、TCC、Saga。</p>
</li>
<li><p>异步确保型（可靠消息最终一致性）：本地消息服务方案(ebay)、消息队列MQ事务；异步回调：最大努力通知型。</p>
</li>
<li><p>Saga：普通RPC重试、异步确保型（主动）、异步回调（被动）。(异步只是提升性能的一种方式)</p>
</li>
<li><p>总结</p>
<ol>
<li>一致性保证：XA &gt; TCC &#x3D; SAGA &gt; 事务消息</li>
<li>业务友好性：XA &gt; 事务消息 &gt; SAGA &gt; TCC</li>
<li>性能损耗：XA &gt; TCC &gt; SAGA &#x3D; 事务消息</li>
</ol>
</li>
<li><p>分布式事务的解决方案都很难做到有高一致性的同时，也有高性能，同时在实现上也有一定的难度。在业务允许的情况下，我们通常处理分布式事务的一般原则应是：业务规避 &gt; 最终一致 &gt; 强一致。</p>
</li>
</ol>
<h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><h3 id="XA跟2PC什么关系？"><a href="#XA跟2PC什么关系？" class="headerlink" title="XA跟2PC什么关系？"></a>XA跟2PC什么关系？</h3><ol>
<li>XA规范中2PC是TM协调RM的方式。</li>
</ol>
<h3 id="XA-VS-TCC"><a href="#XA-VS-TCC" class="headerlink" title="XA VS TCC"></a>XA VS TCC</h3><ol start="0">
<li>XA是数据库的2PC，TCC是业务层的2PC</li>
<li>XA是数据库的分布式事务，强一致性，在整个过程中，数据一张锁住状态，即从prepare到commit、rollback的整个过程中，TM一直把持着数据库的锁，如果有其他人要修改数据库的该条数据，就必须等待锁的释放，存在长事务风险。</li>
<li>TCC是业务的分布式事务，最终一致性，不会出现长事务的锁风险，try是本地事务，锁定资源后就提交事务，confirm／cancel也是本地事务，可以直接提交事务，所以多个短事务不会出现长事务的风险。</li>
</ol>
<p><img src="/2020/09/12/20200912-fen-bu-shi-shi-wu-jian-yao-zong-jie/XA_TCC.png"></p>
<h3 id="XA如何在分布式事务中如何保证隔离性？"><a href="#XA如何在分布式事务中如何保证隔离性？" class="headerlink" title="XA如何在分布式事务中如何保证隔离性？"></a>XA如何在分布式事务中如何保证隔离性？</h3><ol>
<li>由RM直接连接各个数据源(支持XA协议)，RM一般是个单独的服务？</li>
<li>后续通过Seata的XA模式深入了解TODO</li>
</ol>
<h3 id="分布式事务一致性与Paxos一致性的思考"><a href="#分布式事务一致性与Paxos一致性的思考" class="headerlink" title="分布式事务一致性与Paxos一致性的思考"></a>分布式事务一致性与Paxos一致性的思考</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/zp1kJ895zBb9vA7fgJ20eQ">聊一聊分布式事务</a></li>
<li>分布式事务解决方案，如TCC、Saga、本地消息表等，其本质都是2PC。</li>
<li>Paxos算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。</li>
<li>2PC和Paxos都是解决关于“一致性”的问题，其实细想它们解决的问题不在一个层面。<ul>
<li>2PC要求分布式系统中的每个节点要不全部成功，要不全部失败，强调的是原子性。</li>
<li>Paxos要求多个副本之间的数据一致性，其实这里用“一致性”并不准确，应该用“共识（Consensus）”才对。例如2PC中的协调者单点的问题可以用Paxos算法通过选举出新的协调者来解决。</li>
</ul>
</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ol>
<li><a href="https://developer.aliyun.com/article/598758">GTS-阿里巴巴全新分布式事务解决方案</a><ul>
<li>GTS既不在资源层也不在应用层，它是在中间件层解决事务的问题，这是它们本质的区别。</li>
<li>GTS有两个使用模式，AT和MT。AT是自动模式，可以完全自动回滚，可以覆盖90%左右的业务场景，所以比较推荐使用AT模式，它对业务无侵入，高效，强一致性。还有一种MT模式是GTS推出的兼容TCC的模式，因为有一些情况下是无法避免的要使用TCC模式。</li>
<li>强一致？感觉不是。</li>
</ul>
</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://ld246.com/article/1588748307781">XA 规范与 TCC 事务模型</a></li>
<li><a href="https://www.jianshu.com/p/d9e4982384a2">分布式事务（4）XA规范</a></li>
<li><a href="https://www.jianshu.com/p/6c1fd2420274">初识Open&#x2F;X XA</a></li>
<li><a href="https://publications.opengroup.org/c193">Distributed Transaction Processing: The XA Specification</a></li>
<li><a href="https://www.cnblogs.com/agilestyle/p/11623047.html">TCC、XA 、DTP区别</a></li>
<li><a href="https://ld246.com/article/1588748307781">XA 规范与 TCC 事务模型</a></li>
<li><a href="https://help.aliyun.com/document_detail/132895.html">柔性事务的定义与分类</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/48586408">MySQL 中基于 XA 实现的分布式事务</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/78599954">分布式事务的4种模式</a> </li>
<li><a href="https://zhuanlan.zhihu.com/p/163335038">分布式事务如何实现？深入解读 Seata 的 XA 模式</a></li>
<li><a href="https://www.sohu.com/a/336224977_673711">讲清楚分布式事务选型：XA、2PC、TCC、Saga、阿里Seata</a></li>
<li><a href="https://mp.weixin.qq.com/s/jQrPSmPhC_yNbIRcufR8KQ">分布式事务：深入理解什么是2PC、3PC及TCC协议</a></li>
<li><a href="http://mp.weixin.qq.com/s/ROVuCPr2Rg3G1m_daYu-Vg">一种提高微服务架构的稳定性与数据一致性的方法</a></li>
<li><a href="http://www.infoq.com/cn/articles/solution-of-distributed-system-transaction-consistency">分布式系统事务一致性解决方案</a></li>
<li><a href="https://blog.51cto.com/xvjunjie/2420402">分布式事务中的三种解决方案详解</a></li>
<li><a href="https://draveness.me/distributed-transaction-principle">分布式事务的实现原理</a></li>
<li><a href="https://mp.weixin.qq.com/s/omtkduEIZxVIIgkdTlzzSQ">关于如何实现一个TCC分布式事务框架的一点思考</a></li>
<li><a href="https://www.sohu.com/a/295542601_505827">还不理解“分布式事务”？这篇给你讲清楚！</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&mid=2247488985&amp;idx=1&amp;sn=cafd8ce4b47bf098c7e87846318eff4d&source=41#wechat_redirect">RocketMQ 4.3正式发布，支持分布式事务</a></li>
<li><a href="https://insights.thoughtworks.cn/backend-development-eda/">事件驱动架构(EDA)编码实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/o11kXLV94hUn9YylcQ2ayA">微服务中台技术解析之分布式事务方案和实践</a></li>
</ul>
]]></content>
      <tags>
        <tag>分布式事务</tag>
        <tag>TCC</tag>
        <tag>Saga</tag>
        <tag>XA</tag>
        <tag>Seata</tag>
      </tags>
  </entry>
  <entry>
    <title>Java11基础原理和实践</title>
    <url>/2022/02/08/20220208-java11-ji-chu-yuan-li-he-shi-jian/</url>
    <content><![CDATA[<h1 id="一、为什么选择java11"><a href="#一、为什么选择java11" class="headerlink" title="一、为什么选择java11"></a>一、为什么选择java11</h1><p>Java 11 是 Java 8 之后的首个 LTS 版本（Long-term support 长期支持版本），所以有不少开发者表示会选择升级至 Java 11。</p>
<p><img src="/2022/02/08/20220208-java11-ji-chu-yuan-li-he-shi-jian/java11.png"></p>
<p>1、目前相对来说，Java 8 太旧，Java 17 太新，Java11 刚刚好；<br>2、支持以类路径方式运行，适合过渡阶段升级；<br>3、其他原因（下文会说明）</p>
<h1 id="二、模块系统"><a href="#二、模块系统" class="headerlink" title="二、模块系统"></a>二、模块系统</h1><p>模块系统是Java 9的旗舰功能，使用java9，有必要了解一下。</p>
<h2 id="java9之前存在哪些痛点"><a href="#java9之前存在哪些痛点" class="headerlink" title="java9之前存在哪些痛点"></a>java9之前存在哪些痛点</h2><h3 id="1、没有封装"><a href="#1、没有封装" class="headerlink" title="1、没有封装"></a>1、没有封装</h3><p>类一旦公开，意味着没有封装。</p>
<p>如果将一个类设置为protected，那么就可以防止其他类访问该类，除非这些类与该类位于相同的包中。但这样做会产生一个有趣的问题：如果想从组件的另一个包中访问该类，同时仍然防止其他类使用该类，那么应该怎么做呢？事实是无法做到。</p>
<p>让类公开，意味着对系统中的所有类型都是公开的，也就意味着没有封装。</p>
<p>Java在过去经历过相当多的安全漏洞。这些漏洞都有一个共同的特点：不知何故，攻击者可以绕过JVM的安全沙盒并访问JDK中的敏感类。从安全的角度来看，在JDK中对危险的内部类进行强封装是一个很大的改进。同时，减少运行时中可用类的数量会降低攻击面。在应用程序运行时中保留大量暂时不使用的类是一种不恰当的做法。而通过使用模块化JDK，可以确定应用程序所需的模块。</p>
<h3 id="2、编译时无法感知依赖缺失或类重复"><a href="#2、编译时无法感知依赖缺失或类重复" class="headerlink" title="2、编译时无法感知依赖缺失或类重复"></a>2、编译时无法感知依赖缺失或类重复</h3><p>Java确实使用了显式的import语句。但不幸的是，从严格意义上讲，这些导入是编译时结构，一旦将代码打包到JAR中，就无法确定哪些JAR包含当前JAR运行所需的类型。</p>
<p>在Java 9出现之前，JAR文件似乎是最接近模块的，它们拥有名称、对相关代码进行了分组并且提供了定义良好的公共接口。</p>
<p>（1）依赖缺失<br>所有类按照-classpath参数定义的顺序加载类。由于类会延迟加载，JVM无法在应用程序启动时有效地验证类路径的完整性，即无法预先知道类路径是否是完整的，或者是否应该添加另一个JAR。</p>
<p>（2）类重复<br>当类路径上有重复类时，则会出现更为隐蔽的问题。出现相同库的两个版本（如Guava 19和Guava 18）是非常常见的，这两个库JAR以一种未定义的顺序压缩到类路径中。库类的任一版本都可能会被首先加载。此外，有些类还可能会使用来自（可能不兼容的）其他版本的类。此时就会导致运行时异常。</p>
<h2 id="关于类重复"><a href="#关于类重复" class="headerlink" title="关于类重复"></a>关于类重复</h2><p>目前存在以下方法缓解或解决</p>
<h3 id="1、通过插件检查类重复"><a href="#1、通过插件检查类重复" class="headerlink" title="1、通过插件检查类重复"></a>1、通过插件检查类重复</h3><p>在编译时，检测类是否重复，比如使用插件 maven enforcer plugin，但本质上是通过解压全部jar包，检查所有文件是否存在重复类来判断的，效率可想而知。</p>
<h3 id="2、通过构建工具保证只存在一个版本的jar包"><a href="#2、通过构建工具保证只存在一个版本的jar包" class="headerlink" title="2、通过构建工具保证只存在一个版本的jar包"></a>2、通过构建工具保证只存在一个版本的jar包</h3><p>构建工具冲突失败策略设置如gradle中</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="keyword">configurations</span>.all &#123;</span><br><span class="line">    resolutionStrategy &#123;  failOnVersionConflict() &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这种设置仅仅是针对jar包冲突，不能保证不同名的jar包是否存在相同的类。</p>
<p>处理jar包冲突有两种策略：</p>
<p>1）强制指定版本：版本冲突太多，指定版本的情况，后续有新的版本间接依赖也无法直接发现。<br>2）取最高版本：同样有可能引起高版本导致不兼容的问题。</p>
<p>要彻底解决，只有项目依赖完全模块化。</p>
<h2 id="构建工具"><a href="#构建工具" class="headerlink" title="构建工具"></a>构建工具</h2><p>Maven、Gradle等构建工具，在运行时没有任何作用。Maven构建了想要运行的工件，但是最后仍然需要配置Java运行时，以便运行正确的模块路径和类路径。虽然手动配置模块路径比类路径要容易得多，但它仍然是重复的工作，因为相关信息已经在pom.xml文件中了。</p>
<h2 id="模块化的好处"><a href="#模块化的好处" class="headerlink" title="模块化的好处"></a>模块化的好处</h2><p>模块化 可以 在编译时和运行时获得所有这些信息所带来的优势。这可以防止对来自其他非引用模块的代码的意外依赖。通过检查（传递）依赖关系，工具链可以知道运行模块需要哪些附加模块并进行优化。</p>
<p>Java平台模块系统带来了如下最重要的好处：</p>
<p>1．可靠的配置在编译或运行代码之前，模块系统会检查给定的模块组合是否满足所有依赖关系，从而导致更少的运行时错误。<br>2．强封装型模块显式地选择了向其他模块公开的内容，从而防止对内部实现细节的意外依赖。<br>3．可扩展开发显式边界能够让开发团队并行工作，同时可创建可维护的代码库。只有显式导出的公共类型是共享的，这创建了由模块系统自动执行的边界。<br>4．安全性在JVM的最深层次上执行强封装，从而减少Java运行时的攻击面，同时无法获得对敏感内部类的反射访问。<br>5．优化由于模块系统知道哪些模块是在一起的，包括平台模块，因此在JVM启动期间不需要考虑其他代码。同时，其也为创建模块分发的最小配置提供了可能性。此外，还可以在一组模块上应用整个程序的优化。</p>
<p>在模块出现之前，这样做是非常困难的，因为没有可用的显式依赖信息，一个类可以引用类路径中任何其他类。</p>
<p>此外还有：<br>（1）JDK9的模块化可以减少Java程序打包的体积，同时拥有更好的隔离线与封装性。<br>在JDK9之前，JVM的基础类以前都是在rt.jar这个包里，这个包也是JRE运行的基石。这不仅是违反了单一职责原则，同样程序在编译的时候会将很多无用的类也一并打包，造成臃肿。在JDK9中，整个JDK都基于模块化进行构建，以前的rt.jar, tool.jar被拆分成数十个模块，编译的时候只编译实际用到的模块，同时各个类加载器各司其职，只加载自己负责的模块。<br>（2）经过破坏后的双亲委派模型更加高效，减少了很多类加载器之间不必要的委派操作</p>
<h2 id="模块系统的基础"><a href="#模块系统的基础" class="headerlink" title="模块系统的基础"></a>模块系统的基础</h2><p>本质上就是一个jar包切成多模块（更细的jar包）来引用</p>
<h3 id="1、module-info-java描述文件-关键字说明"><a href="#1、module-info-java描述文件-关键字说明" class="headerlink" title="1、module-info.java描述文件 关键字说明"></a>1、module-info.java描述文件 关键字说明</h3><p>requires代表依赖的模块，只有依赖的模块存在才能通过编译并运行.需要注意的是，所有模块均自动隐式依赖java.base模块，不需要显示声明<br>exports指出需要暴露的包，如果某个包没有被exports，那么其他模块是无法访问的。</p>
<p>Readability:指的是必须exports的包才可被其他模块访问<br>Accessibility:指的是即使是exports的包，其中的类的可访问下也要基于java的访问修饰符，仅有public修饰的才可被其他模块访问</p>
<p>Implied Readability(隐式Readability, requires transitive):<br>Readability默认情况下是不会被传递的<br>requires transitive，传递性依赖生效</p>
<p>由于requires transitive的存在，就可以支持聚合模块。有些聚合模块可以没有任何代码，就一个module-info.java描述文件，比如java.se, java.se.ee模块<br>不建议直接引用java.se模块，因为它就相当于java9以前版本的rt.jar的内容。</p>
<p>Qualified Exports(有限制的exports)<br>比如我只想exports某个包给部分模块,而不是所有模块</p>
<h3 id="2、模块化基础"><a href="#2、模块化基础" class="headerlink" title="2、模块化基础"></a>2、模块化基础</h3><p>（1）模块拥有一个名称，并对相关的代码以及可能的其他资源进行分组，同时使用一个模块描述符进行描述。模块描述符保存在一个名为module-info.java的文件中。<br>（2）模块描述符还可以包含exports语句。强封装性是模块的默认特性。只有当显式地导出一个包时（比如示例中的java.util.prefs），才可以从其他模块中访问该包<br>可访问性和可读性的结合可以确保在模块系统中实现强封装性。<br>（3）其他模块无法使用未导出包中的任何类型——即使包中的类型是公共的。这是对Java语言可访问性规则的根本变化。<br>（4）Java 9出现之后，public意味着仅对模块中的其他包公开。只有当导出包包含了公开类型时，其他模块才可以使用这些类型。这就是强封装的意义所在。</p>
<p>在模块出现之前，强封装实现类的唯一方法是将这些类放置到单个包中，并标记为私有。这种做法使得包变得非常笨重，实际上，将类公开只是为了实现不同包之间的访问。通过使用模块，可以以任何方式构建包，并仅导出模块使用者真正必须访问的包。如果愿意的话，还可以将导出的包构成模块的API。</p>
<p>（5）模块提供了导出包的显式信息，从而能够高效地对模块路径进行索引。当从给定的包中查找类型时，Java运行时和编译器可以准确地知道从模块路径中解析哪个模块。而在以前，对整个类路径进行扫描是找到任意类型的唯一方法。</p>
<p>在解析过程中还会完成一些额外的检查。例如，具有相同名称的两个模块在启动时（而不是在运行过程出现类加载失败时）会产生错误。此外，还会检查导出包的唯一性。</p>
<p>模块解析过程以及额外的检查确保了应用程序在一个可靠的环境中运行，降低了运行时失败的可能性。</p>
<p>（6）通过使用未命名模块，尚未模块化的代码可以继续在JDK 9上运行。<br>当将代码放在类路径上时，会自动使用未命名模块。这也意味着需要构建一个正确的类路径。可一旦使用了未命名模块，前面讨论的模块系统所带来的保障和好处也就没有了。</p>
<p>当在Java 9中使用类路径时，还需要注意两件事情。首先，由于平台是模块化的，因此对内部实现类进行了强封装。</p>
<p>（7）模块系统执行的另一个检查是循环依赖。<br>在编译时，模块之间的可读性关系必须是非循环的。而在模块中，仍然可以在类之间创建循环关系</p>
<p>（8）通过使用ServiceLoader API可在模块描述符和代码中表示服务<br>使用这个功能可以对代码的实现进行良好的封装</p>
<h3 id="3、以非模块化方式开发和运行应用"><a href="#3、以非模块化方式开发和运行应用" class="headerlink" title="3、以非模块化方式开发和运行应用"></a>3、以非模块化方式开发和运行应用</h3><p>在java9中也是允许你以非模块化方式开发和运行应用的(也就是说，模块化开发是可选的)，如果你的应用中没有module-info.java，那么这就是一个unnamed module. java9对于unnamed module的处理方式就是所有的jdk模块均直接可用(模块图中是以java.se模块作为root模块的，也意味着单独处于java.se.ee下的一些包，比如JAXB API是无法访问到的)。</p>
<p>但是需要注意的是，在java8以及之前的版本中，我们可以访问jdk中的一些不推荐访问的内部类，比如com.sun.image.codec.jpeg,但在java9模块化之后被强封装了，所以在java9中无法使用这些内部类，也就是说无法通过编译，但是java9为了保持兼容性，允许之前引用这些内部类的已有的jar或已编译的类正确运行。换言之，就是java9不允许源码中引用这些类，无法通过编译，但是之前版本中引用这些类的已编译class文件是允许正常运行的。</p>
<h1 id="三、迁移"><a href="#三、迁移" class="headerlink" title="三、迁移"></a>三、迁移</h1><p>（1）为了便于将基于类路径的应用程序迁移到Java 9，在对平台模块中的类应用深度反射时，或者使用反射来访问非导出包中的类型时，JVM默认显示警告</p>
<p>（2）那些在JDK 8和更早的版本上运行没有任何问题的代码现在会在控制台上显示一个醒目的警告——即使是在生产环境中也是如此。这表明严重破坏了强封装。除了这个警告之外，应用程序仍然照常运行。如警告消息所示，在下一个Java版本中行为将发生变化。将来，即使是类路径上的代码，JDK也会强制执行平台模块的强封装。</p>
<p>（3）可以使用–add-opens标志授予对模块中特定包的类路径深度反射访问。同样，当类路径上的代码尝试访问非导出包中的类型时，可以使用–add-exports来强制导出包。</p>
<p>（4）为了使逐步迁移成为可能，可以混合使用类路径和模块路径。但这不是一种理想的情况，因为只能部分受益于Java模块系统的优点。但是，“小步”迁移是非常有帮助的。</p>
<h2 id="自动模块"><a href="#自动模块" class="headerlink" title="自动模块"></a>自动模块</h2><p>Java模块系统提供了一个有用的功能来处理非模块的代码：自动模块。只需将现有的JAR文件从类路径移动到模块路径，而不改变其内容，就可以创建一个自动模块。这样一来，JAR就转换为一个模块，同时模块系统动态生成模块描述符。相比之下，显式模块始终有一个用户自定义的模块描述符。</p>
<p>自动模块的行为不同于显式模块。自动模块具有以下特征：</p>
<p>（1）不包含module-info.class；<br>（2）它有一个在META-INF&#x2F;MANIFEST.MF中指定或者来自其文件名的模块名称。<br>（3）通过requires transitive请求所有其他已解析模块。<br>（4）导出所有包。<br>（5）读取路径（或者更准确地讲，读取前面所讨论的未命名模块）。<br>（6）它不能与其他模块拆分包。</p>
<p>自动模块并不是一个设计良好的模块。虽然请求所有的模块并导出所有的包听起来不像是正确的模块化，但至少是可用的。</p>
<p>自动模块中仍然没有明确的信息来告诉模块系统真正需要哪些模块，这意味着JVM在启动时不会警告自动模块的依赖项丢失。</p>
<p>作为开发人员，负责确保模块路径（或类路径）包含所有必需的依赖项。这与使用类路径没有太大区别。</p>
<p>模块图中的所有模块都需要通过自动模块传递。这实际上意味着，如果请求一个自动模块，那么就可以“免费”获得所有其他模块的隐式可读性。</p>
<p>当使用自动模块时，也会遇到拆分包。在大型应用程序中，由于依赖关系管理不善，通常会发现拆分包。拆分包始终是一个错误，因为它们在类路径上不能可靠地工作。</p>
<h2 id="未命名模块"><a href="#未命名模块" class="headerlink" title="未命名模块"></a>未命名模块</h2><p>模块路径上的非模块化JAR变成了自动模块。而类路径变成了未命名模块。</p>
<p>类路径上的所有代码都是未命名模块的一部分。</p>
<p>存在一个很大的限制：未命名模块本身只能通过自动模块读取（只有自动模块可以读取类路径）</p>
<p>当读取未命名模块时自动模块和显式模块之间的区别。显式模块只能读取其他显式模块和自动模块。而自动模块可读取所有模块，包括未命名模块。</p>
<p>未命名模块的可读性只是一种在混合类路径&#x2F;模块路径迁移方案中有助于自动模块的机制。</p>
<p>JVM为什么没有那么“聪明”呢？它有权访问自动模块中的所有代码，那么为什么不分析依赖关系呢？如果想要分析这些代码是否调用其他模块，JVM需要对所有代码执行字节码分析。虽然这不难实现，但却是一个昂贵的操作，可能会大量增加大型应用程序的启动时间。而且，这样的分析不会发现通过反射产生的依赖关系。由于存在这些限制，JVM不可能也永远不会这样做。相反，JDK附带了另一个工具jdeps，它可以执行字节码分析。</p>
<p>现代构建工具通常有一个“在重复依赖项上失败”的设置，这使得依赖关系管理问题变得更加清晰，从而迫使尽早解决这些问题。强烈建议使用这个设置。关于该问题，Java模块系统比类路径要严格得多。当它检测到一个包从模块路径上的两个模块导出时，就会拒绝启动。相比于以前使用类路径时所遇到的不可靠情况，这种快速失败（fail-fast）机制要好得多。在开发过程中失败好过在生产过程中失败，尤其是当一些不幸的用户碰到一个由于模糊的类路径问题而被破坏的代码路径时。但这也意味着我们必须处理这些问题。盲目地将所有JAR从类路径移至模块路径可能导致在生成的自动模块之间出现拆分包。而这些拆分包将被模块系统所拒绝。</p>
<p>为了使迁移变得容易一些，当涉及自动模块和未命名模块时，上述规则存在一个例外，即承认很多类路径是不正确的，并且包含拆分包。当（自动）模块和未命名模块都包含相同的包时，将使用来自（自动）模块的包，而未命名模块中的包被忽略。</p>
<p>如果在迁移到Java 9时遇到了拆分包问题，那么是无法绕过的。即使从用户角度来看基于类路径的应用程序可以正确工作，你也必须处理这些问题。</p>
<p>拆分包会导致无法以模块系统的方式启动服务</p>
<h2 id="未命名模块（unnamed-module）和自动模块（automatic-module）总结"><a href="#未命名模块（unnamed-module）和自动模块（automatic-module）总结" class="headerlink" title="未命名模块（unnamed module）和自动模块（automatic module）总结"></a>未命名模块（unnamed module）和自动模块（automatic module）总结</h2><p>（1）一个未经模块化改造的 jar 文件是转为未命名模块还是自动模块，取决于这个 jar 文件出现的路径，如果是类路径，那么就会转为未命名模块，如果是模块路径，那么就会转为自动模块。注意，自动模块也属于命名模块的范畴，其名称是模块系统基于 jar 文件名自动推导得出的<br>（2）两者还有一个关键区别，分裂包规则适用于自动模块，但对未命名模块无效，也即多个未命名模块可以导出同一个包，但自动模块不允许。<br>（3） 未命名模块和自动模块存在的意义在于，无论传入的 jar 文件是否一个合法的模块（包含 module descriptor），Java 内部都可以统一的以模块的方式进行处理，这也是 Java 9 兼容老版本应用的架构原理。运行老版本应用时，所有 jar 文件都出现在类路径下，也就是转为未命名模块，对于未命名模块而言，默认导出所有包并且依赖所有模块，因此应用可以正常运行。<br>（4）基于未命名模块和自动模块，相应的就产生了两种老版本应用的迁移策略，或者说模块化策略。<br>（5）等所有 jar 包都完成模块化改造，应用改为 -m 方式启动，这也标志着应用已经迁移为真正的 Java 9 应用<br>（6）-cp 和 -m 可以同时存在 并运行？？可以（类路径和模块系统可以混合运行）</p>
<h2 id="java9-自动模块-的意义"><a href="#java9-自动模块-的意义" class="headerlink" title="java9 自动模块 的意义"></a>java9 自动模块 的意义</h2><p>（1）个人理解，只是为了让开发者能像模块一样使用起来，引入。实际上封装性方面和类路径没任何区别。<br>（2）未命名模块和自动模块存在的意义在于，无论传入的 jar 文件是否一个合法的模块（包含 module descriptor），Java 内部都可以统一的以模块的方式进行处理，这也是 Java 9 兼容老版本应用的架构原理。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>（1）如何用最快的速度判别它是不是一个模块？它又是如何定义的？<br>试试看 jar -d -f <jar_file>。<br>（2）通过JDK11内置jdeps工具查找过期以及废弃API以及对应的替换<br><code>./jdk-11.0.10.jdk/Contents/Home/bin/jdeps --jdk-internals ./build/libs/service.jar</code><br><code>./jdk-11.0.10.jdk/Contents/Home/bin/jdeps --jdk-internals -R --class-path ./build/deploy/* ./build/libs/*</code><br><code>jdeps --jdk-internals -R --class-path &#39;libs/*&#39; $project</code><br>libs是你的所有依赖的目录，$project是你的项目jar包<br>（3）我们可以在线上使用OpenJDK，开发时，使用任意的JDK。<br><a href="https://zhuanlan.zhihu.com/p/87157172">https://zhuanlan.zhihu.com/p/87157172</a></jar_file></p>
<h2 id="库迁移"><a href="#库迁移" class="headerlink" title="库迁移"></a>库迁移</h2><p>迁移库和迁移应用程序之间最大的区别在于库被许多应用程序使用。这些应用程序可能运行在不同版本的Java上，所以库通常需要在各种Java版本上工作。期望库的用户在你迁移库的同时切换到Java 9是不现实的。</p>
<p>库的迁移过程由以下步骤组成：</p>
<p>1）确保库可以作为自动模块在Java 9上运行。<br>2）使用Java 9编译器编译库（主要使用满足需求的最低Java版本），而不使用新的Java 9功能。<br>3）添加一个模块描述符，并将库转换为显式模块。<br>4）重构库的结构，以便增加封装性，识别API，并尽可能分割成多个模块（可选）。<br>5）开始使用库中的Java 9功能，同时保持向后兼容Java 9的早期版本。</p>
<p>库管理需要使用java8编译，模块描述需要用java9编译，且不能使用新特性，否则java8编译不过</p>
<p>项目模块化后，很多第三库（基于反射的），深度反射项目代码，或jdk，可能不能用，要进行特殊处理</p>
<p>历史解决jar包冲突问题得改造成模块化</p>
<h1 id="四、模块系统实践例子"><a href="#四、模块系统实践例子" class="headerlink" title="四、模块系统实践例子"></a>四、模块系统实践例子</h1><h2 id="1、相同模块不同版本，新版废弃方法"><a href="#1、相同模块不同版本，新版废弃方法" class="headerlink" title="1、相同模块不同版本，新版废弃方法"></a>1、相同模块不同版本，新版废弃方法</h2><p>结论：运行时才会报错</p>
<p>module_2-1.0  依赖 module_1-1.0 printInfo.print2()方法，项目依赖 module_1-2.0 printInfo.print3()；<br>build的时候并不能识别到错误，只有运行时才会发现错误 java.lang.NoSuchMethodError: com.kxw.module1.info.PrintInfo.print2()V</p>
<h2 id="2、不同模块含重复类"><a href="#2、不同模块含重复类" class="headerlink" title="2、不同模块含重复类"></a>2、不同模块含重复类</h2><p>结论：不同模块可以存在相同类，在引入时指定模块，可以正确加载到对应类</p>
<p>（1）如果同时引入两个不同模块（不管是直接还是间接），编译时会检测引入的模块是否包含可读的相同路径<br>编译报错：错误: 未命名的模块同时从 com.kxw.module.four 和 com.kxw.module.three 读取程序包 com.kxw.module.config</p>
<p>（2）如果模块存在相同类，但是却没有通过export声明，仅内部使用，那么编译时将无法检测，但运行时报 （两个模块都没有export的情况，结果一样）<br>Error occurred during initialization of boot layer<br>java.lang.LayerInstantiationException: Package com.kxw.module.config in both module com.kxw.module.three and</p>
<p>没声明（export）的情况下，运行时怎么检测有相同的package？<br>报：Checks for split packages between modules defined to the built-in class loaders.<br> ModuleBootstrap#checkSplitPackages 会检查所有module的package是否重复，通过String other &#x3D; packageToModule.putIfAbsent(p, name);来实现</p>
<p>结论：只要是一个模块，且被引入，有相同包名都可以在启动时被检测出来并报错 （为什么编译时不做的呢？main方法不明确？还是要指定主模块？）</p>
<p>注意：类路径加载的模块都是未命名模块，且不会因为包冲突而报错 </p>
<h1 id="五、classloader的变化"><a href="#五、classloader的变化" class="headerlink" title="五、classloader的变化"></a>五、classloader的变化</h1><h2 id="1、类加载器变化概览"><a href="#1、类加载器变化概览" class="headerlink" title="1、类加载器变化概览"></a>1、类加载器变化概览</h2><h3 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h3><p>（1）任意一个 ClassLoader 在尝试加载一个类的时候，都会先尝试调用其父类的相关方法去加载类，如果其父类不能加载该类，则交由子类去完成。 这样的好处：对于任意使用者自定义的 ClassLoader，都会先去尝试让 jvm 的 Bootstrap ClassLoader 去尝试加载(自定义的 ClassLoader 都继承了它们)。那么就能保证 jvm 的类会被优先加载，限制了使用者对 jvm 系统的影响。</p>
<p>（2）jdk9中的双亲委派机制仍然存在，只是在委派之前会优先寻找模块所属的加载器进行加载。</p>
<h3 id="jdk9之前"><a href="#jdk9之前" class="headerlink" title="jdk9之前"></a>jdk9之前</h3><p>Boostrap -&gt; Extension -&gt; Application</p>
<p>（1）bootstrap classloader加载rt.jar，jre&#x2F;lib&#x2F;endorsed （用来加载 jvm 自身需要的类，c++ 实现，用来加载 rt.jar）<br>（2）ext classloader加载jre&#x2F;lib&#x2F;ext （ 在 jdk9 中已经被移除。）<br>（3）application classloader加载-cp指定的类 (负责加载ClassPath路径下的类)</p>
<h3 id="jdk9及之后"><a href="#jdk9及之后" class="headerlink" title="jdk9及之后"></a>jdk9及之后</h3><p>Application -&gt; Platform -&gt; Boostrap</p>
<p>（1）bootstrap classloader加载lib&#x2F;modules 中的核心模块 （主要用来加载 java.base 中的核心系统类）<br>（2）ext classloader被废弃，新增platform classloader，加载lib&#x2F;modules的非核心模块 （用来加载 jdk 中的非核心模块类）<br>（3）application classloader加载-cp，-mp指定的类 （用来加载一般的应用类）</p>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>JDK9开始，AppClassLoader父类不再是 URLClassLoader；而是BuiltinClassLoader</p>
<p>之前对于动态加载的类，我们总是通过将这个类通过反射调用URLClassLoader加到classpath里面进行加载。这么加载在JDK11中已经无法实现，并且这样加载的类不能卸载。 对于动态加载的类，我们在OpenJDK11中只能自定义类加载器去加载，而不是通过获取APPClassLoader去加载。同时，这么做也有助于你随时能将动态加载的类卸载，因为并没有加载到APPClassLoader。</p>
<p>建议使用自定义的类加载器继承SecureClassLoader去加载类：java.security.SecureClassLoader</p>
<h3 id="BuiltinClassLoader"><a href="#BuiltinClassLoader" class="headerlink" title="BuiltinClassLoader"></a>BuiltinClassLoader</h3><p>BuiltinClassLoader 是 jdk9 中代替 URLClassLoader 的加载器，是 PlatformClassLoader 与 AppClassLoader 的父类。其继承了 SecureClassLoader，其核心的方法主要是 loadClassOrNull(…) 方法</p>
<h3 id="如何自定义加载器"><a href="#如何自定义加载器" class="headerlink" title="如何自定义加载器"></a>如何自定义加载器</h3><p>（1）java9之前</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ArthasClassloader</span> <span class="keyword">extends</span> <span class="title class_">URLClassLoader</span> &#123;</span><br><span class="line"><span class="keyword">public</span> <span class="title function_">ArthasClassloader</span><span class="params">(URL[] urls)</span> &#123;</span><br><span class="line"><span class="built_in">super</span>(urls, ClassLoader.getSystemClassLoader().getParent());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">synchronized</span> Class&lt;?&gt; loadClass(String name, <span class="type">boolean</span> resolve) <span class="keyword">throws</span> ClassNotFoundException &#123;</span><br><span class="line"><span class="keyword">final</span> Class&lt;?&gt; loadedClass = findLoadedClass(name);</span><br><span class="line"><span class="keyword">if</span> (loadedClass != <span class="literal">null</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> loadedClass;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 优先从parent（SystemClassLoader）里加载系统类，避免抛出ClassNotFoundException</span></span><br><span class="line"><span class="keyword">if</span> (name != <span class="literal">null</span> &amp;&amp; (name.startsWith(<span class="string">&quot;sun.&quot;</span>) || name.startsWith(<span class="string">&quot;java.&quot;</span>))) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">super</span>.loadClass(name, resolve);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Class&lt;?&gt; aClass = findClass(name);</span><br><span class="line"><span class="keyword">if</span> (resolve) &#123;</span><br><span class="line">resolveClass(aClass);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> aClass;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line"><span class="comment">// ignore</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">super</span>.loadClass(name, resolve);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）java9之后</p>
<p>TODO</p>
<h2 id="2、扩展机制"><a href="#2、扩展机制" class="headerlink" title="2、扩展机制"></a>2、扩展机制</h2><p>（1）版本9之前的Java SE允许扩展机制，可以通过将JAR放置在系统属性java.ext.dirs指定的目录中来扩展运行时映像。 如果未设置此系统属性，则使用jre\lib\ext目录作为其默认值。 该机制通过扩展类加载器（这是引导类加载器的子类）和系统类加载器的父级加载了该目录中的所有JAR。 它加载所有应用程序类。 这些JAR的内容对于在此运行时映像上编译或运行的所有应用程序都可见。</p>
<p>（2）Java SE 9不支持扩展机制。 如果需要类似的功能，可以将这些JAR放在类路径的前面。 使用名为JAVA_HOME\lib\ext的目录或设置名为java.ext.dirs的系统属性会导致JDK 9中的错误。</p>
<p>（3）在JDK 9之前，扩展类加载器和应用程序类加载器是java.net.URLClassLoader类的一个实例。 在JDK 9中，平台类加载器（以前的扩展类加载器）和应用程序类加载器是内部JDK类的实例。 如果你的代码依赖于URLClassLoader类的特定方法，代码可能会在JDK 9中崩溃。</p>
<h2 id="3、类加载器的加载流程"><a href="#3、类加载器的加载流程" class="headerlink" title="3、类加载器的加载流程"></a>3、类加载器的加载流程</h2><p><img src="/2022/02/08/20220208-java11-ji-chu-yuan-li-he-shi-jian/java11_classloader.png"></p>
<h3 id="在JDK-9之前"><a href="#在JDK-9之前" class="headerlink" title="在JDK 9之前"></a>在JDK 9之前</h3><p>a. JDK使用三个类加载器来加载类<br>b. JDK类加载器以分层方式工作 —— 引导类加载器位于层次结构的顶部。 类加载器将类加载请求委托给上层类加载器。</p>
<p>例如，如果应用程序类加载器需要加载一个类，它将请求委托给扩展类加载器，扩展类加载器又将请求委托给引导类加载器。 如果引导类加载器无法加载类，扩展类加载器将尝试加载它。 如果扩展类加载器无法加载类，则应用程序类加载器尝试加载它。 如果应用程序类加载器无法加载它，则抛出ClassNotFoundException异常。</p>
<p>c. 引导类加载器是扩展类加载器的父类。 扩展类加载器是应用程序类加载器的父类。 引导类加载器没有父类。 默认情况下，应用程序类加载器将是你创建的其他类加载器的父类。</p>
<h3 id="在JDK-9之前的类加载机制"><a href="#在JDK-9之前的类加载机制" class="headerlink" title="在JDK 9之前的类加载机制"></a>在JDK 9之前的类加载机制</h3><p>（1）【Boostrap】引导类加载器加载由Java平台组成的引导类，包括JAVA_HOME\lib\rt.jar中的类和其他几个运行时JAR。 它完全在虚拟机中实现。 可以使用-Xbootclasspath&#x2F;p和-Xbootclasspath&#x2F;a命令行选项来附加引导目录。 可以使用-Xbootclasspath选项指定引导类路径，该选项将替换默认的引导类路径。 在运行时，sun.boot.class.path系统属性包含引导类路径的只读值。 JDK通过null表示这个类加载器。 也就是说，你不能得到它的引用。 例如，Object类由引导类加载器加载，并且Object.class.getClassLoader()表达式将返回null。</p>
<p>（2）【Extension】扩展类加载器用于通过java.ext.dirs系统属性指定的目录中的位于JAR中的扩展机制加载可用的类。要获得扩展类加载器的引用，需要获取应用程序类加载器的引用，并在该引用上使用getParent()方法。</p>
<p>（3）【Application】应用程序类加载器从由CLASSPATH环境变量指定的应用程序类路径或命令行选项-cp或-classpath加载类。应用程序类加载器也称为系统类加载器，这是一种误称，它暗示它加载系统类。可以使用ClassLoader类的静态方法getSystemClassLoader()获取对应用程序类加载器的引用。</p>
<h3 id="在JDK-9及之后"><a href="#在JDK-9及之后" class="headerlink" title="在JDK 9及之后"></a>在JDK 9及之后</h3><p>a. JDK9保持三级分层类加载器架构以实现向后兼容。但是，从模块系统加载类的方式有一些变化。<br>b. 在JDK 9中，应用程序类加载器【Application】可以委托给平台类加载器【Platform】以及引导类加载器【Boostrap】；平台类加载器【Platform】可以委托给引导类加载器【Boostrap】和应用程序类加载器【Application】。</p>
<p>（1）在JDK 9中，引导类加载器是由类库和代码在虚拟机中实现的(不再是c++实现)。 为了向后兼容，它在程序中仍然由null表示。 例如，Object.class.getClassLoader()仍然返回null。 但是，并不是所有的Java SE平台和JDK模块都由引导类加载器加载。 举几个例子，引导类加载器加载的模块是java.base，java.logging，java.prefs和java.desktop。 其他Java SE平台和JDK模块由平台类加载器和应用程序类加载器加载，这在下面介绍。 JDK 9中不再支持用于指定引导类路径，-Xbootclasspath和-Xbootclasspath&#x2F;p选项以及系统属性sun.boot.class.path。-Xbootclasspath&#x2F;a选项仍然受支持，其值存储在jdk.boot.class.path.append的系统属性中。</p>
<p>（2）JDK 9不再支持扩展机制。 但是，它将扩展类加载器保留在名为平台类加载器的新名称下。 ClassLoader类包含一个名为getPlatformClassLoader()的静态方法，该方法返回对平台类加载器的引用。 下表包含平台类加载器加载的模块列表。 平台类加载器用于另一目的。 默认情况下，由引导类加载器加载的类将被授予所有权限。 但是，几个类不需要所有权限。 这些类在JDK 9中已经被取消了特权，并且它们被平台类加载器加载以提高安全性。<br>下面是JDK 9中由平台加载器加载的模块列表。</p>
<p>（3）应用程序类加载器加载在模块路径上找到的应用程序模块和一些提供工具或导出工具API的JDK模块，如下表所示。 仍然可以使用ClassLoader类的getSystemClassLoader()的静态方法来获取应用程序类加载器的引用。</p>
<h3 id="在JDK-9及之后的的类加载机制"><a href="#在JDK-9及之后的的类加载机制" class="headerlink" title="在JDK 9及之后的的类加载机制"></a>在JDK 9及之后的的类加载机制</h3><p>三个内置的类加载器一起协作来加载类。</p>
<p>（1）当应用程序类加载器需要加载类时，它将搜索定义到所有类加载器的模块。 如果有合适的模块定义在这些类加载器中，则该类加载器将加载类，这意味着应用程序类加载器现在可以委托给引导类加载器和平台类加载器。 如果在为这些类加载器定义的命名模块中找不到类，则应用程序类加载器将委托给其父类，即平台类加载器。 如果类尚未加载，则应用程序类加载器将搜索类路径。 如果它在类路径中找到类，它将作为其未命名模块的成员加载该类。 如果在类路径中找不到类，则抛出ClassNotFoundException异常。</p>
<p>（2）当平台类加载器需要加载类时，它将搜索定义到所有类加载器的模块。 如果一个合适的模块被定义为这些类加载器中，则该类加载器加载该类。 这意味着平台类加载器可以委托给引导类加载器以及应用程序类加载器。 如果在为这些类加载器定义的命名模块中找不到一个类，那么平台类加载器将委托给它的父类，即引导类加载器。</p>
<p>（3）当引导类加载器需要加载一个类时，它会搜索自己的命名模块列表。 如果找不到类，它将通过命令行选项-Xbootclasspath&#x2F;a指定的文件和目录列表进行搜索。 如果它在引导类路径上找到一个类，它将作为其未命名模块的成员加载该类。</p>
<p>JDK 9包含一个名为-Xlog::modules的选项，用于在虚拟机加载时记录调试或跟踪消息，可以看到类加载器及其加载的模块和类。其格式如下：</p>
<p><code>-Xlog:modules=&lt;debug|trace&gt;</code><br><code>java -Xlog:modules=trace --module-path lib --module com.jdojo.prime.client/com.jdojo.prime.client.Main &gt; test.txt</code></p>
<h3 id="JDK-9各类加载器对应加载的模块"><a href="#JDK-9各类加载器对应加载的模块" class="headerlink" title="JDK 9各类加载器对应加载的模块"></a>JDK 9各类加载器对应加载的模块</h3><p>（1）bootstrap classloader加载lib&#x2F;modules</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java.base java.security.sasl</span><br><span class="line">java.datatransfer java.xml</span><br><span class="line">java.desktop jdk.httpserver</span><br><span class="line">java.instrument jdk.internal.vm.ci</span><br><span class="line">java.logging jdk.management</span><br><span class="line">java.management jdk.management.agent</span><br><span class="line">java.management.rmi jdk.naming.rmi</span><br><span class="line">java.naming jdk.net</span><br><span class="line">java.prefs jdk.sctp</span><br><span class="line">java.rmi jdk.unsupported</span><br></pre></td></tr></table></figure>
<p>（2）platform classloader，加载lib&#x2F;modules</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java.activation* jdk.accessibility</span><br><span class="line">java.compiler* jdk.charsets</span><br><span class="line">java.corba* jdk.crypto.cryptoki</span><br><span class="line">java.scripting jdk.crypto.ec</span><br><span class="line">java.se jdk.dynalink</span><br><span class="line">java.se.ee jdk.incubator.httpclient</span><br><span class="line">java.security.jgss jdk.internal.vm.compiler*</span><br><span class="line">java.smartcardio jdk.jsobject</span><br><span class="line">java.sql jdk.localedata</span><br><span class="line">java.sql.rowset jdk.naming.dns</span><br><span class="line">java.transaction* jdk.scripting.nashorn</span><br><span class="line">java.xml.bind* jdk.security.auth</span><br><span class="line">java.xml.crypto jdk.security.jgss</span><br><span class="line">java.xml.ws* jdk.xml.dom</span><br><span class="line">java.xml.ws.annotation* jdk.zipfs</span><br></pre></td></tr></table></figure>
<p>（3）application classloader加载-cp，-mp指定的类</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jdk.aot jdk.jdeps</span><br><span class="line">jdk.attach jdk.jdi</span><br><span class="line">jdk.compiler jdk.jdwp.agent</span><br><span class="line">jdk.editpad jdk.jlink</span><br><span class="line">jdk.hotspot.agent jdk.jshell</span><br><span class="line">jdk.internal.ed jdk.jstatd</span><br><span class="line">jdk.internal.jvmstat jdk.pack</span><br><span class="line">jdk.internal.le jdk.policytool</span><br><span class="line">jdk.internal.opt jdk.rmic</span><br><span class="line">jdk.jartool jdk.scripting.nashorn.shell</span><br><span class="line">jdk.javadoc jdk.xml.bind*</span><br><span class="line">jdk.jcmd jdk.xml.ws*</span><br><span class="line">jdk.jconsole</span><br></pre></td></tr></table></figure>
<h2 id="4、其他"><a href="#4、其他" class="headerlink" title="4、其他"></a>4、其他</h2><p>（1）如果你想访问classpath下的内容，你可以读取环境变量：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">pathSeparator</span> <span class="operator">=</span> System</span><br><span class="line">.getProperty(<span class="string">&quot;path.separator&quot;</span>);</span><br><span class="line">String[] classPathEntries = System</span><br><span class="line">.getProperty(<span class="string">&quot;java.class.path&quot;</span>)</span><br><span class="line">.split(pathSeparator);</span><br></pre></td></tr></table></figure>
<p>（2）设置虚拟机参数为”-XX:+TraceClassLoading”来获取类加载信息<br>（3）如何判断类是有未命名模块加载，还是正常模块加载的 ：clazz.getModule()</p>
<h1 id="六、垃圾回收器"><a href="#六、垃圾回收器" class="headerlink" title="六、垃圾回收器"></a>六、垃圾回收器</h1><h2 id="JDK-11-默认使用G1"><a href="#JDK-11-默认使用G1" class="headerlink" title="JDK 11 默认使用G1"></a>JDK 11 默认使用G1</h2><p>G1会比CMS有更多的内存消耗，多了两个内存结构：</p>
<p>Remembered Sets：每个区块Region都有一个与之对应的Remembered Set来记录不同区块间对象引用（其他收集器只是记录新生代、老年代间互相引用）。用来避免全堆扫描<br>Collection Sets：将要被回收区块对象的集合，GC时收集器将这些区块对象复制到其他区块中</p>
<h2 id="ZGC"><a href="#ZGC" class="headerlink" title="ZGC"></a>ZGC</h2><p>ZGC（The Z Garbage Collector）是JDK 11中推出的一款低延迟垃圾回收器，它的设计目标包括：</p>
<p>停顿时间不超过10ms；<br>停顿时间不会随着堆的大小，或者活跃对象的大小而增加；<br>支持8MB~4TB级别的堆（未来支持16TB）。</p>
<p>从设计目标来看，我们知道ZGC适用于大内存低延迟服务的内存管理和回收。</p>
<p>对吞吐量优先的场景，ZGC可能并不适合。<br>ZGC作为下一代垃圾回收器，性能非常优秀。ZGC垃圾回收过程几乎全部是并发，实际STW停顿时间极短，不到10ms。这得益于其采用的着色指针和读屏障技术。</p>
<p>后续考虑在生产环境使用ZGC。</p>
<h1 id="七、新特性"><a href="#七、新特性" class="headerlink" title="七、新特性"></a>七、新特性</h1><h2 id="1、HttpClient-API"><a href="#1、HttpClient-API" class="headerlink" title="1、HttpClient API"></a>1、HttpClient API</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">HttpClient</span> <span class="variable">client</span> <span class="operator">=</span> HttpClient.newHttpClient();</span><br><span class="line"><span class="type">HttpRequest</span> <span class="variable">request</span> <span class="operator">=</span> HttpRequest.newBuilder()</span><br><span class="line">.uri(URI.create(<span class="string">&quot;http://openjdk.java.net/&quot;</span>))</span><br><span class="line">.build();</span><br><span class="line">client.sendAsync(request, BodyHandlers.ofString())</span><br><span class="line">.thenApply(HttpResponse::body)</span><br><span class="line">.thenAccept(System.out::println)</span><br><span class="line">.join();</span><br></pre></td></tr></table></figure>
<h2 id="2、使用Stream-dropWhile-简化代码"><a href="#2、使用Stream-dropWhile-简化代码" class="headerlink" title="2、使用Stream dropWhile 简化代码"></a>2、使用Stream dropWhile 简化代码</h2><p>获取列表从lastId开始到结尾的子集</p>
<p>java8</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (UserDynamicSortSetMemberWithScoreBO bo : sortSetKeyList) &#123;</span><br><span class="line"><span class="keyword">if</span> (bo.getId() == lastId) &#123;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">index++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> sortSetKeyList.stream()</span><br><span class="line">.skip(index + <span class="number">1</span>)</span><br><span class="line">.limit(DynamicConfig.feedListPageSize())</span><br><span class="line">.collect(Collectors.toList());</span><br></pre></td></tr></table></figure>
<p>java9</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> sortSetKeyList.stream()</span><br><span class="line">.dropWhile(v -&gt; !v.getId().equals(lastId))</span><br><span class="line">.skip(<span class="number">1</span>)</span><br><span class="line">.limit(DynamicConfig.feedListPageSize())</span><br><span class="line">.collect(Collectors.toList());</span><br></pre></td></tr></table></figure>
<h2 id="3、Optional-ifPresentOrElse"><a href="#3、Optional-ifPresentOrElse" class="headerlink" title="3、Optional.ifPresentOrElse"></a>3、Optional.ifPresentOrElse</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">optional.ifPresentOrElse( x -&gt; System.out.println(<span class="string">&quot;Value: &quot;</span> + x),() -&gt;</span><br><span class="line">System.out.println(<span class="string">&quot;Not Present.&quot;</span>));</span><br></pre></td></tr></table></figure>


<h1 id="八、迁移实践"><a href="#八、迁移实践" class="headerlink" title="八、迁移实践"></a>八、迁移实践</h1><h2 id="目标1：可运行"><a href="#目标1：可运行" class="headerlink" title="目标1：可运行"></a>目标1：可运行</h2><p>由于项目历史沉重（代码不兼容或依赖未模块化），先使用旧方式运行（类路径而不是模块系统）</p>
<p>1、目标：用最简单快速的方式使用java11编译和运行代码<br>2、收益：使用属于Java 9-11 新的API、工具和性能改进。<br>3、未使用Java 9的旗舰功能——模块系统，仍使用类路径方式运行服务</p>
<h2 id="目标2：使用模块系统运行"><a href="#目标2：使用模块系统运行" class="headerlink" title="目标2：使用模块系统运行"></a>目标2：使用模块系统运行</h2><p>模块化改造，在现有的项目中如何发挥模块化的作用</p>
<h3 id="自动模块会exports所有包，导致分包问题，不同模块包含相同包"><a href="#自动模块会exports所有包，导致分包问题，不同模块包含相同包" class="headerlink" title="自动模块会exports所有包，导致分包问题，不同模块包含相同包"></a>自动模块会exports所有包，导致分包问题，不同模块包含相同包</h3><p>解决的方法：<br>（1）改代码，去除这种不规范（难，第三方包很多这种）<br>（2）把这种包放在未命名模块</p>
<h3 id="由于完全模块化分包的问题无法解决，所以要混合两种方式运行项目"><a href="#由于完全模块化分包的问题无法解决，所以要混合两种方式运行项目" class="headerlink" title="由于完全模块化分包的问题无法解决，所以要混合两种方式运行项目"></a>由于完全模块化分包的问题无法解决，所以要混合两种方式运行项目</h3><p>gradle对混合两种（类路径和模块系统）的支持不足<br>直接命令行使用混合两种运行是可以的：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./jdk-11.0.10.jdk/Contents/Home/bin/java --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED -cp &quot;build/deploy/*&quot; -p &quot;build/module/*&quot; --add-modules &quot;com.xx.xx.xx&quot; com.xx.xx.xx.Application</span><br></pre></td></tr></table></figure>


<h2 id="目标3：使用java17"><a href="#目标3：使用java17" class="headerlink" title="目标3：使用java17"></a>目标3：使用java17</h2><h3 id="1、Gradle-7-3-is-the-first-version-fully-supporting-Java-17"><a href="#1、Gradle-7-3-is-the-first-version-fully-supporting-Java-17" class="headerlink" title="1、Gradle 7.3 is the first version fully supporting Java 17"></a>1、Gradle 7.3 is the first version fully supporting Java 17</h3><h3 id="2、Spring-Boot-2-5-5是Spring-Boot-第一个支持Java-17的版本"><a href="#2、Spring-Boot-2-5-5是Spring-Boot-第一个支持Java-17的版本" class="headerlink" title="2、Spring Boot 2.5.5是Spring Boot 第一个支持Java 17的版本"></a>2、Spring Boot 2.5.5是Spring Boot 第一个支持Java 17的版本</h3><h1 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h1><ul>
<li>新版本jdk现在基本都是规定时间内免费，比如半年或三年，一般情况下直接用openjdk就足够了。</li>
<li><a href="https://cloud.tencent.com/developer/article/1598291">OpenJDK和Oracle JDK有什么区别和联系</a></li>
<li><a href="https://www.fokyl.com/news/openjdk%20oracle%20jdk%20.html">openjdk与Oraclejdk的区别</a><ul>
<li>在2006年11月13日的JavaOne大会上，Sun公司（当时还没被收购）宣布计划要把Java开源，在随后的一年多时间内，它陆续地将JDK的各个部分在GPL v2（GNU General Public License v2）协议下公开了源码，并建立了OpenJDK组织对这些源码进行独立管理。除了极少量的产权代码（Encumbered Code，这部分代码所有权不属于Sun公司，Sun本身也无权进行开源处理）外，OpenJDK几乎拥有了当时SunJDK 的全部代码。</li>
<li>但是随着JDK版本的不断发布，Oracle失去了维护OpenJDK的耐心，因为不赚钱啊。RedHat从Oracle手上接过OpenJDK的管理权利和维护职责。</li>
</ul>
</li>
<li><a href="https://www.zhihu.com/question/19646618">https://www.zhihu.com/question/19646618</a></li>
<li><a href="https://www.zhihu.com/question/353325963">https://www.zhihu.com/question/353325963</a><ul>
<li>OpenJDK 实际上不适合拿来和 OracleJDK 进行对比，OpenJDK 不提供 LTS 服务，而 OracleJDK 每三年都会推出一个 LTS 版进行长期支持。</li>
</ul>
</li>
<li>从 11+ 版本开始 -XX:+UseContainerSupport 已经自动开启, 可以自适应内存pod的内存限制,不用通过<code>-Xms -Xmx</code> 来设置</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>[Java 9模块化开发_核心原则与实践]</li>
<li><a href="https://blog.csdn.net/weixin_34378888/article/details/112584392">模块化加载_Java9模块化的类加载机制实现剖析</a></li>
<li><a href="https://blog.csdn.net/eMac/article/details/107131444">【JDK 11】关于 Java 模块系统，看这一篇就够了</a></li>
<li><a href="https://www.cnblogs.com/IcanFixIt/p/7131676.html">Java 9 揭秘（8. JDK 9重大改变）</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/87157172">从JDK8升级到JDK11，看这篇就足够了</a></li>
<li><a href="https://stackoverflow.com/questions/47685388/load-class-from-exploded-module-using-custom-classloader">Load class from exploded module using custom classloader</a></li>
<li><a href="https://www.baeldung.com/java-classloaders">Class Loaders in Java</a></li>
<li><a href="https://stackoverflow.com/questions/60764/how-to-load-jar-files-dynamically-at-runtime">How to load JAR files dynamically at Runtime?</a></li>
<li><a href="https://stackoverflow.com/questions/46112809/is-it-possible-to-load-and-unload-jdk-and-custom-modules-dynamically-in-java-9">Is it possible to load and unload jdk and custom modules dynamically in Java 9?</a></li>
<li><a href="https://juejin.cn/post/6844903666932006926">聊聊java9的classloader</a></li>
<li><a href="https://segmentfault.com/a/1190000020110723">JVM_类加载机制详解</a></li>
<li><a href="https://mp.weixin.qq.com/s/ag5u2EPObx7bZr7hkcrOTg">新一代垃圾回收器ZGC的探索与实践</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java9</tag>
        <tag>Java11</tag>
        <tag>模块系统</tag>
      </tags>
  </entry>
  <entry>
    <title>《驱动力》笔记</title>
    <url>/2022/04/04/20220404-qu-dong-li-bi-ji/</url>
    <content><![CDATA[<h3 id="行为的三种驱动力（drive）"><a href="#行为的三种驱动力（drive）" class="headerlink" title="行为的三种驱动力（drive）"></a>行为的三种驱动力（drive）</h3><ul>
<li>①生物性驱动力：人类以及其他动物饮食以止饿，饮水以解渴，交配以满足性欲。</li>
<li>②外在动机：做出特定行为时环境会带来的奖励或惩罚。</li>
<li>③内在奖励：完成任务取得的成绩，获得的愉悦感。</li>
</ul>
<hr>
<ul>
<li>传统的激励因素，也就是我所说的“如果–那么”型奖励（“如果你做这个，就能得到那个”），对于很多简单机械的推算型工作很有效，但对于现代经济赖以为生的需要创造力和概念思维能力的复杂右脑工作来说，这些激励因素大多没什么效果。</li>
<li>自主、专精和目的是超越国家和语言界限的概念。这些概念不是美国的想法也不是中国的想法，它们是人类的理想。人类的天性决定了他们会寻求对自己命运的掌控权，希望自己引导自己。无论住在上海还是芝加哥，人们都希望能在有意义的工作上有所成就。此外，无论在哪里工作和生活我们每个人都想奉献，都想改变世界。</li>
</ul>
<h2 id="引言-科学向左，企业向右"><a href="#引言-科学向左，企业向右" class="headerlink" title="引言 科学向左，企业向右"></a>引言 科学向左，企业向右</h2><ul>
<li>当时，科学家们认识到行为有两种主要的驱动力（drive）。第一种驱动力是生物性驱动力：人类以及其他动物饮食以止饿，饮水以解渴，交配以满足性欲。</li>
<li>如果生物性驱动力来自内部，那么第二种驱动力则来自于外在动机：做出特定行为时环境会带来的奖励或惩罚。</li>
<li>内在动机（intrinsic motivation）的东西的确存在，但是显然它从属于另外两种驱动力。如果猴子解开装置可以得到葡萄干作为奖励，那么它们本应该会毫无疑问地表现更好。但是哈洛这么做的时候，猴子们犯的错误却越来越多，装置解开的次数也有所减少。</li>
<li>“把金钱当做某种行为的外部奖励时，行为主体就失去了对这项活动的内在兴趣。”奖励只能带来短期的爆发，就像是少量咖啡因只能帮你多撑几个小时，但其效果会逐渐消失。更糟糕的是，它降低了人们继续这项工作所需的长期积极性。</li>
<li>人类有“发现新奇事物、进行挑战、拓展并施展才能以及探索和学习的内在倾向”。但是，第三种驱动力比另外两种更脆弱，它只有在合适的环境下才能存在。</li>
<li>第三种驱动力驱使，即我们想要主导自己的人生、学习并创造新事物，通过自己以及我们的世界做得更好的内在需求。</li>
</ul>
<h2 id="第一部分-驱动力3-0时代来临"><a href="#第一部分-驱动力3-0时代来临" class="headerlink" title="第一部分 驱动力3.0时代来临"></a>第一部分 驱动力3.0时代来临</h2><ul>
<li>奖励只能带来短期的爆发，就像是少量咖啡因只能帮你多撑几个小时，更糟糕的是，它还降低了人们继续这项工作所需的长期积极性。</li>
<li>驱动力1.0时代：生物冲动在很久很久以前，比如50 000年前，对人类行为的根本假设很简单也很真实——我们要想尽一切办法生存下来。</li>
<li>驱动力2.0时代：寻求奖励，避免惩罚人类形成了更加复杂的社会，身边的陌生人越来越多。为了做成一件事，我们需要与人合作，纯粹建立在生物性驱动力之上的操作系统出现了局限。</li>
<li>事实上，有时候我们甚至需要对这种驱动力加以限制，以免你偷走了我的午餐，我拐走了你的另一半。因此，我们逐步用与我们的工作和生活方式更匹配的新版本代替了旧版本，这真是人类文化工程上一次非凡的壮举。人类不只是生物冲动的集合。第一种驱动力依然在起作用，这一点毋庸置疑，但它不能完全解释我们是谁。我们也有第二种驱动力：寻求奖励，避免惩罚。从这个角度来看，全新的操作系统——驱动力2.0诞生了。当然，其他动物也会对奖励和惩罚做出反应，但事实证明，只有人类能够疏导这种驱动力，并利用它发明了从合同法到便利店等各种新事物。驾驭第二种驱动力对推进全球经济发展的进程至关重要，近两个世纪尤为如此。</li>
<li>为了确保这种情况的发生，你仅仅需要奖励你鼓励的行为，惩罚你不鼓励的行为。人们会理性地对这些外部作用力（外在动机）做出反应，他们自身以及整个系统都会得到发展。</li>
<li>尽管驱动力2.0系统越来越精密，志向也越来越远大，但它却没有让人变得高尚起来。归根结底，它认为人类和马匹没有太大区别，要想让我们朝正确的方向前进，只需在我们面前放个更脆的胡萝卜或者挥舞更锋利的大棒就行了。</li>
<li>1960年，麻省理工学院管理学教授道格拉斯· 麦格雷戈（Douglas McGregor）把马斯洛的一些观点引入商界，对人的本质是懒惰的、若没有外部奖励或惩罚他们就会安于现状的假设提出了挑战。他说，人有其他更高级的驱动力。如果管理人员和企业领导者尊重这些驱动力，它们就能让企业受益。</li>
<li>以乐为本的内在动机，也就是参与项目时能感受到的创造力是最强大、最常见的动机。</li>
<li>经济学家研究的是人的行为，而不是人的言语，因为我们做出的是对我们最有利的行为，我们是理性的自我经济利益计算者。</li>
<li>我们并不总是理性的个人经济利益计算者，通常不会讨价还价以使自己的利益最大化。</li>
<li>“工作，基本上是简单但不怎么有趣的任务。让人们工作的唯一方法是适当激励、严格监督。”在20世纪初，泰勒的话还是有几分道理的。</li>
<li>外部奖励和惩罚（胡萝卜与大棒并用）对推算型工作很适用，但是对探索型工作可能具有破坏性。</li>
<li>千篇一律、没什么意思的重复性工作需要管理，而有意思的非重复性工作依靠的则是自我管理。</li>
</ul>
<h2 id="第2章-奖励的惩罚，胡萝卜大棒失效了"><a href="#第2章-奖励的惩罚，胡萝卜大棒失效了" class="headerlink" title="第2章 奖励的惩罚，胡萝卜大棒失效了"></a>第2章 奖励的惩罚，胡萝卜大棒失效了</h2><ul>
<li><p>鼓励不道德的行为，带来瘾嗜，滋生短视的思维。但胡萝卜大棒并非总是坏东西。它们对于机械的重复性工作也许很有效，这是因为这种工作几乎没有内在积极性可供破坏，也没有多少创造力来扼杀。对于非重复性的脑力劳动来说，奖励更加危险，“如果-那么”型奖励尤为严重。</p>
</li>
<li><p>对一个行为加以奖励会让这种行为发生的频率增加；对一个行为施以惩罚会让这种行为发生的频率减少。</p>
</li>
<li><p>任何有关工作积极性的讨论都出自生活中一个简单的事实：人必须赚钱谋生。工资、合同款、补助、小费都是我所说的“基线报酬”（baseline reward）。如果一个人得到的基线报酬不足或者分配不公，他的关注点就会放在所处环境的不公以及对环境的焦虑上。因此，你既得不到外在激励因素的可预测性，也得不到内在激励因素难以捉摸的效果，基本上你没法激励他。但是一旦过了这道门槛，胡萝卜大棒就可能会得到与其初衷正好相反的结果。本来是想要提高积极性的机制最后降低了积极性；本来是想要激发创造力的策略最后却抑制了创造力；本来是想要让好人好事越来越多实际上却让好人好事越来越少。与此同时，奖励和惩罚没能限制消极行为，反而让它们大爆发，让欺骗、瘾癖和目光短浅的危险行为越来越多。</p>
</li>
<li><p>从这个有趣的情节里，马克· 吐温提炼出了一条重要的有关积极性的原则：“所谓‘工作’就是一个人被迫要干的事情，至于‘玩’就是一个人没有义务要干的事情。”他还写道：“在夏季，英国有钱的绅士每天驾着四轮马拉客车沿着同样的路线走上30～50公里，他们为这种特权花了很多钱。可是如果因此付钱给他们，那就把这桩事情变成了工作，他们就会撒手不干了。”换言之，奖励有时候很奇怪，它就像对人的行为施了魔法：把有意思的工作变成苦工，把游戏变成工作。它通过减少内在激励因素，让成绩、创造性甚至善行都像多米诺骨牌一样接连倾倒，我们称之为“汤姆索亚效应”（Sawyer Effect）。一些有趣的实验抽样调查揭示了这一效应发生的四个领域，同时也再一次证明：科学向左，企业向右。</p>
</li>
<li><p>有形的奖励实际上会对内在激励因素产生消极影响。如果家庭、学校、企业、运动队等关注的是短期目标，选择的是控制人们的行为，它们就会对长期效果造成相当的损害。</p>
</li>
<li><p>人们用奖励来提高其他人的积极性，提高某种行为发生的频率，希望能从中获益，但他们经常破坏人们对某种行为的内在积极性，无意中增加了隐形成本。</p>
</li>
<li><p>由于印度农村的生活成本要比北美低得多，因此研究人员不必倾家荡产就能提供大量奖励。</p>
</li>
<li><p>奖励会使人们的关注面变窄，遮蔽他们宽广的视野，让他们没法看到常见事物的新用法。</p>
</li>
<li><p>“在艺术学院学习期间，越少表现出外在动机的学生，在艺术的道路上就越成功，无论是毕业几年内还是近20年后都是如此。”这一点对男性尤为明显。对受内在动机激励的画家和雕刻家来说，发现的乐趣和创作带来的挑战就是奖励，他们更能经受住考验，渡过没有报酬、不被认可的艰苦时期，而这段时间在他们的艺术生涯中难以避免。第三种驱动力也有自己的爱丽丝仙境，在这个世界中另一个悖论也随之出现。</p>
</li>
<li><p>研究表明：“有些艺术家之所以能在绘画和雕刻道路上苦苦追寻，是因为创作本身的快乐而非外部奖励，而且他们所创造的艺术也得到了更多社会认可。最终得到外部奖励的人，恰恰是那些最没有动力追求外部奖励的人。”</p>
</li>
<li><p>阿马布勒和其他研究者发现，外部奖励对推算型工作，也就是那些按照既有方式就能得出合理结论的工作很有效。但是对于更依赖右脑的工作，也就是那些需要灵活的问题解决能力、发明创造能力以及思维理解能力的工作来说，有条件的奖励可能会很危险。获得奖励的对象在探寻事物的细微之处、找到原创的解决方案方面，通常会遇到更大的困难。这是社会科学中最毋庸置疑的发现之一</p>
</li>
<li><p>它玷污了这种利他举动，把做善事的内在欲望“挤了出去”。</p>
</li>
<li><p>综上所述，胡萝卜大棒的7个致命弱点如下：</p>
<ul>
<li>● 它们会令内在动机消失；</li>
<li>● 它们会令成绩下降；</li>
<li>● 它们会扼杀创造力；</li>
<li>● 它们会抑制善行；</li>
<li>● 它们会鼓励欺诈、走捷径以及不道德行为；</li>
<li>● 它们会让人上瘾；</li>
<li>● 它们会滋生短视思维。</li>
</ul>
</li>
<li><p>基本要求：任何外部奖励都需要是别人预想不到的，而且只有在任务完成后才能给出。<br> 换言之，“如果–那么”型奖励是个错误，应把它改成“既然–那么”型奖励。比如说，“现在你做好了海报，而且干得很出色，既然这样，那我请你出去吃午饭吧。”</p>
</li>
<li><p>如果物质奖励是在人们完成一项任务后出其不意地给出的，那么人们比较不容易认为奖励是做这项任务的理由，它对内部积极性造成危害的可能性也比较小。</p>
</li>
<li><p>支付高于平均水平的工资是一种绕开“如果–那么”型奖励的优雅方式，它能减少员工对不公平的关注，把钱的问题从桌面上拿开。这是让人们把关注点放在工作本身的又一个方法。事实上，其他经济学家也已经证明，基本工资更多比有吸引力的奖金结构更能提高绩效，更能增加组织认同感。</p>
</li>
</ul>
<h2 id="第3章-做I型人还是X型人"><a href="#第3章-做I型人还是X型人" class="headerlink" title="第3章 做I型人还是X型人"></a>第3章 做I型人还是X型人</h2><ul>
<li><p>I型行为更少关注某一活动带来的外部奖励，而更多关注这项活动本身的内在满足感。</p>
</li>
<li><p>自我决定理论认为人类有三种内在需求：能力的需求（competence）、自主性的需求（autonomy）和归属的需求（relatedness）。如果这些需求得到了满足，我们就会行动积极、工作高效、心情愉悦；但如果这些需求受到阻碍，我们的积极性、工作效率和心情愉悦度就会直线下降。瑞安在与我们的一次谈话中说道：“如果我们天性中有什么东西是基础性的，那这个东西就是感兴趣的能力。有些事情会促进这种能力，而有些事情则会破坏这种能力。”换句话说，我们都有第三种驱动力，它是我们身为人类意义的一部分。但是，我们人性中的这一部分是否会在生活中表现出来，还要看周围环境是否允许。</p>
</li>
<li><p>我们的工作重点，应该是营造一个能够激发各种内在心理需求的环境。</p>
</li>
<li><p>人类有自主、独立、寻求归属感的内在动机。如果这个动机被释放出来，人们就能取得更多成就，就能生活得更加充实。</p>
</li>
<li><p>A型行为模式当然是与B型相对应。A型人终日摇旗呐喊，手舞足蹈，像是得了“匆忙症”，而B型人则与他们不同，他们在生活中似乎很少匆匆忙忙，也不会因为自己的愿望而显得有敌意。</p>
</li>
<li><p>在研究中，弗里德曼和罗森曼发现B型人与A型人一样聪慧，而且通常和A型人一样拥有雄心壮志，只是他们用了不同的方法表现自己的雄心壮志。提到B型人时（当时使用以男性为中心的语言很正常），弗里德曼说：“也许他也有相当的‘驱动力’，但是他的性格是那种动力似乎会让他安心的类型，驱动力给了他信心和安全感，不像A型人，驱动力会困扰他、刺激他、惹怒他。”因此，降低心脏病死亡率、改善公共健康的重点在于帮助A型人变得像B型人。</p>
</li>
<li><p>大多数管理者认为他们的员工从骨子里讨厌工作，要是情况允许一定会逃避工作。这些没有个性的奴隶害怕承担责任，迫切需要安全感，极度渴望被指引。因此，“必须强迫他们，控制他们，给他们指引，用惩罚威胁他们，让他们努力工作，并最终达到企业的目标”。但是，麦格雷戈提出，可以从另外一个视角看待员工。这个视角可以更精确地评估人类的境况，让公司的运营有一个更高的起点。这种观点认为：对工作感兴趣“和玩乐、休息一样自然”，很多人都善于创造，他们足智多谋，只要情况允许，他们就会接受甚至主动寻求责任感。</p>
</li>
<li><p>为了解释这两种截然相反的观点，麦格雷戈从字母表最后挖来了两个字母。他称第一种观点为X理论，第二种观点为Y理论。他说，如果你的出发点是X理论，那么你的管理方法产生的效果难免会有局限，有时甚至可能事与愿违；如果你相信“大众皆平庸”，那么平庸就会成为你无法逾越的天花板。但是如果你的出发点是Y理论，结果就会有无限可能，不只是员工潜能无限，公司的表现水准也会大不一样。因此，想让商业机构更好的运营，就要把管理思维从X理论转向Y理论。</p>
</li>
<li><p>X型行为的核心是第二种驱动力，I型行为的核心是第三种驱动力。</p>
</li>
<li><p>如果我们打算增强组织能量、跳出成绩平平的怪圈，如果我们觉得我们的生意、我们的生活、我们的世界出了问题而且想要解决这些问题，那就需要从X型转向I型。我用这两个字母来代表外在和内在，同时也向道格拉斯· 麦格雷戈致敬。的确，把人类的行为简单分为两类似乎忽略了行为之间的一些细微差别。没有人在分分秒秒、时时刻刻都是X型，也没有人完全是I型，但是的确，我们经常表现出明显不同的个性。</p>
</li>
<li><p>对于X型人来说，外在奖励是主要动机，拥有更深层的满足感当然很好，但这只排第二位；对I型人来说，自由、挑战、担当是主要动机，拥有其他的好处也不错，不过那些只是额外奖励而已。</p>
</li>
<li><p>两者之间的6大区别。</p>
<ul>
<li>第一，I型行为是后天习得而不是先天形成的。这些行为模式不是一成不变，而是基于一定的环境、经验、场景而形成的习惯。由于I型行为部分是出于人类的普遍需求，年龄、性别和国籍对它的影响不大。科学证明，一旦人们学习了基本的行为方式和态度，能够把它们作为背景知识，他们的积极性和最终成绩都会提升。任何X型人都能变为I型人。</li>
<li>第二，从长远的角度看，I型人比X型人表现水准更高。由内在因素激励的群体所取得的成就通常高于寻求外部奖励的竞争对手，但是在短期内情况不见得如此。高度关注外部奖励能够更快达到目标，但问题是这种方法难以持续，对满足专精的欲望也没什么帮助，要知道专精的欲望是长期努力的能量之源。有证据显示，最成功的人一般不直接追求通常意义上的成功。他们之所以努力工作、克服困难、持之以恒，是因为他们有着掌控自己生活、了解外部世界、完成某个长期目标的内在欲望。</li>
<li>第三，I型人不会对金钱和认可嗤之以鼻。I型人和X型人都在意金钱。如果报酬没有达到之前所说的基线，也就是说公司给他的钱不够多或者与其他人的相比不公平，员工无论更倾向于I型还是X型都会失去积极性。然而，一旦报酬达到了那条基线，金钱对I型人和X型人的影响就不一样了。I型人不会拒绝升职或加薪。公正地给他们足够的报酬至关重要，因为这样他们就不再考虑金钱问题，而把注意力集中到工作本身。相比之下，对很多X型人来说金钱才是问题本身，是他们做事的原因所在。得到认可也一样，I型人希望得到认可，是因为认可是对他们工作的反馈，但是与X型人的不同之处在于，认可不是他们的目标所在。</li>
<li>第四，I型行为是可再生资源。我们可以把X型行为比做煤炭，把I型行为比做太阳。近几个世纪里，煤是最便宜、最容易得到、使用效率最高的能源。但是煤有两个缺点。首先，它会带来空气污染、温室气体这些讨厌的东西；其次，它是有限的，使用得越多它就越难获得，价格也会逐年升高。X型行为与之类似，强调奖励或惩罚需要大量的其他外在激励因素（在第2章中已经举了多个例子）。“如果–那么”型的激励因素成本会越来越高，但是I型行为依靠的是内在动机，它所需要的能量很容易加满，能量损耗也比较小。它和清洁能源一样：价格低廉，使用安全，可以再生。</li>
<li>第五，I型行为能让生理和心理状态更好。大量心理研究报告显示，相比需要外在动机推动的群体，由内在动机推动的群体自我评价更高，人际关系更好，总体健康状态也更好。相比之下，那些主要动机是金钱、名誉和美貌等这些外在因素的群体，心理健康状态较差。X型和A型之间存在某种联系。德西发现：倾向于控制和外部奖励的人群自我意识更强，自我保护意识更强，也更容易表现出A型行为模式。</li>
<li>第六，I型行为依赖于三种营养素：自主、专精和目的。I型人由自己决定方向，他的目标在于让一件重要的事情变得越来越好，把追求卓越与更崇高的目标联系在一起。也许有人会对这种见解不屑一顾，认为这种观点太理想主义，太模棱两可，但是科学可不这么认为。科学已经确认了这种行为对人类的重要性，如今在快速变化的社会里，这对任何人和机构的成功都至关重要。因此，我们可以做个选择。我们可以不顾现代科学的观点，坚持以古老的习惯来看待人类的积极性，或者我们可以听听这些研究，把我们的商业行为和个人行为升级到21世纪，用一个新的系统来帮助我们、我们的公司以及我们的世界更好地运转。</li>
</ul>
</li>
<li><p>I型行为是后天习得而不是先天形成的</p>
</li>
<li><p>首先问一个大问题：“你的那句话是什么”；再问一个小问题：“今天的我比昨天更优秀吗”</p>
</li>
<li><p>来次施德明吧</p>
<ul>
<li>每7年，施德明就会关闭他的平面设计工作室，告诉客户这一年内他都不在，他要去享受一次365天的长假。他用这段时间去旅行，去他从未去过的地方生活，去试行自己的新项目。</li>
<li>为身心俱疲做好准备。正因为如此，可以做到刻意练习的人才少得可怜，但这也正是它有效的原因所在。</li>
</ul>
</li>
</ul>
<h1 id="第二部分-驱动力3-0的三大要素"><a href="#第二部分-驱动力3-0的三大要素" class="headerlink" title="第二部分 驱动力3.0的三大要素"></a>第二部分 驱动力3.0的三大要素</h1><ul>
<li><p>人们需要在做什么、什么时候做、和谁做以及如何做上能够自主。也许是时候把“管理”这个词扔进语言学的烟灰堆里了，这个时代不需要更好的管理，它需要自我管理的复兴。</p>
</li>
<li><p>知识工作者决定自己的工作内容及其结果非常必要，这是因为他们必须自主。工作者应该仔细思考他们的工作规划，并按照这个规划执行。我应该关注哪个地方？我负责的事情应该有怎样的结果？最后期限应该是什么时候？</p>
</li>
<li><p>但从长期来看，创新物美价廉，中庸才昂贵，而自主能够当做解毒剂。</p>
</li>
<li><p>ROWE：“只问结果的工作环境”（results–only work environment）。</p>
<ul>
<li>他们不需要某个时间前到达办公室，他们任何时间都可以不在办公室，只要把工作做完就行了。至于怎么做、什么时候做、在哪做都由他们自己来决定。</li>
<li>管理不是走来走去看别人在不在办公室里。”管理是营造能让人们以最佳状态工作的环境。</li>
<li>对他们来说，工作就是手艺，他们需要很多自主权。</li>
<li>在ROWE的环境里，人们不会因为工资涨了10 000或者20 000就跳槽去另一家公司。他们工作时享有的自由比涨工资更有价值、更难以比拟，而且员工的爱人、朋友、家人都是ROWE最坚实的拥护者。</li>
</ul>
</li>
<li><p>工作自主</p>
<ul>
<li>充满好奇心、倾向于自我管理才是我们的本性</li>
<li>自主，这一人类天性的基本品质，是自我决定理论的关键所在。</li>
<li>人们会寻求自主，希望用自主来改善自己的生活</li>
<li>支持自主的老板手下的员工能得到更多满足感。这些老板从员工的角度看问题，给员工有意义的反馈和信息，在要做什么、怎么做的问题上为员工留有很大的选择空间，鼓励员工执行新项目</li>
<li>管理不是解决方法，而是问题本身。</li>
<li>卡农布鲁克斯告诉我：“我们总是坚持认为金钱是你唯一能损失的东西。如果你给的薪水不够多，你就会失去人才。但是除了这个以外，金钱也不能成为激励因素，重要的是其他部分。”</li>
<li>要出现I型行为，人们必须在以下4件事上能够自主：工作内容、工作时间、工作方法和工作团队。</li>
<li>20世纪三四十年代，3M董事长威廉· 麦克奈特（William McKnight），为人谦虚低调、想法别具一格。他信奉一个简单的信条，这在那时看来有点颠覆性：“雇用好人，然后不管他们。”</li>
<li>一个人投入时间的多少和他生产的价值之间的联系没有规律可循，也无法预测。</li>
<li>人们想要做好工作，那么，我们应该让他们关注工作本身而不是他们工作所花费的时间。</li>
<li>如果你想要和更多的I型人一起工作，最好的方法就是把自己也变成其中之一。</li>
<li>鼓励自主并不是鼓励不负责任。</li>
</ul>
</li>
<li><p>评论：自主不是不管不闻不问，任其自由发展，等到出问题的时候来收拾或者给人家评语定性，真正的自主是在员工自我提升自发工作的时候给以及时的提醒和帮助。</p>
</li>
<li><p>驱动力2.0假设：如果人们拥有了自由，他们就会逃避，自主是一种绕开责任的方法。驱动力3.0则基于不同的假设：人们想要负责任，而确保他们对自己的工作内容、工作时间、工作方法、工作团队有控制权，是达到这个目标的必经之路。</p>
</li>
<li><p>我们天生就是玩家，而不是小兵。我们想要做的是自主的个体，而不是机器人。</p>
</li>
<li><p>而I型方式则与此不同。成绩单不是潜在的奖励，而是在学习过程中向学生提供有用反馈的方法。而且I型学生了解，自我评价是获取成绩单的好方法。</p>
</li>
<li><p>给孩子零花钱，让孩子做家务，但不要把这两者混在一起告诉你为什么零花钱对孩子有益：给他们一点自己的钱，让他们决定是存还是花，能够让他们有一些自主权，教他们对钱负责。告诉你为什么家务活对孩子有益：家务活儿能告诉孩子们家庭是建立在彼此的义务之上的，家庭成员需要互相帮助。</p>
</li>
<li><p>确定自己是不是已经精通了某件事的最好方法就是，把它教给别人。</p>
</li>
</ul>
<h2 id="第5章-专精：把想做的事情做得越来越好"><a href="#第5章-专精：把想做的事情做得越来越好" class="headerlink" title="第5章 专精：把想做的事情做得越来越好"></a>第5章 专精：把想做的事情做得越来越好</h2><ul>
<li><p>控制带来的是服从，自主带来的则是投入。</p>
</li>
<li><p>驱动力2.0需要服从，而驱动力3.0需要投入。只有投入才能带来专精，把某件重要的事做得越来越好。对专精的追求是我们第三种驱动力中非常重要、但经常隐匿起来的一部分。专精是由“心流”开始的，即当我们所面临的挑战与我们的能力恰好吻合时的最佳体验。</p>
</li>
<li><p>专精是一种心理定向：它需要一项本领，它不仅不认为我们的能力有限，还认为能力能够无限提高；专精是一种痛苦：它需要努力、坚毅以及刻意练习。专精是一条渐近线：它不可能完全实现，但正因如此，它既让人崩溃又令人着迷。</p>
</li>
<li><p>你会发现一些事情能够让你得到深层的满足，而且它们对你来说非常具有挑战性，想要做这些事情的欲望能够激起最高层次的创造力，无论在艺术、科学还是商业上都是如此。</p>
</li>
<li><p>控制带来的是服从，自主带来的则是投入。正是因为这个差异，I型行为的第二个要素出现了：专精，是指把想做的事情做得越来越好的欲望。</p>
</li>
<li><p>服从让我们能够撑过白天，但投入能让你撑过晚上</p>
</li>
<li><p>他用一个新词代替了那个来自于希腊语的晦涩的形容词，用来描述这些处于最佳状态的时刻：心流。人们生活中最兴奋、最令人满意的体验就是他们处在心流之中的时候。</p>
</li>
<li><p>“金凤花任务”（goldilocks task）：既不太热也不太冷、既不会过于困难也不会过于简单的挑战。工作让人崩溃的原因之一是人们必须做的事情和他们能够做的事情之间不匹配。如果他们必须做的事情超过了他们的能力范围，结果就会是焦虑。如果他们必须做的事情达不到他们的能力范围，结果就会是厌倦。</p>
</li>
<li><p>目标可以分为两类：表现目标（performance goals）和学习目标（learning goals）。在法语课上得A是表现目标，能够说法语是学习目标。德韦克写道：“为了坚持下去并不断尝试，有学习目标的学生不会觉得他们已经擅长一个东西了。毕竟，他们的目标是学习，而不是证明他们很聪明。”</p>
</li>
<li><p>在通往专精的道路上挫折无可避免，他们甚至认为挫折可以当做路途上的指示牌。</p>
</li>
<li><p>尽管更加努力的重要性很容易理解，但长时间工作而不转换目标的重要性可能就没那么好理解了……想要取得更高的成就，坚毅与天分同样关键，在任何领域都是如此。</p>
</li>
<li><p>朱利叶斯· 欧文（Julius Erving）说：“专业就是做你喜欢做的事情，即使在你不想做的时候。”</p>
</li>
<li><p>一个设计的最终成品，永远不会是在一瞬间灵光乍现创造而来的；相反，他带着无限的警惕接近它，跟踪它，一会儿从这个角度，一会儿从那个角度……对他来说，最终成品是一条他无限接近但永远不会到达的渐近线。”</p>
</li>
<li><p>这是专精的自然属性：专精是一条渐近线。归根结底，专精之所以吸引人，正是因为它总是在闪躲。</p>
</li>
<li><p>驱动力3.0所需的深层次投入感并非无关紧要的细枝末节。它是必需品，我们需要它才能存活，它是我们灵魂的氧气。</p>
</li>
<li><p>让你的团队成为“无竞争”地带。一些领导让员工互相竞争，希望竞争能激励他们表现得更好，但这种方法很少奏效，而且它经常会破坏内在积极性。如果你一定要用一个以字母C开头的单词，不要用竞争（competition），改成合作（collaboration）、协作（cooperation）</p>
</li>
<li><p>试试工作轮换。如果有人已经厌倦了手头的任务，看看他能不能把这门已经精通了的技艺传授给其他人。然后再看看他能不能承担一些经验更丰富的成员所做的工作。</p>
</li>
<li><p>用目的鼓舞，而不要用奖励激励。没有什么比共同的使命更能将团队团结在一起了。人们越是追求一项共同的事业，你的团队所做的工作就越是出色、越是让人满意，无论这项事业是让某个事物好得出奇，还是把外部竞争者比下去，甚至是改变世界。</p>
</li>
</ul>
<h2 id="第6章-目的：超越自身的渴望"><a href="#第6章-目的：超越自身的渴望" class="headerlink" title="第6章 目的：超越自身的渴望"></a>第6章 目的：超越自身的渴望</h2><ul>
<li>你是不是常听到“效率”、“利益”、“价值”、“优势”、“焦点”、“差异”这样的词语，这些目标很重要，但它们缺乏唤醒人类心灵的能力。我们常常以利润最大化为中心，而驱动力3.0在不拒绝利润的同时，强调的是目的最大化：如果一个人感觉不到自己属于更伟大更长久的事物，他就无法过上真正出色的生活。寻找目的是我们的天性，我们在复兴属于我们的商业，重塑属于我们的世界……</li>
<li>一个人的生命价值，可以用他对处于逆境中的人的影响力来衡量。既然死亡对每个人来说都是一件确定的事，那么从出生到死亡这段时间内，一个人的生活质量就变得更为重要了。</li>
<li>如果一个人感觉不到自己从属于更伟大、更长久的事物，那他就没法过上真正精彩的生活。米哈伊·希斯赞特米哈伊积极心理学大师</li>
<li>I型行为这张三角桌的前两条腿：自主和专精至关重要。但是，为了保持平衡，我们还需要第三条腿：目的，它能为它的两个伙伴提供内容。朝专精努力的自主的人会有高水准的表现，特别是，如果这么做是为了实现更宏伟的目标，那么这样的人就能取得更多成就。那些由个人内心深处驱动的人，会把他们的愿望系于比自己更宏大的事业上，更不用说那些效率最高、自我满足感最多的人了。</li>
<li>这些安装了驱动力3.0系统的公司的目标，不是在遵守道德准则、法律规范的同时追逐利润，它们的目标是追寻目的，利润是它们的催化剂而不是目标。</li>
<li>研究发现，人们如何花钱至少和他们赚了多少钱一样，都是最重要的。具体来说，把钱花在别人身上，比如给你的爱人买花而不是给你自己买MP3，或者花在某项事业上，比如捐给某个宗教机构而不是去理个价值不菲的发，都能增加我们的主观幸福感。</li>
<li>那些认为自己正在实现目标（积累财富，获得赞誉）的人称，他们的自我满意度、自我评价和积极情感水平并不比做学生的时候高。</li>
<li>满足不仅仅取决于有目标，而且取决于有正确的目标。</li>
<li>一个健康的社会、一个健康的商业机构是从目的开始的，它们把利润看做朝这个目的进发的方式，或者是取得成就后让人愉快的副产品。</li>
<li>专业表现水平高的秘密不是我们的生物性驱动力或者追求奖励、逃避惩罚的第二种驱动力，而是我们的第三种驱动力，是我们想要主导我们的生活、延展我们的能力、让生活更有意义的深层欲望。</li>
<li>我们知道人生中最富足的体验不是得到别人的认可，而是能够倾听自己的声音：做重要的事情，做好它，为了达成自己的事业而努力。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>第三种驱动力驱使，即我们想要主导自己的人生、学习并创造新事物，通过自己以及我们的世界做得更好的内在需求。</li>
<li>驱动力2.0，对于机械的重复性工作也许很有效，这是因为这种工作几乎没有内在积极性可供破坏，也没有多少创造力来扼杀。</li>
<li>汤姆索亚效应</li>
<li>外部奖励对推算型工作，也就是那些按照既有方式就能得出合理结论的工作很有效。但是对于更依赖右脑的工作，也就是那些需要灵活的问题解决能力、发明创造能力以及思维理解能力的工作来说，有条件的奖励可能会很危险。</li>
<li>对于无聊的任务，奖励不会破坏人们的内在积极性，因为根本就没有积极性可以破坏。<ul>
<li>尽管这些看得见摸得着的有条件的奖励经常会破坏内在积极性和创造力，但在这里这些坏处没那么重要。这项任务既不用激发深层的热情，也不需要深度思考。在这个案例里，胡萝卜有益无害。</li>
<li>对这项工作的必要性做出合理解释。若一项本身不那么有意思的工作成为一个大目标的一部分，它就可以变得更有意义，也会更吸引人。解释一下为何海报如此重要，为何寄出它们对机构的使命至关重要。</li>
<li>承认此项任务枯燥无趣。当然，这是为别人着想的做法。承认这一点能让人们明白为何这种“如果–那么”型奖励只是特殊情况而已。</li>
<li>让人们用自己的方式完成任务。给他们自主的权利，不要控制他们。说明你需要的结果。</li>
</ul>
</li>
<li>更好的策略是让报酬数量合理，然后再把它们扔到注意力覆盖范围之外。高效的公司给员工报酬的数量和方式能够让员工几乎忘了报酬这回事，而只是专注于工作本身。</li>
<li>I型行为更少关注某一活动带来的外部奖励，而更多关注这项活动本身的内在满足感。</li>
<li>知识工作者决定自己的工作内容及其结果非常必要，这是因为他们必须自主。支持自主的老板手下的员工能得到更多满足感。管理不是解决方法，而是问题本身。</li>
<li>控制带来的是服从，自主带来的则是投入。专精是一种心理定向：它需要一项本领，它不仅不认为我们的能力有限，还认为能力能够无限提高；专精是一种痛苦：它需要努力、坚毅以及刻意练习。</li>
<li>目标可以分为两类：表现目标（performance goals）和学习目标（learning goals）。在法语课上得A是表现目标，能够说法语是学习目标。</li>
<li>一个人的生命价值，可以用他对处于逆境中的人的影响力来衡量。既然死亡对每个人来说都是一件确定的事，那么从出生到死亡这段时间内，一个人的生活质量就变得更为重要了。</li>
<li>这些安装了驱动力3.0系统的公司的目标，不是在遵守道德准则、法律规范的同时追逐利润，它们的目标是追寻目的，利润是它们的催化剂而不是目标。</li>
<li>满足不仅仅取决于有目标，而且取决于有正确的目标。</li>
<li>成就高的人反而焦虑和抑郁，原因之一是他们没有良好的人际关系。他们忙于赚钱，到处应酬，这意味着他们的生活中留给爱、关心、照顾、同情这些真正重要的东西的空间变少了。</li>
</ul>
<h2 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h2><ul>
<li>在工作中寻找驱动力3.0；自由、挑战、担当是主要动机，拥有其他的好处也不错，不过那些只是额外奖励而已。</li>
<li>努力做B型人（驱动力给了他信心和安全感，不像A型人，驱动力会困扰他、刺激他、惹怒他。”因此，降低心脏病死亡率、改善公共健康的重点在于帮助A型人变得像B型人）</li>
<li>为员工创造驱动力3.0的环境，而不是一味压迫。为什么不让大家开心的工作呢？</li>
<li>如何让团队合理的预估时间和工作呢？有条件的情况下，应该让两个团队一起竞争，做相同的事情。最后的评判标准是预估的合理性和效率。失败的团队并不一定要淘汰，而是可以吸取经验，成长成更靠谱的团队。当然如果一直失败，可能要考虑对团队进行重组了。</li>
<li>ROWE环境：支持自主的老板手下的员工能得到更多满足感。管理不是解决方法，而是问题本身。（前提是人才密度）</li>
<li>利润是它们的催化剂而不是目标。满足不仅仅取决于有目标，而且取决于有正确的目标。</li>
<li>成就高的人反而焦虑和抑郁，原因之一是他们没有良好的人际关系。他们忙于赚钱，到处应酬，这意味着他们的生活中留给爱、关心、照顾、同情这些真正重要的东西的空间变少了。</li>
<li>有第三种驱动力的人，喜欢欣赏自己的代码，精益求精。虽然有时候似乎没人欣赏有点失落，但是没关系，这样做至少能提升自己的效率，和后续写代码的体验</li>
</ul>
<hr>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul>
<li>一位老人在一个小乡村里休养，但附近却住着一些十分顽皮的孩子，他们天天互相追逐打闹，喧哗的吵闹声使老人无法好好休息，在屡禁不止的情况下，老人想出了一个办法——他把孩子们都叫到一起，告诉他们谁叫的声音越大，谁得到的奖励就越多，他每次都根据孩子们吵闹的情况给予不同的奖励。到孩子们已经习惯于获取奖励的时候，老人开始逐渐减少所给的奖励，最后无论孩子们怎么吵，老人一分钱也不给。结果，孩子们认为受到的待遇越来越不公正，认为“不给钱了谁还给你叫”，再也不到老人所住的房子附近大声吵闹了。</li>
<li>评论：社会上流传一句话：有钱人才叫生活，普通人只叫做生存。<br>当然，当今社会，只要不懒，生存应该都没有问题。<br>而高质量的生活在主流社会的语境里应该是房子，车子，票子，即丰富的物质生活。<br>本文的所说的高质量生活很明显不是物质生活，而是追求伟大的目的，让生活变得有意义</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>elasticsearch学习记录</title>
    <url>/2022/04/28/20220408-elasticsearch-xue-xi-ji-lu/</url>
    <content><![CDATA[<p>基于ES 7.10下的简要总结</p>
<h1 id="一、官方文档链接"><a href="#一、官方文档链接" class="headerlink" title="一、官方文档链接"></a>一、官方文档链接</h1><ul>
<li>文档主页：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/index.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/index.html</a></li>
<li>rest api: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/rest-apis.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/rest-apis.html</a></li>
<li>Java rest high client: <a href="https://www.elastic.co/guide/en/elasticsearch/client/java-rest/7.10/java-rest-high.html">https://www.elastic.co/guide/en/elasticsearch/client/java-rest/7.10/java-rest-high.html</a></li>
</ul>
<h1 id="二、基础简要总结"><a href="#二、基础简要总结" class="headerlink" title="二、基础简要总结"></a>二、基础简要总结</h1><h2 id="1、REST-Client"><a href="#1、REST-Client" class="headerlink" title="1、REST Client"></a>1、REST Client</h2><ul>
<li><p>Java Low Level REST Client: 低级别的REST客户端，通过http与集群交互，用户需自己编组请求JSON串，及解析响应JSON串。兼容所有ES版本。</p>
</li>
<li><p>Java High Level REST Client: 高级别的REST客户端，基于低级别的REST客户端，增加了编组请求JSON串、解析响应JSON串等相关api。使用的版本需要保持和ES服务端的版本一致，否则会有版本问题。</p>
</li>
<li><p>ES 7.0版本中弃用TransportClient客户端，且在8.0版本中完全移除它</p>
</li>
</ul>
<h2 id="2、文档元数据"><a href="#2、文档元数据" class="headerlink" title="2、文档元数据"></a>2、文档元数据</h2><ul>
<li>一个文档不仅仅包含它的数据 ，也包含 元数据 —— 有关 文档的信息。 三个必须的元数据元素如下：<ul>
<li>（1）_index<br>  文档在哪存放 （粗暴认为相当于Mysql的database）</li>
<li>（2）_type<br>  文档表示的对象类别 （粗暴认为相当于Mysql的table）（在ES7版本开始已经被打上废弃标识）<br>  -（3）_id<br>  文档唯一标识</li>
<li>（4）其他预定义字段（通常以_开头）<br>    - <code>_timestamp</code> 记录文档索引时间,<code>_ttl</code> 存活时间,  <code>_source</code> 原始JSON文档， <code>_all</code> 所有字段<br>    - <code>_size</code>等</li>
</ul>
</li>
</ul>
<h3 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h3><ul>
<li>ES7为什么废弃type类型：<a href="https://blog.csdn.net/numbbe/article/details/109656567">https://blog.csdn.net/numbbe/article/details/109656567</a></li>
</ul>
<h2 id="3、索引的分片数"><a href="#3、索引的分片数" class="headerlink" title="3、索引的分片数"></a>3、索引的分片数</h2><ul>
<li>（1）一个分片可以是 主分片或者 副本分片。 索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量。<br>(索引包含多个主分片,主分片包含多个文档), 技术上来说，一般一个主分片最大能够存储 Integer.MAX_VALUE - 128 个文档（2147483647 &#x2F; 二十一亿）；</li>
<li>（2）一个副本分片只是一个主分片的拷贝。 副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。<br>在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改；</li>
<li>（3）索引在默认情况下会被分配5个主分片,但是可以在创建时修改；<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PUT /blogs</span><br><span class="line">&#123;</span><br><span class="line">   &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;number_of_shards&quot; : 3,</span><br><span class="line">      &quot;number_of_replicas&quot; : 1</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<ul>
<li>3个主分片和一份副本（每个主分片拥有一个副本分片）</li>
<li>拥有6个分片（3个主分片和3个副本分片）的索引可以最大扩容到6个节点，每个节点上存在一个分片，并且每个分片拥有所在节点的全部资源。</li>
<li>如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。<br>但是更多的副本分片数提高了数据冗余量 。</li>
</ul>
<h2 id="4、索引查询路由"><a href="#4、索引查询路由" class="headerlink" title="4、索引查询路由"></a>4、索引查询路由</h2><ul>
<li><p>路由一个文档到一个分片中</p>
</li>
<li><p>Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？</p>
<ul>
<li><code>shard = hash(routing) % number_of_primary_shards</code></li>
</ul>
</li>
<li><p>routing 是一个可变值，默认是文档的 <code>_id</code></p>
<ul>
<li>这就解释了为什么要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，</li>
<li>那么所有之前路由的值都会无效，文档也再也找不到了。</li>
</ul>
</li>
</ul>
<h2 id="5、分析器（Analyzer）和分词器（Tokenizer）"><a href="#5、分析器（Analyzer）和分词器（Tokenizer）" class="headerlink" title="5、分析器（Analyzer）和分词器（Tokenizer）"></a>5、分析器（Analyzer）和分词器（Tokenizer）</h2><ul>
<li>Elasticsearch这种全文搜索引擎，会用某种算法对建立的文档进行分析，从文档中提取出有效信息（Token）</li>
<li>对于es来说，有内置的分析器（Analyzer）和分词器（Tokenizer）</li>
<li>Es中也支持非常多的分词器：<ul>
<li>Standard 默认的分词器根据 Unicode 文本分割算法，以单词边界分割文本。它删除大多数标点符号。它是大多数语言的最佳选择。</li>
<li>Letter 遇到非字母时分割文本</li>
<li>Lowercase 类似 letter ，遇到非字母时分割文本，同时会将所有分割后的词元转为小写</li>
<li>Whitespace 遇到空白字符时分割位文本</li>
</ul>
</li>
</ul>
<h2 id="6、文档更新并发控制"><a href="#6、文档更新并发控制" class="headerlink" title="6、文档更新并发控制"></a>6、文档更新并发控制</h2><ul>
<li>更新文档：POST，可以发送部分文档进行更新; upsert (更新或新增文档)；使用脚本来更新文档（不常用）</li>
<li>通过版本来实现并发控制（可以取时间戳作为version参数）</li>
<li>版本冲突时自动重试更新操作（retry_on_conflict 参数）</li>
<li>更新文档其实是先删除旧的文档，再索引新的文档。</li>
</ul>
<h2 id="7、文档查询"><a href="#7、文档查询" class="headerlink" title="7、文档查询"></a>7、文档查询</h2><ul>
<li>在 Elasticsearch 中， 每个字段的所有数据 都是 默认被索引的。 即每个字段都有为了快速检索设置的专用倒排索引</li>
<li>返回文档的一部分: 单个字段能用 <code>_source</code> 参数请求得到，多个字段也能使用逗号分隔的列表来指定</li>
</ul>
<h2 id="8、搜索提示"><a href="#8、搜索提示" class="headerlink" title="8、搜索提示"></a>8、搜索提示</h2><ul>
<li>Elasticsearch Suggester- Google在用户刚开始输入的时候是自动补全的，而当输入到一定长度，如果因为单词拼写错误无法补全，就开始尝试提示相似的词。</li>
<li>那么类似的功能在Elasticsearch里如何实现呢？ 答案就在Suggesters API。 Suggesters基本的运作原理是将输入的文本分解为token，然后在索引的字典里查找相似的term并返回。</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>Term Suggester，基于编辑距离，对analyze过的单个term去提供建议，并不会考虑多个term&#x2F;词组之间的关系。</li>
<li>Phrase Suggester，在Term Suggester的基础上，通过ngram以词组为单位返回建议。</li>
<li>Completion Suggester，FST数据结构，类似Trie树，并非使用倒排索引，只能前缀匹配，快速返回</li>
<li>Context Suggester，在Completion Suggester的基础上，用于filter和boost</li>
</ul>
<h3 id="相关链接-1"><a href="#相关链接-1" class="headerlink" title="相关链接"></a>相关链接</h3><ul>
<li>elasticsearch suggest： <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/search-suggesters.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/search-suggesters.html</a></li>
<li>elasticsearch Term Suggester ：<a href="https://www.cnblogs.com/Neeo/articles/10694969.html">https://www.cnblogs.com/Neeo/articles/10694969.html</a></li>
<li>elasticsearch Phrase Suggester： <a href="https://blog.csdn.net/UbuntuTouch/article/details/103952092">https://blog.csdn.net/UbuntuTouch/article/details/103952092</a></li>
<li>elasticsearch completion Suggester: completion ：<a href="https://www.jianshu.com/p/8a6b80813a34">https://www.jianshu.com/p/8a6b80813a34</a></li>
</ul>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="mapping中的store属性"><a href="#mapping中的store属性" class="headerlink" title="mapping中的store属性"></a>mapping中的store属性</h3><ul>
<li>Elasticsearch 理解mapping中的store属性：<a href="https://www.cnblogs.com/sanduzxcvbnm/p/12157453.html">https://www.cnblogs.com/sanduzxcvbnm/p/12157453.html</a></li>
</ul>
<h3 id="searchType"><a href="#searchType" class="headerlink" title="searchType"></a>searchType</h3><ul>
<li>QUERY_THEN_FETCH,QUERY_AND_FEATCH,DFS_QUERY_THEN_FEATCH和DFS_QUERY_AND_FEATCH</li>
<li>总结一下， 从性能考虑 QUERY_AND_FETCH 是最快的， DFS_QUERY_THEN_FETCH 是最慢的。从搜索的准确度来说， DFS 要比非 DFS 的准确度更高。</li>
</ul>
<h4 id="相关链接-2"><a href="#相关链接-2" class="headerlink" title="相关链接"></a>相关链接</h4><ul>
<li><a href="https://www.cnblogs.com/ningskyer/articles/5984346.html">https://www.cnblogs.com/ningskyer/articles/5984346.html</a></li>
<li><a href="https://segmentfault.com/a/1190000015409044">https://segmentfault.com/a/1190000015409044</a></li>
</ul>
<h1 id="三、DSL全文搜索"><a href="#三、DSL全文搜索" class="headerlink" title="三、DSL全文搜索"></a>三、DSL全文搜索</h1><ul>
<li>Elasticsearch Query DSL之全文检索(Full text queries) ： <a href="https://blog.csdn.net/prestigeding/article/details/102295397">https://blog.csdn.net/prestigeding/article/details/102295397</a></li>
</ul>
<h2 id="1、match-query"><a href="#1、match-query" class="headerlink" title="1、match query"></a>1、match query</h2><ul>
<li>标准的全文检索模式，包含模糊匹配、前缀或近似匹配等。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;query&quot;: &#123;</span><br><span class="line">&quot;match&quot; : &#123;</span><br><span class="line">&quot;message&quot; : &quot;this out Elasticsearch&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SearchSourceBuilder</span> <span class="variable">sourceBuilder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SearchSourceBuilder</span>();</span><br><span class="line">sourceBuilder.query(QueryBuilders.matchQuery(<span class="string">&quot;message&quot;</span>, <span class="string">&quot;this out elasticsearch&quot;</span>));</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2-match-phrase-query"><a href="#2-match-phrase-query" class="headerlink" title="2. match_phrase query"></a>2. match_phrase query</h2><ul>
<li>与match query类似，但只是用来精确匹配的短语。</li>
<li>如果查询字符串为 quick fox，分词后的词根序列为 quick fox，与原词根序列不匹配。如果指定slop属性，设置为1，则匹配，其表示每一个词根直接跳过一个词根形成新的序列，与搜索词根进行比较，是否匹配。</li>
</ul>
<h2 id="3-match-phrase-prefix-query"><a href="#3-match-phrase-prefix-query" class="headerlink" title="3. match_phrase_prefix query"></a>3. match_phrase_prefix query</h2><ul>
<li>与match_phrase查询类似，但是在最后一个单词上执行通配符搜索。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match_phrase_prefix&quot; : &#123;</span><br><span class="line">            &quot;message&quot; : &#123;</span><br><span class="line">                &quot;query&quot; : &quot;quick brown f&quot;,</span><br><span class="line">                &quot;max_expansions&quot; : 10</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>默认查找50组，受参数max_expansions控制，在使用时请设置合理的max_expansions，该值越大，查询速度将会变的更慢。该技术主要完成及时搜索，指用户在输入过程中，就根据前缀返回查询结果，随着用户输入的字符越多，查询的结果越接近用户的需求。</li>
</ul>
<h2 id="4-multi-match-query-（多字段查询）"><a href="#4-multi-match-query-（多字段查询）" class="headerlink" title="4. multi_match query （多字段查询）"></a>4. multi_match query （多字段查询）</h2><h3 id="type-属性"><a href="#type-属性" class="headerlink" title="type 属性"></a>type 属性</h3><ul>
<li>指定multi_query内部的执行方式，取值如下：best_fields、most_fields、cross_fields、phrase、phrase_prefix （5种）。</li>
</ul>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><ul>
<li><p>best_fields 按照match检索，所有字段单独计算得分并取最高分的field为最终_score，虽然是默认值，但不建议使用，数据量上来后查询性能会下降</p>
</li>
<li><p>most_fields 按照match检索，融合所有field得分为最终_score</p>
</li>
<li><p>cross_fields 将fields中的所有字段融合成一个大字段进行match检索，此时要求所有字段使用相同分析器</p>
</li>
<li><p>phrase 按照match_phrase检索，默认slop为0，执行短语精确匹配，所以即便设置 minimum_should_match 也无效; 取最高字段得分</p>
</li>
<li><p>phrase_prefix 按照match_phrase_prefix检索，滑动步长slop默认为0；取最高字段得分</p>
</li>
<li><p>bool_prefix 按照match_bool_prefix检索</p>
</li>
<li><p>slop参数告诉match_phrase查询词条能够相隔多远时仍然将文档视为匹配。相隔多远的意思是，你需要移动一个词条多少次来让查询和文档匹配？<br>我们以一个简单的例子来阐述这个概念。为了让查询quick fox能够匹配含有quick brown fox的文档，我们需要slop的值为1</p>
</li>
</ul>
<h3 id="1、best-fields"><a href="#1、best-fields" class="headerlink" title="1、best_fields"></a>1、best_fields</h3><ul>
<li>type默认值，只要其中一个字段匹配则匹配文档（match query)。但是使用最佳匹配的字段的score来表示文档的分数，会影响文档的排序。</li>
</ul>
<h3 id="2、most-fields"><a href="#2、most-fields" class="headerlink" title="2、most_fields"></a>2、most_fields</h3><ul>
<li><p>查找匹配任何字段并结合每个字段的_score的文档，Elasticsearch会为每个字段生成一个match查询，然后将它们包含在一个bool查询中。其算法的核心是各个字段的评分相加作为文档的最终得分参与排序。</p>
</li>
<li><p>其建议场景是不同字段对同一关键字的存储维度不一样，例如字段一可能包含同义词、词干、变音符等；字段二可能包含原始词根，这种情况下综合各个字段的评分就会显的更加具有相关性。</p>
</li>
</ul>
<h3 id="3、phrase、phrase-prefix"><a href="#3、phrase、phrase-prefix" class="headerlink" title="3、phrase、phrase_prefix"></a>3、phrase、phrase_prefix</h3><ul>
<li>这两种类型score的计算采用best_fields方法，但是其查询方式分别为match_phrase、match_phrase_prefix</li>
</ul>
<h3 id="4、cross-fields"><a href="#4、cross-fields" class="headerlink" title="4、cross_fields"></a>4、cross_fields</h3><ul>
<li>交叉字段，对于需要匹配多个字段的结构化文档，cross_fields类型特别有用。例如，在查询“Will Smith”的first_name和last_name字段时，在一个字段中可能会有“Will”，而在另一个字段中可能会有“Smith”。这听起来很象most_fields，cross_fields与most_fields的两个明显区别如下：</li>
<li>对于opreator、minimum_should_match的作用域不一样，most_fields是针对字段的，（遍历每个字段，然后遍历查询词根列表，进行逐一匹配），而cross_fields是针对词根的，即遍历词根列表，搜索范围是所有字段。</li>
<li>相关性的考量不相同，cross_fields重在这个交叉匹配，对于一组查询词根，一部分出现在其中一个字段，另外一部分出现在另外一个字段中，其相关性计算评分将更高。</li>
</ul>
<h3 id="tie-breaker属性"><a href="#tie-breaker属性" class="headerlink" title="tie_breaker属性"></a>tie_breaker属性</h3><ul>
<li>默认情况下，每个词汇混合查询将使用组中任何字段返回的最佳分数，然后将这些分数相加，以给出最终分数。tie_breaker参数可以改变每项混合查询的默认行为。</li>
<li>tie_breaker可选值如下：<ul>
<li>0.0 ： 默认行为，使用最佳字段的score。</li>
<li>1.0 ：所有匹配字段socre的和。</li>
<li>0.0 ~ 1.0 : 使用最佳匹配字段的score + (其他匹配字段score) * tie_breaker。</li>
</ul>
</li>
</ul>
<h3 id="most-fields-vs-cross-fields"><a href="#most-fields-vs-cross-fields" class="headerlink" title="most_fields vs cross_fields"></a>most_fields vs cross_fields</h3><ul>
<li><p>most_fields: Finds documents which match any field and combines the <code>_score</code> from each field.</p>
</li>
<li><p>cross_fields: Treats fields with the same analyzer as though they were one big field. Looks for each word in any field.</p>
</li>
<li><p>Elasticsearch搜索之cross_fields分析: <a href="https://www.cnblogs.com/clonen/p/6674939.html">https://www.cnblogs.com/clonen/p/6674939.html</a></p>
</li>
<li><p>cross_fields类型采用了一种以词条为中心(Term-centric)的方法，这种方法和best_fields及most_fields采用的以字段为中心(Field-centric)的方法有很大的区别。</p>
</li>
</ul>
<h3 id="most-field-vs-best-field"><a href="#most-field-vs-best-field" class="headerlink" title="most_field vs best_field"></a>most_field vs best_field</h3><ul>
<li><p><a href="https://www.cnblogs.com/lovezhr/p/14421872.html">https://www.cnblogs.com/lovezhr/p/14421872.html</a></p>
</li>
<li><p>best-fields策略，主要是说将某一个field匹配尽可能多的关键词的doc优先返回回来</p>
</li>
<li><p>most-fields策略，主要是说尽可能返回更多field匹配到某个关键词的doc，优先返回回来</p>
</li>
<li><p>两者差异</p>
<ul>
<li>（1）best_fields，是对多个field进行搜索，挑选某个field匹配度最高的那个分数，同时在多个query最高分相同的情况下，在一定程度上考虑其他query的分数。简单来说，你对多个field进行搜索，就想搜索到某一个field尽可能包含更多关键字的数据<ul>
<li>优点：通过best_fields策略，以及综合考虑其他field，还有minimum_should_match支持，可以尽可能精准地将匹配的结果推送到最前面</li>
<li>缺点：除了那些精准匹配的结果，其他差不多大的结果，排序结果不是太均匀，没有什么区分度了</li>
<li>实际的例子：百度之类的搜索引擎，最匹配的到最前面，但是其他的就没什么区分度了</li>
</ul>
</li>
<li>（2）most_fields，综合多个field一起进行搜索，尽可能多地让所有fieldquery参与到总分数的计算中来，此时就会是个大杂烩，出现类似best_fields案例最开始的那个结果，结果不一定精准，某一个document的一个field包含更多的关键字，但是因为其他document有更多field匹配到了，所以排在了前面；所以需要建立类似sub_title.std这样的field，尽可能让某一个field精准匹配query string，贡献更高的分数，将更精准匹配的数据排到前面<ul>
<li>优点：将尽可能匹配更多field的结果推送到最前面，整个排序结果是比较均匀的</li>
<li>缺点：可能那些精准匹配的结果，无法推送到最前面</li>
<li>实际的例子：wiki，明显的most_fields策略，搜索结果比较均匀，但是的确要翻好几页才能找到最匹配的结果</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="相关链接-3"><a href="#相关链接-3" class="headerlink" title="相关链接"></a>相关链接</h4><ul>
<li><a href="https://blog.csdn.net/prestigeding/article/details/102295397">https://blog.csdn.net/prestigeding/article/details/102295397</a></li>
<li><a href="https://www.jianshu.com/p/2a27b4985331">https://www.jianshu.com/p/2a27b4985331</a></li>
</ul>
<h2 id="5-common-terms-query"><a href="#5-common-terms-query" class="headerlink" title="5. common terms query"></a>5. common terms query</h2><ul>
<li>相比match query，消除停用词与高频词对相关度的影响。</li>
<li>定位：排除停用词或高频词对文档的匹配影响。提高文档匹配的精确度，同时不对性能产生影响。</li>
</ul>
<h2 id="6-query-string-query"><a href="#6-query-string-query" class="headerlink" title="6. query_string query"></a>6. query_string query</h2><ul>
<li><p>查询字符串方式。query_string查询解析器支持对查询字符串按照操作符进行切割，每个部分独立分析</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;query_string&quot; : &#123;</span><br><span class="line">            &quot;default_field&quot; : &quot;content&quot;,</span><br><span class="line">            &quot;query&quot; : &quot;(new york city) OR (big apple)&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>多字段支持（multi field）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;query_string&quot; : &#123;</span><br><span class="line">            &quot;fields&quot; : [&quot;content&quot;, &quot;name&quot;],</span><br><span class="line">            &quot;query&quot; : &quot;this AND that&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>其含义类似于：“query”: “(content:this OR name:this) AND (content:that OR name:that)”。</p>
</li>
<li><p>同时query_string(查询字符串)模式同样支持match_query等查询对应的参数，其工作机制一样</p>
</li>
</ul>
<h2 id="7-simple-query-string-query"><a href="#7-simple-query-string-query" class="headerlink" title="7. simple_query_string query"></a>7. simple_query_string query</h2><ul>
<li>简单查询字符串方式</li>
<li>使用SimpleQueryParser解析上下文的查询。与常规的query_string查询不同，simple_query_string查询永远不会抛出异常，并丢弃查询的无效部分</li>
</ul>
<h2 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h2><ul>
<li>match_all 查询</li>
<li>match 查询</li>
<li>multi_match 查询</li>
<li>range 查询</li>
<li>term 查询</li>
<li>terms 查询</li>
<li>exists 查询</li>
<li>missing 查询</li>
</ul>
<ul>
<li>bool 查询<ul>
<li>must<br>  文档 必须 匹配这些条件才能被包含进来。</li>
<li>must_not<br>  文档 必须不 匹配这些条件才能被包含进来。</li>
<li>should<br>  如果满足这些语句中的任意语句，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。</li>
<li>filter<br>  必须 匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。<br>  如果没有 must 语句，那么至少需要能够匹配其中的一条 should 语句。但，如果存在至少一条 must 语句，则对 should 语句的匹配没有要求。</li>
</ul>
</li>
</ul>
<h1 id="四、扩展"><a href="#四、扩展" class="headerlink" title="四、扩展"></a>四、扩展</h1><h2 id="1、索引别名和零停机"><a href="#1、索引别名和零停机" class="headerlink" title="1、索引别名和零停机"></a>1、索引别名和零停机</h2><ul>
<li>重建索引的问题是必须更新应用中的索引名称。 索引别名就是用来解决这个问题的。</li>
<li>索引 别名 就像一个快捷方式或软连接，可以指向一个或多个索引，也可以给任何一个需要索引名的API来使用。</li>
<li>在应用中使用别名而不是索引名。然后就可以在任何时候重建索引。</li>
<li>准备好数据才能切换。</li>
<li>新增新字段不需要重建索引。</li>
</ul>
<h3 id="重新索引数据"><a href="#重新索引数据" class="headerlink" title="重新索引数据"></a>重新索引数据</h3><ul>
<li>尽管可以增加新的类型到索引中，或者增加新的字段到类型中，但是不能添加新的分析器或者对现有的字段做改动。 如果你那么做的话，结果就是那些已经被索引的数据就不正确， 搜索也不能正常工作。</li>
<li>对现有数据的这类改变最简单的办法就是重新索引：用新的设置创建新的索引并把文档从旧的索引复制到新的索引。</li>
<li>为了有效的重新索引所有在旧的索引中的文档，用 scroll 从旧的索引检索批量文档 ， 然后用 bulk API 把文档推送到新的索引中。</li>
<li>(从Elasticsearch v2.3.0开始， Reindex API 被引入。它能够对文档重建索引而不需要任何插件或外部工具。)</li>
</ul>
<h3 id="使用reindex-api将旧索引数据导入新索引"><a href="#使用reindex-api将旧索引数据导入新索引" class="headerlink" title="使用reindex api将旧索引数据导入新索引"></a>使用reindex api将旧索引数据导入新索引</h3><ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/docs-reindex.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/docs-reindex.html</a></li>
<li>reindex的底层是scroll实现<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line"> &quot;source&quot;: &#123;</span><br><span class="line">  &quot;index&quot;: &quot;song.20220425_3&quot;</span><br><span class="line"> &#125;,</span><br><span class="line"> &quot;dest&quot;: &#123;</span><br><span class="line">  &quot;index&quot;: &quot;song.20220425_4&quot;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="新索引同时在写数据，如何防止冲突？"><a href="#新索引同时在写数据，如何防止冲突？" class="headerlink" title="新索引同时在写数据，如何防止冲突？"></a>新索引同时在写数据，如何防止冲突？</h3><ul>
<li>默认情况下，当发生 version conflict 的时候，_reindex 会被 abort，任务终止【此时数据还没有 reindex 完成】，在返回体中的 failures 指标中会包含冲突的数据【有时候数据会非常多】，除非把 conflicts 设置为 proceed。</li>
<li>（1）只创建目标索引中缺少的文档  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">&quot;source&quot;: &#123;</span><br><span class="line">&quot;index&quot;: &quot;pigg_test&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;dest&quot;: &#123;</span><br><span class="line">&quot;index&quot;: &quot;pigg_test2&quot;,</span><br><span class="line">&quot;op_type&quot;: &quot;create&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>（2）版本高的才复制<ul>
<li>external 等同 external_gt</li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/docs-index_.html#index-version-types">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/docs-index_.html#index-version-types</a>  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">&quot;source&quot;: &#123;</span><br><span class="line">&quot;index&quot;: &quot;twitter&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;dest&quot;: &#123;</span><br><span class="line">&quot;index&quot;: &quot;new_twitter&quot;,</span><br><span class="line">&quot;version_type&quot;: &quot;external&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="如何提升迁移效率？"><a href="#如何提升迁移效率？" class="headerlink" title="如何提升迁移效率？"></a>如何提升迁移效率？</h3><ul>
<li>默认情况下，_reindex使用1000进行批量操作，您可以在source中调整batch_size。</li>
</ul>
<h3 id="如何查看执行进度？"><a href="#如何查看执行进度？" class="headerlink" title="如何查看执行进度？"></a>如何查看执行进度？</h3><ul>
<li>默认执行同步返回结果的。</li>
</ul>
<h4 id="异步执⾏"><a href="#异步执⾏" class="headerlink" title="异步执⾏"></a>异步执⾏</h4><ul>
<li>如果 reindex 时间过⻓，建议加上 wait_for_completion&#x3D;false 的参数条件，这样 reindex 将直接返回 taskId。<pre>
POST /_reindex?wait_for_completion=false
  {
      "source": {
          "index": "blog"
      },
      "dest": {
          "index": "blog_lastest"
      }
  }
  
  返回：
  
  {
    "task" : "dpBihNSMQfSlboMGlTgCBA:4728038"
  }</pre></li>
</ul>
<p></p>
<h3 id="根据taskId可以实时查看任务的执行状态"><a href="#根据taskId可以实时查看任务的执行状态" class="headerlink" title="根据taskId可以实时查看任务的执行状态"></a>根据taskId可以实时查看任务的执行状态</h3><ul>
<li>一般来说，如果我们的 source index 很大【比如几百万数据量】，则可能需要比较长的时间来完成 _reindex 的工作，可能需要几十分钟。而在此期间不可能一直等待结果返回，可以去做其它事情，如果中途需要查看进度，可以通过 _tasks API 进行查看。</li>
<li><code>GET /_tasks/&#123;taskId&#125;</code></li>
</ul>
<h3 id="如何取消任务"><a href="#如何取消任务" class="headerlink" title="如何取消任务?"></a>如何取消任务?</h3><ul>
<li><code>POST _tasks/task_id/_cancel</code></li>
</ul>
<h3 id="相关链接-4"><a href="#相关链接-4" class="headerlink" title="相关链接"></a>相关链接</h3><ul>
<li><a href="https://zhuanlan.zhihu.com/p/341337374">https://zhuanlan.zhihu.com/p/341337374</a></li>
</ul>
<h2 id="2、深分页问题"><a href="#2、深分页问题" class="headerlink" title="2、深分页问题"></a>2、深分页问题</h2><ul>
<li><p>需要从集群取回大量的文档，使用游标查询 Scroll：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/scroll-api.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/scroll-api.html</a></p>
</li>
<li><p>scroll 查询 可以用来对 Elasticsearch 有效地执行大批量的文档查询，而又不用付出深度分页那种代价。</p>
</li>
<li><p>游标查询会取某个时间点的快照数据。 查询初始化之后索引上的任何变化会被它忽略。</p>
</li>
<li><p>它通过保存旧的数据文件来实现这个特性，结果就像保留初始化时的索引 视图 一样。</p>
</li>
<li><p>深度分页的代价根源是结果集全局排序，如果去掉全局排序的特性的话查询结果的成本就会很低。</p>
</li>
<li><p>启用游标查询可以通过在查询的时候设置参数 scroll 的值为我们期望的游标查询的过期时间。</p>
</li>
<li><p>这个过期时间的参数很重要，因为保持这个游标查询窗口需要消耗资源，所以我们期望如果不再需要维护这种资源就该早点儿释放掉。<br>设置这个超时能够让 Elasticsearch 在稍后空闲的时候自动释放这部分资源。</p>
</li>
<li><p>查询的返回结果包括一个字段 <code>_scroll_id</code>， 它是一个base64编码的长字符串</p>
</li>
<li><p>尽管我们指定字段 size 的值为1000，我们有可能取到超过这个值数量的文档。 当查询的时候， 字段 size 作用于单个分片，所以每个批次实际返回的文档数量最大为 <code>size * number_of_primary_shards</code> 。</p>
</li>
<li><p>注意游标查询每次返回一个新字段 <code>_scroll_id</code>。每次我们做下一次游标查询， 我们必须把前一次查询返回的字段 <code>_scroll_id</code> 传递进去。当没有更多的结果返回的时候，我们就处理完所有匹配的文档了。</p>
</li>
<li><p>理解为什么深度分页是有问题的，我们可以假设在一个有 5 个主分片的索引中搜索。 当我们请求结果的第一页（结果从 1 到 10 ），每一个分片产生前 10 的结果，并且返回给 协调节点 ，协调节点对 50 个结果排序得到全部结果的前 10 个。</p>
</li>
<li><p>现在假设我们请求第 1000 页–结果从 10001 到 10010 。所有都以相同的方式工作除了每个分片不得不产生前10010个结果以外。 然后协调节点对全部 50050 个结果排序最后丢弃掉这些结果中的 50040 个结果。</p>
</li>
<li><p>可以看到，在分布式系统中，对结果排序的成本随分页的深度成指数上升。这就是 web 搜索引擎对任何查询都不要返回超过 1000 个结果的原因。</p>
</li>
<li><p>排序过程可能会变得非常沉重，使用大量的CPU、内存和带宽。因为这个原因，我们强烈建议你不要使用深分页。</p>
</li>
<li><p>实际上， “深分页” 很少符合人的行为。当2到3页过去以后，人会停止翻页，并且改变搜索标准。</p>
</li>
<li><p>会不知疲倦地一页一页的获取网页直到你的服务崩溃的罪魁祸首一般是机器人或者web spider。</p>
</li>
<li><p>如果确实 需要从你的集群取回大量的文档，你可以通过用 scroll 查询禁用排序使这个取回行为更有效率。</p>
</li>
</ul>
<h2 id="3、highlight-参数"><a href="#3、highlight-参数" class="headerlink" title="3、highlight 参数"></a>3、highlight 参数</h2><ul>
<li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/highlighting.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/highlighting.html</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line"> &quot;query&quot;: &#123;</span><br><span class="line">  &quot;match&quot;: &#123;</span><br><span class="line">   &quot;content&quot;: &quot;kimchy&quot;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;,</span><br><span class="line"> &quot;highlight&quot;: &#123;</span><br><span class="line">  &quot;fields&quot;: &#123;</span><br><span class="line">   &quot;content&quot;: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>ragment_size ：指定高亮数据展示多少个字符回来； <br>  fragment_size The size of the highlighted fragment in characters. Defaults to 100</p>
</li>
</ul>
<h2 id="4、聚合（aggregations）"><a href="#4、聚合（aggregations）" class="headerlink" title="4、聚合（aggregations）"></a>4、聚合（aggregations）</h2><ul>
<li><p>允许我们基于数据生成一些精细的分析结果</p>
</li>
<li><p>加载和搜索相匹配的文档，并且完成各种计算。</p>
</li>
<li><p>两种类型的聚集：桶型和度量型</p>
<ul>
<li>度量型 ： 某个字段最大值，最小值，平均值等</li>
<li>桶型 ：某个论坛最流行的帖子等</li>
</ul>
</li>
</ul>
<h2 id="5、集群扩容、故障转移"><a href="#5、集群扩容、故障转移" class="headerlink" title="5、集群扩容、故障转移"></a>5、集群扩容、故障转移</h2><ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/scalability.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/scalability.html</a></li>
</ul>
<h2 id="6、运维监控"><a href="#6、运维监控" class="headerlink" title="6、运维监控"></a>6、运维监控</h2><ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/monitor-elasticsearch-cluster.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/monitor-elasticsearch-cluster.html</a></li>
</ul>
<h2 id="7、es-日志，-慢搜索，慢索引"><a href="#7、es-日志，-慢搜索，慢索引" class="headerlink" title="7、es 日志， 慢搜索，慢索引"></a>7、es 日志， 慢搜索，慢索引</h2><ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/index-modules-slowlog.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/index-modules-slowlog.html</a></li>
</ul>
<h2 id="8、相关性"><a href="#8、相关性" class="headerlink" title="8、相关性"></a>8、相关性</h2><ul>
<li><p>Elasticsearch 相关度评分 TF&amp;IDF算法：<a href="https://www.jianshu.com/p/05219358a2e9">https://www.jianshu.com/p/05219358a2e9</a></p>
</li>
<li><p>fuzzy 查询会计算与关键词的拼写相似程度，terms 查询会计算 找到的内容与关键词组成部分匹配的百分比，</p>
</li>
<li><p>但是通常我们说的 relevance 是我们用来计算全文本字段的值相对于全文本检索词相似程度的算法。</p>
</li>
<li><p>Elasticsearch 的相似度算法 被定义为检索词频率&#x2F;反向文档频率， TF&#x2F;IDF ，包括以下内容：</p>
<ul>
<li>检索词频率<br>  检索词在该字段出现的频率？出现频率越高，相关性也越高。 字段中出现过 5 次要比只出现过 1 次的相关性高。</li>
<li>反向文档频率<br>  每个检索词在索引中出现的频率？频率越高，相关性越低。检索词出现在多数文档中会比出现在少数文档中的权重更低。</li>
<li>字段长度准则<br>  字段的长度是多少？长度越长，相关性越低。 检索词出现在一个短的 title 要比同样的词出现在一个长的 content 字段权重更大。</li>
</ul>
</li>
<li><p>控制相关度：<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/search-rank-eval.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/search-rank-eval.html</a></p>
</li>
</ul>
<h2 id="9、explain-api"><a href="#9、explain-api" class="headerlink" title="9、explain api"></a>9、explain api</h2><ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/_explain_analyze.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/_explain_analyze.html</a></li>
</ul>
<h2 id="10、refresh-API-和-flush-API"><a href="#10、refresh-API-和-flush-API" class="headerlink" title="10、refresh API 和  flush API"></a>10、refresh API 和  flush API</h2><ul>
<li><p>重点：新段会被先写入到文件系统缓存，refresh则是从这个文件缓存获取新段（写入和打开一个新段的轻量的过程叫做 refresh ）<br>默认一秒刷新，可以设置</p>
</li>
<li><p>在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 refresh 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是 近 实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。</p>
</li>
<li><p>如果没有用 fsync 把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证 Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。</p>
</li>
<li><p>在 动态更新索引，我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。</p>
</li>
<li><p>即使通过每秒刷新（refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。</p>
</li>
<li><p>Elasticsearch 增加了一个 translog ，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录。通过 translog</p>
</li>
<li><p>translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。</p>
</li>
<li><p>translog 也被用来提供实时 CRUD 。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前， 首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。</p>
</li>
<li><p>这个执行一个提交并且截断 translog 的行为在 Elasticsearch 被称作一次 flush 。 分片每30分钟被自动刷新（flush），或者在 translog 太大的时候也会刷新。</p>
</li>
<li><p>flush API 可以 被用来执行一个手工的刷新（flush）<br><code>POST /blogs/_flush</code> , <code>POST /_flush?wait_for_ongoin</code></p>
</li>
</ul>
<h1 id="五、常用REST命令"><a href="#五、常用REST命令" class="headerlink" title="五、常用REST命令"></a>五、常用REST命令</h1><ul>
<li><p>PUT 谓词(“使用这个 URL 存储这个文档”)，</p>
</li>
<li><p>POST 谓词(“存储文档在这个 URL 命名空间下”)</p>
</li>
<li><p>GET 查询</p>
</li>
<li><p>DELETE 删除</p>
</li>
<li><p>HEAD 检查文档是否存在</p>
</li>
<li><p>某些特定语言（特别是 JavaScript）的 HTTP 库是不允许 GET 请求带有请求体的。 事实上，一些使用者对于 GET 请求可以带请求体感到非常的吃惊。</p>
</li>
<li><p>而事实是这个RFC文档 RFC 7231— 一个专门负责处理 HTTP 语义和内容的文档 — 并没有规定一个带有请求体的 GET 请求应该如何处理！</p>
</li>
<li><p>结果是，一些 HTTP 服务器允许这样子，而有一些 — 特别是一些用于缓存和代理的服务器 — 则不允许。</p>
</li>
<li><p>对于一个查询请求，Elasticsearch 的工程师偏向于使用 GET 方式，因为他们觉得它比 POST 能更好的描述信息检索（retrieving information）的行为。<br>然而，因为带请求体的 GET 请求并不被广泛支持，所以 search API 同时支持 POST 请求</p>
</li>
</ul>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul>
<li><a href="https://www.cnblogs.com/nankezhishi/archive/2012/06/09/getandpost.html#!comments">https://www.cnblogs.com/nankezhishi/archive/2012/06/09/getandpost.html#!comments</a></li>
<li>不是所有客户端都支持发起带有body的HTTP GET请求，比如jQuery就直接限制了</li>
</ul>
<h2 id="1、数据索引"><a href="#1、数据索引" class="headerlink" title="1、数据索引"></a>1、数据索引</h2><ul>
<li>数据的mapping一般只执行一次，不使用代码方式创建，使用curl即可<br>关掉自动映射：即”dynamic”:”false”， 未预先定义的字段不自动保存<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ curl -X PUT &#x27;localhost:9200/accounts&#x27; -d &#x27;</span><br><span class="line">&#123;</span><br><span class="line"> &quot;mappings&quot;: &#123;</span><br><span class="line">  &quot;dynamic&quot; : &quot;false&quot;,</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">   &quot;user&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">    &quot;analyzer&quot;: &quot;ik_max_word&quot;,</span><br><span class="line">    &quot;search_analyzer&quot;: &quot;ik_max_word&quot;</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;title&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">    &quot;analyzer&quot;: &quot;ik_max_word&quot;,</span><br><span class="line">    &quot;search_analyzer&quot;: &quot;ik_max_word&quot;</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;desc&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">    &quot;analyzer&quot;: &quot;ik_max_word&quot;,</span><br><span class="line">    &quot;search_analyzer&quot;: &quot;ik_max_word&quot;</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;&#x27; </span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="2、分析查询"><a href="#2、分析查询" class="headerlink" title="2、分析查询"></a>2、分析查询</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ curl -X POST -H Content-Type:application/json &#x27;localhost:9200/_analyze&#x27; -d &#x27;</span><br><span class="line">&#123;</span><br><span class="line">&quot;analyzer&quot;:&quot;ik_max_word&quot;,</span><br><span class="line">&quot;text&quot;:&quot;中华人民共和国国歌&quot;</span><br><span class="line">&#125;&#x27; </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">&quot;text&quot;: &quot;我爱北京天安门&quot;,</span><br><span class="line">&quot;analyzer&quot;: &quot;icu_analyzer&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="3、查看索引"><a href="#3、查看索引" class="headerlink" title="3、查看索引"></a>3、查看索引</h2><ul>
<li><code>curl -X GET &quot;localhost:19200/xxxxxx/_mapping?pretty&quot;</code></li>
<li><code>curl -X GET &quot;localhost:19200/_cat/indices&quot;</code></li>
</ul>
<h2 id="4、索引别名"><a href="#4、索引别名" class="headerlink" title="4、索引别名"></a>4、索引别名</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -XPOST &#x27;http://localhost:9200/_aliases&#x27; -d &#x27;</span><br><span class="line">&#123;</span><br><span class="line"> &quot;actions&quot;: [&#123;</span><br><span class="line">  &quot;add&quot;: &#123;</span><br><span class="line">   &quot;index&quot;: &quot;testtmp&quot;,</span><br><span class="line">   &quot;alias&quot;: &quot;test&quot;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;]</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="5、替换别名"><a href="#5、替换别名" class="headerlink" title="5、替换别名"></a>5、替换别名</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST _aliases</span><br><span class="line">&#123;</span><br><span class="line"> &quot;actions&quot;: [&#123;</span><br><span class="line">  &quot;remove&quot;: &#123;</span><br><span class="line">   &quot;index&quot;: &quot;anchor.20220421&quot;,</span><br><span class="line">   &quot;alias&quot;: &quot;anchor&quot;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;, &#123;</span><br><span class="line">  &quot;add&quot;: &#123;</span><br><span class="line">   &quot;index&quot;: &quot;anchor.20220422&quot;,</span><br><span class="line">   &quot;alias&quot;: &quot;anchor&quot;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="6、查看ES版本"><a href="#6、查看ES版本" class="headerlink" title="6、查看ES版本"></a>6、查看ES版本</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -XGET localhost:19200</span><br><span class="line">&#123;</span><br><span class="line"> &quot;name&quot;: &quot;node-1&quot;,</span><br><span class="line"> &quot;cluster_name&quot;: &quot;es6_dev_2&quot;,</span><br><span class="line"> &quot;cluster_uuid&quot;: &quot;MG_zNwBhQZC1C4Yjm8IFQA&quot;,</span><br><span class="line"> &quot;version&quot;: &#123;</span><br><span class="line">  &quot;number&quot;: &quot;6.7.1&quot;,</span><br><span class="line">  &quot;build_flavor&quot;: &quot;default&quot;,</span><br><span class="line">  &quot;build_type&quot;: &quot;tar&quot;,</span><br><span class="line">  &quot;build_hash&quot;: &quot;2f32220&quot;,</span><br><span class="line">  &quot;build_date&quot;: &quot;2019-04-02T15:59:27.961366Z&quot;,</span><br><span class="line">  &quot;build_snapshot&quot;: false,</span><br><span class="line">  &quot;lucene_version&quot;: &quot;7.7.0&quot;,</span><br><span class="line">  &quot;minimum_wire_compatibility_version&quot;: &quot;5.6.0&quot;,</span><br><span class="line">  &quot;minimum_index_compatibility_version&quot;: &quot;5.0.0&quot;</span><br><span class="line"> &#125;,</span><br><span class="line"> &quot;tagline&quot;: &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="7、文档索引"><a href="#7、文档索引" class="headerlink" title="7、文档索引"></a>7、文档索引</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PUT anchor/_doc/1?version=2&amp;version_type=external</span><br><span class="line">&#123;</span><br><span class="line">&quot;id&quot;: &quot;54354&quot;,</span><br><span class="line">&quot;userId&quot;: 324325,</span><br><span class="line">&quot;nickname&quot;:&quot;i love you&quot;,</span><br><span class="line">&quot;searchStatus&quot;: 1,</span><br><span class="line">&quot;weight&quot;: 99 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="8、查看索引数量"><a href="#8、查看索引数量" class="headerlink" title="8、查看索引数量"></a>8、查看索引数量</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /_cat/count/song?v</span><br></pre></td></tr></table></figure>

<h1 id="六、其他"><a href="#六、其他" class="headerlink" title="六、其他"></a>六、其他</h1><h2 id="1、jdk版本"><a href="#1、jdk版本" class="headerlink" title="1、jdk版本"></a>1、jdk版本</h2><ul>
<li>由于Elasticsearch依赖于jdk，es和jdk有着对应的依赖关系。具体可见：<br><a href="https://www.elastic.co/support/matrix">https://www.elastic.co/support/matrix</a><br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/setup.html">https://www.elastic.co/guide/en/elasticsearch/reference/7.10/setup.html</a></li>
</ul>
<h2 id="2、安装问题"><a href="#2、安装问题" class="headerlink" title="2、安装问题"></a>2、安装问题</h2><ul>
<li><a href="https://www.cnblogs.com/heyongboke/p/11379472.html">https://www.cnblogs.com/heyongboke/p/11379472.html</a></li>
<li><a href="https://www.jianshu.com/p/64d4b7472cfb">https://www.jianshu.com/p/64d4b7472cfb</a></li>
</ul>
<h2 id="3、String类型已弃用"><a href="#3、String类型已弃用" class="headerlink" title="3、String类型已弃用"></a>3、String类型已弃用</h2><ul>
<li><p>String：string（弃用）, text, keyword（ElasticSearch 5.0开始支持）</p>
</li>
<li><p>ElasticSearch数据类型–string类型已死, 字符串数据永生: <a href="https://segmentfault.com/a/1190000008897731">https://segmentfault.com/a/1190000008897731</a></p>
</li>
</ul>
<h3 id="text-vs-keyword"><a href="#text-vs-keyword" class="headerlink" title="text vs keyword"></a>text vs keyword</h3><ul>
<li><p>Elasticsearch中text与keyword的区别:<br><a href="https://www.cnblogs.com/sanduzxcvbnm/p/12177377.html">https://www.cnblogs.com/sanduzxcvbnm/p/12177377.html</a></p>
</li>
<li><p>text类型</p>
<ul>
<li>1:支持分词，全文检索,支持模糊、精确查询,不支持聚合,排序操作;</li>
<li>2:test类型的最大支持的字符长度无限制,适合大字段存储；</li>
<li>使用场景：<br>  存储全文搜索数据, 例如: 邮箱内容、地址、代码块、博客文章内容等。<br>  默认结合standard analyzer(标准解析器)对文本进行分词、倒排索引。<br>  默认结合标准分析器进行词命中、词频相关度打分。</li>
</ul>
</li>
<li><p>keyword</p>
<ul>
<li>1:不进行分词，直接索引,支持模糊、支持精确匹配，支持聚合、排序操作。</li>
<li>2:keyword类型的最大支持的长度为——32766个UTF-8类型的字符,可以通过设置ignore_above指定自持字符长度，超过给定长度后的数据将不被索引，无法通过term精确匹配检索返回结果。</li>
<li>使用场景：<br>  存储邮箱号码、url、name、title，手机号码、主机名、状态码、邮政编码、标签、年龄、性别等数据。<br>  用于筛选数据(例如: select * from x where status&#x3D;’open’)、排序、聚合(统计)。<br>  直接将完整的文本保存到倒排索引中。</li>
</ul>
</li>
</ul>
<h2 id="4、客户端代码转curl技巧"><a href="#4、客户端代码转curl技巧" class="headerlink" title="4、客户端代码转curl技巧"></a>4、客户端代码转curl技巧</h2><ul>
<li>该方法仅限于使用rest client的情况</li>
<li>有时想知道代码实际发出的请求是怎样的，并且在控制台进行快速调整测试，可以怎么做？</li>
<li>其中一个方法就是使用代理（fiddler、whistle等）抓包。</li>
</ul>
<h3 id="（1）连接-ES时指定代理"><a href="#（1）连接-ES时指定代理" class="headerlink" title="（1）连接 ES时指定代理"></a>（1）连接 ES时指定代理</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RequestConfig.<span class="type">Builder</span> <span class="variable">builder</span> <span class="operator">=</span> RequestConfig.custom()</span><br><span class="line">builder.setProxy(<span class="keyword">new</span> <span class="title class_">HttpHost</span>(proxyHost, proxyPort));</span><br></pre></td></tr></table></figure>
<h3 id="（2）如果连接的ES是HTTPS的，那么需要安装代理导出的证书"><a href="#（2）如果连接的ES是HTTPS的，那么需要安装代理导出的证书" class="headerlink" title="（2）如果连接的ES是HTTPS的，那么需要安装代理导出的证书"></a>（2）如果连接的ES是HTTPS的，那么需要安装代理导出的证书</h3><p><code>shell keytool -import -alias whistle -keystore cacerts -file rootCA.crt </code></p>
<h2 id="扩展-1"><a href="#扩展-1" class="headerlink" title="扩展"></a>扩展</h2><h3 id="基于MySQL如何自动同步到ES"><a href="#基于MySQL如何自动同步到ES" class="headerlink" title="基于MySQL如何自动同步到ES"></a>基于MySQL如何自动同步到ES</h3><ol>
<li>使用canal监听MySQL的binlog</li>
<li>也可以考虑使用<a href="https://github.com/go-mysql-org/go-mysql-elasticsearch">https://github.com/go-mysql-org/go-mysql-elasticsearch</a></li>
</ol>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><ul>
<li>很多东西不用纠结，以前每看一次es，都会纠结类型怎么使用合理，实际上这本书就是一个不合理的设计，官方最后也承认并废弃了</li>
</ul>
]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>《重新定义团队：谷歌如何工作》-笔记</title>
    <url>/2020/10/24/20201024-chong-xin-ding-yi-tuan-dui-gu-ge-ru-he-gong-zuo-bi-ji/</url>
    <content><![CDATA[<h3 id="自序"><a href="#自序" class="headerlink" title="自序"></a>自序</h3><ul>
<li><p>韦尔奇和康纳迪采用了20-70-10的绩效排名体系，在这种体系下，他们将通用电气的员工分为三类：最优秀的20%，中间层的70%，末尾的10%。最优秀的员工得到赞扬，作为奖励可以选择工作任务，参加领导力培训项目和享有优先认股权。末尾的10%会遭到解雇。</p>
</li>
<li><p>清晰明了的“前20%”“中间70%”和“末尾10%”被更加委婉的描述方式取代：“顶尖人才”“极具价值”和“需要改进”。</p>
</li>
<li><p>因为自由的状态是以自由表达为基础的，而自由表达又依靠对信息和真实情况的了解。</p>
</li>
<li><p>在这里有时会精疲力竭，有时会倍感沮丧，但永远奋发进取，创造有目的性的、自由的和充满创造力的环境。</p>
</li>
</ul>
<h3 id="前言-为什么谷歌的原则也对你适用"><a href="#前言-为什么谷歌的原则也对你适用" class="headerlink" title="前言 为什么谷歌的原则也对你适用"></a>前言 为什么谷歌的原则也对你适用</h3><ul>
<li>当员工信任领导层的时候，他们就会成为品牌的代言人，从而为其家庭、所处的群体和环境带来积极的改变。员工生产效率变高，企业发展增速，顾客购买热情高涨，商业投资回报也就自然而然地实现了。</li>
<li>从管理的核心角度来讲，权力的动态方向恰与自由背道而驰。员工要依靠管理者，希望取悦他们。然而，注重取悦管理者意味着与其进行开诚布公的探讨是有风险的。如果你不取悦他，内心就可能惶恐不安或焦躁愤恨。同时他还要保证你实现某些工作成果。</li>
<li>谷歌应对此类问题的方法是割开这个结。我们刻意剥夺了管理者对员工的控制权。下面一些例子是谷歌的管理者不能单方面做出的一些决定：•雇用谁•解雇谁•如何评估一个人的表现•给某个人加薪多少，给多少分红或分配多少股权•选谁来拿最佳管理奖•给谁升职•代码何时才算合格，可以纳入到公司的软件代码库中•一种产品的最终设计以及何时投放市场。<br>上述决定都是由一组同事、一个委员会或一个特别任命的独立团队做出。</li>
<li>升职的问题又摆到了眼前，这时他们又会惊愕地发现自己没有权力独自决定给他们认为团队里最优秀的员工升职。问题在于，你和我对“最优秀的员工”的认识有所不同。也有可能你的团队中最差的成员比我的团队最优秀的员工还要好，这种情况下，你的整个团队都应该升职，而我的团队成员都不应该升职。</li>
<li>一名管理者到底该做些什么呢？只有一件事情可以做。按照我们的执行总裁埃里克·施密特的话说就是“管理者服务于团队”。和其他企业一样，我们当然也遭遇过意外和失败，但是在谷歌这种不干预的领导方式下，管理者的关注重点不是惩罚或奖励，而是清除路障，鼓励团队。</li>
<li>只有公司采用了给员工充分授权的经营方式（比如，剥夺管理者的决定权，并将该权力分配给一些个体或团队），为员工提供工作之外的学习机会，提高团队信任度（给团队足够的自主权，允许员工自行组队），或是组合利用上述方法，这样业绩才能得到提升。<br>简而言之，只有当企业着手给员工更多的自由时，业绩才能提升。</li>
<li>我们所做的绝大多数事情的费用都极低。即便是只拿死工资的时候，也能把工作做得更好，使员工更有幸福感。其实，越是在经济状况不好的时候，善待员工越是重要。</li>
<li>我们只需要坚信员工都是好的，再就是要有足够的勇气，把员工看成是企业的主人翁，而不是把他们当成机器。机器会完成工作；主人翁会竭尽所能帮助企业和团队获得成功。人的一生大部分时间都在工作，但是对多数人而言，工作是一件痛苦的事情，只是一种谋生的手段。可以不必如此的。</li>
<li>如何更好地探寻和发展自由、富有创造力和宽松的环境，使员工在这种环境下工作。</li>
</ul>
<h3 id="第一章-成为一名创始人"><a href="#第一章-成为一名创始人" class="headerlink" title="第一章 成为一名创始人"></a>第一章 成为一名创始人</h3><ul>
<li><p>他们都希望创造出这样一家公司：工作有意义，员工可以尽情发挥自己的激情，他们和他们的家人都得到关怀。</p>
</li>
<li><p>建立杰出的团队或机构的起点是有一位创始人。但是成为一名创始人并不意味着要建立一家新的公司。任何人都有能力成为一名创始人，也可以成为所在团队的文化创造者，不管你是一家公司的第一名雇员还是一家数十年历史的公司中的一员。</p>
</li>
<li><p>我写作本书的愿望之一就是，希望阅读本书的人都能站在创始人的角度看待自己。或许不是一家公司的创始人，但是也可以成为一个团队、一个家庭或一种文化的创始人。谷歌的经历带来的最根本的一点经验就是你必须先决定自己想要成为一名创始人还是一名雇员。这个问题关乎的不是实际的所有权而是做事的态度。</p>
</li>
<li><p>谷歌工作法则：成为一名创始人□把自己看成是一名创始人□像创始人一样行动</p>
</li>
</ul>
<h3 id="第二章-“文化可以把战略当早餐一样吃掉”"><a href="#第二章-“文化可以把战略当早餐一样吃掉”" class="headerlink" title="第二章 “文化可以把战略当早餐一样吃掉”"></a>第二章 “文化可以把战略当早餐一样吃掉”</h3><ul>
<li><p>如果你给员工以自由，他们将还你以惊喜</p>
</li>
<li><p>公司文化的三个根本元素：使命、透明和发声的权利。</p>
</li>
<li><p>我们的使命是“整合全球信息，使人人都能访问并从中受益”</p>
</li>
<li><p>谷歌的使命与众不同，既在于其简洁明了，也在于其未曾言及的方面。没有言及利润或市场。没有言及顾客、股东或用户。没有言及为何选此作为公司使命，也未曾言及如何实现这些目标。相反，谷歌的使命整合全球信息，使人人都能访问并从中受益是一件不言自明的好事。这样的使命使个人的工作有了意义，因为它不是一种商业目标而是一种道德目标。史上最有影响力的运动都要有道德动机，或是追求独立，或是追求平等权利。</p>
</li>
<li><p>归根结底，我们永远也无法达成我们的使命，因为总有更多的信息需要集成，总有更多的方式可以使人们从中受益。这样就给我们创造了动机，促使我们不断创新，探索新的领域。要成为“市场领导者”这种公司使命，一旦实现，就难以再带来更多的激励。</p>
</li>
<li><p>我们在践行公司使命时，也带来了令人惊喜的实用价值。</p>
</li>
<li><p>每一类职业的人里面都大约有三分之一将自己的工作看作一种使命。这样做的人不仅更快乐，而且也更健康。</p>
</li>
<li><p>如果你相信员工，就不必害怕与他们分享信息透明是我们公司文化的第二块基石。“默认开放”（Default to open）是在开源社区中时常会听到的一个短语。</p>
</li>
<li><p>如果你能给员工以自由，他们就会为你创造惊喜。他们有时也会令你失望，但是我们也都知道人无完人。这并非宣扬自由的檄文，只不过是权衡利弊后的选择。</p>
</li>
<li><p>谷歌工作法则：打造了不起的文化□将工作看作是一种命运的召唤，而且工作要有富于意义的使命。□给人以稍多于你的舒适区的信任、自由和自主权。如果你没有感到紧张，那是因为你给的还不够。</p>
</li>
</ul>
<h3 id="第三章-只聘用比你更优秀的人"><a href="#第三章-只聘用比你更优秀的人" class="headerlink" title="第三章 只聘用比你更优秀的人"></a>第三章 只聘用比你更优秀的人</h3><ul>
<li><p>如果我们前期选人的时候能做到更好，也就意味着聘用他们之后在这些人身上投入的精力就会减少。聘用水平超过90%应聘者的员工，最糟的情况他们也能有平均水平的表现。这些员工几乎不可能成为公司里表现最差的</p>
</li>
<li><p>你如何能够判断自己到底有没有找到一名非凡的人才？我所遵循的首要原则——也是你在招聘时需要做出的第二个改变——是：“只聘用比你更优秀的人。”我所聘用的人都在某些特定的方面比我更优秀的。</p>
</li>
<li><p>从《人才的谬见》一文中得到的教训不是“不要聘用聪明人”。而是“不要只聘用聪明人”。至理名言。出色的招聘工作不仅在于聘请到名头很大的人、顶尖的销售人员或最聪明的工程师，而且在于搜寻到在你所处组织的环境下能够成功的最优人才，在于找到能使周围每个人都更加成功的人才。</p>
</li>
<li><p>谷歌工作法则：关于招聘□资源有限的情况下，将人力资源费用首先投入到招聘上。□慢慢来，聘用最优秀的人才，只聘用在某些特定的方面比你更优秀的人，不要让经理独自做团队人员聘用决策。</p>
</li>
</ul>
<h3 id="第四章-搜寻最优人才"><a href="#第四章-搜寻最优人才" class="headerlink" title="第四章 搜寻最优人才"></a>第四章 搜寻最优人才</h3><ul>
<li><p>最优秀的人并不在寻找工作。表现极为优秀的人在现在的工作岗位上很开心，满足感很强。他们不会进入人们的推荐人名单中，因为人们会想为什么要推荐一些在现在岗位上很开心的人呢？而且他们肯定也不会考虑新的工作。</p>
</li>
<li><p>谷歌工作法则：搜寻非凡的应聘者?□要详细说明寻找人才的标准，依此找到最优秀的被推荐人□使招聘成为每个人的工作□不要害怕尝试疯狂的事情，以此引起最优秀人才的注意</p>
</li>
</ul>
<h3 id="第五章-不要相信你的直觉"><a href="#第五章-不要相信你的直觉" class="headerlink" title="第五章 不要相信你的直觉"></a>第五章 不要相信你的直觉</h3><ul>
<li><p>根据头10秒钟的印象做出的预测是没有任何意义的。这头10秒钟的预测使我们在整个面试过程中都在试图证明我们对某个人的印象，而不是真正地去评估他们。心理学家将这种现象称作证实偏见（Confirmation Bias），“倾向于寻找、解释或优先考虑那些能够支持我们观点或假设的信息”。</p>
</li>
<li><p>多数的面试都是在浪费时间，因为99.4%的时间都用在证实面试官最初10秒钟的印象，不论印象好坏。“请做一下自我介绍。”“你最大的缺点是什么？”“你最大的优势是什么？”毫无价值。</p>
</li>
<li><p>你不仅要评估应聘者，还需要让他们喜欢上你。真的。你得让他们有一次非常棒的体验，处理好他们关心的问题，使他们感觉刚刚经历过一生中最快乐的一天。</p>
</li>
<li><p>谷歌工作法则：筛选新雇员?□设定高质量标准□寻找自己的应聘者□客观评估应聘者□给应聘者一个加入的理由</p>
</li>
</ul>
<h3 id="第六章-打造最幸福的公司"><a href="#第六章-打造最幸福的公司" class="headerlink" title="第六章 打造最幸福的公司"></a>第六章 打造最幸福的公司</h3><ul>
<li><p>权力导致腐败，绝对的权力导致绝对的腐败</p>
</li>
<li><p>如果要做假设，也应该认为掌握权力的人是恶的，权力越大，恶念越深……伟人多数是恶人，即便他们不滥用权力，而只是施加影响力；如果你再考虑到权力带来腐败的可能性或必然性，他们的恶会更甚。</p>
</li>
<li><p>回想一下你参加过的会议。我敢打赌，级别最高的那个人总是坐在会议桌的上首。是因为他们匆匆地从一间办公室冲到另一间办公室，抢先来到会议室，才占到这个最好的位置吗？下次仔细观察一下。随着参会者陆续到场，他们会刻意将上首的座位空着。此种现象证明了我们一些不自觉的微妙举动都创造了等级制度。没有指示，没有讨论，甚至没有有意识的思考，我们就会为“上级”留出位置。</p>
</li>
<li><p>我们最高层的一些领导对这种现象也非常熟悉，并尝试打破这种状态，选择坐到会议桌某一侧的中间。</p>
</li>
<li><p>经理都倾向于累积和运用权力。员工都倾向于服从命令。</p>
</li>
<li><p>不可否认的是，我们很多人都同时扮演着经理和员工两个角色。我们都遇到过控制欲很强的经理，也都遇到过不服从管理的员工，这样的挫败感我们每个人都曾有过。</p>
</li>
<li><p>授权于群众的第一步就是要保证人们能够安全地发表意见。俗话说“枪打出头鸟”，就是警示人不要随便发表评论。正是因为这个原因我们才尽可能削弱经理的权力。他们拥有的正式授权越少，就越难利用萝卜加大棒的政策辖制团队，这个团队的创新范围便会越广。</p>
</li>
<li><p>为了减轻人类内在寻求等级划分的倾向，我们尝试除去显示权力和地位的象征符号。</p>
</li>
<li><p>谷歌坚持的核心准则中一直都有一条“不要耍政治手腕。用数据说话”</p>
</li>
<li><p>经理们忽略的是，每次他们放弃一些控制权，就可以为团队创造一次提升的好机会，也给自己节省出更多时间应对新的挑战。找出某个令你的团队感到沮丧的领域，让他们改变现状。如果有限制，比如时间或资金有限制，就告诉他们。要对员工透明，在塑造团队或公司的过程中给他们发言权。你会惊讶于他们的成就。</p>
</li>
<li><p>谷歌工作法则：授权于员工□消除地位象征□依靠数据而不是根据经理的想法做决定□探寻方法，让员工塑造自己的工作和公司□高期待</p>
</li>
</ul>
<h3 id="第七章-为什么每个人都讨厌绩效管理"><a href="#第七章-为什么每个人都讨厌绩效管理" class="headerlink" title="第七章 为什么每个人都讨厌绩效管理"></a>第七章 为什么每个人都讨厌绩效管理</h3><ul>
<li><p>关注个人成长而不是评分和奖励，以此改善绩效</p>
</li>
<li><p>OKRs（Objectives and Key results，目标和主要结果）。目标必须具体、可度量、可检验；如果你达成所有结果，就能完成目标。</p>
</li>
<li><p>正如普拉萨德·塞迪解释的：“传统的绩效管理体系犯了一个大错。他们将两件应该彻底分开的事情合到了一起：绩效评估和人员发展。评估有其必要性，可确定加薪或奖金等有限资源的分配。发展也同样很有必要性，可以促进员工的成长与提高。”如果你希望员工成长，不要同时进行这两项谈话。确保发展成为你与团队成员之间不断往返的一个过程，而不是年底的一次惊喜。</p>
</li>
<li><p>为了确保员工与经理的交谈更有效，我们整理出一份一页的讲义，分发给他们，在绩效交谈的时候使用。做这一份讲义的目的还是为了使对话更具体，更切合实际。我们给员工分发这些讲义只是为了稳妥；我们希望经理能够覆盖恰当的话题，但是让员工准备好引导讨论也没有什么坏处。</p>
</li>
<li><p>把奖励分配谈话与员工发展谈话分开。两项谈话混为一谈会扼杀学习的动力。不管公司规模多大，这一点都适用。</p>
</li>
<li><p>谷歌工作法则：绩效管理□正确地设定目标□收集同事的反馈意见□通过校准流程确定考评结果□把奖励分配谈话与员工发展谈话分开</p>
</li>
</ul>
<h3 id="第八章-管理团队的两端——最优员工和最差员工"><a href="#第八章-管理团队的两端——最优员工和最差员工" class="headerlink" title="第八章 管理团队的两端——最优员工和最差员工"></a>第八章 管理团队的两端——最优员工和最差员工</h3><ul>
<li><p>从统计学上讲，这些现象更适合用“幂律分布”（power law distribution）解释。</p>
</li>
<li><p>大多数公司在管理员工时都采用正态分布，大多数员工被列为平均水平，两端为表现差和表现优秀的员工。两端并不像身高分布那样对称，因为失败的员工都被解雇了，最差的应聘者根本就进不了公司，因此左侧的一段很短。但是很多公司认为员工的表现还会符合同样的正态分布。这样的认识是一个错误。事实上，组织中大多数的个人表现符合幂律分布。</p>
</li>
<li><p>并非大批平均水平的员工通过数量优势做出主要贡献，而是由少数精英员工通过强大的表现做出主要贡献。</p>
</li>
<li><p>采用一种不同的方式：我们的目标在于告诉底端5%的每一位员工，他们处于这样一个群体。这种对话不会是幽默风趣的。但是我们向这些员工传递出的信息使这项工作简单了一些：“你在整个谷歌处于底端的5%。我知道这样的感觉不好。我之所以要告诉你是因为我想要帮助你成长，变得更好。”换言之，这不是一次“要么好好干，要么走人”的谈话；这是一次感性的谈话，目的是帮助一个人发展。有一位同事曾经将其形容为“富有同情心的实用主义”。绩效表现糟糕极少是因为某人的能力不足或品性不佳。更多的是由于技能的缺陷（或许可以改进，或许不能）或意愿不足（员工没有做工作的动力）。在后一种情况下，可能是由于个人问题，也可能预示着团队中出现了某个更大的问题需要修正。</p>
</li>
<li><p>通常，调岗之后这个人的绩效能够提升到平均水平。这听起来或许不算什么，但是反过来这样想想：100个人的团队中，吉姆是表现最差的5个人之一。经过这次干预之后，吉姆的绩效表现进入了前50位。</p>
</li>
<li><p>余下的一些员工，有的选择主动离职，有的就只能解雇了。听起来很残酷，但是最后他们通常会更开心一些，因为我们表现出对他们状况的理解，并与他们一道投入了改进过程，而且我们给他们时间寻找一家能够发挥专长的公司。</p>
</li>
<li><p>在分布底端投入时间精力的这个循环意味着你们的团队能够提升很多。员工或是得到大幅的提升，或是离职去别的地方寻找成功。</p>
</li>
<li><p>对员工直接一些实际上是仁慈的表现</p>
</li>
<li><p>我要强调一点，谷歌识别底端5%的员工并非“员工大排名”，不是要按照固定的分布将员工的绩效表现分类。那种考评方式下，员工为了不落在底端会激烈竞争，最终搅乱了公司文化。<br>我采访过的每一位现在和过去的微软员工——每一位——都认为员工大排名是微软内部最有害的政策，在这种政策下，无数的员工被迫离职……“如果你的团队中有10个人，你开始工作的第一天就了解到，不管每一位员工多么优秀，都将有两个人获得好评，7个人获得中评，另外有一个人获得差评，”一位前微软软件开发工程师说，“这使员工的注意力都放在内部互相竞争上，而不是与其他公司竞争。”</p>
</li>
<li><p>如果你相信员工本质都是好的，认为他们值得信任，那就必须对他们坦诚相待，保持透明度。这就包括让他们知道自己的绩效拖了后腿。但是在一家使命导向性、有目标的公司，处理人力问题时要有敏感性。多数表现不佳的员工能够认识自己的表现，想要变得更好。给他们改进的机会非常重要。</p>
</li>
<li><p>顶端的员工生活在高产出、良好的反馈意见、更高的产出和更好的反馈意见这样一个良性循环中。他们每天都沐浴在爱的环境中，给他安排的额外工作也使他更加开心。更重要的是要从最优秀的员工身上学习。</p>
</li>
<li><p>最优秀经理手下工作的谷歌人在十几项Googlegeist评估维度上要比最差经理手下工作的谷歌人高5%至18%。除此之外，他们在以下几方面的认可度明显更高：•职业决策更加公正。绩效评估公正，得到升职的都是实至名归的人选。•个人的职业目标能够达成，他们的经理是非常有帮助的支持者和引导者。•工作高效，决策迅速，资源分配合理，从多种视角考虑问题。•团队成员之间没有等级制度，互相尊重，决策依据数据做出而不是靠耍手段，团队内部各人的工作和信念都保持透明。•他们适当地参与到决策制定过程中，并且得到一定的授权去完成工作。•他们可以自由地平衡工作和私人生活。</p>
</li>
<li><p>最优秀经理领导的团队绩效表现也更好，人员流动率更低。</p>
</li>
<li><p>调查显示高分经理具备八种低分经理所不具备的共性：8个氧气项目特性1. 做一名好的导师。2. 给团队授权，不随便插手下属工作。3. 表达出对团队成员的成功和个人幸福的兴趣和关心。4. 高效&#x2F;结果导向型。5. 善于沟通——聆听和分享信息。6. 在职业发展方面助力团队。7. 对团队有清晰的愿景和战略。8. 具备重要的技术技能，可为团队提供建议。</p>
</li>
<li><p>我们发现在伟大的经理中间，技术专业性是8种特性里重要性最低的一项。不要误会，技术专业性非常关键。一名不会编代码的经理不可能在谷歌领导一个团队。但是在区分最优秀的经理行为时，技术能力在不同团队中是差异最小的。</p>
</li>
<li><p>这是对经理–员工关系的一次华丽反转。想要提高，最好的方法是与那些提供反馈意见的员工进行交谈，询问他们希望自己做出哪些改变。</p>
</li>
<li><p>让处于绩效分布底端的人了解真相，但是不要将绩效与薪酬或职业成果直接挂钩，尽可能用一种积极的方式警示并激励他们。数百名经理需要面对自己并非好经理的现实。</p>
</li>
<li><p>谷歌工作法则：管理团队的两端—最优员工和最差员工?□助力有难处的员工□将最优秀的人放在显微镜下观察□利用调查和检查清单寻找真相，推动员工学习□与人分享员工对你的反馈意见，以身作则采取行动解决问题，身先示范</p>
</li>
</ul>
<h3 id="第九章-打造学习型组织"><a href="#第九章-打造学习型组织" class="headerlink" title="第九章 打造学习型组织"></a>第九章 打造学习型组织</h3><ul>
<li><p>在某一领域精熟的人，不管是小提琴家、外科医生、运动员[插图]还是拼字比赛冠军[插图]，学习的方法都有异于常人。他们将活动分解成细小的动作，比如连续数小时在雨中练习同一种击球动作，不断重复。每一次，他们都会观察效果，做微小的——几乎难以觉察的——调整，逐步改进。埃里克森将这种方式称作刻意练习：有意重复类似的小任务，即时反馈、修正和实验。</p>
</li>
<li><p>不过或许你不想要手下最优秀的销售人员去教学。毕竟，不应该让她全心全意做销售吗？我认为这是一种短视的想法，因为个人的绩效表现的提升是线性的，而培训授课则会带来几何级数的增长。</p>
</li>
<li><p>学习型组织发端于一种认识，即我们所有人都渴望成长，也都希望帮助他人成长。然而，在很多组织中却是员工受教，专业人士负责教学。为什么不让员工同时做两件事情？</p>
</li>
<li><p>谷歌工作法则：打造学习型组织□进行刻意练习：将课程分成易于消化的小块，给出明晰的反馈意见，并不断重复这个过程□请最优秀的员工教学□只在已经证明能够改变员工行为的课程上进行投入</p>
</li>
</ul>
<pre>
培训的效果衡量四个层次，一是反应，课后调查反馈课堂效果及氛围。二是学习，调查学员学到了那些知识，学习效果如何。三是形行为，接受学员学以致用的反馈，是否有提升，同时调查团队周边或客户的客观评价。四是结果，最终是否导致了效率提升，绩效比变好等等
</pre>

<h3 id="第十章-不公平薪酬"><a href="#第十章-不公平薪酬" class="headerlink" title="第十章 不公平薪酬"></a>第十章 不公平薪酬</h3><ul>
<li><p>总结下来共4条原则：1. 不公平薪酬。2. 以成就为荣，不以报酬为荣。3. 创造易于传播爱的环境。4. 精心筹划却遭受失败的要奖励。</p>
</li>
<li><p>如何庆祝成功的同时不滋生嫉妒</p>
</li>
<li><p>这样做带来了不良的后果，假如你是非常优秀的员工，将会得到几次大幅加薪，之后加薪的速度会越来越慢，直到最后你接近容许的薪酬范围上限，加薪也会随之停止。最优秀的队员除了需要高报酬之外，也能持续创造优异的成果。</p>
</li>
<li><p>对于那些快速学习成长和表现最顶尖的人来说，确保你的薪水与所创造的价值相适应有一种方法，就是离开这种垄断的内部市场，进入自由市场。即寻找一份新工作，以你的真正价值为基础，协商薪酬，然后离开现在的公司。这也是你在人才市场上看到的真实情况。</p>
</li>
<li><p>为什么公司不设计一种体系，避免最优秀和潜力最大的员工辞职呢？因为他们对公平有一种错误认识，没有勇气坦诚面对自己的员工。薪酬的公平并不是说所有在同级别岗位上的人都要拿同样的薪水或是上下差不到20%。薪酬与贡献相匹配才能算得上公平。因此，个人的薪酬应该有巨大的差异</p>
</li>
<li><p>正态分布（又称高斯分布）与幂律分布最大的区别在于，某些现象中，正态分布严重低估了极端事件发生的概率。</p>
</li>
<li><p>个人的表现符合幂律分布。事实上，大多数员工都在平均水平以下：•66%的研究员发表论文的数量低于平均水平。•84%艾美奖提名演员获得提名数低于总提名平均数。•68%的美国参议院议员的任职届数要低于平均数。•71%的NBA球员得分低于平均分。低于平均数并非坏事。这只不过是一种数学统计而已。数据显示，非凡贡献者的表现水平要远高于大多数人，他们可以拉动平均数远高于中位数。</p>
</li>
<li><p>“10%的产出来自最顶尖1%的员工，26%的产出来自最顶尖5%的员工。”换言之，他们发现最顶尖1%员工的产出是平均产出的10倍，最顶尖5%的员工的产出是平均产出的4倍多。当然，这种算法并非在所有地方都适用。恰如奥博伊尔和阿吉斯所指出的：“工业和以体力劳动工作为主的组织，技术能力有限，对最低和最高产量有严格的标准。”在这些地方的员工表现更接近于正态分布。在这种环境下，极少有机会能做出非凡的成就。但除此种情况之外，幂律分布都占据主导。</p>
</li>
<li><p>那些拿到100万美元奖励的人一定、一定是狂喜的吧？他们确实很开心。我的意思是说，拿到这样的奖励非常激动人心。人生就此改变。之后，我们最优秀的、最有创造力的、又有洞察力的技术人员中有一些（虽然不是全部）——他们曾创造出谷歌历史上最具有影响力的一些产品——意识到自己不太可能通过同样的产品两次获得创始人奖，因此立刻会想要转移到新的产品领域。虽然并非本意，但是我们创造出的这种激励体系，使公司里几乎所有人都不如以前开心，即使有少数人开心了，但也动了念头，不愿继续从事为他们赢得奖励的关键的创新性工作！</p>
</li>
<li><p>我们公开地进行体验奖励，私下里进行差异化奖金和股权奖励。这样的结果使谷歌人变得比以前更开心。</p>
</li>
<li><p>在奖励员工的时候，一定不能只用现金奖励，还要考虑体验奖励。很少有人回顾人生时会只看到一张张薪水单。他们会记住一些谈话、一些午餐，与同事和朋友共度的一些事件。不要用金钱庆祝，要用行动庆祝。</p>
</li>
<li><p>谷歌工作法则：不公平薪酬□控制情感，做到不公平薪酬。薪酬差异化要明显，应符合绩效表现的幂律分布□以成就为荣，不以报酬为荣□创造易于传播爱的环境□精心筹划却遭受失败的要奖励</p>
</li>
</ul>
<pre>
来源微信读书
分章读书总结：
1、在绩效方面，更多要参考幂律分布而不是传统的正态分布，平均数不等于中位数，实际上组织内大部分员工处于平均值之下，组织10%绩效产出来自1%的员工，出于人才保留和激励，不公平薪酬完全是合理且必要的；
2、人对于公正性的感知非常强，会极大影响他对于自身价值的认识、工作满意度、上级信任度和组织忠诚度，所以极端奖励体系要同时满足分配公正和程序公正；
3、在奖励员工时，不能只考虑现金奖励，还要考虑体验奖励；金钱激励是即时性的，所以在金钱激励时要辅以绩效谈话或颁奖等仪式性行为，以加深记忆，拉长激励的保质期，但总体来讲，用行动庆祝比用金钱庆祝更有持续记忆力；
4、要在组织内创造易于传播爱的环境，公开的赞许是最有效的一种管理工具，相信员工能做正确的事，结果通常他们会去做正确的事；
5、奖励成功也要奖励失败，否则员工会失去创造方面的冒险性；
</pre>

<h3 id="第十一章-世上最好的东西是免费的"><a href="#第十一章-世上最好的东西是免费的" class="headerlink" title="第十一章 世上最好的东西是免费的"></a>第十一章 世上最好的东西是免费的</h3><ul>
<li><p>我们做的几乎所有事情都是免费或费用很低的。所有这些项目都是为了提升效率，创造社区意识或创新精神。</p>
</li>
<li><p>我不能给出数据证明有多少经济价值是因为免费洗衣机创造的，因为我根本就不在乎这些。我还记得职业生涯早期的麻烦经历，从我公寓到地下室的公用洗衣机要经过堆满杂物的楼道和摆满清洁用品的楼梯，而后要困在家里好几个小时，生怕别人来偷走我的衬衫。超级烦人。我们为什么不在园区找一间空房间，放上几台洗衣机和一些清洁剂，让生活稍微愉悦一些呢？我们为什么不请一些演讲者来园区给我们做演讲呢？</p>
</li>
<li><p>我们进行过离职调查，从来没有任何人说这些服务能够使他们留下，也没有人因为这些服务才加入谷歌。这其中并没有什么大秘密：我们所做的这些事情（大多数）仅是举手之劳，但却收获巨大，而且我们感觉这样做是应该的。</p>
</li>
<li><p>微小的关怀和资源投入也能带来巨大的成果。</p>
</li>
<li><p>谷歌工作法则：效率、社区意识和创新精神?□使员工的生活容易一些□想办法说可以□生命中的不幸罕有发生……一旦员工遭遇不幸，要伸出援手</p>
</li>
</ul>
<h3 id="第十二章-助推"><a href="#第十二章-助推" class="headerlink" title="第十二章 助推"></a>第十二章 助推</h3><ul>
<li><p>诺贝奖获得者、普林斯顿大学荣誉退休教授丹尼尔·卡尼曼在他的《思考，快与慢》（Thinking, Fast and Slow）一书中描述人类有两套思维系统。其中一套慢、有深度、有思索、以数据为导向，而另外一套快、依靠本能、属于直觉思维系统。多数时候我们会依赖第二套思维系统，因此即便我们认为自己理性的时候，其实恐怕也并非如此。</p>
</li>
<li><p>在面对对自我观念和自我认同的威胁时，防御是一种自然的反应。</p>
</li>
<li><p>只需简单地提供信息，然后依靠人的本性——好胜的本性和利他主义的本性——就能改变一个机能失调的团队，看到这种现象真是既有趣，又令人振奋。</p>
</li>
<li><p>谷歌工作法则：助推走向健康、富有和快乐□区分“实是”和“应是”的不同□进行许多小的实验□助推，不要硬推</p>
</li>
</ul>
<h3 id="第十三章-谷歌的教训"><a href="#第十三章-谷歌的教训" class="headerlink" title="第十三章 谷歌的教训"></a>第十三章 谷歌的教训</h3><ul>
<li><p>任何想法走了极端都会变得愚蠢可笑。</p>
</li>
<li><p>因此外界批评从原则上来讲是对的，但在实践中却并非如此。每年我们都要遭受一次重大的信息泄露。每一次都要进行一次调查，而且每一次信息泄露不管是刻意而为还是意外事故，不管是出于善意还是恶意，当事人都会被解雇。我们不会宣布泄露信息的人是谁，但是我们会让公司里的所有人都知道泄露的信息是什么，以及后果怎样。很多人了解到很多信息，总不可避免地有几个人会搞砸。但这样是值得的，因为泄露信息造成的损失相比我们享受的开放性而言并不算重大。</p>
</li>
<li><p>一次失败的绩效管理变革。每一次我们对谷歌的绩效管理体系做出改变的时候，都会遭遇两个不证自明的真理：1. 没人喜欢当下的体系。2. 没人喜欢改变当下体系的提议。</p>
</li>
<li><p>谷歌工作法则：搞砸的时候□承认错误。坦诚面对错误□吸取各个方面的意见□不管什么坏掉了，修好□找出错误中的寓意，加以传播</p>
</li>
</ul>
<h3 id="第十四章-从明天起你可以做些什么"><a href="#第十四章-从明天起你可以做些什么" class="headerlink" title="第十四章 从明天起你可以做些什么"></a>第十四章 从明天起你可以做些什么</h3><ul>
<li><p>问题并非管理体系需要如何改变人性，而是如何改变工作的性质。</p>
</li>
<li><p>一家组织的经营方式可以遵循两种极端的模型。本书的核心在于我的信念，相信你可以选择出期望打造何种类型的组织，而我所做的只是展示一些实现目标的工具。“低自由度”的一端是指挥控制型组织，对员工的管理很严格，工作强度大，公司对员工弃之如敝屣。“高自由度”的一端以自由为基础，员工受到尊重，对公司如何发展有一定的话语权。</p>
</li>
<li><p>如果你希望建立高度自由的环境，下面有10个步骤可以帮助你的团队和组织实现转型。1. 赋予工作意义2. 相信员工3. 只聘用比你更优秀的人4. 不要将职业发展与管理绩效混为一谈5. 关注团队的两端—最优员工和最差员工6. 既要节俭又要慷慨7. 不公平薪酬8. 助推9. 管理日益提升的期望10. 享受！然后回到第1条，再来一遍</p>
</li>
</ul>
<ol>
<li>赋予工作意义工作至少占据了我们生活三分之一的时间和清醒时的一半时间。工作可以——也应该——不仅仅是一种达成结果的手段。非营利组织从很久以前就已将工作的意义作为吸引和激励员工的方法。比如，帮助难民的非营利组织避难通道（Asylum Access）的创始人艾米丽·阿诺德–费尔南德斯建立起一个世界一流的全球团队，这个团队的建立完全基于成员的共同愿景，即帮助难民找到工作，送他们的孩子上学，帮助他们在新的国家中建立起新的家园。在很多环境下，工作仅仅是为了得到薪水，但是亚当·格兰特的研究成果证明，只需与那些因你的工作而受益的人建立起微小的联系，便能大幅提升生产效率，而且还能使人更开心。所有的人都希望自己的工作有一定的目的。将工作与一种超越日常但却能真实反映所做事情的理念或价值观联系在一起。谷歌立志整合全球信息，使人人都能访问并从中受益。任何在这里工作的人都要践行这项使命，不管职位多么低微。这种使命吸引来了人才，激励他们留下来，去冒险，以最高水平的表现去工作。如果你是一名鲑鱼切片工，你就是在养育他人；如果你是一名管道工，你就是在改善人们的生活质量，保持他们家园的清洁和健康；如果你在生产线上工作，不管生产的产品是什么都将为人所用，帮助到他们。不管你在做什么，都会对某人有重要的意义。而你所做的这项工作对你也应有重要的意义。作为一名经理，你的工作就是帮助员工发现这种意义。</li>
<li>相信员工如果你相信人本善，就应如此行动。要对员工保持透明和真诚，给他们话语权，决定如何行事。从小事做起也可以。真的，你之前表现出的信任越少，小的举动就会令人感到越重大的意义。对于一家传统上一直进行不透明管理的公司而言，一个意见箱，员工知道其中的意见真正地有人读过且有人处理，会令人有革命性的感觉。请团队成员问你是什么促使你做出最近的一些决定的。如果你拥有的是一家小商店，要经常询问员工他们认为做出哪些改变能使商店更好，或者问他们如果这是他们的公司，他们会怎么做。因为你希望他们能这样做。就好似这是他们的公司一样。要实现这种状态唯一的方法就是你放弃一小部分权力，给他们朝这个方向发展的空间。这听起来或许有些令人望而却步，但其实并不需要冒太大的风险。管理层随时都可以拿走意见箱，或告诉员工不再需要他们的意见，或者甚至可以解雇一些人。如果你担心这样做会有损你的权威，那么就告诉员工每一种改变都只是试行几个月。如果可行，就继续。如果不可行，就停下来。即便仅仅是尝试，你的员工也会心怀感激的。如果你是团队的成员，就向你的老板提出这样的请求：给我一个机会。帮助我理解你的目标是什么，让我理清如何达成这些目标。这样的小举动将创造通往主人翁文化的途径。</li>
<li>只聘用比你更优秀的人企业总会认为尽快填补一个空缺岗位比耐心寻找最适合一个岗位的人更重要。有销售人员对我说过：“宁滥毋缺”，意思是说他们宁愿由一名领域内中等水平的人完成70%的限定销售额，也不愿让一个岗位空缺。但是在招聘质量要求上的妥协就已经是一个错误了。聘用糟糕的员工就好似在锅里扔进了一颗老鼠屎，不仅自身的表现不佳，还会拖累周围人的表现、士气和精力。如果拒绝一个人意味着其他每个人在短期内都需要更努力地工作，只需要提醒他们回想一下与上一个浑蛋同事共事时的遭遇就好了。成立委员会完成招聘工作，预先设定客观的标准，永远不要妥协，定期查看新聘用的员工是否优于以往聘用的员工。能够证明你的招聘工作做得很好的是新聘用的员工中十有八九都比你更优秀。如果他们不及你优秀，暂时不要聘用，直到找到一个更优秀的人。短期内你们的工作会放缓，但最终你将建立一个更加强大的团队。</li>
<li>不要将职业发展与管理绩效混为一谈克里斯·阿基里斯向我们展示了，即便最成功的人也有学不会的时候。如果他们都无法学习，那么余下的我们又能有什么希望呢？面对自己的缺点时总是难以令人愉悦。如果你将后果与批评结合在一起，如果员工感觉犯了一个错误就意味着在职业或经济上受损，那么他们就会争辩而不是保持开放的态度去学习和成长。发展谈话要随时进行，确保平稳且富有成效，恰如我以前的经理在每次会后进行的谈话一样。开启一次发展谈话的时候永远要保持这样的态度：“我能做些什么帮你取得更大成功？”否则，员工的防御心理就会增强，学习将中断。在实现目标的道路上，要确保发展谈话的平稳进行。不管目标有没有实现，两种谈话都应在空间和时间上分开。一个绩效考评阶段结束之后，立刻直入主题就设定的目标进行讨论，探讨哪些目标已经实现，以及奖励如何与绩效挂钩。但是这一次交谈应该只针对成果，而不是过程。可能没有达成目标，可能完成了目标，也可能超额完成了目标，每一种结果都应该对应不同的奖励或鼓励。如果处理好这方面的工作，绩效讨论就不再会是突然袭击，因为在整个过程中你们都在进行沟通，员工也能感觉到你在每一步工作上对他们的支持。不管在什么情况下，都不要完全依赖经理确定员工表现的确切情况。为了团队的发展，恳请同事贡献意见，即使是简单地问询一些问题或发布一些简单问卷也可以。至于绩效考评，要求经理们坐在一起组成团队，共同校准考评结果，确保公正。</li>
<li>关注团队的两端——最优员工和最差员工将最优秀的人放在显微镜下观察。他们结合了环境和技能，精心打磨才理清了如何成就超常表现。不仅要识别出最佳全能员工，还要识别出特定方面最突出的员工。不要寻找最优秀的销售人员；寻找面向特定规模的新用户销售量最大的人。找到能在夜雨中练习高尔夫球那样的优秀人才。在专业方面分得越精细，就越利于研究你的明星员工，发现他们比其他人更成功的原因。然后不仅要让他们成为其他人的榜样，围绕他们所做之事制定检查清单，还要请他们做老师。教授一项技能是掌握它的最好方法之一。请明星员工做教员，即使是半小时的咖啡交谈时间，也要促使他们清楚地讲述自己是如何开展工作的，而这个过程也有助于他们的成长。如果你身边有这样的同事，要仔细观察他们，多向他们提问题，利用这个机会从他们身上获取知识。与此同时，对表现最糟糕的员工也要心怀怜悯。如果你的招聘工作没有犯错，那么大多数陷入困境的员工都是因为没有找到合适的岗位，而不是因为自身笨拙。帮助他们学习或找到新的角色。但是如果上述努力失败，立刻辞退他们。让他们留在公司里并非仁慈，在一个自己并非最差员工的环境中，他们会更加快乐。</li>
<li>既要节俭又要慷慨我们为员工做的大多数事情都不需要任何花费。请供应商来公司为员工服务或与当地三明治店协商为公司送午餐。TGIF和嘉宾演讲者需要的仅仅是一个房间和一支麦克风。然而却带来了无比丰富的财富：启发谷歌人开发出一种新的服务或引发讨论。省下钱来，在员工最需要的时候，在他们遇到灾难或大喜之时使用。当某人需要急诊医疗护理或迎接家庭新成员之时，你的慷慨会带来最大的影响力。关注人类最重大的一些时刻能够突出你们的组织关心每一个员工。了解到自己在人生低谷和顶峰之时背后都有整个机构的力量做后盾，每个人都会感到宽慰。这一点对很小的公司也同样适用。我的父亲成立过一家工程公司，他亲自领导了30年。他深切关怀每一位员工，不仅付给他们薪水，而且善意赞扬，为他们提建议，做引导。团队中任何一个人任职5年之后，他都会拉他们出来私聊一番。他告诉他们公司有一项退休金计划，5年时间的投入已经满额。除了员工自己存下来的积蓄，他还为他们每个人额外存了一笔钱。有些人欢呼雀跃，有些人感动流涕，有些人只是简单地谢过了他。他没有提早告诉员工这项计划，因为他不希望人们为了钱才留下来工作。他希望员工留下来是因为喜欢创造东西，是因为喜爱这个团队。关键时刻他很慷慨，因此也使结果大不相同。</li>
<li>不公平薪酬不管你们的人力资源部门是怎么对你说的，要记住大多数工作中的绩效表现都是符合幂律分布的。你们的团队中90%甚至更高的价值都是由顶尖的10%的人创造的。因此，最优秀的员工远比平均水平的员工更有价值。他们的价值或许比平均水平的员工高50%，或许高50倍，但是不管高多少肯定值得你为他们付出更多。一定要让他们感觉到这些。即使你没有足够的资金为他们提供超高额的薪水，但是更高一些的薪水也算一种心意表达。另外一位员工对这种奖励或许会有些不高兴，但是你可以坦诚相对，解决这个问题：向他们解释薪酬差异化的原因，以及他们怎么做才能改变现状。与此同时，在公众认可方面要慷慨投入。团队的成就要庆贺，虽然失败但却学到重要经验教训的时候也要鼓励。</li>
<li>助推本书中提到的各种想法中对你未来的人生能够带来最大切实改善的一种就是改变每笔收入中存下来的金额。如果比较30年里赚到的钱同样多的一些人，他们累积的财富却可能有3000%的差异，而这一切几乎完全取决于你存下了多少钱。存钱从来都不是一件简单的事情。除非你比克罗伊斯[插图]还要富有，节省下来的每一个美元都像是一种利弊权衡。我是要买品牌货还是一般产品？是买3美元的花生酱还是吃甜点？换一辆新车还是再凑合一年？我毕业后的第一年，当演员的同时还做服务生，经常光顾小镇附近的女主人廉价商店（Hostess Thrift shop），店里售卖一些马上就要过期的面包和点心。我有了零食蛋糕（有节制的！），而且还能每周多省下几美元。要记住，督促谷歌人提升不到3%的存钱比例，每位谷歌人的退休基金将增加262000美元。很多人听到下面的事情或许会觉得很疯狂。我认识一些人，将度假胜地汉普顿斯的10万美元夏日出租房看成生活必需品；我的一些银行家朋友虽然在2008年丢掉了工作，但还是能躲到海滨别墅里度假。我一直反复强调这一点，但人们还是不愿意改变存款比例。计算出当前你存下来的钱占收入的比例，从现在起再多存一些。不论何时这都不是一件容易的事情。但这样做肯定是值得的。上面是对你个人而言。现在环顾四周，看看你所处的环境是如何助推你与周围的人的。你能很容易地看到其他人，与他们建立联系吗？你们冰箱里最不健康的零食放在与人的视线平齐的位置上吗？你给同事和朋友发邮件或短信的时候是分享好消息还是抱怨发火？我们都时刻受到环境的助推，也时刻助推着周围的人。利用这一点，使你自己和你的团队更快乐、更高效。工作场所的空间布置要鼓励你所期望的行为：如果你需要员工协作，但却受困于工位是小隔间，那么就推倒隔断。向员工传递讯息的时候要深思熟虑。分享一些积极的数据，比如参加当地慈善活动志愿者的人数，鼓励其他人参与。你将惊异于同一个工作场所给人带来的感觉会有如此大的不同。</li>
<li>管理日益提升的期望有时你会犯错误，这时就需要倒退几步。要准备好吃下你们自己的枸杞派。明白了这一点之后，在开始实验之前，告诉周围的人你打算实验本书中的一些想法。这样做有助于促使他们从批判者转变为支持者，实验走上了弯路的时候，他们的质疑将给你带来更多的益处。</li>
<li>享受！然后回到第1条，再来一遍拉里和谢尔盖立志创立一个他们都希望为之工作的地方。你也可以做同样的事情。即使你刚毕业加入一家公司，还只是一名初级职员，或者是第1000006号职员，你也可以像一位创始人一样选择与周围人的沟通方式，选择如何设计自己的工作场所，选择如何领导。你这样做可以帮助创造一个能够吸引地球上最优秀人才的场所。</li>
</ol>
<ul>
<li>这并非一劳永逸的努力。想要打造了不起的公司文化和环境要求我们不断地学习和革新。不要担心立刻尝试所有事情。实验本书中介绍的一种或多种想法，从实验中学习经验，对项目进行调整，然后再次尝试。这种方式的美妙之处在于，良好的环境可以自我强化：所有这些努力可以互相支持，共同创造出一个有创造力、有趣、努力且效率极高的组织。如果你相信人本善，那么就应在工作中践行自己的信念。谷歌已经30多次被卓越职场研究所评为最佳雇主，另外还获得数百种支持女性、非裔美国人、老兵等人群的组织和政府、社会机构颁发的荣誉。但是我们并非第一个“最佳雇主”，也不会是最后一个，甚至在今日也不是唯一一个。谷歌真正擅长的是大规模运营，建立起的体系服务20亿人也如服务10人一样周到可靠。员工的创新得益于一批有先见之明的创始人、狂热的企业文化捍卫者、周密的学术研究，以及具有创造力的公司和政府。数千名谷歌人共同塑造了我们运营的方式，推动我们找到最具有创造力和最公平的方式解决与人相关的问题，使我们肩负起了责任。我有幸与见解深刻、勇于担当、富于创造力的同事和人力运营团队共事，竭尽全力才跟得上他们的步伐。我每天都能从他们身上获得启发。每年有成千上万的人参观我们的园区，问我们：“为什么这里的人这么开心？”“谷歌的秘密是什么？”“我在我的组织里做些什么才能使其更具创新性？”答案就在你的手中。谷歌工作法则1. 赋予工作意义2. 相信员工3. 只聘用比你更优秀的人4. 不要将职业发展与管理绩效混为一谈5. 关注团队的两端——最优员工和最差员工6. 既要节俭又要慷慨7. 不公平薪酬8. 助推9. 管理日益提升的期望10. 享受！然后回到第1条，再来一遍</li>
</ul>
<h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><ul>
<li>我们一直围绕着4条基本原则构建谷歌人力运营部：1. 为实现极乐天堂而奋斗。2. 利用数据预测和塑造未来。3. 不遗余力地提高生产力。4. 创建非传统型团队。</li>
<li>我选择血细胞来图示“人力资源正在做的工作”旨在强调我们的项目就如人体的循环系统一样无处不在且同样可靠。</li>
<li>大多数公司，包括几年前的谷歌都会向升职的人道贺，但却毫不关注那些没有得到升职机会的人。这是非常愚蠢的行为。只需要一两个小时的时间找出你认为可能会因此沮丧的人，告诉他们如何才能得到持续发展。人们都希望受到这样的待遇。这样做从程序上讲更公正，有助于员工认同流程的开放性和可靠性。这样远比导致某人辞职，失去他们带来的产值，再寻找新人替代，聘用新人，引领新人走上高速通道这个过程对公司更有利。而且，在某人职业生涯非常脆弱的时刻，你这样做是帮助他们理解了发生的事情，利用一个消极事件激发他的动力。要构建这种能力需要花费一些时间，但是不管你所在组织的规模大小，开始这项工作都不是难事。</li>
<li>她完全不知道电子数据表有一项功能可以做计算。我们需要留心所属专业的两端，并针对他们采取相应的行动。她的例子解释了为什么越来越多的公司将非人力资源从业人员安排为人力资源部的主管。</li>
<li>情商高的人通常有更明晰的自我认知，因此也不会那么傲慢。这也使他们更容易转移到新的领域。</li>
<li>教会整个团队一些传统人力资源团队不会学到的技巧，比如使用sQL或r等编程语言，或将员工面试中搜集的定性数据进行编码的方法。</li>
<li>通过三分招聘模型的使用，我们招聘到具备各种能力的人：人力资源专业人员教会我们如何对员工和组织施加影响，识别不同的形态模式；咨询师可以提升我们对商业的理解力以及我们解决问题的水平；分析人员能提高我们所做各项工作的质量。</li>
<li>在人力运营部中将我们所有人团结在一起的最重要因素在于我们共同的愿景，认为工作不必令人痛苦。工作可以令人更高雅、更有活力、更兴奋。这是推动我们努力的原因。</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>自由的状态是以自由表达为基础的，而自由表达又依靠对信息和真实情况的了解。(自由需要控制在一定的合理范围内？)</li>
<li>从管理的核心角度来讲，权力的动态方向恰与自由背道而驰。</li>
<li>剥夺管理者对员工的控制权。由一组同事、一个委员会或一个特别任命的独立团队做出。</li>
<li>管理者服务于团队。管理者的关注重点不是惩罚或奖励，而是清除路障，鼓励团队。</li>
<li>只有当企业着手给员工更多的自由时，业绩才能提升。</li>
<li>坚信员工都是好的，再就是要有足够的勇气，把员工看成是企业的主人翁，而不是把他们当成机器。</li>
<li>让处于绩效分布底端的人了解真相，但是不要将绩效与薪酬或职业成果直接挂钩，尽可能用一种积极的方式警示并激励他们。数百名经理需要面对自己并非好经理的现实。</li>
<li>有效的管理不是简单粗暴地不允许你犯错，而是预见到可能发生的错误，提供一个合理的标准和方法，在错误发生之前就避免它。</li>
<li>情商高的人通常有更明晰的自我认知，因此也不会那么傲慢。这也使他们更容易转移到新的领域。</li>
</ul>
<h3 id="管理借鉴"><a href="#管理借鉴" class="headerlink" title="管理借鉴"></a>管理借鉴</h3><ol>
<li>尽量创造自由的环境；(高自由度)</li>
<li>不能把员工当作机器；</li>
<li>会议时不坐在上首座位，避免潜在的等级关系；(除去显示权力和地位的象征符号)</li>
<li>尽量保持透明；</li>
<li>放弃一些控制权，就可以为团队创造一次提升的好机会，也给自己节省出更多时间应对新的挑战;</li>
<li>关注个人成长而不是评分和奖励，以此改善绩效;</li>
<li>把奖励分配谈话与员工发展谈话分开;</li>
<li>绩效交谈前发讲义，覆盖恰当的话题，引导讨论；</li>
<li>打造学习型组织;</li>
</ol>
<pre>
最优秀经理手下工作的谷歌人在十几项Googlegeist评估维度上要比最差经理手下工作的谷歌人高5%至18%。除此之外，他们在以下几方面的认可度明显更高：
•职业决策更加公正。绩效评估公正，得到升职的都是实至名归的人选。
•个人的职业目标能够达成，他们的经理是非常有帮助的支持者和引导者。
•工作高效，决策迅速，资源分配合理，从多种视角考虑问题。
•团队成员之间没有等级制度，互相尊重，决策依据数据做出而不是靠耍手段，团队内部各人的工作和信念都保持透明。
•他们适当地参与到决策制定过程中，并且得到一定的授权去完成工作。
•他们可以自由地平衡工作和私人生活。

调查显示高分经理具备八种低分经理所不具备的共性：8个氧气项目特性
1.  做一名好的导师。
2.  给团队授权，不随便插手下属工作。
3.  表达出对团队成员的成功和个人幸福的兴趣和关心。
4.   高效/结果导向型。
5.   善于沟通——聆听和分享信息。
6.   在职业发展方面助力团队。
7.   对团队有清晰的愿景和战略。
8.   具备重要的技术技能，可为团队提供建议。
</pre>

<h3 id="招聘借鉴"><a href="#招聘借鉴" class="headerlink" title="招聘借鉴"></a>招聘借鉴</h3><ol>
<li>只聘用比你更优秀的人(至少某些特定的方面比你更优秀的。)</li>
<li>最优秀的人通常并不在寻找工作；</li>
<li>让面试者开心；</li>
<li>谷歌工作法则：筛选新雇员?□设定高质量标准□寻找自己的应聘者□客观评估应聘者□给应聘者一个加入的理由</li>
</ol>
]]></content>
      <tags>
        <tag>BOOK</tag>
        <tag>JOB</tag>
      </tags>
  </entry>
  <entry>
    <title>《深度工作：如何有效使用每一点脑力》-笔记</title>
    <url>/2021/08/13/20210813-shen-du-gong-zuo-ru-he-you-xiao-shi-yong-mei-yi-dian-nao-li-bi-ji/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><ul>
<li><p>深度工作（Deep Work）：在无干扰的状态下专注进行职业活动，使个人的认知能力达到极限。这种努力能够创造新价值，提升技能，而且难以复制。</p>
</li>
<li><p>浮浅工作（Shallow Work）：对认知要求不高的事务性任务，往往在受到干扰的情况下开展。此类工作通常不会为世界创造太多新价值，且容易复制。</p>
</li>
<li><p>深度工作假设（The Deep Work Hypothesis）：深度工作的能力日益稀少，而几乎同时，其在社会经济中的价值也日益提升。因此，能够培养这项技能，并将其内化为工作生活之核心的人，将会取得成功。</p>
</li>
</ul>
<h3 id="如何在新经济形势下成为赢家"><a href="#如何在新经济形势下成为赢家" class="headerlink" title="如何在新经济形势下成为赢家"></a>如何在新经济形势下成为赢家</h3><ul>
<li><p>我发现有两类人注定会成功，而且我认为可以推广借鉴：一种是能够利用智能机器进行创造性工作的，一种是自己所在领域的个中翘楚。在数字鸿沟不断扩大的当下，有什么窍门能够为进入此类有利领域提供助力？我认为如下两种核心能力是关键。</p>
<ul>
<li>·迅速掌握复杂工具的能力</li>
<li>·在工作质量和速度方面都达到精英层次的能力</li>
</ul>
</li>
<li><p>智能机器的复杂性是难以掌握的。因此，要想较好地运用这些机器，你就要培养出掌握复杂事物的能力。而且由于这些科技变化很快，掌握复杂事物的过程便永远不会结束：你必须能够快速完成，一次又一次。当然，这种迅速掌握复杂事物的能力并不仅仅是能熟练运用智能机器所必需的；基本上也是想要成为任何领域的超级明星的关键因素，即便是与科技关联性很小的领域。</p>
</li>
<li><p>如果你无法学习，就无法成功。</p>
</li>
<li><p>由此我们总结出想要加入当前经济形势下赢家群体的另一项要点：如果你不产出，就不会成功，不管你的技艺多么纯熟，天资多么聪颖。</p>
</li>
<li><p>上文阐述的两种核心能力依赖于你进行深度工作的能力。如果你没有掌握这项基本能力，想要学习艰涩的知识或达到精英水平就会很挣扎。这些能力对于深度工作的依赖性并非即时显现的，这要求我们更深入地探究与学习、专注和生产力相关的科学</p>
</li>
</ul>
<h3 id="深度工作帮助你迅速掌握困难的事物"><a href="#深度工作帮助你迅速掌握困难的事物" class="headerlink" title="深度工作帮助你迅速掌握困难的事物"></a>深度工作帮助你迅速掌握困难的事物</h3><ul>
<li><p>（1）你的注意力全情投入到某个你希望提升的技能或想要掌握的理念上；</p>
</li>
<li><p>（2）你能得到反馈意见，这样你就可以调整自己的方法，保持注意力的投入有最佳产出。</p>
</li>
<li><p>刻意练习不能在有干扰的情况下进行，要求在无干扰状态下保持专注。</p>
</li>
</ul>
<h3 id="深度工作有助于精英级产出的实现"><a href="#深度工作有助于精英级产出的实现" class="headerlink" title="深度工作有助于精英级产出的实现"></a>深度工作有助于精英级产出的实现</h3><ul>
<li><p>高质量工作产出&#x3D;时间×专注度</p>
</li>
<li><p>工作时专注度达到最高，单位时间里的工作产出也将实现最大化。</p>
</li>
<li><p>当你从某项任务A转移到任务B时，你的注意力并没有即时转移，你的注意力残留仍然在思考原始任务。如果在转移工作之前，你对任务A缺乏控制且关注度较低，残留会尤其浓厚，但即使你在转移工作之前已经完成了任务A，你的注意力还是会有一段分散的时间。</p>
</li>
<li><p>注意力残留的概念有助于解释专注度公式的真实性，因此也有助于解释格兰特的高效产出。格兰特长时间不转移注意力，完成单一困难任务，使注意力残留负面影响降到最低，从而使他在当前任务上的表现成果最优化。换言之，当格兰特与世隔绝数日完成一篇论文时，其效率水平远高于奉行多任务策略的一般教授，这些教授的工作反复受到残留量极大的干扰。</p>
</li>
<li><p>要达到个人巅峰的产出效率，你需要长时间、无干扰地高度专注于单一任务。换一种说法，使你的表现最优化的做法是深度工作。如果你无法做到长时间深度工作，就很难使你的表现达到质量和数量的巅峰，而这种巅峰状态对于你的职业成功越来越重要。除非你的才能和技能全面压制对手，否则对手中的深度工作者定将超越你的表现。</p>
</li>
</ul>
<h3 id="杰克·多西是怎么回事？"><a href="#杰克·多西是怎么回事？" class="headerlink" title="杰克·多西是怎么回事？"></a>杰克·多西是怎么回事？</h3><ul>
<li><p>杰克·多西没有深度工作而取得成功，在其所处的精英管理层中是很常见的。</p>
</li>
<li><p>明确了这一事实之后，我们必须退后一步提醒自己，这种现象并不会破坏深度工作的普遍价值。为什么？因为这些高管工作中分心的必然性是在其特定工作中特有的现象。从根本上讲，一名优秀的首席执行官就是一部难以自动化的决策引擎，与《危险边缘》游戏中IBM的“沃森”机器人没有太大区别。他们努力积累起丰富的经验库，打磨并证明了自己在市场中的灵敏嗅觉。而后他们全天都必须处理和解决电子邮件、会议、现场考察等纷至沓来的工作。要求一名首席执行官花上4个小时的时间深度思考单一问题浪费了他们的价值所在。最好是聘用三个聪明的副手，深度思考这些问题，然后将解决方案呈递给高管做决策。这种特殊案例很重要，因为这种状况告诉我们，如果你是一家大型公司的高管，或许就不需要听取下述章节中的意见。另一方面，它也告诉我们不能将这些高管的工作方法外推至其他工作中。多西鼓励外界打扰，克里·特雷纳不断查阅电子邮件，虽然有这些案例，但并不意味着你学着他们的做法也能成功：他们的行为是公司领导者这个特定角色所特有的。</p>
</li>
<li><p>我们必须时刻记住，在社会经济的某些角落，深度工作并没有价值。除了高管之外，还有部分类型的销售人员和说客，对他们而言持续联系是其最大价值所在。甚至还有一些人身处深度工作有所助益的领域，却在备受干扰中经过艰苦努力取得成功。</p>
</li>
<li><p>深度工作并非是我们的经济中唯一有价值的技能，不培养这种能力也有可能做得很好，但是不需要深度工作的职业会越来越少。</p>
</li>
</ul>
<h2 id="第2章-深度工作是少见的"><a href="#第2章-深度工作是少见的" class="headerlink" title="第2章 深度工作是少见的"></a>第2章 深度工作是少见的</h2><ul>
<li>发现即使很短暂的干扰也会显著延长完成一项任务所需要的时间。</li>
</ul>
<h3 id="度量的黑洞"><a href="#度量的黑洞" class="headerlink" title="度量的黑洞"></a>度量的黑洞</h3><ul>
<li><p>大致说来，由于知识工作者的工作复杂性比体力劳动者高，所以也更难衡量个体努力所带来的价值。</p>
</li>
<li><p>我们不应期望破坏深度工作的行为对底线的影响很容易被察觉。恰如汤姆·考克兰的发现，此类度量属于不透明区，难以轻松衡量。我将这个区域称作度量黑洞。当然，难以衡量深度工作相关的度量，并不意味着我们在商业中就应忽略其作用。</p>
</li>
</ul>
<h3 id="最小阻力原则"><a href="#最小阻力原则" class="headerlink" title="最小阻力原则"></a>最小阻力原则</h3><ul>
<li><p>谈及工作场所中普通存在的干扰行为，我们必须为占主导地位的联结文化留个位置，这种文化期望人们能够迅速阅读和回复电邮（及相关交流）。</p>
</li>
<li><p>最小阻力原则（The Principle of Least Resistance）：在工作环境下，若各种行为对于底线的影响没有得到明确的反馈意见，我们倾向于采用当下最简单易行的行为。</p>
</li>
<li><p>最小阻力原则受到度量黑洞的保护，少有人对其加以审视，在这种原则支配下的工作文化，免去了我们短期内对保持专注和做计划的忧虑，却牺牲了长期的满足感和真实价值的产出。这样一来，最小阻力原则就驱使我们在深度工作愈发受到青睐的经济形势下流于浮浅工作。</p>
</li>
</ul>
<h3 id="忙碌代表生产能力"><a href="#忙碌代表生产能力" class="headerlink" title="忙碌代表生产能力"></a>忙碌代表生产能力</h3><ul>
<li><p>经理栖居于一片迷茫的精神领地，受冥冥中难以捉摸但必须应答的命令驱使而焦躁不安。</p>
</li>
<li><p>我认为知识工作者越来越多地表现为可视的忙碌，是因为他们没有更好的方法证明自身价值。我们来给这种倾向性起一个名字。</p>
</li>
<li><p>忙碌代表生产能力（Busyness as Proxy for Productivity）：在工作中，对于生产能力和价值没有明确的指标时，很多知识工作者都会采用工业时代关于生产能力的指标，以可视的方式完成很多事情。</p>
</li>
<li><p>这种思维方式为很多有损深度的行为之盛行提供了又一种解释。如果你随时都在收发电子邮件，如果你不断安排、参加会议，如果有人在Hall之类的即时通讯系统中发布一个新问题，让你在几秒钟内就参与其中，又或者你在开放式办公室中漫步，随时向遇到的人道出自己的想法——所有这些行为都可以使你在公众眼里看似很忙碌。如果你将忙碌看作生产能力，那么想要自己和他人信服你的工作做得很好，这些行为就至关重要。</p>
</li>
</ul>
<h3 id="对互联网的顶礼膜拜"><a href="#对互联网的顶礼膜拜" class="headerlink" title="对互联网的顶礼膜拜"></a>对互联网的顶礼膜拜</h3><ul>
<li><p>已故传播学理论学者、纽约大学教授尼尔·波兹曼（Neil Postman）提出的一个警告中找到基础。20世纪90年代初期，个人电脑革命首次进入快车道，波兹曼在文章中辩称我们的社会与科技的关系愈发令人不安。他写道，我们不再权衡新科技的利弊，不再平衡新增效益和新引入的问题之间的关系。我们开始自以为是地认定，只要是高科技就是好的，而不用再做探讨。他将这种文化称作技术垄断（Technopoly），在提出警醒时也没有拐弯抹角：“技术垄断阻断了其他选择，</p>
</li>
<li><p>在技术垄断的时代，深度工作有很大的劣势，因为它所创建的品质、匠心和通达等价值都是传统的，与技术垄断无关的。更糟糕的是支持深度工作往往要抵制新的高科技。</p>
</li>
</ul>
<h3 id="对生意来讲是坏事，对个人来讲是好事"><a href="#对生意来讲是坏事，对个人来讲是好事" class="headerlink" title="对生意来讲是坏事，对个人来讲是好事"></a>对生意来讲是坏事，对个人来讲是好事</h3><ul>
<li><p>包括深度工作很难，浮浅工作更简单；当工作中没有明确目标时，围绕浮浅工作的表面忙碌会成为一种本能；还有在我们的文化中已经形成了一种信念，认为与“网络”相关的行为都是好的，不论其对我们创造有价值事物之能力有何影响。由于深度工作价值以及忽略深度工作所造成的损失很难直接衡量，这些潮流才会大行其道。</p>
</li>
<li><p>本书的终极目标：系统地培养个人进行深度工作的能力，并由此获得丰富的成果</p>
</li>
</ul>
<h3 id="从神经学角度论证深度"><a href="#从神经学角度论证深度" class="headerlink" title="从神经学角度论证深度"></a>从神经学角度论证深度</h3><ul>
<li><p>你的为人、你的思考、你的感受和所做之事，以及你的喜好，恰是你所关注事物的概括。”</p>
</li>
<li><p>从神经学角度来看，靠浮浅事务度过的一天很可能会是枯燥、令人沮丧的一天，即使抓住你注意力的浮浅事务看似无害甚至有趣。</p>
</li>
</ul>
<h3 id="从心理学角度论证深度"><a href="#从心理学角度论证深度" class="headerlink" title="从心理学角度论证深度"></a>从心理学角度论证深度</h3><ul>
<li><p>一个人的身体或头脑在自觉努力完成某项艰难且有价值的工作过程中达到极限时，往往是最优体验发生的时候。</p>
</li>
<li><p>具有讽刺意味的是，工作其实比休闲时光更容易带来享受，因为工作类似于心流活动，有其内在目标、反馈规则和挑战，所有这些都鼓励个人积极参与到工作中，专注其中，全身心投入到工作里。休闲时光则组织松散，需要很大的努力才能创造出值得享受的事情。</p>
</li>
</ul>
<h3 id="深度智人"><a href="#深度智人" class="headerlink" title="深度智人"></a>深度智人</h3><ul>
<li>“我将活出专注的人生，因为这是最好的选择。”</li>
</ul>
<h2 id="第二部分-准则"><a href="#第二部分-准则" class="headerlink" title="第二部分 准则"></a>第二部分 准则</h2><ul>
<li><p>你的意志力是有限的，它在使用的过程中会被不断消耗。换言之，你的意志力并非性格的展现，可以无限制地使用；相反，它恰如肌肉一般，会疲劳。</p>
</li>
<li><p>培养深度工作的习惯，关键在于越过良好的意图，在工作生活中加入一些特别设计的惯例和固定程序，使得进入并保持高度专注状态消耗的意志力最小化。</p>
</li>
</ul>
<h3 id="选定你的深度哲学"><a href="#选定你的深度哲学" class="headerlink" title="选定你的深度哲学"></a>选定你的深度哲学</h3><ol>
<li>禁欲主义哲学的深度工作</li>
<li>双峰哲学的深度工作</li>
<li>节奏哲学（更符合人类的真实天性、适合常规办公室工作）</li>
<li>记者哲学</li>
</ol>
<ul>
<li><p>克努特采用的是我所谓的禁欲主义哲学的深度工作日程安排。这种哲学通过摒弃或最小化浮浅职责，从而实现深度工作的最大化。禁欲主义哲学的实践者往往有明确且价值极高的职业目标追求，而且他们在职业上取得的大部分成就都是由于工作表现特别突出。</p>
</li>
<li><p>适用禁欲主义哲学的个人是有限的。如果你不属于这个群体，也大可不必太过嫉妒。如果你属于这个群体——对世界的贡献是实在的、清晰的、可以个体化的[插图]，那么你就应该认真考虑一下这种哲学，因为这种哲学或许会成为决定性因素，决定你完成的是一个庸庸碌碌还是能为后人所铭记的职业生涯。</p>
</li>
<li><p>我将荣格这种方式称作双峰哲学的深度工作。这种哲学要求你将个人时间分成两块，将某一段明确的时间用于深度追求，余下的时间做其他所有事情。在深度时间里，双峰工作者会像禁欲主义者一般工作——追求高强度、无干扰的专注。在浮浅时间里，专注并非首要目标。这种划分深度和开放时间的做法可以在多个时间层级上实现。</p>
</li>
<li><p>节奏哲学。这种哲学认为轻松启动深度工作的最好方法就是将其转化成一种简单的常规习惯。换言之，其目标是创造一种工作节奏，让你不需要你投入精力便可以决定是否需要以及何时需要进入深度状态。链条法是节奏哲学深度工作日程安排的典型例子，因为这种方法结合了一种简单的启发式调度（每天都要做这项工作）和一种提醒你做这项工作的简单方法：日历上的大红X。</p>
</li>
<li><p>实施节奏哲学的另外一种常见方式是拿掉链条法中的视觉辅助工具，转而设定一个启动时间，每天在这个时间开始深度工作。</p>
</li>
<li><p>节奏哲学与双峰哲学形成了一种有趣的对比。节奏哲学下或许难以达到双峰哲学追随者喜好的最高强度深度思考。然而，这种方法的好处在于更符合人类的真实天性。节奏日程安排者通过雷打不动的惯例支持深度工作，确保能够定期完成一定的工作，在一年的时间里往往能够累积更多的深度工作时长。</p>
</li>
<li><p>对于很多人来说，并非因为自控原因才倾向于选择节奏哲学，而是由于现实中某些工作的确不允许你在需要深入的时候一连消失几天。</p>
</li>
<li><p>常规办公室工作的深度工作者最常选择节奏哲学的原因吧。</p>
</li>
<li><p>我将这种在日程安排中随时可插入深度工作的方法称作记者哲学</p>
</li>
<li><p>我个人也偏爱记者哲学的深度工作，因为这也是我将各项工作安排到日程中所采用的主要方法。换言之，我在深度工作中不是禁欲主义（尽管偶尔我也会嫉妒同行计算机科学家唐纳德·克努特完全与世隔绝但却不用心怀歉意），我也不会像双峰主义者一样接连安排多天的深度工作时间，此外，尽管我很有兴趣采用节奏哲学，但是我的日程安排已经很满，没办法压缩出时间施行这种习惯。我更多的时候如艾萨克森一样，面对每周的工作，竭尽可能压缩出更多的深度工作时间。比如，写作本书的过程中，我会充分利用任何一小段空闲时间。如果我的孩子睡着了，我就会拿出笔记本，把自己锁到书房里。如果妻子在周末要去附近的安纳波利斯拜访她的父母，我就会抓住有额外的人照看孩子的机会，躲到他们房子的一个安静角落去写作。如果工作中有一次会议取消了，或是下午没有安排，我就会来到学校里最喜欢的一间图书馆里，写上几百个词。诸如此类。</p>
</li>
</ul>
<h3 id="习惯化"><a href="#习惯化" class="headerlink" title="习惯化"></a>习惯化</h3><ul>
<li>伟大的创造性头脑如艺术家般思考，却如会计般工作。”</li>
</ul>
<h3 id="不要独自工作"><a href="#不要独自工作" class="headerlink" title="不要独自工作"></a>不要独自工作</h3><ul>
<li><p>深度工作与协作之间的关系非常微妙。然而，这种关系值得我们花时间去解开，因为恰当展开协作可以提升你在职业生活中深度工作的质量。</p>
</li>
<li><p>“我们鼓励员工到开阔区域工作，因为我们相信意外发现——员工互相协作会产生新想法。”</p>
</li>
<li><p>在提倡专注还是意外发现之间做出选择，暗示了深度工作（个体努力）无法与创造性洞见（协作努力）相容。然而这个结论是有缺陷的。我认为这个结论的基础是对偶然创造力理论的片面理解。</p>
</li>
<li><p>偶然创造理论似乎非常符合这些历史记录。我们可以颇有信心地争辩道，晶体管的发明或许需要贝尔实验室的支持，将固态物理学家、量子论理论学家和世界一流的实验物理学者汇聚一堂，互相学习各自的专长，得到偶然的意外发现。这项发明不太可能由某位容身卡尔·荣格那石塔一样的学术处所深度思考的科学家完成。</p>
</li>
<li><p>这种隔音办公室与宽阔公共空间的组合，形成了中心辐射型的创新建筑结构，在这里偶遇的意外发现和与世隔绝的深度思考都能实现。这种设置囊括了两个极端，一方面我们能找到独立的思考者，没有外界激发灵感，但也少了外来的干扰，另一方面我们能看到在开放式办公室里互相协作的思考者，灵感不断，却也缺乏将其付诸实践的深度思考。</p>
</li>
<li><p>如果将注意力转回到20号楼和贝尔实验室上，我们就能发现，二者的建筑设计也有同样的特点。二者都不同于现代的开放式办公室布局，而是利用标准的私人办公室结合共享走廊的方式。</p>
</li>
<li><p>他们的创造性魔力更多的是由于这些办公室共享少量的长联通空间——迫使研究人员在不同地点来往时互相交流。换言之，这些宽大走廊提供了高效中枢。</p>
</li>
<li><p>因此，我们可以抛弃摧毁深度工作的开放式办公室概念，但是可以保留激发偶然创造力的创新产出理论。关键在于保持一种中心辐射型的布局：时常来到中枢区域与他人交流想法，同时也保留独立的辐射区域，可以在其中完成深度工作，处理偶遇的想法。</p>
</li>
<li><p>总结一些关于深度工作中协作之作用的实用结论。20号楼和贝尔实验室的成功证明与世隔绝并非有效深度工作所必需的条件。事实上，这两个例子表明，对于很多类型的工作而言——特别是追寻创新的——协作深度工作可以产出更好的效果。因此，这种策略要求你思考这种选择，考虑如何更好地将深度融入你的职业生活中。</p>
</li>
<li><p>在深度工作时，恰当的时机可以采用协作的方式，因为这样可以推动你的成果提升到一个新档次。与此同时，也不要过分追求交流和积极的偶遇，以免破坏了专注的状态，因为我们最终还是靠专注从包围在我们周围的各种想法的漩涡中提取有用之物。</p>
</li>
</ul>
<h3 id="像经商一样执行"><a href="#像经商一样执行" class="headerlink" title="像经商一样执行"></a>像经商一样执行</h3><ul>
<li><p>据克里斯坦森回忆，格鲁夫在一次会间休息时问他：“我该如何去做这件事？”克里斯坦森就与他探讨了商业策略，向格鲁夫解释说他可以成立一个新的公司业务单元之类的。格鲁夫生硬地打断了他：“你真是个天真的学院派啊。我问你如何做，你却告诉我应该做什么。我知道自己该做什么。我只是不知道如何做而已。”</p>
</li>
<li><p>克里斯坦森后来解释说，这种什么与如何的区别非常重要，但在职业世界中往往容易被忽略。找出实现某个目标的战略往往很简单，但是真正引领公司上行的反而是确定了战略之后该如何实施战略。</p>
</li>
<li><p>4DX框架下的4种原则，针对每一种原则我都会介绍自己是如何将其加以改进，以应对深度工作习惯培养中的特定问题。</p>
<ul>
<li>原则1：关注点放到极端重要的事情上正如《高效能人士的执行4原则》的作者所说的：“你想做的事情越多，完成的事情反而越少。”这句话阐述的意思是，执行需要专注于少量“极端重要的目标”。这样简化选择，有助于组织和集中足够的精力来达成实在的成果。</li>
<li>原则2：抓住引领性指标确定了极端重要的目标之后，你需要衡量自己的成功程度。在4DX框架下，有两种衡量指标：滞后性指标和引领性指标。滞后性指标用于描述你最终尝试改善的方面<ul>
<li>引领性指标则“衡量了实现滞后性指标的新行为”</li>
<li>引领性指标引导你将注意力转移到提升你在短期内可以直接控制的行为上，并会对你的长期目标带来积极的影响。</li>
<li>对于专注于深度工作的个人而言，确定相应的引领性指标非常容易：专注于极度重要目标上的深度工作状态时间</li>
</ul>
</li>
<li>原则3：准备一个醒目的计分板“计分的时候，人们的表现很不同。”4DX的作者解释道。当驱使你的团队专注于所在组织的极度重要目标时，在一个公开的地方记录、跟踪他们的引领性指标非常重要。这个计分板可以制造一种竞争氛围，驱使他们专注于这些指标，即使其他诉求吸引他们注意力的时候也不例外。此外计分板还可以强化动机。一旦团队注意到他们在引领性指标上的成功，他们就会很投入地保持这种状态。</li>
<li>在前述的一项原则中，我提出要想一个个体专注于深度工作，用于深度工作的时间应该作为引领性指标。因此这个人的计分板应该是工作场所的人工制品，显示这个人当前的深度工作时间。在我早期的4DX实验中，我设定了一种简单但有效的计分方式。[插图]我拿出一张卡片纸，将其剪成条，每一条记录当前学期的一个周。而后我在每一条卡片上记下了每周的日期，将其贴在电脑显示器旁边的墙上（在这里我无法忽略它的存在）。每一周我都在当周的卡片上简单地做个标记，记录当周的深度工作时间。为了使这个计分板带来的动力最大化，每当我的学术论文取得重要进展时（比如解决了一项关键论证），我就会在实现这个成果的那个小时标记上画一个圈。这么做有两个目的。首先，这样可以使我从本能层面将累积的深度工作时长与实在的结果相联系。第二，这样有助于我校准个人对于完成每项成果所需深度工作时间的期望。这种做法（比我最初想象的要更有效）激励我每周都挤出更多的深度工作时间。</li>
<li>原则4：定期问责4DX的作者详细阐释了保持专注于引领性指标的最后一步是要“保持节律性地与同享极度重要目标的团队会面”</li>
<li>对于专注于深度工作的个人而言，很可能没有任何团队去会面，但是这并不意味着你就可以免去定期问责的过程。贯穿本书，我都在探讨、推荐每周回顾的习惯，在每周回顾的过程中你可以指定下一周的工作计划（参见准则4）。在实验4DX的过程中，我每周回顾自己的计分板，庆贺表现好的一周，理清是什么导致了表现糟糕的一周，而且最重要的是找出能够确保未来几天得到好分数的方法。此举使我不断调整日程计划，以满足引领性指标的要求，大幅增加深度工作时间。</li>
</ul>
</li>
<li><p>在整个4DX的实验过程中，目标的明晰性，辅以引领性指标计分板提供的简单但却难以回避的反馈，促使我达到了此前从未实现的深度状态。现在回想起来，这并不是因为我的深度工作强度提升了，而是因为它变得更规律了。以前我常常将深度思考的过程放到论文截稿期前，而4DX习惯能帮助我的头脑全年都保持专注。我必须承认，那一年令我筋疲力尽（特别是我还在同时写作本书）。但是那一年的经历也同样是对4DX的有力认可：到2014年夏天，我有9篇论文被接收，比此前任何一年的成果都要多上一倍</p>
</li>
</ul>
<h3 id="图安逸"><a href="#图安逸" class="headerlink" title="图安逸"></a>图安逸</h3><ul>
<li><p>大多数情况下，你在浮浅工作上投入越多的时间，就能完成越多的工作。但是作为一名作家和艺术家，克莱德尔关注的是深度工作——能够创造出对世界有价值的苦功夫。他坚信完成这样的工作需要定期放松大脑。</p>
</li>
<li><p>一种更实际但也同样有很好启发性的方法：工作日结束的时候，在第二天早晨到来之前，屏蔽掉对工作问题的担忧——晚饭后不要查电子邮件，不要回顾白天的对话，也不要筹划如何处理即将到来的挑战；彻底屏蔽与工作相关的思考。如果需要更多的时间完成工作，就加一下班，但是一旦屏蔽工作之后，大脑就必须放松，如克莱德尔享受金凤花、椿象和星星一样</p>
</li>
<li><p>安逸时光之价值背后的科学道理。仔细研究文献，发现下面三种原因或许可以解释这种价值。</p>
<ul>
<li>原因1：安逸时光有助于提升洞察力<ul>
<li>积极刻意地去思考这些决定结果反而会更糟糕，不如在了解相关信息之后转移到其他事情上，让潜意识去考虑这些事。</li>
<li>无意识思维理论（Unconscious Thought Theory, UTT）——理解有意识和无意识思考在决策中所起作用的一种尝试。从更高层的角度上，这个理论提出在需要严格规则应用的决策中，必须要采用有意识思维。比如，如果你需要做数学计算，只有有意识思维才能严格按照数学运算法则得出正确结果。另一方面，对于涉及大量信息和多项模糊不清之处，甚至存在矛盾和约束条件的决策，无意识思维或许更适合。</li>
<li>UTT推测这种现象是由于大脑的这些区域有更多的神经频宽，可以处理更多的信息，相比有意识思考中心能够筛取更多的潜在解决方法。在这种理论下，你的有意识思维就好似家庭电脑一样，可以通过某种事先编写好的程序，得出有限数量问题的正确答案；而你的无意识思维就好像谷歌庞大的数据中心，通过数据算法在兆兆字节无结构可循的信息中筛选，为困难问题找出出乎人们意料的解决方案。这项研究的结果显示，给有意识的头脑休息的时间可以激活无意识头脑，从而理清最复杂的职业挑战。因此，屏蔽工作的习惯并不一定会降低你高效工作的时间，反而会使你开展的工作类型多样化。</li>
</ul>
</li>
<li>原因2：安逸时光有利于补充深度工作所需的能量<ul>
<li>对于本书的目的真正重要的是认识到ART不仅限于从自然中获得的益处。这个理论的核心机理在于，自主性引导注意力的能力可以得到复原，只要你能停下相应的活动一段时间。在自然中行走可以得到这样的精神放松，因此任何放松行为都可以有同样的效果，只要能够提供类似的“天然引人入胜的刺激”，能够暂时放下自主性专注状态。与朋友轻松地交谈，做晚饭的同时听听音乐，和孩子玩玩游戏，跑跑步——在你屏蔽工作的晚上可以填满时间的各种活动——与在自然中行走都有同样的注意力复原作用。另一方面，如果你整个晚上不停地查看、回复电子邮件，或是晚饭后又安排几个小时赶上即将到期的进度，你就剥夺了自主性注意力复原所必需的无干扰休息。即使中间做的这些工作只用去了很少的时间，也会使你无法达到注意力复原所需的深度放松。只有彻底放下，直到第二天开始之前不再工作，才能说服你的大脑充分放松，开始补充能量，为接下来的一天做好准备。换一种说法，晚间挤出一点时间工作可能会降低你第二天的工作效率，以致最后完成的工作比屏蔽工作还要少。</li>
<li>你每天处于深度工作状态的时间是有限的。如果你的日程安排足够合理（比如，利用准则4中介绍的一些策略），工作时间应该就已经达到了每日深度工作的极限。因此，进一步说来，到夜里你已经没有足够的精力做到有效的深度工作了。任何可以在夜里做的工作都不会是高价值产出的活动，不会对你的事业精进带来真正的益处；你此时的努力应该局限到低价值的浮浅任务上（以一种缓慢、低能耗的节奏进行）。换言之，推后了夜间的工作，你不会有什么重要的损失。</li>
<li>首先必须接受这种承诺，一旦工作日终了，就不能让任何职业相关的事情侵扰你的注意力，再小的也不可以。这其中尤其包括查看电子邮箱，以及浏览与工作相关的网站。上述两种情况下，即使短暂的工作侵扰也会形成一种自我强化的干扰流，持续长时间阻碍前文描述的屏蔽优势</li>
</ul>
</li>
</ul>
</li>
<li><p>定期休息大脑可以提升深度工作的质量。工作时，努力工作。完成时，就放松下来。</p>
</li>
<li><p>不要不断分心，而要不断专注</p>
</li>
<li><p>使用令人分心的网络工具这件事本身，并不能减损你大脑专注的能力。实际上减损这种能力的行为是，稍有无聊或遭遇一点点认知上的挑战，就从低刺激、高价值的活动转向高刺激、低价值的活动，这使得你的大脑不能容忍没有新奇性的东西。</p>
</li>
</ul>
<h3 id="像罗斯福一样工作"><a href="#像罗斯福一样工作" class="headerlink" title="像罗斯福一样工作"></a>像罗斯福一样工作</h3><ul>
<li><p>有一点需要提醒的是，一定要给自己设定一个几乎不可能的时间期限。你应该总是可以赶在最后期限前完成任务（至少是接近），但是这期间需要你用上吃奶的力气。</p>
</li>
<li><p>这个策略的主要意图很明显。深度工作需要专注的强度远远超出了大部分知识工作者的舒适区。</p>
</li>
<li><p>从某种意义上说，罗斯福冲锋配以截止期限，为大脑控制注意力的部分提供了反复的训练，可以系统性地提升你平时的成就水平。另一个益处就是这些冲锋不与分心兼容（在分心的情况下，你是不可能赶在截止期限前完成任务的）。因此，每一次的冲锋都是一个抵抗新奇刺激的过程：你心底里感到无聊，并且真的想寻求更多的新奇刺激，但是你得抵抗。正如我们在前边所讨论的，你抵抗这种冲动的实践越多，你的抵抗力就越强。</p>
</li>
<li><p>在应用这个策略几个月之后，随着前所未有的高强度体验，你对于专注的理解也会改变。如果你像年轻的罗斯福一样，就可以把由此节省出来的时间投入到生活中的赏心乐事中，比如说试着打动那些眼光老辣的纳塔尔鸟类学俱乐部成员。</p>
</li>
</ul>
<h3 id="有成果的冥想"><a href="#有成果的冥想" class="headerlink" title="有成果的冥想"></a>有成果的冥想</h3><ul>
<li><p>有成果的冥想的目标是：在身体劳作而心智空闲的时候（比如走路、慢跑、开车、淋浴），将注意力集中到一件定义明确的专业难题上。因个人专业不同，这个难题可能是为一篇文章列提纲，写一篇讲话稿，推演一个证明，或者是打磨一个商业策略。如同佛教的打坐，你的注意力可能会涣散或停滞，但你必须不断的把它重新集中到当前的问题上。</p>
</li>
<li><p>住在波士顿时，在每天上下班的过河旅途中，我至少做一次有成果的冥想。随着这方面能力的提高，我的成绩也有了提升。比如说，在步行的路上，我想好了上一本书的大部分章节的提纲，也在攻克学术研究方面的棘手问题上取得了进展。我建议你在生活中采用有成果的冥想。你并不需要每天进行严格的练习，一周进行至少两到三次即可。幸运的是，为这个策略找时间是简单的，因为这只需要你利用本可能被浪费掉的时间（比如说遛狗和通勤）。如果一切顺利，这种做法可以提升你在专业上的产出，却不需要占用你的工作时间。实际上，为了用有成果的冥想来解决你当前最紧急的问题，你甚至可以考虑在工作时间安排一次散步。</p>
</li>
<li><p>然而，我在这推荐有成果的冥想并不仅仅是因为它能提高生产效率（这当然已经很好了），而是因为它可以迅速提高你深度思考的能力。按照我的经验，有成果的冥想可以帮助你实现在本准则引言中介绍的两个关键理念。它通过迫使你抵抗分心，不断地把自己的注意力集中到一个定义明确的问题上，来增强你抵抗分心的心智。通过迫使你在一个问题上不断深入研究，助力专注能力的提升。为了更好地利用有成果的冥想，有一点必须要注意，那就是和其他的冥想一样，这种能力需要实践来磨炼。</p>
</li>
</ul>
<h3 id="准则3-远离社交媒体"><a href="#准则3-远离社交媒体" class="headerlink" title="准则3 远离社交媒体"></a>准则3 远离社交媒体</h3><ul>
<li><p>我们越来越深刻地意识到这些工具把我们的时间碎片化，削弱了我们集中注意力的能力。这一点现在几成定论。</p>
</li>
<li><p>在训练自己的同时沉迷于手机应用和网页浏览中，那么你的努力就可能会事倍功半。一个人的意志力是有限的，你的工具对你越有吸引力，你就越难在重要的事情上集中注意力。因此，要掌握深度工作的艺术，你必须摆脱各种各样的诱惑，重新掌控自己的时间和注意力。</p>
</li>
<li><p>当前知识分子讨论网络工具和注意力的问题时表现出来的无能。明明知道这些工具在压榨自己的时间，瑟斯顿却不知所措，他感觉自己唯一的选择就是（暂时的）完全戒掉网络。这种认为应对社交媒体和娱乐信息节目分散注意力问题的唯一方法就是选择激进的“网络假期”[插图]的想法，正逐渐占据我们文化讨论的主流。这种二元论的处理问题方法存在的缺点就是这两种选择都太残忍，因此不可能有用。很显然，认为可以戒掉网络的观点属于冠冕堂皇地偷换概念，对大多数人来说是不可行的（除非你是一名正在尝试写一篇关于分散注意力事物的记者）。没人会真的效仿巴拉唐德·瑟斯顿的做法——这个事实也证明了另一个选择的正确性：认识到我们目前注意力被分散的状态是不可避免的并接受现实。</p>
</li>
<li><p>认识到这些工具并不完全是邪恶的，有些甚至对你的成功和幸福是十分重要的；然而与此同时，也意识到应该对那些能够经常占用你时间和注意力（更不要说个人信息）的网站设立一个严格的限制标准，大部分人应该更少地使用此类工具。换言之，我不会要求你像2013年的巴拉唐德·瑟斯顿那样完全戒掉网络25天，但是我会要求你避免那种促使他开展激进实验的状态——注意力分散并且超高度依存于网络。网络的使用存在着一个中庸状态。如果你对深度工作的习惯感兴趣，你必须努力争取达到这个中庸状态。</p>
</li>
<li><p>选择网络工具的“任何益处法”：一旦发现使用一款网络工具有任何可能的益处，或者是不使用就可能错过某些事，你就觉得有足够理由使用这款网络工具。 很显然，该方法的缺点就是忽视了伴随这款网络工具而来的各种弊端。这些网络工具具有致瘾性——从那些对实现职业和个人目标有更直接帮助的活动中（比如说深度工作）抢走时间和注意力。如果过度使用这些工具，你将陷入精疲力竭、注意力散乱的网络依赖状态，就是这种状态使巴拉唐德·瑟斯顿和像他一样数以百万计的人们饱受煎熬。这就是任何益处思维定式带来的不容易察觉的危害。使用网络工具也是可以带来害处的。如果你不努力权衡利弊，一看到可能的益处就决定不加限制地使用某种工具，那么你就可能在不知不觉中失掉了在知识工作世界里取得成功的能力。客观来讲，这个结论并不令人惊奇。在网络工具的背景下，我们已经习惯了任何益处的思维定式，但是如果我们放宽视界，在熟练劳动[插图]的维度下思考这种思维定式，我们就会发现这是一种诡异的、目光短浅的工具选择方法论。</p>
</li>
<li><p>工具选择的手艺人方法：明确在你的职业和个人生活中决定成功与幸福的核心因素。只有一种工具对这些因素的实际益处大于实际害处时才选择这种工具。</p>
</li>
<li><p>请注意，此手艺人方法与任何益处方法恰好相对立。任何益处思维定式认为任何潜在的益处都可以成为使用此工具的借口，手艺人方法要求这些益处能够影响到核心因素，并且益处大于害处。</p>
</li>
</ul>
<h3 id="在你的网络使用习惯中采用关键少数法则"><a href="#在你的网络使用习惯中采用关键少数法则" class="headerlink" title="在你的网络使用习惯中采用关键少数法则"></a>在你的网络使用习惯中采用关键少数法则</h3><ul>
<li><p>问题不是推特是否带来了益处，而是它带来的益处是否足够抵消它所消耗的你的时间和注意力</p>
</li>
<li><p>关键少数法则在许多情境中，80%的已知效果源自20%的可能原因。</p>
</li>
<li><p>有一个正式的数学原理能够说明这一现象（一个80&#x2F;20的分布大概符合幂律分布，这种分布在现实世界进行测量时会经常遇到），并可以来创造性地提醒大家，在许多情况中，一个结果成因中的诸因素并不是地位平等的。</p>
</li>
<li><p>再进一步，假设这一法则对我们生命中的重要目标也是成立的。</p>
</li>
<li><p>如果公司80%的利润来自20%的顾客，那么公司可以通过从带来低利润的顾客身上节省更多的精力，用于更好地服务少数带来高利润的顾客——花在后者身上每一小时的产出都高于花在前者身上的。这个道理也适用于你的职业和私人生活。把花在低影响力活动上的时间（比如在脸谱网上找老朋友）转投到高影响力的活动上（比如和一位好朋友共进午餐），这样你就能取得目标的更大成功。因此，放弃使用一款网络工具的逻辑是放弃它所能带来的小益处，转而致力于你已经知道的可能带来更大益处的活动。</p>
</li>
</ul>
<h3 id="戒掉社交媒体"><a href="#戒掉社交媒体" class="headerlink" title="戒掉社交媒体"></a>戒掉社交媒体</h3><ul>
<li>我认为社交媒体大行其道的一个原因，就是它打破了努力创作有实际价值的作品和吸引到人们注意力之间的正相关关系。相反的，它用浅薄的集体主义式交换取代了永恒的资本主义交换：如果你注意我说了什么，我就会注意你说了什么，不管这话语有无价值。</li>
</ul>
<h3 id="不要用网络来消遣"><a href="#不要用网络来消遣" class="headerlink" title="不要用网络来消遣"></a>不要用网络来消遣</h3><ul>
<li><p>一旦你阅读了其中某一网站的一篇文章，页面旁边或底部的链接会吸引你接着点击，持续点击。人类心理学中任何一个可使用的把戏都用于其中，从把标题列为“流行”或“趋势”到使用醒目的图片，目的就是吸引住你。比如，就在此时此刻，BuzzFeed上最受欢迎的文章包括：“17个倒过来拼写就会意思完全不同的单词”和“33只赢得一切的狗”。一周的工作结束时，如果你有些空闲时间，这些文章就成为你主要的娱乐，在这种情况下，这些网站尤其有害。当你在排队，或者等待电视节目中的情节有所进展，或者是等待吃饭的时候，这些文章可以成为你打发时间的工具。</p>
</li>
<li><p>然而，如我在准则2中所说，这些行为是有害的，因为它们损害你抵抗分心事物的能力，使你在试图深度工作的时候更难集中注意力。更可怕的是，这些网络工具不需要你登录，因此在生活中更难戒掉（这使得之前的两个策略失效）。它们总是触手可得，只需要随手点几下。幸运的是，阿诺德·本内特在一百多年前就发现了解决之道：在你的娱乐时间做更多的思考。换言之，这个策略就是指在个人娱乐的时候，不要被任一随意的事物吸引，相反应该主动思考我如何度过“一天中的一天”。我们之前提到的这些致瘾性网站在真空中才能活跃：如果你没有在某一个特定时段给自己安排任务，这些网站总是一种有诱惑力的选择。如果你在自由时间有高质量的事情去做，这些网站对你的注意力的控制就会减弱。</p>
</li>
<li><p>因此，在晚上或周末到来之前就确定要做的事情是十分重要的。一些安排好的爱好为这些时间提供了充足的养料。为了特定的目标完成特定的活动，这将填满你的时间。根据本内特所言，每个晚上都有序地阅读自己挑选好的一系列书，也是一个很好的选择。同样的活动还有锻炼，与益友（面对面）交往。</p>
</li>
<li><p>消遣做得这么有条理会有损消遣的目的，因为许多人相信消遣就是要没有任何计划，没有责任。安排得一板一眼的晚上是否会让你在第二天工作的时候感到困乏，无法焕然一新？感谢本内特，他已经预料到了这样的担忧。他解释称，此等担忧源自对真正令人类恢复精力的事物的误解： 什么？你认为在那16个小时投入全部的精力会削弱工作8小时的价值？不是的。恰恰相反，它必定会增加工作8小时的价值。人们都要懂得一个重要的道理，人的智力系统可以进行长时间的高强度活动：它不像人的手脚一样会疲倦。除睡觉以外，它只需要变化，而不是停止。</p>
</li>
<li><p>按照我的经验，这个分析完全正确。如果在你全部的清醒时间，都能给自己的大脑找到有意义的事情去做，而不是放任自己在迷糊的状态下漫无目的地浏览几个小时网页，那么在一天结束时，你会觉得更加充实，第二天开始时更加轻松。总结一下，如果你想抵御娱乐网站对你时间和精力的诱惑，那么就给大脑找一些高质量的替代活动。这样不仅可以使我们避免分心，保持专注的能力，同时还有可能实现本内特的宏伟目标：体验到何为生活，而不仅仅是生存。</p>
</li>
</ul>
<h3 id="准则4-摒弃浮浅"><a href="#准则4-摒弃浮浅" class="headerlink" title="准则4 摒弃浮浅"></a>准则4 摒弃浮浅</h3><ul>
<li><p>2007年夏天，软件公司37signals（现在叫basecamp）做了一个实验：将每周5天工作制缩短成4天。尽管工作日少了一天，但是员工似乎还可以完成相同的工作量，于是他们的这项改革变成了永久政策：每年5～10月，37signals的员工只需从周一工作到周四（售后服务除外，他们一周7天都要工作）。公司发起人之一贾森·弗里德（Jason Fried）在博文里风趣地说道：“在夏季，人们应该享受美好的天气。”</p>
</li>
<li><p>4天完成40小时的工作对于员工来说是十分有压力的。但是他解释道，这不是他所建议的工作方式。“一周4天工作制的意义在于做更少的工作。”他写道，“不是一天10小时的工作……是正常的一天8小时。</p>
</li>
<li><p>很少有人能做到一天工作8个小时。在充斥着各种会议、干扰、网页浏览、办公室政治和私人事务的一个普通工作日里，能够专心工作几个小时就已经很幸运了。更少的正式工作时间有助于挤压出更高的效率。如果每个人都只有更少的时间完成任务，他们就会更加尊重时间。人会变得珍惜时间，而这是一件很好的事情。他们不会把时间花在无关紧要的事情上。如果拥有的时间变少，你就会更聪明地利用时间。</p>
</li>
<li><p>换句话说，37signals工作时间的减少主要是集中在浮浅工作而不是深度工作。因为深度工作几乎没有减少，所以重要的事情仍能完成。结果证明那些原来看似十分紧急的浮浅工作其实是无关紧要的。</p>
</li>
<li><p>虽然深度工作的价值远远超过了浮浅工作，但这并不意味着你必须像堂吉诃德一样试图把你所有的时间都投入到深度工作中。其中一个方面是，一定量的浮浅工作在大多数知识工作中是必要的。你应该可以避免每10分钟检查一次自己的电子邮件，但是不可能永远不回复重要的信息。从这个意义讲，我们应该明白该准则的目标是减少浮浅工作在我们日程中的分量，而不是将其消除。</p>
</li>
<li><p>在给定的一天时间内，一个人可以保持多长时间的深度工作。</p>
</li>
<li><p>一天一小时是一个合理的上限。对于熟悉此类活动严酷性的人来说，上限可以达到4个小时，但是很少能持续更久。</p>
</li>
<li><p>这意味着一旦你在一天中达到了深度工作的上限后，继续试图增加深度工作效果就会下降。因此，浮浅工作并不可怕，只有其比例增加太多影响到你当天的深度工作上限时才需要注意。乍一看，这个警示或许没有那么可怕。通常一个工作日8个小时。这8小时内，没有一个熟练的深度工作者可以保持超过4个小时的深度状态。这样的结果就是一天中你可以有半天做浮浅工作，而且不会有害处。可是你可能没有意识到这些时间其实很容易被占用，尤其要考虑那些会议、预约、电话和其他计划内事务。在很多工作中，这些时间终结者将导致你每天只有很少的时间可以单独工作。</p>
</li>
<li><p>总而言之，希望你能用怀疑的眼光对待浮浅工作，因为其害处经常被低估，而作用却经常被高估。这种工作不可避免，但是你必须对其加以限制，使其不影响你充分深度工作的能力，因为深度工作决定着你的最终工作成效。接下来的策略将助力你的实践活动。</p>
</li>
</ul>
<h3 id="一天的每一分钟都要做好计划"><a href="#一天的每一分钟都要做好计划" class="headerlink" title="一天的每一分钟都要做好计划"></a>一天的每一分钟都要做好计划</h3><ul>
<li><p>我们一天中的大多数时间是在浑浑噩噩中度过的，对于应该如何安排时间并没有考虑太多。这是一个问题。如果不果敢地调整深度工作与浮浅工作的关系，不在行动前暂停一下问问自己“现在去做什么是最有意义的”，你将很难避免被烦琐杂事占满日程。接下来的几个段落将会介绍一些促使你这样做的策略。这些观点乍一看显得极端，但是很快你就会发现要充分享用深度工作的好处，就需要一天中的每一分钟都要做好计划。</p>
</li>
<li><p>我建议：为本策略专门准备一个笔记本，在每个工作日开始的时候翻开新的一页。在页面的左侧，每隔一行写下这一天的每一个小时，包括普通工作日的全部时间。接下来是最重要的一个环节：将工作日的每一天划成方格，把活动放在这些空格中。</p>
</li>
<li><p>完成一天的工作计划之后，每一分钟都应该在某个方格里有所体现。实际上，你已经为这一天的每一分钟安排了时间。此时，请你使用这个工作计划来引导一天的工作。可以预见的是，大部分人从这一步开始就遇到了麻烦。随着一天工作的展开，关于该工作计划，有两个方面容易（并且也极为可能）出岔子。第一，你的计划可能不符合实际。例如你为写新闻通讯稿预留了两小时，但是实际上你花掉了两个半小时。第二，你可能会被打断，新的工作任务会出现到你的日程里。这些事情也会打乱你的日程。这些都没有问题。如果你的日程被打断，在紧接下来的空闲时间，就应该花几分钟修改一天余下时间的计划。你可以翻到新的一页，也可以擦掉原有的重新编写，还可以像我一样：划掉原有的方格，在其右方为今天剩余的时间画出新的方格（我画的格子很瘦，所以有足够的空间修改几次）。有些日子里，你可能一天要修改十多次计划。如果出现了这种情况，不要气馁。你的目标并不是竭尽全力维持既定的计划，而是在时间的推进中掌握工作的主动权，即使是在一天中，我们的决定也会一变再变。如果你觉得计划改变的频率高得难以接受，这里有一些可以增加稳定性的诀窍。首先，你应该承认，你对大多数事情所需要的时间是预备不足的。刚开始尝试这个习惯时，很可能会一厢情愿地制定计划——完美一天的样板。经过一段时间的练习，你应该尝试准确地（甚至有些保守地）预估完成任务所需要的时间。</p>
</li>
<li><p>第二个诀窍就是使用备用方格。如果你不确定一个既定任务需要多长时间，先初步预估需要的时间，然后在下面再多安排一个方格，这个方格可以有多重作用。如果这个既定任务需要更多时间才能完成，那么就占用下边这个备用方格。但是如果你在预定的时间内完成了任务，那么就把备用的方格安排做其他的活动（比如说一些非紧急事务）。这样就可以保证在不改变日程的情况下，容许不可预知的事情发生。</p>
</li>
<li><p>在我的日常安排原则里，除了经常会为探索性思考和探讨预留大块的时间格之外，还时刻保持着一项准则，即一旦有灵光乍现，有了突破性的洞见，一天的其他日程安排就都可以暂时抛到一边（当然，实在抛不到一边的也没有办法）。之后我会坚持探究这种新的洞见，直到理清其中的头绪。这之后我会抽身出来，重新安排一天余下的时间。换言之，我不仅允许日程中有突发性改变，甚至会主动寻求这种改变。约瑟夫的批评是源于他对日程表的误解，他认为日程表就是强迫一个人严格按计划行事。然而我所说的日程计划的核心目的不是限制，而是强调谋划周到。在一天里时常拿出一点时间来询问自己“在今天剩下的时间里，我做什么最有道理”，是一个很简单的习惯。这是一个让你思考如何产出最大化的习惯，而不是让你对自己的答案保持不折不挠的忠贞。我甚至要说，一个同时具有综合计划能力和修正自己计划的意愿的人，相比那些采用传统“自发性”方法、一天没有任何计划的人，将享有更多的创造性洞见。没有计划，你的时间很可能被浮浅事务占用——电子邮件、社交媒体、浏览网页。这些浮浅事务虽然在短时间内会令人愉悦，但是并不有助于培养创造力。借助计划，你可以确保经常性的安排时间来处理新主意，或者在有挑战性的领域进行深度工作，或者在一个固定时间内进行头脑风暴——这些活动更容易带来创新（例如回想一下在准则1中，很多著名的创意思考者所遵循的一些习惯）。因为当创新性想法出现时，你也愿意放弃原本的日程安排，所以在灵感涌现的时候，你也可以像那些纷扰中搞创新的人一样跟进。</p>
</li>
<li><p>总而言之，该策略的目的在于帮助你认识到，深度工作要求你尊重自己的时间。要做到真正尊重时间，下面这一条建议是个很不错的开端：提前决定你一天的每一分钟要做什么工作。因为一个人的日程都是由内在驱动和外在要求这两股力量决定的，所以开始的时候你对这个主意有所抵触也是自然的。但是如果你想发掘自己的潜力，成为一个有所成就的人，那就必须打破这种疑虑。</p>
</li>
</ul>
<h3 id="定量分析每一项活动的深度"><a href="#定量分析每一项活动的深度" class="headerlink" title="定量分析每一项活动的深度"></a>定量分析每一项活动的深度</h3><ul>
<li><p>浮浅工作：对认知要求不高的事务性任务，通常在受到干扰的情况下开展。此类工作通常不会为世界创造太多新价值，且容易复制。</p>
</li>
<li><p>为你提供一个明确而且稳定的计量表，以衡量一项给定任务的深浅度。如使用这个策略，你需要先问自己一个简单（但是很有启发性的）问题来评估这些任务： 要让一个刚毕业还没有在该领域接受特别训练的大学生完成这项工作需要多久（几个月）？</p>
</li>
</ul>
<h3 id="向老板申请浮浅工作预算"><a href="#向老板申请浮浅工作预算" class="headerlink" title="向老板申请浮浅工作预算"></a>向老板申请浮浅工作预算</h3><ul>
<li><p>有一个很重要的问题很少被问及：你的时间应该有几成被投入到浮浅工作中？这个策略建议你问一下这个问题。也就是说，如果你有老板的话，应该和他谈谈这个问题（或许你应该先向他们介绍“深度工作”和“浮浅工作”的定义）。如果你是自己当老板，问自己这个问题。两种情况下，都力争得到一个答案。然后——这是重要的一环，试着控制在这个预算范围内。</p>
</li>
<li><p>你可以自信地对老板说：“这正是我上周在浮浅工作上的时间占比，”然后迫使他或她明确同意你给出的比例。在数据及其阐释的经济现实面前（比如说，让一位受过高等训练的专业人士回复电子邮件、一周参加30个小时的会议，是不可思议的浪费），老板自然会得出这样的结论：你需要拒绝一些事情，简化一些事情，即使这会使得你老板或同事的生活舒适度降低。因为一项生意的最终目的还是产出价值，而不是确保员工的生活尽可能简单。如果你自己做老板，这项练习将使你正视现实：你“繁忙”的日程中只有很少一部分时间是真正产出价值的。这些残酷的数据将激发你的信心，减少那些偷走时间的浮浅活动。没有这些数据，一位企业家将很难拒绝任何可能产生某种积极回报的机会。</p>
</li>
<li><p>“我要上推特！”“我要保持在脸谱网上的活跃度！”“我得优化博客上的小工具栏！”因为独处的时候，拒绝这些活动可能会显得你很懒。通过学习并坚持这种深浅度的分配比例，你可以摆脱因羞耻感而带来的无条件接受，转而坚持更健康的习惯，把本来留给浮浅工作的时间节省下来以发挥其最大效用（这样你仍然面临很多机遇），把浮浅工作占用的时间和精力限制得足够小，从保证你的深度工作推动事业进步。</p>
</li>
<li><p>一份不需要深度工作的工作不可能使你在当前的知识经济时代取得成功。在这种情况下，你应该感谢老板的反馈，然后迅速谋划如何转型到一个重视深度的新岗位。</p>
</li>
</ul>
<h3 id="5点半之前结束工作"><a href="#5点半之前结束工作" class="headerlink" title="5点半之前结束工作"></a>5点半之前结束工作</h3><ul>
<li><p>5点半之前结束工作在我写这段话前的连续7天，我进行了65个不同的电子邮件对话。在这65组对话中，我在5点半后只发送了5封电子邮件。上例中的这些数据直接说明了一个事实：除极个别例外，我不在5点半后发电子邮件。总体来说，电子邮件和我们的工作是紧密相连的，所以这个事例告诉我们一个更令人吃惊的现实：我不在5点半后工作。</p>
</li>
<li><p>我把这种坚持叫作固定日程生产力。因为我确定了一个坚定的目标，在某个固定时间后不再工作，然后在工作中寻找提高产出的策略以达成目标。</p>
</li>
<li><p>减少浮浅工作为实现深度工作节省了更多的精力，使我们的产出比采用密集日程安排时更高。其二，我们的时间有限，因而会更谨慎地思考个人的组织习惯，这也使得我们产出的价值能够高于采用长时间但混乱的日程安排的人。</p>
</li>
</ul>
<h3 id="变得不容易联系到"><a href="#变得不容易联系到" class="headerlink" title="变得不容易联系到"></a>变得不容易联系到</h3><ul>
<li>森特诺认为用私人一对一的对话来一遍又一遍地回答相同的问题是十分不经济的。如果你过了这一步，他会让你点击几个复选框来做出以下三种承诺：√我不是在问安东尼奥一个使用谷歌搜索10分钟就可以得到答案的问题。√我不是复制粘贴了常见请求给安东尼奥发垃圾邮件，以推销我个人的不相关生意的。√如果安东尼奥在23个小时内答复我，我将为某位陌生人做一件善事。当你点击同意了所有三个承诺之后，联系页面才会出现一个信息框供你输入信息。</li>
</ul>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><ul>
<li>深度的生活并不是适合所有人。你需要为此付出艰苦的努力，从根本上改变你的习惯。对于很多人来说，快速地收发电子邮件和在社交媒体上发消息所带来的繁忙假象会给他们带来慰藉，深度的生活却是要你摆脱这些东西。在你尽个人全力去创造一件美好的事物时，会有一种不安牵扰着你，因为这迫使你面对自己最好的成果（暂且）还没有那么好的可能。与涉足政坛，期望做出一番事业相比，夸夸其谈地品论我们的文化会显得更安全。</li>
</ul>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>如果你无法学习，就无法成功</li>
<li>无干扰状态下保持专注</li>
<li>高质量工作产出&#x3D;时间×专注度</li>
<li>转移工作、注意力残留 -&gt; 专注、深度工作</li>
<li>深度工作并非是我们的经济中唯一有价值的技能，不培养这种能力也有可能做得很好，但是不需要深度工作的职业会越来越少。</li>
<li>最小阻力原则</li>
<li>忙碌代表生产能力（Busyness as Proxy for Productivity）：在工作中，对于生产能力和价值没有明确的指标时，很多知识工作者都会采用工业时代关于生产能力的指标，以可视的方式完成很多事情。</li>
<li>支持深度工作往往要抵制新的高科技</li>
<li>当工作中没有明确目标时，围绕浮浅工作的表面忙碌会成为一种本能</li>
<li>工作其实比休闲时光更容易带来享受？</li>
<li>意志力是有限的</li>
<li>培养深度工作的习惯，关键在于越过良好的意图，在工作生活中加入一些特别设计的惯例和固定程序，使得进入并保持高度专注状态消耗的意志力最小化。！！！！！</li>
<li>选定你的深度哲学（节奏哲学）、并习惯化</li>
<li>恰当展开协作可以提升你在职业生活中深度工作的质量</li>
<li>这种隔音办公室与宽阔公共空间的组合，形成了中心辐射型的创新建筑结构，在这里偶遇的意外发现和与世隔绝的深度思考都能实现。</li>
<li>专注于少量“极端重要的目标”</li>
<li>引领性指标</li>
<li>专注于极度重要目标上的深度工作状态时间</li>
<li>4DX框架下的4种原则 ！！！</li>
<li>在整个4DX的实验过程中，目标的明晰性，辅以引领性指标计分板提供的简单但却难以回避的反馈，促使我达到了此前从未实现的深度状态。</li>
<li>定期放松大脑！！工作日结束的时候，在第二天早晨到来之前，屏蔽掉对工作问题的担忧。</li>
<li>定期休息大脑可以提升深度工作的质量。工作时，努力工作。完成时，就放松下来。</li>
<li>不要不断分心，而要不断专注</li>
<li>设定一个几乎不可能的时间期限；深度工作需要专注的强度远远超出了大部分知识工作者的舒适区。</li>
<li>有成果的冥想</li>
<li>远离社交媒体</li>
<li>在晚上或周末到来之前就确定要做的事情是十分重要的。（避免陷入其他无效的诱惑）</li>
<li>人的智力系统可以进行长时间的高强度活动：它不像人的手脚一样会疲倦。除睡觉以外，它只需要变化，而不是停止。！！！</li>
<li>如果你想抵御娱乐网站对你时间和精力的诱惑，那么就给大脑找一些高质量的替代活动。这样不仅可以使我们避免分心，保持专注的能力，同时还有可能实现本内特的宏伟目标：体验到何为生活，而不仅仅是生存。</li>
<li>减少浮浅工作在我们日程中的分量，而不是将其消除</li>
<li>一天的每一分钟都要做好计划（笔记本）</li>
<li>深度工作要求你尊重自己的时间。要做到真正尊重时间，下面这一条建议是个很不错的开端：提前决定你一天的每一分钟要做什么工作。</li>
<li>5点半之前结束工作。固定日程生产力。</li>
<li>变得不容易联系到；文档化</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>借《黑客与画家》记录一下想法</title>
    <url>/2023/01/14/20230114-jie-hei-ke-yu-hua-jia-ji-lu-yi-xia-xiang-fa/</url>
    <content><![CDATA[<p><img src="/2023/01/14/20230114-jie-hei-ke-yu-hua-jia-ji-lu-yi-xia-xiang-fa/messi2.jpg"></p>
<p>借本书记录自己的想法(从前混乱的头脑，没能及时总结)，阅读这本书有种相逢恨晚的感觉，有相似或者认同的想法.</p>
<blockquote>
<blockquote>
<p>“黑客精神”是这本书的核心理念所在。“黑客”本身具有各种各样的描述和象征意义。在不同场景下，人们对“黑客”的定义也不一样。在保罗的观念里，以及在YC和奇绩创坛的实践观察中，我们发现，黑客精神的真谛是动手去创造性地解决问题。“解决问题”必须跟人的需求有关，需要持久地满足越来越多人的需求。“动手”需要有勇气，很务实，以行动为导向，除此以外，黑客还必须是一个积极向上的人。“创造性”则意味着不受束缚、敢于探索。此外，黑客精神还意味着独立思考，坚持说真话。“动手去创造性地解决问题”代表了创造者一系列的核心行为和思想状态。这句话虽然听上去很简单，但它具有深刻含义，且完全反映了创造者的核心要素。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>在本书中，“黑客”就是指最优秀的程序员，而不是入侵计算机系统的人。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>作者想让公众了解，黑客并不神秘，更不是技术怪人。《黑客与画家》这个书名就是在提示应该把黑客与画家当作同一种人看待。和画家一样，黑客只是怀有一门特殊手艺、有创造天赋的普通人。这个书名还有另一层含义，即编程是一种艺术创作，黑客就是艺术家，开发软件与画家作画、雕塑家雕刻、建筑师设计房屋并没有本质不同。</p>
</blockquote>
</blockquote>
<ul>
<li>写通用的基础sdk就是一种艺术创作，封装，易用，优雅，安全，高效</li>
</ul>
<h2 id="第一部分-黑客如何成长及看待世界"><a href="#第一部分-黑客如何成长及看待世界" class="headerlink" title="第一部分 黑客如何成长及看待世界"></a>第一部分 黑客如何成长及看待世界</h2><h3 id="1为什么书呆子不受欢迎"><a href="#1为什么书呆子不受欢迎" class="headerlink" title="1为什么书呆子不受欢迎"></a>1为什么书呆子不受欢迎</h3><blockquote>
<blockquote>
<p>为什么黑客那么在乎言论自由？我认为，部分原因在于，革新对于软件行业实在是太重要了，而革新和异端实际上是同一件事。优秀的黑客养成了一种质疑一切的习惯。</p>
</blockquote>
</blockquote>
<ul>
<li>我很喜欢质疑, 有些理论上成立的东西, 如果直觉不认可, 我喜欢亲自去验证它。</li>
</ul>
<blockquote>
<blockquote>
<p>我认为，这就是问题的根源。“书呆子”的目标具有两重性。他们毫无疑问想让自己受欢迎，但是他们更愿意让自己聪明。</p>
</blockquote>
</blockquote>
<ul>
<li>很多事情并是只有0或1, 不是你不想要, 只是事情总有优先级</li>
<li>来自微信读书评论: 想和去做是两码事，没人不希望自己受欢迎，但聪明人有更重要的事要做。不在乎名利不见的有多聪明。</li>
<li>来自微信读书评论: 没有人喜欢孤独，怎么样才会受欢迎很多人都知道，只不过不想去做罢了。</li>
</ul>
<blockquote>
<blockquote>
<p>举例来说，大多数人似乎认为，绘画能力与生俱来，画家就像高个子一样，是天生的。事实上，大多数“会画”的人，本身就很喜欢画画，将许多时间投入其中，这就是他们擅长画画的原因。同样，受欢迎也不是天生的，而是需要你自己争取来的。</p>
</blockquote>
</blockquote>
<ul>
<li>之前投入的大量时间, 才让现在似乎得心应手。</li>
</ul>
<blockquote>
<blockquote>
<p>一般来说，成年人就不会去欺负书呆子。为什么小孩子会这样做呢？一个原因是，青少年在心理上还没有摆脱儿童状态，许多人会残忍地对待他人。他们折磨书呆子的原因就像拔掉一条蜘蛛腿一样，觉得很好玩。在一个人产生良知之前，折磨就是一种娱乐。</p>
</blockquote>
</blockquote>
<ul>
<li>确实,很多人小时候都这样,特别是男孩子,后天正确的引导很重要。</li>
</ul>
<blockquote>
<blockquote>
<p>没有什么比一个共同的敌人更能使得人们团结起来了。</p>
</blockquote>
</blockquote>
<ul>
<li>这提醒我有时要看清问题的本质以及别人的真正目的,避免被误导,毕竟希望自己是个聪明的人。</li>
</ul>
<blockquote>
<blockquote>
<p>如果我没记错的话，最受欢迎的孩子并不欺负书呆子，他们不需要靠踩在书呆子身上来垫高自己。大部分的欺负来自处于下一等级的学生，那些焦虑的中间层。</p>
</blockquote>
</blockquote>
<ul>
<li>确实, 人类社交属性的同时, 也会产生对比和嫉妒, 时刻提醒自己不做这种无意义的事</li>
</ul>
<blockquote>
<blockquote>
<p>没错，成年人不知道孩子们内部发生的事。认识到这一点很重要。在抽象意义上，成年人知道孩子的行为有时是极端残酷的，这正如我们在抽象意义上知道贫穷国家的人们生活极端艰难。但是，像所有人一样，成年人不喜欢揪住这种令人不快的事实不放。你不去埋头探寻，就不会发现具体的证据，就会永远以为这件事是抽象的。</p>
</blockquote>
</blockquote>
<ul>
<li>很多成年人都忘记自己小孩子时所经历的感觉, 表现出很不理解小孩子的行为, 并粗暴的归结为叛逆, 其实他们根本不想去了解和回忆, 觉得这浪费他们的精力, 毕竟他们还有很多“正经事”</li>
</ul>
<blockquote>
<blockquote>
<p>总体上看，我就读的学校与上面说的监狱差不多。校方最重视的事情，就是让学生待在自己应该待的位置。与此同时，让学生有东西吃，避免公然的暴力行为，接下来才是尝试教给学生一些东西。除此以外，校方并不愿意在学生身上多费心思。就像监狱的狱卒，老师们很大程度上对学生是放任自流的。结果，学生就像犯人一样，发展出了野蛮的内部文化。</p>
</blockquote>
</blockquote>
<ul>
<li>将心比心, 很多人都这样, 无可厚非, 毕竟大部分人工作仅仅为了维持生活的收入, 多一事不如少一事, 当然还是有很多伟大负责任的老师</li>
</ul>
<blockquote>
<blockquote>
<p>当你所做的事情能产生真实的效果，那就不仅仅是好玩而已了，发现正确的答案就开始变得重要了，这正是书呆子的优势所在。你马上就能联想到比尔·盖茨。他不善于社交是出了名的，但是他发现了正确的答案，至少从收入上看是如此。</p>
</blockquote>
</blockquote>
<ul>
<li>当你有影响力的时候, 别人才会高看你, 很现实但很真实</li>
</ul>
<blockquote>
<blockquote>
<p>至于学校，不过是这个虚假环境中关住“牲口”的围栏。表面上，学校的使命是教育儿童。事实上，学校的真正目的是把儿童都关在同一个地方，以便大人白天可以腾出手来把事情做完。我对这一点没有意见，在一个高度工业化的社会，对孩子不加管束，让他们四处乱跑，无疑是一场灾难。</p>
</blockquote>
</blockquote>
<ul>
<li>工作的束缚, 时常在想这是什么阴谋和圈套, 我们真的需要每天工作这么长的时间? 或者我们真的需要这样被限制性的工作? 太多的疑问了.</li>
</ul>
<blockquote>
<blockquote>
<p>这种看法无所不在，甚至孩子们自己都相信了，但是相信这种话可能一点帮助也没有。你告诉一个人，他的脚天生就是坏的，并不能阻止他去怀疑他可能穿错了鞋子。</p>
</blockquote>
</blockquote>
<ul>
<li>时刻记住, 逻辑的严谨: 充分必要条件, 控制变量法</li>
</ul>
<blockquote>
<blockquote>
<p>还有别的问题存在，甚至可能是更糟糕的问题。那就是我们没有得到真正的工作，没能发挥我们的才能。人类喜欢工作，在世界上大多数地方，你的工作就是你的身份证明。但是，我们那时做的所有事情根本就是无意义的，至少那时看来是这样。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>而且，没有办法回避那些事情。成年人已经达成共识，认定通往大学的途径就是这样的。逃离这种空虚生活的唯一方法，就是向它屈服。</p>
</blockquote>
</blockquote>
<ul>
<li>读大学前学的很多知识, 很大概率是你下大半辈子没用的, 学习它仅仅是因为通向大学的筛选机制</li>
</ul>
<blockquote>
<blockquote>
<p>我们有一个专门的短语描述这种情况，即对于在没有任何严肃标准的前提下产生排名的情况，我们会说情况“倒退至人缘比赛”（degenerate into a popularity contest）。</p>
</blockquote>
</blockquote>
<ul>
<li>微信投票、升级加薪、绩效等</li>
</ul>
<blockquote>
<blockquote>
<p>没有外在的对手，孩子们就互相把对方当作对手</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果存在针对真正能力的外部测试，待在等级关系的底层也不会那么痛苦。球队的新人并不会怨恨老队员的球技，他希望有一天自己也能球技高超，所以很高兴有机会向老队员求教。老队员可能也会因此产生一种传帮带的光荣感（noblesse oblige）。最重要的是，老队员的地位是通过他们本身出色的能力获得的，而不是通过排挤他人获得的。</p>
</blockquote>
</blockquote>
<ul>
<li>共同的敌人? 共同的目标?</li>
</ul>
<blockquote>
<blockquote>
<p>我误解最深的一个词是“老成”（tact）。成年人使用这个词，含义似乎就是“闭上嘴巴，不要说话”。我以为它与“缄默”（tacit）和“不苟言笑”（taciturn）有着相同的词根，字面意思就是“安静”。我对自己发誓，我绝不要变成“老成”的人，没有人能够让我闭上嘴巴。可是事实上，这个词的词根与“触觉”（tactile）相同，它真正的意思是“熟练”。“老成”的反义词是“笨拙”（clumsy）。进入大学以后，我才搞明白了这个词。</p>
</blockquote>
</blockquote>
<ul>
<li>叛逆、愤青? 很多人根本不知道怎么解释, 抑或是自己被洗脑了, 懦弱, 只会站在道德制高点给你贴标签. 而我可能注定“叛逆”到死</li>
<li>来自微信读书评论: 许多人的所谓成熟，不过是被习俗磨去了棱角，变得世故而实际了。那不是成熟，而是精神的早衰和个性的夭亡。真正的成熟，应当是独特个性的形成，真实自我的发现，精神上的结果和丰收。  ——尼采</li>
</ul>
<blockquote>
<blockquote>
<p>校园生活的真正问题是空虚。除非成年人意识到这一点，否则无法解决这个问题。可能意识到这个问题的成年人，是那些读书时就是书呆子的人。</p>
</blockquote>
</blockquote>
<ul>
<li>作为一个“坏孩子”, 有时我很理解别人所认为的“坏孩子”的感受</li>
</ul>
<h3 id="2黑客与画家"><a href="#2黑客与画家" class="headerlink" title="2黑客与画家"></a>2黑客与画家</h3><blockquote>
<blockquote>
<p>黑客与画家的共同之处，在于他们都是创作者。与作曲家、建筑师和作家一样，黑客和画家都试图创作出优秀的作品。他们本质上都不是在做研究，虽然在创作过程中，他们可能会发现一些新技术（那样当然更好）</p>
</blockquote>
</blockquote>
<ul>
<li>有时候, 写代码, 特别是对一些通用逻辑进行抽象的时候, 确实有种愉悦感, 甚至完成之后还会反复的欣赏自认为是优雅的设计</li>
</ul>
<blockquote>
<blockquote>
<p>我一直不喜欢“计算机科学”这个词，主要原因是根本不存在这种东西。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>计算机科学就像一个大杂烩，由于某些历史意外，很多不相干的领域被强行拼装在一起。这个学科的一端是纯粹的数学家，他们自称“计算机科学家”，只是为了得到国防部研究局（DARPA）的项目资助。中间部分是计算机博物学家，研究各种专业性的题目，比如网络数据的路由算法。另一端则是黑客，只想写出有趣的软件，对于他们来说，计算机只是一种表达的媒介，就像建筑师手里的混凝土，或者画家手里的颜料。所以，在“计算机科学”的名下，数学家、物理学家和建筑师都不得不待在同一个系里。</p>
</blockquote>
</blockquote>
<ul>
<li>很多技术的实现就是那样, 但有些人总能包装成高大上的东西, 特别是在大公司. 我并不是批判这种行为, 相反我实际上有点羡慕这种能力.</li>
</ul>
<blockquote>
<blockquote>
<p>黑客搞懂“计算理论”（theory of computation）的必要性，与画家搞懂颜料化学成分的必要性差不多大。一般来说，在理论上，你需要知道如何计算“时间复杂度”和“空间复杂度”（time and space complexity）；如果你要写一个解析器，可能还需要知道状态机（state machine）的概念；除此以外，并不需要知道特别多的理论。这些可比画家必须记住的颜料成分少很多。我发现，黑客新想法的最佳来源，并非那些名字里有“计算机”三个字的理论领域，而是其他创作领域。与其到“计算理论”领域寻找创意，你还不如在绘画中寻找创意。</p>
</blockquote>
</blockquote>
<ul>
<li>就像现在IT行业盛行的八股文一样, 简直走火入魔. 我并不认为理论和原理并不重要, 但是跟清楚“颜料成分是多少”一样, 你很厉害, 但实际上大部分情况下对工作用处不大. 世界上的知识太多了, 这些细节没有人的全部掌握. 而知识的广度, 快速学习和搜索知识的能力, 对于程序员来说才是更重要的. 当然我能理解, 考核人员的无能以及巨大的岗位竞争, 产生了如今的现状.</li>
</ul>
<blockquote>
<blockquote>
<p>如果黑客认识到自己与其他创作者——比如作家和画家——是一类人，这种诱惑对他就不起作用。作家和画家没有“对数学家的妒忌”，他们认为自己在从事与数学完全不相关的事情。我认为，黑客也是如此。如果大学和实验室不允许黑客做他们想做的事情，那么适合黑客的地方可能就是企业。不幸的是，大多数企业也不允许黑客做他们想做的事情。大学和实验室强迫黑客成为科学家，企业强迫黑客成为工程师。</p>
</blockquote>
</blockquote>
<ul>
<li>确实, 想任性的做自己的事, 可能是创业吧, 但是需求是什么?</li>
</ul>
<blockquote>
<blockquote>
<p>直到最近我才发现这一点。雅虎收购Viaweb的时候，他们问我想做什么。我对商业活动从来都没有太大兴趣，就回答说我想继续做黑客。等我来到雅虎以后，发现在他们看来，“黑客”的工作就是用软件实现某个功能，而不是设计软件。在那里，程序员被当作技工，职责就是将产品经理的“构想”（如果这个词是这么用的话）翻译成代码。这似乎是大公司的普遍情况。大公司这样安排的原因是降低结果的标准差。因为实际上只有很少一部分黑客懂得如何正确设计软件，公司的管理层很难正确识别到底应该把设计软件的任务交给谁，所以，大部分公司不把设计软件的职责交给一个优秀的黑客，而是交给一个委员会，黑客的作用仅仅是实现那个委员会的设计。</p>
</blockquote>
</blockquote>
<ol>
<li>很奇怪的现象, 很多大公司很喜欢全部员工一起开总结大会, 然后说员工需要提出自己的产品想法之类的. 实际上, 平常的工作中, 产品说了算, 甚至都不会听程序员的意见, 直接扔出一句“这是老板的需求”, 所以我一直认为开这种大会, 其实就是形式主义. 甚至开会的内容和现实对比, 可笑至极, 讽刺至极. </li>
<li>这样的产品, 把自己当成传话筒, 工具人, 直接躺平混日子了. 他们的目标只是满足老板的需求, 而不是用户的需求. 他们的目标只是保住工作混工资. 可是仔细想想, 很多人包括我自己, 又到达哪种境界呢? 可能大家其实半斤八两吧. </li>
<li>公司的目的是降低风险. 有时交给委员会, 实际上也是对普通员工的一种“保护”</li>
</ol>
<blockquote>
<blockquote>
<p>所有创作者都面临这个问题。价格是由供给和需求共同决定的。好玩的软件的需求量，比不上解决客户麻烦问题的软件的需求量；在小剧场里演出的酬劳，比不上穿着卡通大猩猩服装、在展览会上为厂商站台的酬劳；写小说的回报比不上写广告文案的回报；开发编程语言的收入，比不上把某些公司老掉牙的数据库连上服务器的收入。黑客如何才能做自己喜欢的事情？我认为这个问题的解决方法是一个几乎所有创作者都知道的方法：找一份养家糊口的“白天工作”（day job）。这个词是从音乐家身上来的，他们晚上表演音乐，所以白天可以找一份其他工作。更一般地说，“白天工作”的意思是，你有一份为了赚钱的工作，还有一份为了爱好的工作。</p>
</blockquote>
</blockquote>
<ul>
<li>对于“晚上”工作, 其实我并没有找到明确的目标, 又或者自身太过于“急躁”了</li>
</ul>
<blockquote>
<blockquote>
<p>因为黑客更像创作者，而不是科学家，所以要了解黑客，不应该在科学家身上寻找启示，而是应该观察其他类型的创作者。那么，从画家身上，我们还能借鉴到什么对黑客的启示呢？有一件事情是可以借鉴的（至少可以确认），那就是应该如何学习编程。画家学习绘画的方法主要是动手去画，黑客学习编程的方法也理应如此。大多数黑客不是通过大学课程学会编程的，而是从实践中学习，有的13岁时就自己动手写程序了。即使上了大学，黑客学习编程依然主要通过自己写程序。</p>
</blockquote>
</blockquote>
<ul>
<li>确实, 需要先模仿, 再创新. 很多东西确实有共同的特点</li>
</ul>
<blockquote>
<blockquote>
<p>绘画还有一个值得借鉴的地方：一幅画是逐步完成的。通常一开始是一张草图，然后再逐步填入细节。但是，它又不单纯是一个填入细节的过程。有时，原先的构想看来是错的，你就必须动手修改。无数古代油画放在X光下检视，就能看出修改痕迹，四肢的位置被移动过，或者脸部的表情经过了调整。绘画的这个创作过程就值得学习。我认为黑客也应该这样工作。你不能盼望先有一个完美的规格设计，然后再动手编程，这样想是不现实的。如果你预先承认规格设计是不完美的，在编程的时候，就可以根据需要当场修改规格，最终会有一个更好的结果。</p>
</blockquote>
</blockquote>
<ol>
<li>软件的设计, 比如一些通用框架, 或者服务架构, 当然是最好一开始就想清楚, 并设计好(并不代表后续不能改动), 这样有助于后续细节的实现, 也有一个基本的大局观, 同时也可以提前发现存在的问题, 避免后续的无用功, 还有提前确认好项目风险等等. </li>
<li>这个问题其实我是潜意识知道的，但还是因为懒，感觉太累不想思考，选择做一下具体的细节先，但有时也算是一种适当的放松吧</li>
</ol>
<blockquote>
<blockquote>
<p>黑客就像画家，工作起来是有心理周期的。有时候，你有了一个令人兴奋的新项目，你会愿意为它一天工作16个小时。等过了这一阵，你又会觉得百无聊赖，对所有事情都提不起兴趣。为了做出优秀的工作，你必须把这种心理周期考虑在内。只有这样，你才能根据不同的事情找出不同的应对方法。你有一辆手动变速的汽车，你把它开上山，有时不得不松开离合器，防止汽车熄火。同样，暂时放手有时也能防止热情熄火。对于画家和黑客这样的创作者，有些工作需要投入巨大的热情，另一些工作则是不需要很操心的日常琐事。在你厌倦的时候再去做那些比较容易的工作，这是一个不错的主意。对于编程，这实际上意味着你可以把bug留到以后解决。消灭bug对我来说属于轻松的工作，只有在这个时候，编程才变得直接和机械，接近社会大众想象中的样子。消灭bug的过程就像解一道数学题，已知许许多多的约束条件，你只要根据条件对方程求解就可以了。你的程序应该能产生x 结果，却产生了y 结果。哪里出错了？你知道自己最后肯定能解决这个问题，所以做起来就很轻松，就好像刷墙一样，接近于休闲了。</p>
</blockquote>
</blockquote>
<ol>
<li>深有同感, 松弛有度, 这样才能更愉快和保持热情的工作</li>
<li>一味的逼迫自己把同一件事做好, 有时却会适得其反, 因为厌倦和抗拒, 虽然工作完成了,但是实际上完成质量和效率是存在疑问的. 或许你先做另一件事,在回来做这件事,整体的效率和质量是更高的.</li>
<li>以前看过一种说法, 有时觉得累了并不是需要休息, 而是你的大脑需要换其他的事情</li>
</ol>
<blockquote>
<blockquote>
<p>我认为，这也是多人共同开发一个软件的正确模式。需要合作，但是不要“合”得过头。如果一个代码块由三四个人共同开发，就没有人真正“拥有”这块代码。最终，它就会变得像一个公用杂物间，没人管理，又脏又乱，到处堆满了冗余代码。正确的合作方法是将项目分割成严格定义的模块，每一个模块由一个人明确负责。模块与模块之间的接口经过精心设计，如果可能的话，最好把文档说明写得像编程语言规范那样清晰。</p>
</blockquote>
</blockquote>
<ul>
<li>提前分工明确能避免无用功, 同时能尽量确保交付时间</li>
</ul>
<blockquote>
<blockquote>
<p>普通黑客与优秀黑客的所有区别之中，会不会“换位思考”可能是最重要的单个因素。有些黑客很聪明，但是完全以自我为中心，根本不会设身处地为用户考虑。这样的人很难设计出优秀软件，因为他们不从用户的角度看待问题。</p>
</blockquote>
</blockquote>
<ul>
<li>换位思考实在是太重要了, 很多事情都能以此为切入点, 找到解决方案或者事情的本质</li>
</ul>
<blockquote>
<blockquote>
<p>判断一个人是否具备“换位思考”的能力有一个好方法，那就是看他怎样向没有技术背景的人解释技术问题。我们大概都认识这样一些人，他们在其他方面非常聪明，但是把问题解释清楚的能力却低下得惊人。如果聚会上外行人问他们“什么是编程语言”，他们会这样回答：“哦，高级语言就是编译器的输入代码，用来产生目标码。”高级语言？编译器？目标码？……如果对方不知道什么是编程语言，那么他显然也不会知道这些概念。</p>
</blockquote>
</blockquote>
<ul>
<li>学会类比, 使用通俗的语言, 言简意赅</li>
</ul>
<blockquote>
<blockquote>
<p>把代码写得便于阅读，并不是让你塞进去很多注释。我想引申一下阿尔贝森和萨斯曼的那句话：“程序必须写得供人们阅读，偶尔供计算机执行。”一种好的编程语言应该比英语更容易解释软件。只有在那些不太成熟、容易出现问题的地方，你才应该加上注释，提醒读者注意，就好像公路上只有在急转弯处才会出现警示标志一样。</p>
</blockquote>
</blockquote>
<ol>
<li>以前学了很多设计模式, 经常把自己搞乱, 也看了很多别人的代码, 搞了很多设计模式, 看起来好像高大上, 实际上阅读起来非常痛苦. 后来我相通了, 只有简单的代码才是最好最容易理解的, 复杂重复的地方就抽取封装, 至此, 我基本上没听说有人说我代码很难阅读, 至少在我没听过.</li>
<li>当然, 遇到使用了设计模式, 实现优雅可读性强的代码, 也要借鉴学习.</li>
</ol>
<h3 id="3不能说的话"><a href="#3不能说的话" class="headerlink" title="3不能说的话"></a>3不能说的话</h3><blockquote>
<blockquote>
<p>让我先问你一个问题：大庭广众之下，你有没有什么观点不愿说出口？如果回答“没有”，那么你也许应该停下来想一想了。你的每一个观点都能毫不犹豫地说出口，你自己深深赞同这些观点，并且你也确信肯定会获得别人的赞同，这是否太过于巧合了？一种可能是，也许事情并没有这么巧合，你的观点就是从别人那里听来的，别人告诉你什么，你就相信了什么，你把别人灌输的观点当作了自己的观点。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>另一种可能是，你的思想观点确实是独立思考得到的，碰巧与社会主流的思想观点一模一样。这种情况的可能性似乎不大，因为这意味着，如果别人犯错了，你也必须碰巧犯一个同样的错误。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有时候，别人会对你说：“要根据社会需要，改造自己的思想。”这种说法隐含的意思似乎是，如果你不认同社会，那么肯定是你自己的问题。你同意这种说法吗？事实上，它不仅不对，而且会让历史倒退。如果你真的相信了它，凡是不认同社会之处，你连想都不敢想，马上就放弃自己的观点，那才会真正出问题。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>过去和现在之间的变化有时代表了一种进步。在物理学领域，如果我们与前人看法不一样，那是因为我们是对的，他们是错的。但是，物理学是一门硬科学4，换成其他学科，我们很快就无法确定谁对谁错了。如果你遇到的是社会问题，请问过去的看法与现在的看法哪一个更正确？很多时候你无法回答，因为过去与现在之间的变化往往不是因为对错，而是因为社会观念变了。比如，法定结婚年龄的变化。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>4 在学术上，“硬科学”指的是那些严格精确、以事实为依据的学科，典型代表是自然科学，比如物理学。相对应的概念则是“软科学”，指的是不那么严格精确、难以用事实检验的学科，典型代表是社会科学。——译者注</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我们可能自以为是地相信，当代人比古人更聪明、更高尚。但是，了解的历史越多，就越明白事实并非如此。古人与我们是一样的人，他们既不更勇敢，也不是更野蛮，而是像我们一样通情达理的普通人。不管他们产生怎样的想法，都是正常人产生的想法。所以，我们就有了找出“不能说的话”的第三种方法：将当代观念与不同时期的古代观念diff5一下。diff得到的结果，有一些用当代标准衡量是很令人震惊的。古人认为可以说的话，我们认为是不可以说的。但是，你有把握断言你比古人更正确吗？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>但是，流行的道德观念不是这样，它们往往不是偶然产生的，而是被刻意创造出来的。如果有些观点我们不能说出口，原因很可能是某些团体不允许我们说。那些团体神经越紧张，它们所产生的禁止力量就越大。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了在全社会制造出一个禁忌，负责实施的团体必定既不是特别强大也不是特别弱小。如果一个团体强大到无比自信，它根本不会在乎别人的抨击。美国人或者英国人对外国媒体的诋毁就毫不在意。但是，如果一个团体太弱小，就会无力推行禁忌。</p>
</blockquote>
</blockquote>
<ul>
<li><p>来自微信读书评论: 强权就是公理。因为强权可以制造任何的其他客观条件，不管是社会舆论还是特定事件营销。并不觉得他们不在意，而且他们掌握更多的话语权，其他的话语流星般转瞬即逝。</p>
</li>
<li><p>来自微信读书评论:  思考：<br>人也是如此。<br>当你手里有千万资产，你会在乎别人说你穷吗？不会，你甚至都不想证明。<br>同样，当你真的有能力，你会在乎别人说你无能吗？不会。</p>
</li>
</ul>
<blockquote>
<blockquote>
<p>有一种行为怪癖叫作“嗜粪症”，它的患者人数以及影响力眼下似乎就不太足够，无法把自己的观点推广给其他人。我猜想，道德禁忌的最主要制造者是那些在权力斗争中略占上风的一方。你会发现，这一方有实力推行禁忌，同时又软弱到需要禁忌来保护自己的利益。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>其次，我这样做是因为我不喜欢犯错。如果像其他时代一样，那些我们自以为正确的事情将来会被证明是荒谬可笑的，我希望自己能够知道是哪些事情，这样我就不会上当。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为什么？可能仅仅是因为科学家比其他领域的学者更聪明。如果有必要的话，大多数物理学家有能力拿到法国文学的博士学位，但是反过来就不行，很少存在法国文学的教授有能力拿到物理学的博士学位。13或者，另一种原因是，在科学中，命题的真伪更显而易见，所以这使得科学家能够更勇敢地质疑传统观点。（这句话也可以这样说，因为科学命题的真伪更显而易见，所以你想在科学界谋职，就不得不训练自己的智力，去发现并解决那些真正的问题，而不能仅仅当一个政治家，通过搞人事关系和派系斗争立足。）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>13 这句话本身就是一种明显的“不能说的话”。它犯了大学中的一个大忌：评判各种学科的难易。大学校园中有一条默认的公理——各种领域的研究所要求的智力水平都是相同的。毫无疑问，这条公理确实能够减少冲突，让一切平稳运作。但是，如果这条公理为真，那将是多么巧合的事情啊，所有学科的难易程度居然一模一样！而且，承认这条公理比不承认它会使得一切都方便得多！你只要想到这些，怎能不质疑它呢！尤其是当你想到，一旦接受了这条公理所产生的必然推论，就更无法不质疑它了。比如，它意味着不会出现单个学科的停滞或爆发式发展，所有学科的发展形态必须是完全同步的，因为这条公理告诉我们，各个学科面对的问题难度是一样的！（要弥补这个推论，你真的会伤透脑筋。）此外，如果大学开设了烹饪系或运动管理系，你会怎么想？如果你接受上面的公理，那么大学到底还要开设什么系？你真的认为微分几何和烹饪学的难度相同吗？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不管是哪一个原因，看来都存在一个很清晰的关系：智力越高的人，越愿意去思考那些惊世骇俗的思想观点。这不仅仅因为聪明人本身很积极地寻找传统观念的漏洞，还因为传统观念对他们的束缚力很小，很容易摆脱。从他们的衣着上你就可以看出这一点：不受传统观念束缚的人，往往也不会穿流行的衣服。做一个异端是有回报的，不仅在科学领域，在任何有竞争的地方，只要你能看到别人看不到或不敢看的东西，你就有很大的优势。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一旦发现了“不能说的话”，下一步怎么办？我的建议就是别说，至少也要挑选合适的场合再说，只打那些值得打的仗。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果你以此作为人生目的，一定要为黄颜色平反昭雪，现在的局面可能正中你下怀。但是，如果你的兴趣主要是别的事情，变成他人眼里的“黄色分子”对你则是极大的干扰。与笨蛋辩论，你也会变成笨蛋。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 真理越辩越明？不会的，争辩让你妄想说服对方，争辩让你学会讨好观众，这些有时会让你失去自由。</li>
</ul>
<blockquote>
<blockquote>
<p>这时你要明白，自由思考比畅所欲言更重要。如果你感到一定要跟那些人辩个明白，绝不咽下这口气，一定要把话说清楚，结果很可能是从此你再也无法自由理性地思考了。</p>
</blockquote>
</blockquote>
<ul>
<li><p>社会本来就需要各种各样的人, 有时候不说话的人的利益, 就是说话的人牺牲的人带来的. </p>
</li>
<li><p>来自微信读书评论: 可如果所有人都遵守这个准则，那么又何来变化和进步呢？每个大的进步和改革背后，都是一群不愿闭嘴的人推动而成吧</p>
</li>
<li><p>来自微信读书评论: 谭嗣同愿意以身犯险，最终奔赴黄泉，但推行“戊戌变法”，叫醒国人他功不可没！你说的没毛病，就看你怎么选择了</p>
</li>
</ul>
<blockquote>
<blockquote>
<p>我认为这样做不可取，更好的方法是在思想和言论之间划一条明确的界线。在心里无所不想，但是不一定要说出来。我就鼓励自己在心里默默思考那些最无法无天的想法。你的思想是一个“地下组织”，绝不要把那里发生的事情一股脑说给外人听。“格斗俱乐部”的第一条规则，就是不要提到格斗俱乐部。15</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我承认，“守口如瓶”看上去是一种“怯懦”的行为。可是问题在于，“不能说的话”太多了，如果口无遮拦，你就没时间做正事了。为了与他人论战，你不得不变成一个语言学家</p>
</blockquote>
</blockquote>
<blockquote>
<p>“守口如瓶”的真正缺点在于，你从此无法享受讨论带来的好处了。讨论一个观点会产生更多的观点，不讨论就什么观点也没有。所以，如果可能的话，你最好找一些信得过的知己，只与他们畅所欲言、无所不谈。这样不仅可以获得新观点，还可以用来选择朋友。能够一起谈论“异端邪说”并且不会因此气急败坏的人，就是你最应该认识的朋友。</p>
</blockquote>
<blockquote>
<blockquote>
<p>你的策略，简单地说，就是不赞同这个时代的任何一种歇斯底里的行为，但是又不明确告诉别人到底不赞同哪一种。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果你想要清晰地思考，就必须远离人群。但是走得越远，你的处境就会越困难，受到的阻力也会越大，因为你没有迎合社会习俗，而是一步步地与它背道而驰。小时候，每个人都会鼓励你不断成长，变成一个心智成熟、不再耍小孩子脾气的人。但是，很少有人鼓励你继续成长，变成一个怀疑和抵制社会错误潮流的人。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果自己就是潮水的一部分，怎么能看见潮流的方向呢？你只能永远保持质疑：什么话是我不能说的？为什么？</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 离经叛道不是一件好事，尤其在我国。<br>作者让人们保持质疑，虽然只想不说，也很难说是不是好事。<br>这跟郑板桥提倡的难得糊涂恰好相反，我支持郑，因为对大部分个体，发现真相却不能做什么，只会陷入深切痛苦。<br>这时作者唤醒的就不是“嘲笑鸟”，而是沉睡的恶魔。</li>
</ul>
<h2 id="第二部分-黑客如何工作及影响世界"><a href="#第二部分-黑客如何工作及影响世界" class="headerlink" title="第二部分 黑客如何工作及影响世界"></a>第二部分 黑客如何工作及影响世界</h2><h3 id="4良好的坏习惯"><a href="#4良好的坏习惯" class="headerlink" title="4良好的坏习惯"></a>4良好的坏习惯</h3><blockquote>
<blockquote>
<p>对于适当的不服从管教保持宽容，这不会有太大的坏处，反而很有利于造就美国的国家优势，它使得美国不仅能吸引聪明人，还能吸引那些很自负的人。黑客永远是自负的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>这种事情早有先例：人们惊慌失措时采取的措施到头来产生了适得其反的效果。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 紧急情况下猛打方向，结果汽车撞上护栏，最终翻车；碰到劫匪声嘶力竭地大叫，导致劫匪因惊慌临时动了杀心；碰到地震火情冲向还闭着的门，导致踩踏，打不开门，最终自食恶果。极度惊慌，是人类的最强大武器——头脑失效的时刻，也就演变成坐以待毙的时刻。</li>
</ul>
<blockquote>
<blockquote>
<p>那些占据高位、本能地想要约束黑客、强迫黑客服从的人，请谨慎施为，因为你们真有可能成为千古罪人。</p>
</blockquote>
</blockquote>
<h3 id="5另一条路"><a href="#5另一条路" class="headerlink" title="5另一条路"></a>5另一条路</h3><blockquote>
<blockquote>
<p>早一点发现bug就不容易形成复合式bug，也就是互相影响的两个bug。举例来说，一个bug是楼梯很滑，另一个bug是扶手松了，那么只有当这两个bug互相作用时，才会导致你从楼梯上摔下来。在软件中，复合式bug是最难发现的bug，往往也会导致最大的损失。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 复合式bug有一个子类型：两个bug是互相弥补的，好比“负负得正”，软件反而能正常运行。这种bug可能才是最难发现的bug。当你修正了其中的一个bug，另一个bug才会暴露出来。这时对你来说，你会觉得刚才修正错了，因为那是你最后修改的地方，你就怀疑自己在那里做错了，但是你其实是对的。</li>
</ul>
<blockquote>
<blockquote>
<p>向一个项目增加人手，往往会拖慢项目进程。随着参与人数的增加，人与人之间需要的沟通成本呈现指数级增长。人数越来越多，开会讨论各个部分如何协同工作所需的时间越来越长，无法预见的互相影响越来越大，产生的bug也越来越多。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 《人月神话》是一本软件项目管理名著。所谓“人月”就是一个人在一个月内所能完成的工作量。假如某个项目预估需要12个人月，那么派4个人处理这个项目，理论上需要3个月，派6个人则只需要2个月。但是，布鲁克斯认为这种换算机制在软件业行不通，是一个神话，因为软件项目是交互关系复杂的工作，需要大量的沟通成本，人力的增加会使沟通成本急剧上升，反而无法达到缩短工期的目的。在本质上，软件项目的人力与工期是无法互换的，当项目进度落后时，光靠增加人力到该项目中，并不会加快进度，反而有可能使进度更加延后。</li>
</ul>
<blockquote>
<blockquote>
<p>人数越来越少，软件开发的效率将呈指数式上升。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>不要只因为对方的头衔是市场专家、设计师或产品经理，就盲目听从他们的话。如果他们的观点真的很好，那就听从他们，关键是你要自己判断，不要盲从。只有懂得设计的黑客，才能设计软件，不能交给对软件一知半解的设计师。如果你不打算自己动手设计和开发，那就不要创业。</p>
</blockquote>
</blockquote>
<ul>
<li>实际在大公司, 通常只能按照产品说的做</li>
<li>心中放置一种观点: 虽然我按照你说的做了, 但实际上我并不认同, 仅仅是因为工作需要</li>
</ul>
<h3 id="6如何创造财富"><a href="#6如何创造财富" class="headerlink" title="6如何创造财富"></a>6如何创造财富</h3><blockquote>
<blockquote>
<p>承受较大的压力通常会为你带来额外的报酬，但是你还是无法逃避基本的守恒定律。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>现在先不考虑比尔·盖茨，因为名人不适合用来举例子，媒体只报道那些最有钱的人，而他们往往属于特例。比尔·盖茨很聪明，有决断力，工作也很勤奋，但是单单这样还不足以让你成为他，你还需要非同一般的好运气。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>任何公司的成功历程中，运气都是一个很大的随机因素。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>致富的方法有许多种，本文只谈论其中的一种，也就是通过创造有价值的东西在市场上得到回报，从而致富。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过创造有价值的东西而致富，这种方法的优势不仅仅在于它是合法的（许多其他方法如今都是不合法的），还在于它更简单，你只需要做出别人需要的东西就可以了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>3 近代历史上，政府有时都搞不清楚金钱和财富的区别。亚当·斯密在《国富论》中提到，许多国家政府为了保住“财富”，禁止出口白银或者黄金。但是，黄金和白银实际上只是一种交换媒介，留住它们并不会让一个国家变得更富有。如果物质财富保持不变，金钱越多，导致的唯一结果就是物价越高。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>财富是最基本的东西。我们需要的东西就是财富，食品、服装、住房、汽车、生活用品以及外出旅行等都是财富。即使你没有钱，你也能拥有财富。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 如此说来，以后还是尽量避免说自己穷，如果真的要说的话直接说自己现在没有钱好了。</li>
</ul>
<blockquote>
<blockquote>
<p>你真正需要的是财富。财富才是你的目标，金钱不是。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>虽然在某些特定的情况下（比如某个家庭当月的收入），你能用来与他人交换的金钱数量是固定不变的，但是大多数情况下，世界上可供交换的财富不是一个恒定不变的量。人类历史上的财富一直在不停地增长和毁灭（总体上看是净增长）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>假设你拥有一辆老爷车，你可以不去管它，在家中悠闲度日，也可以自己动手把它修葺一新。这样做的话，你就创造了财富。世界上因为多了一辆修葺一新的车，财富就变得更多了一点，对你而言尤其是如此。这可不是隐喻的用法，如果你把车卖了，你得到的卖车款就比以前更多。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>通过修理一辆老爷车，你使得自己更富有。与此同时，你也并没有使得任何人更贫穷。所以，这里明显不是一个面积不变的大饼。事实上，当这样观察的时候，你会很好奇，为什么有人会觉得大饼的面积无法增大。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 财富是创造出来的。如果我们养成健康的体魄，坚持锻炼，节制饮食，这也是我们所创造出的健康财富呀！</li>
</ul>
<blockquote>
<blockquote>
<p> 如果在修理旧车的过程中，你对环境造成了一些微小的破坏，那么你可能使得每个人都变得更贫穷了一点。但是即使把环境的成本考虑在内，这依然不是一个零和游戏，依然存在财富的净增长。我们可以举出这样的例子，一台坏机器里有一个零件松了，你把零件拧紧，机器可以重新运作，那么你就没对环境造成任何破坏，并且创造了财富。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>最可能明白财富能被创造出来的人就是那些善于制作东西的人，也就是手工艺人。他们做出来的东西直接放在商店里卖。但是，随着工业化时代的来临，手工艺人越来越少。目前还存在的最大的手工艺人群体就是程序员。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>要致富，你需要两样东西：可测量性和可放大性。你的职位产生的业绩应该是可测量的，否则你做得再多，也不会得到更多的报酬。此外，你还必须有可放大性，也就是说你做出的决定能够产生巨大的效应。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 可放大性：使用人数的指数型上涨，如果你所创造的财富有缺陷，会被无限放大；可测量性：每个员工所做的工作都有其明确的反馈。</li>
</ul>
<blockquote>
<blockquote>
<p>任何一个通过自身努力而致富的个人，在他身上应该都能同时发现可测量性和可放大性。我能想到的例子就有CEO、电影明星、基金经理和专业运动员。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>有一个办法可以发现是否存在可放大性，那就是看失败的可能性。因为收入和风险是对称的，所以如果有巨大的获利可能，就必然存在巨大的失败可能。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>黑客都是极度厌恶风险的人</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我们宁愿以百分之百的把握去赚100万美元，也不愿以20%的把握去赚1 000万美元，尽管后者理论上的期望值比前者高出一倍。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>保险的做法就是在早期卖掉自己的创业公司，放弃未来发展壮大</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>缓慢工作的后果并不仅仅是延迟了技术革新，而且很可能会扼杀技术革新。只有在快速获得巨大利益的激励下，你才会去挑战那些困难的问题，否则你根本不愿意去碰它们。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>每一个这样做的人差不多应用了同样的诀窍：可测量性和可放大性</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一旦自己的财产有了保证，那些想致富的人就会愿意去创造财富</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>要鼓励大家去创业，只要懂得藏富于民，国家就会变得强大。让“书呆子”保住他们的血汗钱，你就会无敌于天下。</p>
</blockquote>
</blockquote>
<h3 id="7关注贫富分化"><a href="#7关注贫富分化" class="headerlink" title="7关注贫富分化"></a>7关注贫富分化</h3><blockquote>
<blockquote>
<p>一旦通过创造财富而使致富成为可能，社会从整体上就会快速地变得更富有。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>首先，技术肯定加剧了有技术者与无技术者之间的生产效率差异，毕竟这就是技术进步的目的。一个勤劳的农民使用拖拉机比使用马可以多耕6倍的田，但是前提条件是他必须掌握如何使用新技术。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>但是，苹果公司推出了强大而且便宜的个人计算机，使得一切成为可能，这本身就是在创造财富。程序员马上接了上去，使用苹果公司的产品，再去创造更多的财富。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>技术应该会引起收入差距的扩大，但是似乎能缩小其他差距。100年前，富人过着与普通人截然不同的生活。他们住在大房子里，有许多仆人服侍，穿着华丽但是不舒适的服装，乘着马车旅行（因此还有马厩和马夫）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>现在，由于技术的发展，富人的生活与普通人的差距缩小了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>汽车就是一个很好的例子。如果富人不购买普通汽车，而是购买全手工制作、售价高达几十万美元一辆的豪华车，对他反而不利。因为对于汽车公司来说，生产那些销量很大的普通汽车要比生产那些销量很小的豪华车更有利可图，所以汽车公司会在普通车辆上投入更多的精力和资金，进行设计和制造。如果你购买专为你一个人定制的汽车，质量反而不可靠，某个部件肯定会出问题。这样做的唯一意义就是告诉别人你有能力这样做。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>无法被技术变得更便宜的唯一东西，就是品牌。这正是为什么我们现在越来越多地听到品牌这个词。富人与穷人之间生活的鸿沟正在缩小，品牌是这种差距的遗留物。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>无论在物质上，还是在社会地位上，技术好像都缩小了富人与穷人之间的差距，而不是让这种差距扩大了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果参观雅虎、英特尔或思科公司，你会看到每个人都穿着差不多的衣服，有着同样的办公室（或者小隔间）、同样的家具，彼此直呼对方的名字，不加任何头衔或敬语。表面看大家没什么差距，但如果看到每个人银行户头上的余额差别之大，你一定会感到震惊不已。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>技术的发展加大了贫富差距，这是不是一个社会问题？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>好像没有那么严重。技术在加大收入差距的同时，缩小了大部分其他差距。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我想提出一种相反的观点：现代社会的收入差距扩大是一种健康的信号。技术使得生产率的差异加速扩大，如果这种扩大没有反映在收入上面，只有三种可能的解释：（a）技术革新停顿了；（b）那些创造大部分财富的人停止工作了；（c）创造财富的人没有获得报酬。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果得不到报酬，人们是否愿意创造财富？唯一的可能就是，工作必须能提供乐趣。会有人愿意免费写一个操作系统，但是他们不愿意免费为你安装、提供电话支持、进行客户培训等。即使是最先进的高科技公司，也有至少90%的工作没有乐趣、令人生厌。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>一个社会需要有富人，这主要不是因为你需要富人的支出创造就业机会，而是因为他们在致富过程中做出的事情。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我在这里谈的不是财富从富人流向穷人的那种涓滴效应（trickle-down effect），也不是说如果你让亨利·福特致富，他就会在下一场宴会雇用你当服务员，而是说如果你让他致富，他就会造出一台拖拉机，使你不再需要使用马匹耕田了。</p>
</blockquote>
</blockquote>
<h3 id="9设计者的品味"><a href="#9设计者的品味" class="headerlink" title="9设计者的品味"></a>9设计者的品味</h3><blockquote>
<blockquote>
<p>但是，如果你是一个设计师，并且你不承认有一种人们共同认可的东西叫作“美”，那么你就没有办法做好工作。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果品味只是一种个人偏好，那么每个人都是完美无缺的：你喜欢自己看上的东西，那就足够了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>就像别的工作一样，只要你不断地从事设计工作，你就会做得越来越好。你的品味会出现变化，你会像别人一样有所提高。如果这样的话，那么你以前的品味就不只是与现在不同，而是不如现在的好。因此，所谓“品味没有好坏之分”的公理也就顿时见鬼去了</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>众多不同学科对“美”的认识有着惊人的相似度。优秀设计的原则是许多学科的共同原则，一再出现。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: <ul>
<li><p>比如：艺术上的美感包括什么类型？鲜明、丰富、和谐、简约等多种类型。把这种美感映射到代码上，体现是：模块功能清晰、齐全、借口调用方便、设计简洁等等。映射到科研上，体现是：工作思路巧妙、分析严密、逻辑通畅、简明扼要等。</p>
</li>
<li><p>懂审美买美的，爱慕虚荣的买贵的，懂技术的买性价比高的，爱明星买明星代言的。这些属性会有重合，重合越多这个产品的消费群体就越广。</p>
</li>
<li><p>作者总结的共同原则有：<br>  好设计是简单的设计。<br>  好设计是永不过时的设计。<br>  好设计是解决主要问题的设计。<br>  好设计是启发性的设计。<br>  好设计通常是有点趣味性的设计。<br>  好设计是艰苦的设计。<br>  好设计是看似容易的设计。<br>  好设计是对称的设计。<br>  好设计是模仿大自然的设计。<br>  好设计是一种再设计。<br>  好设计是能够复制的设计。<br>  好设计常常是奇特的设计。<br>  好设计是成批出现的。<br>  好设计常常是大胆的设计。</p>
</li>
<li><p>一般拥有这种品位和能力的人，都让人觉得有点洁癖，强迫症以及所谓的完美主义倾向，这些特质不是所谓的作秀和装逼，而是内心觉得看到觉得不对的就内心极为难受，压抑不住，创造者的特质就是在细节方面让人觉得有吹毛求疵的倾向。</p>
</li>
<li><p>丘吉尔：Perhaps I can implore you not to feel the need to be too accurate.（我想恳请你不必画得太准确。）<br>  给丘吉尔画肖像画的画家：Why? Accuracy is truth.（为什么？准确才是真实。）<br>  丘吉尔：No. For accuracy, We have the camera. Painting is the higher art. And I never let accuracy get in the way of truth if I don’t want it to.（不。想准确的话，我们有相机。绘画是更高一层的艺术。我从来不会让准确遮挡真相。）<br>  ——美剧《王冠》第一季</p>
</li>
<li><p>以前历史老师总说，是历史成就了一个人，而不是一个人成就了历史，尽管当时不是那个人，也会有另一个人出现。经常是大势和环境成就了你，不一定因为你就多么与众不同。</p>
</li>
<li><p>时势造英雄，个人的能力是渺小的，无论你认为你多么强大，在历史的洪流之下，我们顺势而行。无论你认为你做出多么英明的决策也不过是在环境和条件的自然反射。</p>
</li>
<li><p>不得不说，发展就是让平均每个人可利用的资源越来越多。当总资源无法满足每个人的需求时，就会催生技术变革；当总资源很大程度可以满足每个人的需求时，生活水平就会极速提高。</p>
</li>
</ul>
</li>
</ul>
<h2 id="第三部分-黑客的工具和工作方法"><a href="#第三部分-黑客的工具和工作方法" class="headerlink" title="第三部分 黑客的工具和工作方法"></a>第三部分 黑客的工具和工作方法</h2><h3 id="10编程语言解析"><a href="#10编程语言解析" class="headerlink" title="10编程语言解析"></a>10编程语言解析</h3><blockquote>
<blockquote>
<p>一个操作所需的代码越多，就越难避免bug，也越难发现它们</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>程序员的时间要比计算机的时间昂贵得多，后者已经变得很便宜了，所以几乎不值得非常麻烦地用汇编语言开发软件。只有少数最关键的部分可能还会用到汇编语言，比如开发某个计算机游戏时，你需要在微观层面控制硬件，使得游戏速度得到最大限度的终极提高。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>语言设计者之间的最大分歧也许就在于，有些人认为编程语言应该防止程序员干蠢事，另一些人则认为程序员应该可以用编程语言干一切他们想干的事。Java语言是前一个阵营的代表，Perl语言则是后一个阵营的代表。（美国国防部很看中Java也就不足为奇了。）</p>
</blockquote>
</blockquote>
<ul>
<li>现在的人信息量太大了，没大多时间深入学习精通，大多数水平有限，但又要避免出错，所以go的限制，静态语言，一定程度上符合大家的利益</li>
<li>来自微信读书评论: rust的设计哲学恰恰相反，认为编码的都是傻x，事实上rust这种思路更符合现实</li>
</ul>
<h3 id="11一百年后的编程语言"><a href="#11一百年后的编程语言" class="headerlink" title="11一百年后的编程语言"></a>11一百年后的编程语言</h3><blockquote>
<blockquote>
<p>任何一种编程语言都可以分成两大组成部分：基本运算符的集合（扮演公理的角色）以及除运算符以外的其他部分（原则上，这个部分可以用基本运算符表达出来）。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果我们把一种语言的内核设想为一些基本公理的集合，那么仅仅为了提高效率就往内核添加多余的公理，却没有带来表达能力的提升，这肯定是一件很糟的事。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>没错，效率是很重要，但是我认为修改语言设计并不是提高效率的正确方法。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>正确做法应该是将语言的语义与语言的实现予以分离。在语义上不需要同时存在列表和字符串，单单列表就够了。而在实现上做好编译器优化，使它在必要时把字符串作为连续字节的形式处理。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: Common Lisp的变量是动态的，数据类型是静态的。比如declare function的时候，任何数据类型都可以作为变量；而一个有string type的语言，变量名就只能是string<br>用动态语言编写的程序会更简洁，互动性更强，更多hacks，更常用prototype而不是class。但同时运行的时候也会有更多type error，所以需要好好写测试。<br>用静态语言编写的程序在设计上更直观，程序更稳定，更常用class而不是prototype。程序在编译的时候就可以捕获大多数错误。<br>另一种理解动态静态的方式是：动态的思维是离散的、公理化的、prototypical的、象征着直觉；静态的思维是抽象的、定理推导式的、classified and hierarchical的、遵循着逻辑。<br>这篇文章既然在讨论程序语言的进化，那么一定是从动态的角度出发，从设计简洁的基本公理开始，以期达成创新。（后文提到是否应该用list来表达数字正是作者对简化公理的猜想。或许新的计算机出现以后这真会成为现实呢？）<br>由此推算，可能初创公司更适合用迭代快速的动态语言，而成熟的企业更需要静态语言来确保代码的可读性和实用性。<br>我等菜鸡还是先乖乖练好静态语言再说吧。动态语言也就是作者这样的满级人类用得比较爽，毕竟他已经把写代码比作写文章了……</li>
</ul>
<blockquote>
<blockquote>
<p>对于大多数程序，速度不是最关键的因素，所以你通常不需要费心考虑这种硬件层面上的微观管理。随着计算机速度越来越快，这一点已经越发明显了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>essay（论文）这个词来自法语的动词essayer，意思是“试试看”。从这个原始意义来说，论文就是你写一篇文章，试着搞清楚某件事。软件也是如此。我觉得一些最好的软件就像论文一样，也就是说，当作者真正开始动手写这些软件的时候，他们其实不知道最后会写出什么结果。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 好的软件是边探索边写边迭代出来的，作者大概指的是黑客写的小而精美的软件，而不是软件工程下的大型软件</li>
</ul>
<blockquote>
<blockquote>
<p>一般来说，如果你动手创造一种新语言，那是因为你觉得它在某些方面会优于现有的语言。Java语言之父詹姆斯·高斯林在第一份《Java白皮书》中说得很清楚，之所以要设计Java，就是想解决C++的一些弱点。所以结论就是，各种编程语言的编程能力是不相同的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>编程时提高代码运行速度的关键是使用好的性能分析器（profiler）</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了写出优秀软件，你必须同时具备两种互相冲突的信念。一方面，你要像初生牛犊一样，对自己的能力信心万丈；另一方面，你又要像历经沧桑的老人一样，对自己的能力抱着怀疑态度。在你的大脑中，有一个声音说“千难万险只等闲”，还有一个声音却说“早岁那知世事艰”。这里的难点在于你要意识到，实际上这两种信念并不矛盾。你的乐观主义和怀疑倾向分别针对两个不同的对象。你必须对解决难题的可能性保持乐观，同时对当前解法的合理性保持怀疑。</p>
</blockquote>
</blockquote>
<ul>
<li>有很多工作并不像计算机一样，不是0就是1，对待任务，我很有信心做好，但同时以往的经验告诉我，随着工作进行的深入，会有很多细节需要考虑，可能并不是简单就能完成的事，毕竟内心还是想尽可能接近完美</li>
</ul>
<blockquote>
<blockquote>
<p>做出优秀成果的人，在做的过程中常常觉得自己做得不够好。其他人看到他们的成果觉得棒极了，而创造者本人看到的都是自己作品的缺陷。这种视角的差异并非偶然，因为只有对现状不满，才会造就杰出的成果。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果你能平衡好希望和担忧，它们就会推动项目前进，就像自行车在保持平衡中前进一样。在创新活动的第一阶段，你不知疲倦地猛攻某个难题，自信一定能够解决它。到了第二阶段，你在清晨的寒风中看到自己已经完成的部分，清楚地意识到存在各种各样的缺陷。此时，只要你对自己的怀疑没有超过你对自己的信心，就能够坦然接受这个半成品，心想不管多难我还是可以把剩下的部分做完。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>让这两股相反的力量保持平衡是很难的。初出茅庐的年轻黑客都很乐观，自以为做出了伟大的产品，从不反思和改进。上了年纪的黑客又太不自信，甚至故意回避一些挑战性很强的项目。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 达克效应的两面：无知的人认为自己无所不知、无所不能，能力越差越自信无比；能力强的人经常怀疑自己的能力，自信不足。学会平衡两种状态</li>
</ul>
<blockquote>
<blockquote>
<p>大家都知道，让一个委员会负责设计语言是非常糟糕的主意。委员会只会做出恶劣的设计。但是我觉得，委员会最大的问题在于他们妨碍了“再设计”。在委员会的主持下，修改一种语言是非常麻烦的事，没有人愿意自讨苦吃。而且，即使大多数成员不喜欢某种做法，委员会最后的决定往往还是维持现状。</p>
</blockquote>
</blockquote>
<ul>
<li>大公司会有很多制度，有些人很不喜欢，但我恰恰认为这是保护员工的机制</li>
</ul>
<blockquote>
<blockquote>
<p>设计与研究的区别看来就在于，前者追求“好”，后者追求“新”。优秀的设计不一定很“新”，但必须是“好”的；优秀的研究不一定很“好”，但必须是“新”的。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>我认为这两条道路最后会发生交叉：只有应用“新”的创意和理论，才会诞生超越前人的最佳设计；只有解决那些值得解决的难题（也就是“好”的难题），才会诞生最佳研究。所以，最终来说，设计和研究都通向同一个地方，只是前进的路线不同罢了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>如果把创造一种编程语言看成设计问题，而不是科研方向，那么有何不同？最大的不同在于你会更多地考虑用户。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>优秀的建筑师不会先设计，然后强迫用户接受，而是先研究最终用户的需求，然后做出用户需要的设计。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>注意，我说的是“用户需要的设计”，而不是“用户要求的设计”。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: <ul>
<li>乔布斯：“人们不知道他们想要什么，直到你把产品放到他们面前。” 用户不可能了解所有选择，特别是那些还未被创造的选择，直到你创造出了它们。王维嘉《暗知识》里对这种情况做了更basic的梳理：有些需求是已知的，有些需求是未知的。在你把未知的选项呈现在它们面前之前，你永远不可能通过倾听需求而得到最优解。</li>
<li>用户提的需求不一定都是对的，要经过思考后加以取舍。分清目标和手段，目标只有一个，手段途径却有很多</li>
<li>并不是来自用户的所有需求都是合理的，即便是面对合理的需求，从用户提出需求所解决的问题着手，去挖掘出他们的根本目的，再设计出完备的解决方案，会比直接照搬照套来得更有效果。</li>
</ul>
</li>
</ul>
<blockquote>
<blockquote>
<p>在软件领域，贴近用户的设计思想被归纳为“弱即是强”（Worse is Better）模式2。这个模式实际上包含了好几种不同的思想，所以至今人们还在争论它是否真的成立。但是， 其中有一点是正确的，那就是如果你正在设计某种新东西，就应该尽快拿出原型，听取用户的意见。</p>
</blockquote>
</blockquote>
<ul>
<li>来自微信读书评论: 刚做软件的时候，我也很赞同这种模式，原因是因为我认为如果你发布了一个很磕碜的产品恶心到了用户，用户一定不会在给你任何尝试的机会，所以应该一气呵成出一个完美的产品交给用户，让他们忠实。后来发现根本不可行，闭门造车，永远造不出用户喜欢的东西。但是如何避免磕碜的产品恶心到用户呢？那就是采用天使用户模式，每次迭代产品让这部分愿意参与尝试的天使用户进行尝鲜，根据他们的反馈来决定是否大量发布，既保证了快速迭代，又保证了用户体验</li>
</ul>
<blockquote>
<blockquote>
<p>2 “弱即是强”指的是一种软件传播的模式，由Common Lisp专家理查德·加布里埃尔（Richard P. Gabriel）于1991年在“Lisp: Good News, Bad News, How to Win Big”一文中首先提出。它的含义非常广泛，涉及软件设计思想的各个方面，其中一个重要结论就是软件功能的增加并不必然带来质量的提高。有时候，更少的功能（弱）反而是更好的选择（强），因为这会使得软件的可用性提高。相比那些体积庞大、功能全面、较难上手的软件，一种功能有限但易于使用的软件可能对用户有更大的吸引力。加布里埃尔本人经常举Unix和C语言的例子，Unix和C在设计上考虑了实际环境，放弃了一些功能，但是保证了简单性，这使得它们最终在竞争中胜出，成为主流操作系统和编程语言。——译者注</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>与之对照，还有另一种软件设计思想，也许可以被称为“万福玛丽亚”模式。它不要求尽快拿出原型，然后再逐步优化，它的观点是你应该等到完整的成品出来以后再一下子隆重地推向市场，就像圣母玛丽亚降临一样，哪怕整个过程漫长得像橄榄球运动员长途奔袭、达阵得分也没有关系。在互联网泡沫时期，无数创业公司因为相信了这种模式而自毁前程。我还没听说过有人采用这种模式而获得成功。</p>
</blockquote>
</blockquote>
<ul>
<li>我的另一种想法: 一个app用于试错，最后开发另外一个app替换，前一个app用来导流，制造竞争关系</li>
</ul>
<blockquote>
<blockquote>
<p>软件领域以外的人可能没听过“弱即是强”，所以意识不到这种模式在艺术领域普遍存在。以绘画为例，文艺复兴时期就有人发现了这一点。如今，绝大部分美术老师会告诉你准确画出一个东西的方法，不是沿着轮廓慢慢地一个部分一个部分地把它画出来，因为这样的话各个部分的错误会累积起来，最终导致整幅画失真。你真正应该采用的方法是快速地用几根线画出一个大致准确的轮廓，然后再逐步地加工草稿。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>先做出原型，再逐步加工做出成品，这种方式有利于鼓舞士气，因为它使得你随时都可以看到工作的成效。在开发软件的时候，我有一条规则：任何时候，代码都必须能够运行。如果你正在写的代码一个小时之后就可以看到运行结果，这好比让你看到不远处就是唾手可得的奖励，你因此会受到激励和鼓舞。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>跟你说实话吧，画家之间甚至流传着一句谚语：“画作永远没有完工的一天，你只是不再画下去而已。”</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>士气也可以解释为什么很难为低端用户设计出优秀产品，因为优秀设计的前提是你自己必须喜欢这种产品，否则你不可能对设计有兴趣，更不要说士气高昂了。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>为了把产品设计好，你必须对自己说“哇，这个产品太棒了，我一定要设计好！”，而不是心想：“这种垃圾玩意，只有傻瓜才会喜欢，随便设计一下就行了。”</p>
</blockquote>
</blockquote>
<ul>
<li>现在写代码，对一些复杂的代码段，我喜欢针对做一下单元测试，这样可以快速看到效果，也可以避免后续整个流程时出现太多的bug</li>
<li>来自微信读书评论<ul>
<li>学习编程语言也是这样，不要妄想着从书本上把所有东西都学精通，然后再开始接触实际的项目，没有实际的操作，不能对自己学到的东西加以巩固和思考，书上的东西始终是作者的</li>
<li>先有整体概念，然后，再优化。先做一个框架，然后再丰富细节，一定要先想好，保证框架是对的，不然，重头再来的成本太高。</li>
<li>如何能把事情做的更好：<br>  1、目标分解成小目标。2、在众多方案中采取能看到过程效果的方案。3、奖赏机制，如quick win。</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>《不拘一格：网飞的自由与责任工作法》-笔记</title>
    <url>/2021/08/11/20210811-bu-ju-yi-ge-wang-fei-de-zi-you-yu-ze-ren-gong-zuo-fa-bi-ji/</url>
    <content><![CDATA[<h3 id="推荐序一-企业如何最大化地驱动创新"><a href="#推荐序一-企业如何最大化地驱动创新" class="headerlink" title="推荐序一 企业如何最大化地驱动创新"></a>推荐序一 企业如何最大化地驱动创新</h3><ul>
<li><p>网飞文化的内核是人才，它的理论基础是我们大家必须关注的“人才效益现象”，即一个富有才华的人所产出的创新效果将数倍于一个能力中等的人，并且随着技术和创新发展，这种倍数还在不断增加。这里需要强调的是，这种人才效益现象针对的是创新能力起决定性作用的工作岗位，比如技术研究和产品开发等。针对这一现象，里德提出将人才密度作为企业创新能力的内核基础。因为优秀人才能激励其他优秀人才，而精英创造的出色成果能感染更多的出色人才。一个企业只具备少量的人才是不够的，它需要累积足够的人才密度才能具备高水平的创新能力。</p>
</li>
<li><p>在管理上放权，赋予员工更多的自由，同时也让员工承担其相应的企业责任。它们的核心宗旨是让员工最大化地施展他们的才华和对企业的责任心，使企业能最大化地发挥人才潜能，驱动创新。</p>
</li>
<li><p>网飞再下一层更为核心的企业改革是从“控制管理模式”转型到“情景管理模式”。这对很多企业管理者和企业创新探索者来讲，是一个长期追求但非常难实现的企业管理境界。在企业决策过程当中，理想的情况是每一个重要决定都由最了解情况、专业能力最强的相关责任人来做决策，但是绝大部分企业在管理上都采用金字塔决策模式，重要的决定都是由领导层来做，而领导层往往并不是最适合做这些决策的。网飞所采用的是树形的决策模式，企业领导层只负责树根部分，确保整个企业有高度一致的战略方向，同时赋能每一根树枝，让它们能基于相应的业务情景来做决策。</p>
</li>
</ul>
<h3 id="推荐序二-打造面向未来的新型组织文化"><a href="#推荐序二-打造面向未来的新型组织文化" class="headerlink" title="推荐序二 打造面向未来的新型组织文化"></a>推荐序二 打造面向未来的新型组织文化</h3><ul>
<li><p>网飞文化的核心是“人才重于流程，创新高于效率，自由多于管控”。</p>
</li>
<li><p>“自由与责任的关系并不是像我先前所想的那样背道而驰，相反，自由是通往责任的一条途径。</p>
</li>
<li><p>“当老板放弃‘决策审批者’这一身份时，公司业务发展会更加迅速，员工创新能力也会增强。”</p>
</li>
</ul>
<h3 id="自序一-没有规则的规则"><a href="#自序一-没有规则的规则" class="headerlink" title="自序一 没有规则的规则"></a>自序一 没有规则的规则</h3><ul>
<li><p>如果我们自己都做不好，他们又能起什么作用呢？</p>
</li>
<li><p>规定和管理流程成了我们工作的基础，那些擅长在条条框框里循规蹈矩的人得到了提拔，而许多有创造力且特立独行的员工却感到窒息，于是他们便离职去了别处。看到他们离开，我很难过，但那时我相信这就是公司成长的过程。</p>
</li>
<li><p>经过多年的反复实践、试错，以及不断的改进，我们最后终于找到了行之有效的办法。如果你给员工更多的自由，而不是制定规则来阻止他们发挥自己的判断，他们会做出更好的决定，也更有责任感。这样，员工工作起来会更愉快，更有动力，公司经营也会更加灵活。但是，要实现这种自由，你必须有一个基础，即让公司先从以下两个方面得到提升：第一，提高人才密度。在大多数公司，规则和控制流程针对的都是那些表现马虎、做事不专业或不负责任的员工。但如果你规避或者剔除掉这样一些人，你就完全不需要那些规则。如果你能组建一支几乎完全由高绩效员工组成的团队，那么大多数规则都是可以去掉的。人才密度越高，你能提供的自由度就越大。第二，提高坦诚度。有才华的人身上有很多东西值得学习。但在一般情况下，讲究客套的人际交往会妨碍员工做出必要的反馈，从而影响绩效水平的提升。如果优秀的员工都养成坦诚反馈的习惯，那么他们就能更好地完成工作，同时对彼此负责，这就进一步减少了对传统管控的依赖。在此基础上，须做好一道减法——减少管控。首先，将员工手册由厚变薄，差旅、经费支出、休假等相关规定统统可以不要。然后，随着人才密度越来越大，反馈越来越频繁和坦诚，你就可以取消整个组织的审批流程，教会你的经理们“进行情景管理，而非控制管理”，同时让员工把握这样一个原则：工作不是要费心地取悦老板。</p>
</li>
<li><p>创建自己特有的、富于自由与责任的企业文化。</p>
</li>
</ul>
<h3 id="自序二-把员工当成真正的成年人"><a href="#自序二-把员工当成真正的成年人" class="headerlink" title="自序二 把员工当成真正的成年人"></a>自序二 把员工当成真正的成年人</h3><ul>
<li><p>且不说炒掉那些努力工作但业绩并不出众的员工是否有悖道德，这些幻灯片让我觉得这是一种极其糟糕的企业管理模式。这一模式违反了哈佛商学院教授埃米·埃德蒙森（Amy Edmondson）所说的“心理安全”原则。</p>
</li>
<li><p>埃德蒙森教授在2018年出版的《无畏的组织》（The FearlessOrganization）一书中指出：如果你想激励创新，你就需要创造一个让员工可以安心地放飞梦想、大胆发言和勇于冒险的环境。工作环境让员工越有安全感，就越能激发他们的创新意识。很显然，网飞公司没有人读过这本书。他们雇用了最优秀的员工，然后向他们灌输一种忧患意识，告诉他们如果不追求卓越，就自个儿拿一笔遣散费走人。这听起来无疑是扼杀了创新的希望。</p>
</li>
<li><p>如果没有限期休假的制度，员工真正休假的时间可能就更少了。这样的认识是有理论依据的，即心理学家所说的“损失规避”。我们人类都不想失去自己已经拥有的东西，这种感觉甚至超过我们对新事物的渴望。面对可能失去的东西，我们会竭尽全力地抓住它。所以，如果有休假的安排，我们还是会尽可能地去休假。</p>
</li>
<li><p>如果没有假期，你当然也没必要担心会失去假期，所以就更不可能去休假了。而许多传统政策中“过期作废”的规则听起来像是一种限制，但实际上是在鼓励人们抓住机会休假。</p>
</li>
<li><p>没有人会赞同将工作环境建立在秘密和谎言的基础上，但有时采取一定的策略，显然比直言不讳更好。例如，当团队成员陷入困境，需要鼓舞士气或者增强自信时，我们就需要委婉地处理。而“总是坦诚”的一揽子规则听起来却是在破坏关系，磨灭激情，还会造成一个不太愉快的工作环境！</p>
</li>
<li><p>总的来说，网飞的《自由与责任》给我的印象就是极度男性化，充斥了过多的对抗性和彻头彻尾的攻击性。你可能会觉得，这种公司的创造者，就是一个在一定程度上用机械论和理性主义观点来看待人性的工程师。</p>
</li>
<li><p>网飞认为你具有惊人的判断力……判断力几乎可以解决所有模棱两可的问题，而流程做不到。</p>
</li>
<li><p>我越来越感到好奇：这样一个组织，在现实生活中是如何成功运作的呢？我刚开始的感觉是，缺乏规则必然会造成混乱；如果员工不能发挥出超高的工作水平，就得立马走人，这又难免会引起员工的恐慌。</p>
</li>
<li><p>史蒂夫·乔布斯在斯坦福大学的毕业典礼上做过一场著名的演讲。他在演讲中说道：“面向未来，你无法将所有节点串联在一起；只有回望过去，你才能看清这些节点是如何串在一起的。你要相信，这些节点会在未来以某种方式联系在一起。所以你要有一种信念，这种信念可能是你的直觉、你认定的命运，抑或你向往的生活、你所相信的因果报应，或者其他某种想法。这种方法从来没有让我失望过，这让我的生活变得与众不同。”</p>
</li>
</ul>
<h3 id="1-优秀同事造就优质工作环境"><a href="#1-优秀同事造就优质工作环境" class="headerlink" title="1 优秀同事造就优质工作环境"></a>1 优秀同事造就优质工作环境</h3><ul>
<li><p>具有非凡的创造力、工作出色，且与他人合作良好的员工是留下来的最佳人选</p>
</li>
<li><p>在一个真正人才济济的公司，每个人都会努力工作。工作效率高的人，在整体人才密度高的环境中，也能得到更好的发展。我们的员工都在相互学习，团队也在高效运作。这既增加了个人的积极性和满意度，也使整个公司的工作效率更高。我们发现，周围全是优秀人才的环境，能够让你的工作上到一个新的台阶。最重要的是，与才华横溢的同事一起工作很令人振奋，容易受到鼓舞，同时能感受到很多的乐趣。</p>
</li>
<li><p>今天，公司拥有7 000名员工，但和当时只有80名员工一样，我依然有这样的感受。事后看来，一个团队只要有一两个表现欠佳的人，就会拉低整个团队的绩效。如果你有五名优秀员工和两名表现欠佳的员工，这两名表现欠佳的员工会造成如下后果：</p>
<ul>
<li>·消耗管理者的精力，使他们没有时间把精力放在优秀员工身上。</li>
<li>·团队讨论的质量得不到保证，拉低团队整体智商。</li>
<li>·强迫他人围绕着他们开展工作，致使工作效率低下。</li>
<li>·排挤其他追求卓越的员工。</li>
<li>·向团队表明你接受平庸，从而使问题更加严重。</li>
</ul>
</li>
<li><p>对于优秀员工而言，好的工作环境并不意味着一间豪华的办公室，一个好的健身房，或者一顿免费的寿司午餐，而在于周围全是才华横溢的人，具有合作精神的人，让你不断进步的人。如果每一名员工都很优秀，他们就会相互学习、相互激励，工作表现也会迅速得到提升。</p>
</li>
<li><p>许多人的工作在细节方面做得并不好，这实际上向他人表明，表现平平也是可以的。这样便导致了公司整体水平的下降。</p>
</li>
<li><p>构建一个高效且具有创造力的工作环境，离不开出色的员工。他们背景不同，看问题的角度各异，但他们有着共同的特点，那就是：具有超凡的创新能力，能够完成繁重的任务，并能很好地相互协作。你必须首先确保这一关键点落实到位，否则其他原则都没有意义。</p>
</li>
<li><p>作为领导者，你的首要目标是营造一个完全由优秀员工组成的工作环境。</p>
<ul>
<li>·优秀的员工能完成大量重要的工作，而且极富创造力和工作热情。<br>  团队中如果有成员过于狂傲，做事懒散，平庸，或者悲观，整个团队的表现都会受到影响。</li>
</ul>
</li>
<li><p>迈向自由与责任的企业文化当你淘汰了表现欠佳的员工，提高了人才密度之后，就可以着手引入坦诚的企业文化。</p>
</li>
</ul>
<h3 id="2-以积极的态度说出你真实的想法"><a href="#2-以积极的态度说出你真实的想法" class="headerlink" title="2 以积极的态度说出你真实的想法"></a>2 以积极的态度说出你真实的想法</h3><ul>
<li><p>我也努力把坦诚这一信条带到公司。我开始鼓励每个人说出自己的真实想法，但意图必须是积极的，不要攻击或伤害他人，从而将各种想法、意见和反馈摆到台面上来加以解决。</p>
</li>
<li><p>我们当时没有雇任何新人，也没有提高任何人的薪水，但日益增加的坦诚度却让公司的人才密度得到了提高。</p>
</li>
<li><p>评价一个人，要人前人后一个样。</p>
</li>
<li><p>在给予反馈和接受反馈成为一种常态之后，人们会学得更快，工作效率也会更高。</p>
</li>
<li><p>高绩效+无私的坦诚&#x3D;极高绩效</p>
</li>
<li><p>你认为你的观点得不到支持。</p>
<ul>
<li>·你不想被视作一个“麻烦”。</li>
<li>·你不想陷入不愉快的争论。</li>
<li>·你不想惹恼或激怒你的同事。</li>
<li>·你担心会被认为缺乏团队精神。</li>
</ul>
</li>
<li><p>在网飞，如果你与同事有不同意见，或者是有好的建议却不说出来，就会被视为对公司不忠，因为你本可以为企业提供帮助，但你却没有这样做。</p>
</li>
<li><p>当我第一次听说网飞的坦诚文化时，我对此表示怀疑。网飞不仅提倡坦诚反馈，而且还提倡持续反馈。当时在我看来，这只会让员工听到更多伤人的话。大多数人都不愿接受刺耳的言论，觉得这样的话可能会让思想变得消极。鼓励人们坦诚地发表反馈，这一想法听起来不仅令人觉得难以适应，而且风险很大。但是，当我开始与网飞员工合作的时候，我看到了这样做的好处。</p>
</li>
<li><p>我们不喜欢但需要坦诚很少有人喜欢受到批评。工作中收到负面的反馈，会让你对自己产生怀疑，让你感到沮丧，感到自己很脆弱。你的大脑会对负面反馈做出反应，就像面对身体威胁时的战逃反应一样，都会将激素释放到血液中，从而加快反应速度并产生一定的情绪。</p>
</li>
<li><p>要说有什么比面对面的批评更令人不安的，那就是当着众人的面收到负面反馈。在我的演讲过程中，那位当着同事的面提出反馈的女士给了我很大的帮助。她告诉我她的意见对我有用，需要及时地反馈给我。不过，在众人面前收到反馈，会向大脑发出危险警报。我们的大脑对遭受群体排斥这类信号特别关注，因为大脑具有求生的机制，而我们最成熟的生存技能之一就是尽可能寻求安全。在原始社会，遭受排斥就意味着孤立和死亡。如果有人在你的部落宗族面前指出你犯的错误，你的大脑中一直对危险保持警惕的杏仁核——这也是大脑中最原始的一个结构——将会发出警报：“你将受到群体的排斥。”面对这种情况，我们的本能反应就是逃跑。同时，也有大量的研究表明，收到积极的反馈会刺激大脑释放催产素。这种令人愉悦的激素也能使母亲在哺乳时感到快乐。这便能解释为什么很多人喜欢说恭维的话，而不愿给出诚实的、建设性的意见。</p>
</li>
<li><p>然而，研究也表明，我们大多数人出于本能，还是能够理解真相的价值。</p>
</li>
<li><p>尽管赞美可以带来愉悦，但多数人还是认为，同积极反馈相比，纠正性反馈更能帮助我们提高水平和能力。持这一观点的人数几乎是持相反观点人数的三倍。多数人都说，他们觉得积极反馈对于他们的成功没有太大的帮助。</p>
</li>
<li><p>反馈环是提高绩效最有效的办法之一。如果在我们合作共事的过程中，能不断地提出并接收到反馈，便能学得更快，完成得更多。反馈有助于我们避免误解，营造共担责任的氛围，同时减少对权力和规则的需求。</p>
</li>
<li><p>在考虑是否给予反馈时，人们经常会纠结于这样一个问题：他们既不想伤害接收者的感受，又希望能给对方提供帮助。而网飞的目标则是：帮助彼此取得成功，不要担心偶尔伤害了对方的感受。更重要的是，我们发现，在恰当的氛围中采用正确的方法，我们完全可以大胆地提供反馈而不会对他人造成伤害。</p>
</li>
<li><p>如果你想在自己的机构或团队中培养坦诚的文化氛围，可以采取几个步骤。要做到第一步并不容易。你可能会认为，培养坦诚的第一步是从最简单的步骤开始：领导者向员工提供大量反馈。但我建议，首先将重点放在更困难的事情上面：让员工向领导者坦诚地反馈。当然，领导者与员工间的反馈也可能是同时进行的，但只有员工向领导者提供了真实的反馈，坦诚反馈的最大好处才会真正体现出来。</p>
</li>
<li><p>你在组织中的地位越高，收到的反馈就越少，你就越有可能是“赤裸着身体在工作”，也越容易犯下除你之外所有人都看得见的错误。这不仅会导致整个机构的运作出问题，而且还很危险。</p>
</li>
<li><p>另一项至关重要的，是你在获取反馈时的行为反应。你必须向员工表明，如果你能心怀感激地面对他人的批评，能够给予足够的“认同提示”，那么你也可以放心地提供反馈意见。</p>
</li>
<li><p>我在洗手间碰到特德。他问我第一天感觉怎么样。我对他说：“哇，特德，我简直不敢相信，那个人在会议上居然敢用那种态度对你说话。”特德一副迷惑不解的样子。他说：“布赖恩，如果哪一天你因为害怕不受待见而不敢提出反馈意见，那你可能就得离开网飞了。我们聘请你来，就是需要听你的意见。会议室里的每一个人，都有责任把他的想法坦率地告诉我。”</p>
</li>
<li><p>一个领导者要想获得员工的反馈，有些事情是必须要做的。他不仅要向员工征求反馈，而且要告诉员工，自己期待着他们的反馈（就像他对布赖恩所说的那样）。当你收到反馈时，需要通过认同提示进行回应。</p>
</li>
<li><p>罗谢尔认真遵循了网飞的原则，即在这种情况下，保持沉默就是对公司的不忠。晚上，她给里德写了一封电子邮件，发送之前自己先“读了100遍。因为即使是在网飞，还是感觉有一定的风险”。最后，她把邮件发了出去。在邮件里，她是这么说的：嗨，里德：昨天我也是参会者中的一员。听了你对帕蒂所说的话，我感觉似乎有些轻率，而且对帕蒂也不够尊重。我之所以提出这一点，是因为在去年的务虚会上，你谈到了创建一个良好的对话环境的重要意义。在这种环境下，人们应该有勇气把心里的话讲出来，无论是赞同还是反对。昨天在会议室里，有董事和副总裁，还有一些不太了解你的人。听到你对帕蒂说话的语气，如果我也不了解你，那我今后无论如何也不敢当着众人向你表达我的观点。因为担心你会否定我的想法。我刚才对你讲的，希望你不要介意。罗谢尔在听完罗谢尔的故事之后，我想到了过去我曾经做过的工作，从斯里兰卡咖喱餐厅的服务员到一家大型跨国公司的培训经理，再到一家波士顿小型公司的董事和一所商学院的教授。我也努力回忆了一下，看自己在担任这些不同角色的过程中，是否曾听到过有人礼貌而坦诚地告诉领导，说他在会议上说话的语气不太妥当。回忆的结果是一个大大的“不”。我给里德发了一封邮件，问他是否记得5年前罗谢尔的这封邮件，他几分钟之内就回复了。艾琳：我还记得我们开会的房间，以及我和帕蒂所坐的位置。我还记得当时有些沮丧，情绪没控制好。里德他还把他回复罗谢尔的邮件也转发给了我。罗谢尔：非常感谢收到你的反馈。如果你发现我仍有不当之处，请继续与我联系。里德</p>
</li>
<li><p>罗谢尔的反馈是坦诚的，同时也是经过深思熟虑的，其真正目的是帮助里德做得更好。但营造坦诚氛围的最大风险，就是可能会造成人们有意或无意的滥用。这就需要迈出培养坦诚文化的第二步。学会正确地给予和接受反馈</p>
</li>
<li><p>坦诚把握不好便会尽显丑陋。</p>
</li>
<li><p>尽管网飞大力提倡反馈，但仅靠坦诚是没有用的，坦诚的氛围并不意味着一切。网飞的员工最初向我提供反馈时，我感到非常吃惊，以为反馈的原则就是“说出你的想法，不惜一切代价”。</p>
</li>
<li><p>事实上，网飞的管理者们花费了大量的时间，帮助他们的员工懂得了何为正确的反馈、何为错误的反馈。</p>
</li>
<li><p>他们的经验可以总结为4项准则，我把它们统称为4A反馈准则，你也可以尝试一下。4A反馈准则提供反馈</p>
<ol>
<li>目的在于帮助（Aim to assist）：反馈的目的必须是积极的。反馈不是为了发泄，不是为了中伤他人，也不是为自己捞取资本。反馈者应清晰阐述这样做对他人和公司有什么样的好处，而不是对自己有什么好处。“你在与外部合作伙伴会面时在剔牙，这样做很让人生气。”这是错误的反馈方式。正确的反馈应该是这样：“如果在与外部合作伙伴见面时你不再剔牙，那么合作伙伴可能会觉得你很敬业，我们就更有可能建立牢固的关系。”</li>
<li>反馈应具有可行性(Actionable)：你的反馈必须说明接收人可以做一些什么样的改变。我在古巴的那次演讲中，如果收到的是这样一个反馈：“你在演讲过程中的做法与你自己的观点不符。”那这样的反馈就是有问题的。而正确的反馈可以是这样的：“你选取听众发言的方式导致了最后的参与者只有美国人。”或者这样说更好：“如果你还有别的方法，让其他国籍的参会者也发一下言，那你的演讲将更有说服力。”接收反馈</li>
<li>感激与赞赏(Appreciate)：我们在受到批评时都会为自己辩护或寻找借口，这是人类的本能；我们都会条件反射式地进行自我保护，维护自身的名誉。当你收到反馈时，你需要有意识地反抗这种本能，并且问一问自己：“我该如何去认真地聆听，以开放的心态去认真地对待反馈？既不辩护，也不生气，还应该满怀欣赏和感激。”</li>
<li>接受或拒绝(Accept or discard)：在网飞，你会收到很多人的反馈。你需要认真地听，同时也认真地思考。不是每条反馈都要求你照办，但有必要向反馈者真诚地致谢。你和反馈者都必须清楚：对反馈意见的处理完全取决于反馈的接收者。</li>
</ol>
</li>
<li><p>在本章开头的案例中，道格向乔丹提出了反馈，让乔丹看到在印度工作时，应该如何调整自己的行为，这是遵循4A反馈准则的一个典范。道格意识到，乔丹与客户会面的方式会影响他自己的计划。而道格的目标，就是帮助乔丹改进行为方式，并帮助团队取得成功（4A准则之“目的在于帮助”）。道格提供的反馈意见让乔丹很受用。乔丹说，他现在与印度方面合作，采取的就是更好的方法（4A准则之“反馈应具有可行性”）。乔丹表达了对道格的感谢（4A准则之“感激与赞赏”）。当然，他可以选择不接受反馈，但是这一次他接受了。他说：“现在出去之前，我也不会对别人说教了。取而代之的是，我会对同事说：‘嘿，这可是我的弱点！如果下次印度的尼廷为我们安排城市观光，我又盯着手表看的话，就把我狠狠地教训一顿！’”（4A准则之“接受或拒绝”。）</p>
</li>
<li><p>大多数人都和道格一样，会觉得及时的反馈尤其困难。他们会首先把自己调整好，等条件和时机成熟之后再说出想法。这样一来，反馈的效果就没有那么好了。于是，我们就要迈出坦诚文化培养的第三步。当场反馈，实时反馈</p>
</li>
<li><p>剩下的最后一个问题就是：我们应该在什么时间、什么地点提供反馈呢？答案就是：随时随地。这可能意味着反馈意见还是在私底下说最合适。艾琳在网飞做主题演讲时，当着三四个人的面收到了第一个反馈，这样也挺好的。如果反馈真的对别人有极大的帮助，我们当着40个人的面说出来都没有问题。</p>
</li>
<li><p>每一只高高举起的手都像是一个挑战。似乎所有的人都在喊：“你知道自己在做什么吗？！”面对一个又一个挑战，我不禁加快了语速，心里也感到不安。听众对我的质疑越多，我就越担心自己没法把内容讲完，于是讲得越来越快。</p>
</li>
<li><p>后来，罗丝的亲密同事比安卡在房间的后面挥动着手臂，这无疑为罗丝提供了一件救生衣。这是一种典型的网飞风格。“罗丝！你这样不行！你快要失去控制了！你听起来像是在为自己辩解！你讲得太快了。你没有好好地听别人的问题。你在重复自己的东西而没有回应别人的关切。深吸一口气，你需要大家的参与。”她大声喊道。</p>
</li>
<li><p>那一刻，我仿佛看到了观众眼中的自己——说得多，听得少，一副气喘吁吁的样子。我深吸了一口气。“谢谢你，比安卡。你是对的。我是怕时间不够。我需要每个人都了解这个项目。我来这里的目的就是想听到并解答大家的问题。我们回到正题上面来吧。刚才还有哪位提问我没有叫到的？”我有意识地改变了自己着力的方向，这让整个会议的气氛也发生了变化。大家的声调缓和了，脸上开始露出微笑，先前那种咄咄逼人的气势也烟消云散了，我也说服了大家参与这个项目。比安卡的坦诚拯救了我。</p>
</li>
<li><p>比安卡的目的就是要帮助罗丝取得成功（4A准则之“目的在于帮助”）；她告诉罗丝可以采取哪些具体措施以调整自己的表现（4A准则之“反馈应具有可行性”）；罗丝对比安卡报以感谢（4A准则之“感激与赞赏”）；最后，她听从了比安卡的建议，这对所有人都是有好处的（4A准则之“接受或拒绝”）。</p>
</li>
<li><p>如果你遵循这一准则，随时随地都可以提出反馈，最大限度地让接收者受益。</p>
</li>
<li><p>厘清什么是无私的坦诚，什么是有才华的浑蛋</p>
</li>
<li><p>和我们共事的，不乏聪明绝顶的人。这类人你是知道的，他们具有惊人的洞察力，口齿清楚，解决问题时总能直击要害。你的机构中人才越密集，聪明人也就越多。但是，如果周围全是聪明人，你可能就有危险了。有时候，有才华的人听到的赞美之词太多，就会觉得自己真的比其他人更优秀。如果有他们认为不明智的想法，他们可能会报以嘲笑；如果有人发言不够清晰，他们可能会翻白眼；他们还会侮辱那些他们认为天赋不如自己的人。换句话说，这些人就是浑蛋。如果你在团队中倡导坦诚的文化氛围，就必须把这样的人剔除出去。许多人可能会认为“这个人确实很聪明，没有他不行”，但是，不管这样的人有多么出色，如果让他留在团队里，你营造坦诚氛围所付出的努力就不会有太好的效果。浑蛋对整个团队的效率有很大的影响，他们可能会将你的组织从内部撕裂。因为他们老是喜欢中伤同事，然后丢下一句：“我这是坦诚。”</p>
</li>
<li><p>坦诚的文化并不意味着不加考虑地说出自己的想法。相反，每个人都需要仔细地审视一下4A准则。在你提出反馈之前，可能需要反思，有时还需要做一些准备，必要时可以让专门的人员进行监督和指导。</p>
</li>
<li><p>在网飞任职初期，我所在团队的一名工程师在我的专业领域犯了一个大错。之后他还发来一封电子邮件推卸责任，而且也没有提出任何解决办法。我非常生气，于是打电话给他，希望他能纠正自己的错误。在电话中，我直言不讳地批评了他。我并不喜欢这样做，但是我觉得自己是在为公司着想。让我没想到的是，一周后，他的经理站在了我的办公桌前。他告诉我，他知道我与那名工程师联系过，并且认为从技术层面讲，我确实没有错。但他问我是否知道，自从我批评了那名工程师之后，那名工程师就一直情绪不振；还问我是否故意把他的员工搞得那么缺乏动力，工作效率低下。不，当然不是。那名经理继续说：“你应该把要求给我的工程师讲清楚，让他积极地去解决问题。你是这样做的吗？”“当然，那是肯定的。”“那好。今后请一直都这样做。”于是，我就一直是这样做的。这场对话持续了不到两分钟，但效果立竿见影。请注意，他并没有指责我品行有问题。相反，他问我：“你打算伤害公司的利益吗？”“你采取的方式合理吗？”这些问题实际上只有一个答案。如果他只是对我说：“你这人有点浑蛋。”我可能会回答：“我哪里浑蛋了？”但他通过几个问题，让我在回答的同时也进行了反思。</p>
</li>
<li><p>贾斯廷部分遵循了4A准则。他的目的是帮助工程师走上正确的道路。他强调了要牢记公司的利益。或许他的意见也是可行的，但是他依然被认为有些过火，因为他通过反馈宣泄心中的不满，这就违反了第一条准则。</p>
</li>
<li><p>此外，还有其他一些一般性的反馈准则，例如“还在气头上切勿发表批评意见”“在给予纠正性反馈时要注意语气平和”，等等。这些对于反馈都是有帮助的。</p>
</li>
</ul>
<h4 id="本章要点"><a href="#本章要点" class="headerlink" title="本章要点"></a>本章要点</h4><ul>
<li><p>·一旦有了坦诚的氛围，高效率的员工将成为杰出的员工。坦诚的反馈将成倍地提高团队的工作效率。</p>
</li>
<li><p>·在日常的会谈中引入反馈机制，从而为坦诚搭建舞台。</p>
</li>
<li><p>·按照4A准则，指导员工有效地提供和接收反馈。</p>
</li>
<li><p>·作为领导者，要不断征求反馈意见，在收到反馈时用认同提示予以回应。</p>
</li>
<li><p>·要营造坦诚的氛围，先清除掉团队中的浑蛋。</p>
</li>
<li><p>有了人才密度和坦诚的氛围，你就可以着手取消管控，营造更加自由的工作环境。</p>
</li>
<li><p>迈向自由与责任的企业文化</p>
</li>
</ul>
<h3 id="3上-取消限期休假制度"><a href="#3上-取消限期休假制度" class="headerlink" title="3上 取消限期休假制度"></a>3上 取消限期休假制度</h3><ul>
<li><p>创造性工作的价值不应当通过工作时长来衡量。靠时间来衡量价值的想法源于工业时代，那时的工作都是靠人工完成，但现在主要由机器完成。</p>
</li>
<li><p>在步入信息化时代的今天，人们关注的是你的成果，而不是你大量的付出。</p>
</li>
<li><p>我担心的是，若是公司不给员工安排假期，员工就会放弃休假。我们“无期限的”休假制度会不会变成“无休假”制度？事实证明，我们很多杰出的创意都是员工在放松状态下的灵光乍现。</p>
</li>
<li><p>休假能够让员工的身心得到放松，使他们能够进行创造性的思考，并且以崭新的姿态面对自己的工作。如果一直不停地工作，那么他只会在原地转圈，而无法从全新的角度去看待问题。</p>
</li>
<li><p>公司借此向员工传递了这样一个信息：公司是信任员工的。从而进一步增强了他们的责任心。尽管如此，如果另外两步没有走好，我的噩梦就真的有可能成为你的现实。第一步——休长假，领导要带头</p>
</li>
<li><p>在没有相关制度的情况下，员工休假的长短在很大程度上取决于他的领导和周围的同事。所以，如果你真的要实行无期限的休假制度，必须从鼓励领导休长假开始，让他们做出表率。</p>
</li>
<li><p>由于没有制度的规定，大多数员工都会观察部门其他员工的情况，以了解“软性的限度”。</p>
</li>
<li><p>随着公司规模的扩大，越来越多的部门并没有以里德为榜样，实行帕蒂所倡导的无期限的休假。在这样一些部门中，这项制度还真有点像是“无休假”的制度。不过，还是有很多部门领导学着像里德那样休假，并且让下面的人都看得到。一旦他们这样做了，员工们也会以他们为榜样，进而为公司带来很多意想不到的好处。</p>
</li>
<li><p>“作为领导，光靠说是不够的，员工们也在看我们是如何做的。如果我只是说‘我希望你们能够在工作与生活之间找到一个可持续的、健康的平衡点’，但自己每天却工作12个小时，那么员工也只会看我的行动，而不会听我说的话。”</p>
</li>
<li><p>重要的并不是假期的长短，而是可以完全按照自己喜欢的方式来安排生活。只要你工作出色，没有人会在意你有没有休假。</p>
</li>
<li><p>要实施无期限休假，领导做表率是第一步。另一个值得关注的问题就是取消休假期限以后，有的员工可能会觉得非常自由，于是会选择在不恰当的时候休假，而且一休就是几个月，以致对团队工作和公司业务造成影响。</p>
</li>
<li><p>原有的休假制度取消后，员工会一时陷入迷茫之中：有些人会不知所措，直到老板明确告诉他们可以怎么休假；如果不告诉他们，他们是不会主动休假的。而另一些人会觉得他们完全自由了，因而做出一些极不恰当的决定，例如在不适宜的时候休假，从而给其他同事带来很多的麻烦。这不仅会降低团队的工作效率，而且可能导致被解雇的命运，这对谁都没有好处。</p>
</li>
<li><p>由于没有书面的制约，每个部门经理都应当花时间与团队成员进行沟通，告知员工怎样做才合适。会计部门主管应当坐下来与团队成员交流一下，告诉大家1月份不适合休假，还可以分析一下哪些月份休假更合适。那位在厨房里泪盈盈的经理也应该与团队商量，共同设定一系列休假参数。例如“一次只能一名团队成员休假”，以及“在休假备案之前，应确保不会让团队其他成员感到非常不妥”。经理设定的情景越清晰越好。比如像那位会计部门的主管就可以这样对员工说：“若需要一个月的假期，至少得提前三个月提出来；若只是五天的假期，通常提前一个月就可以了。”</p>
</li>
<li><p>网飞公司的宗旨是：一名优秀员工胜过两名普通员工。</p>
</li>
<li><p>事实上，要想实行无期限休假并不难，你需要做的仅仅是创建一个相互信任的环境。我们公司就是基于以下三条准则：（1）始终为公司的最大利益行事；（2）绝不做任何妨碍他人实现其目标的事；（3）努力实现自己的目标。只要满足上述几条，员工完全可以按照自己的意愿休假。</p>
</li>
<li><p>给予自由，再落实责任</p>
</li>
<li><p>我曾以为如果我们不追踪记录员工的假期，公司会被搞得天翻地覆。但事实上，公司的秩序并没有发生大的变化，而员工的满意度更高了。一些喜欢特立独行的员工，比如像前面提到的工程师萨拉（连续工作三周，每周工作80个小时，然后跑去探访亚马孙森林亚诺玛米部落）就特别支持这一做法。我们的这一举措，使高绩效的员工可以更好地掌控自己的生活，同时又使每个人感到更加自由。由于我们的人才密度很高，我们的员工都非常认真负责；由于我们有坦诚的文化氛围，如果有员工滥用制度或自由，其他员工就会当面阻止，直接告诉他那样做的不良后果。</p>
</li>
<li><p>差不多与此同时，公司里又出现了一些新的迹象。我和帕蒂都注意到，员工们在办公室更具有责任感了。这从一些小事情就可以看出来，比如会有人主动把冰箱里变质的牛奶拿出去扔掉。</p>
</li>
<li><p>给员工更多自由，可以使他们更具归属感和责任感</p>
</li>
<li><p>于是我和帕蒂便提出“自由与责任”的理念。我们之所以这样说，不仅仅是因为我们需要两者兼有，而是员工获得更多自由之后，自然就会产生归属感和责任感。我也逐渐明白了，自由与责任的关系并不是像我先前所想的那样背道而驰，相反，自由是通往责任的一条途径。</p>
</li>
</ul>
<h3 id="3下-取消差旅和经费审批"><a href="#3下-取消差旅和经费审批" class="headerlink" title="3下 取消差旅和经费审批"></a>3下 取消差旅和经费审批</h3><ul>
<li><p>如今在网飞，我不希望公司任何人在这种没有意义的讨论上浪费时间；我更不希望有才华的员工在发挥聪明才智的时候，却被一些愚蠢的规章制度困扰，这无疑会破坏富有奇思妙想和充满创造力的工作氛围。</p>
</li>
<li><p>我们确定了关于公司开销的第一条准则：怎么花自己的钱，就怎么花公司的钱</p>
</li>
<li><p>据一项研究显示：被调查者一旦确信自己的行为不会为人所知，远超半数的人会利用漏洞，为自己谋取更多利益。</p>
</li>
<li><p>没有透明度，就没有财务报销的自由。</p>
</li>
<li><p>正是公司给予员工的自由，让他在关键时刻做出了有利于公司的决断。当然，自由不是取消报销制度的唯一好处，还有一个好处就是减少流程，提高效率。</p>
</li>
<li><p>随着一个快速灵活的初创企业发展为成熟的企业，公司往往会建立一套完整的体系对员工的支出进行监管。这让管理有了一种控制感，但往往也会拖慢公司业务的进程。</p>
</li>
<li><p>企业拥有一支高绩效的团队，员工才会认真负责地工作；企业拥有坦诚的文化氛围，员工才会互相监督，共同维护公司利益。在此前提下，企业可以放松对员工的管控，给予他们更多的自由。</p>
</li>
</ul>
<h4 id="本章要点-1"><a href="#本章要点-1" class="headerlink" title="本章要点"></a>本章要点</h4><ul>
<li>（上）·企业取消限期休假之后，员工休假无须事先获得批准，员工本人及上级领导无须记录休假时长。·员工自行决定是否休假及休假时长，几个小时、一天、一周或一个月都可以。·取消限期休假会造成制度空缺。应为员工提供请假情景以填补制度空缺。但这一切需要基于充分的讨论，以确定员工在何种情景下适合休假。·老板的表率作用很关键。取消了限期休假制度，但没有带头休假的领导，整个企业或者部门等于没有假期。</li>
<li>（下）·企业取消差旅及报销制度后，应鼓励管理人员就员工如何进行事前支付及事后审核设定相关情景。如果有超支的情况，需要设定更加详细的情景。·企业取消费用管控之后，财务部门每年需要对收据进行抽检。·如果员工滥用权利，无论其表现多么优秀，都应予以开除并向全体员工进行通报。这一点非常必要，以此告诫其他员工这类行为的严重后果。·员工的自由消费可能会增加企业成本。但相较于超支所增加的成本，员工自由所带来的收益会更高。·由于员工开支自由，他们在该花钱的时候便能够及时地做出决定，从而有助于业务的开展。·由于不存在采购订单及采购流程的管理成本和时间等待，企业能够节约更多的资源。·相对于一个靠各种规则构建的体制，员工在自由环境中的花费可能更小。你告诉员工你相信他们，那么员工也会向你表明，他们值得你信任。</li>
</ul>
<ol>
<li>继续探索提高人才密度的新方法。为吸引和留住优秀人才，我们必须确保薪酬具有足够大的吸引力。</li>
<li>继续探索提高公司坦诚度的新方法。企业要想在管控方面放手，就必须确保在没有监管的情况下，员工能够对信息有充分的了解，从而做出正确的决定。这就要求提高组织的透明度，做到信息公开化。如果我们希望员工能够自己做出明智的决定，就需要他们像高层一样，了解公司的业务状况。</li>
</ol>
<h3 id="4-支付行业最高薪资"><a href="#4-支付行业最高薪资" class="headerlink" title="4 支付行业最高薪资"></a>4 支付行业最高薪资</h3><ul>
<li><p>一名最好的程序员为你增加的价值何止10倍啊，简直有上百倍！我曾在微软与比尔·盖茨共事，据说他对这个问题有更深刻的理解。他经常引用这样一句名言：“一名优秀车工的工资是一名普通车工的好几倍；而一名优秀程序员写出来的代码比一名普通程序员写出来的要贵上一万倍。”在软件行业，这种说法虽有争议，但也算是一条尽人皆知的原则。</p>
</li>
<li><p>我和帕蒂就想，网飞的哪些部门也可以遵循精英原则呢？对此，我们把工作分成了操作型和创造型两类。</p>
</li>
<li><p>但是在网飞，像这样的岗位并不多。我们大多数工作都需要依靠员工的创新和创造力。</p>
</li>
<li><p>对于创造性的工作，最优秀员工的工作效率可以轻轻松松地高出普通员工10倍以上</p>
</li>
<li><p>对公司所有操作型的工作，根据明晰的标准，按市场中间价开工资。但是对于创造型的工作，我们会给某一名能力超强的员工开出市场上的最高工资，而不是花同样的钱去雇十几名或更多表现平平的普通员工。这样，我们的员工团队就得到了精简。我们靠的是一个高效率的员工来代替很多普通的员工，同时，我们给他的工资也是相当可观的。</p>
</li>
<li><p>我们最不希望的是，我们的员工在12月份才实现自己同年1月份设定的目标，结果仍然获得了奖励。这种做法的风险是，员工会专注于目标本身，而不考虑现阶段怎么做才对公司发展最有利。</p>
</li>
<li><p>除此之外，我也不能接受这样的想法，即如果你拿出更多金钱摆在优秀员工的面前，他们就会更加卖力地工作。绩效高的人会自觉地追求成功，会竭尽全力做好自己的工作，无论是否有奖金摆在他们面前。</p>
</li>
<li><p>我很喜欢前德意志银行首席执行官约翰·克莱恩说的这样一句话：“我不知道为什么要跟你签订一份含有奖金的合同。我不会因为有人给我的奖金多就更加努力，也不会因为给我的奖金少就松懈下来。”任何能力与薪水相称的管理者都会这么说。</p>
</li>
<li><p>研究也证明了里德的感觉是对的。依照绩效制定的薪酬对日常工作有一定激励作用，但实际上也影响了创造力的发挥。</p>
</li>
<li><p>创造性工作要求在一定程度上解放你的大脑。如果你总想着要怎么做才能表现好，才能得到高额的奖金，那么你就缺少开放的认知空间，产生最好的想法和最好创意的可能性也微乎其微。结果，你反倒做得更差。</p>
</li>
<li><p>我在网飞的发现也确实如此。在我们用足够高的工资帮助员工减轻家庭负担之后，他们最具创造力。但是如果他们并不确定自己能否得到额外的报酬，创造力就会下降。由此可见，有利于激发创造力的，是足够高的工资，而非绩效奖金。</p>
</li>
<li><p>当我们决定开出丰厚的工资就不再支付额外奖金之后，一个大大的惊喜是我们吸引了更多的优秀人才。</p>
</li>
<li><p>网飞是愿意花钱来吸引和留住人才的，因此他们与员工的谈话主要是想弄清楚两点：（1）估计自己未来的员工在其他公司能挣多少钱；（2）网飞支付的薪水会略高于其他公司。</p>
</li>
<li><p>起初，新员工会因为拿着市场最高工资而动力满满。但不久之后，随着他自身能力的提高，竞争者会开出更高的工资诱使他跳槽。如果他的实力跟高薪匹配，那么他的市场价值就会继续上升，跳槽的概率就会越来越大。因此，自相矛盾的是，每一家公司在薪资方面的做法就像是在鼓励员工跳槽，从而降低了公司的人才密度。公关总监若昂讲述了他在前雇主那里遇到的类似问题。</p>
</li>
<li><p>工资审查的时候，大多数公司是用“加薪池”和“工资等级”来决定工资的涨幅，而非员工的市场价值。</p>
</li>
<li><p>如果一个员工放弃原来的工作，跳槽到一家新的公司，那么他工资的平均涨幅将达到10%~20%。一直待在同一家公司，是没什么“钱途”的</p>
</li>
<li><p>如果存在长期雇佣关系，而且员工的市场价值不太可能在几个月内飙升，那么加薪池和工资级别对大多数公司的员工都是有效的。但是如果考虑到员工频繁地换工作，而经济情况又在不断地变化，这一做法显然就不再适用了。</p>
</li>
<li><p>但是，像网飞这种给员工开市场上最高工资的模式确实很少见，也很难理解。</p>
</li>
<li><p>向猎头了解自己的市场价值</p>
</li>
<li><p>在世界上几乎所有的公司，员工去参加其他公司的面试都会让现任老板感到生气、失望，甚至会疏远员工。员工对老板来说越有价值，老板就会越生气，其原因显而易见。一名优秀的新员工哪怕仅仅是决定去其他公司面试，老板都会有投资受损的风险；如果他参加了面试，发现新工作比自己当前的工作好，那么老板就会失去这名员工，至少是失去他工作的热情。这就是为什么大多数公司的老板会让他们的员工产生这样一种感觉：跟其他公司的招聘人员交谈就像是做了叛徒似的。</p>
</li>
<li><p>拉里的上司特德·萨兰多斯在跟员工分享当月最新市场信息时说：“市场对人才的需求在持续升温，你们将会不断接到招聘人员的电话。这些电话可能来自亚马逊、苹果和脸书。如果你们不确定自己目前拿到的是不是市场最高工资，你们可以接听这些电话，弄清楚自己在那些公司可以拿到多少钱。如果你们发现同样的工作，它们给的工资比我们高，那么请告诉我们。”拉里听罢十分吃惊：“网飞大概是唯一一家公开鼓励员工去跟竞争对手交谈，甚至去面试的公司。”</p>
</li>
<li><p>如果我发现员工在别处能挣到更多的钱，我会立马给他们涨工资。”为了留住最优秀的员工，最好在他们得到其他工作机会之前，主动把工资涨上去。当然，拉里自己也是这一方案的受益者，他得到了更高的工资，而特德也留住了他这样一个人才。但是，特德的这种做法听起来未免风险太大。有多少人接到招聘人员的电话之后，就会喜欢上新的工作，最终离开自己的团队呢？对于这个问题，特德是这样解释的：如果市场对人才的需求持续升温，招聘人员就会不断给优秀人才打电话，我们的员工自然会对新工作产生好奇。这时候，我说什么都没有用，一些员工还是会去跟他们交谈，然后去参加面试。要是我不明确允许他们这么做的话，他们就会背地里偷偷摸摸地去参加面试，然后跳槽，那我连挽留他们的机会都没有。就在我公开发布这项规定的一个月前，我们损失了一位非常优秀的高管，她的才华是无可取代的。她来找我的时候，已经接受了其他公司的工作，所以事情已经没有挽回的余地了。她告诉我，她喜欢网飞的工作，但是其他公司给她的工资要比网飞高40%。听罢，我的心都沉了。要是我早知道她的市场价值已经有了变化，那我一定会对她的工资进行相应的调整！这就是我允许员工尽可能多地去跟其他公司交流的原因，但前提是他们得光明正大地去做，并且回来后将获取的信息告诉我。</p>
</li>
<li><p>网飞的规则就是，当招聘人员打电话给你的时候，你在说“不用了，谢谢”之前，先问一句：“多少钱？”</p>
</li>
<li><p>第四个关键点为了提高员工队伍的人才密度，在所有创造型的部门，我们宁愿聘用一名优秀的员工，也不要聘用10名或者更多普通的员工。优秀人才的市场价格无论有多高，都要以市场最高价聘用他们。为防止竞争对手给他们开出更高的工资，每年至少给他们调一次工资。如果你当前的预算没法给这些优秀员工开出市场最高价，那就算解雇一些没那么优秀的员工，也一定要把他们的工资提上去。这样，公司的人才密度才会更高。</p>
</li>
</ul>
<h4 id="本章要点-2"><a href="#本章要点-2" class="headerlink" title="本章要点"></a>本章要点</h4><ul>
<li>·如果要打造一支有创造力且人才密度高的团队，目前大多数公司的薪资方式都不够理想。</li>
<li>·把你的员工分为创造型和操作型两类。给创造型的员工市场最高的工资，这就意味着招到一个能力超群的人，而不是10个或更多水平一般的人。要努力打造一支完全由高水平人才组成的团队，这对于一些关键技术和重大问题的解决尤为重要。</li>
<li>·不要搞绩效奖金，也不要股权激励，要把这些全部包含在工资里面。</li>
<li>·引导员工发展自己的人际网络，及时了解自己以及所在团队不断变化的市场价值。</li>
<li>这可能意味着他们会接听招聘人员的电话，甚至去参加其他公司的面试。然后，要及时对他们的薪资进行相应的调整。迈向自由与责任的企业文化人才密度的不断增加，为提高员工决策的自由度做好了准备。不过，你得首先把坦诚放在第一位。在大多数公司里面，大部分员工即使很有才华，在决策上的自由度也相当小，因为公司最高层所掌握的一些信息对他们而言都是秘密。如果你的公司全都是责任心很强的员工，他们自励、自觉且自律，那么公司的很多信息都可以和他们分享。而在大多数公司里，这些信息可能都是不公开的。</li>
</ul>
<h3 id="5-开卷管理"><a href="#5-开卷管理" class="headerlink" title="5 开卷管理"></a>5 开卷管理</h3><ul>
<li><p>要迅速建立信任，最好的办法莫过于直接说出一个潜在的秘密。</p>
</li>
<li><p>此处，我们暂时使用“潜在秘密”这样一个表达。秘密这个词的诡异之处就在于，一旦你把它告诉了某一个人，它就不再是秘密了。</p>
</li>
<li><p>不论大事小事、好事坏事，如果你的第一反应是把信息公之于众，那其他人也会这样做。在网飞，我们称之为“阳光行动”，对此我们付出了很多努力。</p>
</li>
<li><p>我不想让我的员工觉得自己是在为网飞工作，而是让他们感觉自己是网飞的一分子。”从那时起，我就认定，如果你在网飞工作，没有人会为你在头顶撑一把伞。你要做好淋雨的准备。</p>
</li>
<li><p>我的目标就是让员工感到自己是公司的主人，从而增强他们的责任感。不仅如此，向员工公开信息还有另外一个好处：它使我们的员工变得更加聪明了。你把那些通常只有高管才知道的信息直接分享给底层员工，他们就可以自己做判断，完成更多的工作。由于不需要浪费时间去寻求信息和获得批准，他们的工作效率会更高。没有上级的指示，他们自己就可以做出更好的决策。</p>
</li>
<li><p>对于我们的员工来说，透明度代表我们相信员工能够认真负责地对待工作。我们对他们的信任又会增强他们的归属感、使命感和责任感。</p>
</li>
<li><p>但是，尽管会有个别员工辜负你的信任，但处理完这一个案之后，请继续对其他员工保持透明。不要因为一个人的失职而迁怒于大多数的人。</p>
</li>
<li><p>网飞是真正地把员工当成可以独立处理复杂信息的成年人来看待，我很欣赏这一点。这种做法会给员工带来一种巨大的认同感与责任感。</p>
</li>
<li><p>在网飞，你的住房状况以及你各方面的生活都跟工作无关。公司是把你当成一个正常的成年人看待，同时把所有的信息都跟你分享，以便你能做出明智的决定。</p>
</li>
<li><p>总之，透明是我们的准则，但任何事情都不是绝对的。</p>
</li>
<li><p>我确实有一份只对我的6名直接下属开放的文档。在这份文档里，我们可以发表任何东西，包括对“爱尔兰共和军问题”的担忧，这对公司其他成员是不开放的。但这样的情况很少。一般来说，每当我们举棋不定的时候，我都会尽早公开整个实施流程，以此获得员工的认同感。这也让员工明白，尽管情况总在不断地变化，但他们至少可以随时获知事情的动向。</p>
</li>
<li><p>我也知道，要真正做到这一点是有难度的。任何想要信息透明化的领导都会认识到：将信息公之于众肯定会跟个人隐私存在冲突。毋庸置疑，二者同等重要。但问题是，当公司有人离职的时候，每个人都很想知道原因，就算你极力掩饰，终有一天也会真相大白。相反，如果你坦诚地把原因告诉大家，那么流言就会戛然而止，员工对你的信任也会只增不减。</p>
</li>
<li><p>如果事情与工作相关，那就应该告知每一个人；而如果只是牵涉员工的私人问题，那么愿不愿意分享就由员工自己决定吧。</p>
</li>
<li><p>如果一个人公开承认自己的错误，人们会觉得他更加值得信任，这是人的本性。从那以后，每当觉得自己犯了错误，我都毫无保留地说出来。我很快就发现，领导把自己的错误公之于众，一个最大的好处就是可以鼓励员工把犯错当作一件很正常的事情，继而鼓励他们在不确定一件事情是否能够成功之前，敢于去冒险尝试。这样，整个公司的创新能力就能得到大大的提升。由此我们得出一个结论：自我揭露建立信任，主动求助促进学习，敢于认错赢得谅解，而公开你的失败则可以鼓励更多员工大胆地放手一搏。这就是在场景四的测试中，我毫不犹豫地选择B的原因。谦逊是一位领导、一个模范人物的重要品质。当你取得成功的时候，要轻描淡写地带过，或者让别人来说。当你犯了错误的时候，一定要清楚而响亮地说出来。这样，其他人就可以从你的错误中学习，从你的错误中获益。换言之，就是——成功了小声说，犯错了大声说。</p>
</li>
<li><p>坦诚地对待错误，对人际关系、健康状况和工作表现都是有利而无害的。</p>
</li>
<li><p>这种倾向被称为“出丑效应”，指一个人犯了错误之后的吸引力是增加还是减少，取决于他总体表现出来的能力。</p>
</li>
<li><p>一名领导有卓越的才能，又深受团队的爱戴，那么当他把自己的错误拿出来“见阳光”时，就更容易建立起信任并起到激励的作用，他的公司也会因此受益。而对于一名刚刚崭露头角或者没有取得信任的领导人来说，这项建议可能并不适用。在大声说出自己的错误之前，你得先让员工相信你的工作能力。</p>
</li>
<li><p>如果你拥有了最优秀的员工，并且营造了坦诚反馈的文化氛围，那么，公开企业的秘密会增强员工的主人翁意识和责任感。你要相信自己的员工能够正确把握并处理重要信息，而你的员工也会向你表明：他们是值得信任的。</p>
</li>
</ul>
<h4 id="本章要点-3"><a href="#本章要点-3" class="headerlink" title="本章要点"></a>本章要点</h4><ul>
<li>·要建立透明的企业文化，就要考虑一下你平时传递给员工怎样的信号。不要大门紧锁的办公室，不要充当警卫的助理，其实所有的地方都不用上锁。</li>
<li>·对员工开诚布公。教会他们怎么去阅读财务报表。跟公司里的每个人分享敏感的财务和战略信息。</li>
<li>·如果公司有重组或裁员之类的打算，在事情确定下来之前，提前跟员工说明情况。这可能会引起一些焦虑和不安，但是你建立起来的信任比负面影响更重要。</li>
<li>·当公司透明度与员工的个人隐私相冲突时，请遵循以下原则：如果是工作中出现的状况，那么请果断选择透明，坦诚地告知所发生的事情；如果与员工私人生活相关，那么请告诉你的员工，以你的立场不便透露，如果他们关心的话，可以直接去问当事人。</li>
<li>·只要你的能力已被大家认可，你就可以公开地告诉大家你所犯过的错误，并且鼓励各部门的负责人也这么做。这可以在整个机构内增加信任度，传达良好的意愿，同时激发员工的创新能力。</li>
</ul>
<h3 id="6-无须决策审批"><a href="#6-无须决策审批" class="headerlink" title="6 无须决策审批"></a>6 无须决策审批</h3><ul>
<li><p>从那时起，我开始意识到这种决策金字塔可能造成的弊端。我作为公司老板，肯定会有自己的观点，也很乐意和大家分享。但对于日常事务的决策，比方说买多少张光碟，我并不是最佳人选。我告诉他：“特德，你的工作不是要让我高兴，也不能因为我赞成，就做出这样的决策。你的决策应当有利于公司的发展，不能因为我的错误决定而让公司的业务受到影响！”</p>
</li>
<li><p>在大多数公司，老板都会对员工的决策进行审批。然而，这种审批方式会限制员工的创新，并阻碍公司的发展。在网飞，我们鼓励员工不要一味认同上司的决策。我们不希望员工因为上司的否定而放弃任何一个好主意。这就是我们一直强调的：工作的目的不在于取悦老板，而在于对公司有利。</p>
</li>
<li><p>对于大多数企业，无论是否实行了微观管理，员工都倾向于做出最容易获得上司青睐的决策。对此最合理的解释是：上司地位高，所以知道得多。如果你不想丢掉工作，也不想因违背上级命令而遭到指责，那你就乖乖地听话吧。</p>
</li>
<li><p>但是，这类自上而下的决策模式并不值得我们学习，因为我们相信：公司的员工有了自主决策权，效率才会更高，才会更具创新性。我们一直在努力培养员工独立的决策能力，公司高层也很少参与具体事务的决定，我们对此感到骄傲。</p>
</li>
<li><p>实行分散决策模式的前提是高人才密度和高透明度。如果尚未满足这两个条件，实行这样的决策模式恐怕只会适得其反。而一旦满足了条件，你就可以考虑逐步取消管控。你不仅可以取消假期追踪这一类管控制度，还可以取消工作环节中的种种管控，从而大幅提高员工的创新能力。</p>
</li>
<li><p>如果你的员工足够优秀，你可以把决策权下放给他们，让他们去实施那些他们相信能够带来效益的好点子。这样，创新也会随之产生。当然，对于某些产业而言，必须保证零失误。但网飞的业务并不涉及与安全相关的产业，如医疗、核能等。我们的市场就是需要创新。从长远来看，我们面临的最大危机不是犯错误，而是缺乏创新，缺乏让客户满意的娱乐创意，这将最终导致我们被市场淘汰。</p>
</li>
<li><p>如果你希望团队更富有创新性，那么，你需要教会员工自己寻求途径推动业务发展，而不是一味地讨好老板。同时，你也需要鼓励员工敢于挑战自己的上司</p>
</li>
<li><p>网飞创新过程如果你有一个令自己心动的主意，你需要：1.收集异议或者交流想法。2.对重大决策进行彻底检验。3.知情指挥要大胆下注。4.庆祝成功，正视失败。</p>
</li>
<li><p>决策不是个人成功或失败的问题，而是一个学习过程；员工通过不断地学习，就能推动业务向前发展。同时，这样的交流还可以帮助新员工，让他们敢于公开承认自己的失败，就像网飞的其他员工一样。</p>
</li>
<li><p>如果你一直抓着员工的失误不放，这无疑是断送了未来的冒险之路。这样一来，尽管员工知道你倡导分散决策，但不会再按照你所倡导的那样去做。</p>
</li>
<li><p>如果你能坦然面对失败，所有人都能受益。你之所以会成功，是因为周围的人相信你告诉了他们实情，知道你会对自己的行为负责。团队之所以会成功，是因为每位成员能够从失败中吸取教训。公司之所以成功，是因为每位员工都能清楚地认识到，失败是创新的必经之路。我们不应该惧怕失败，而应该更加坦然地去面对。</p>
</li>
<li><p>在网飞，我们与其将下注失败看作一件隐秘的事情，还不如把它看成是一个错误。当克里斯谈论曾经的失败时，无论是“探索者”还是“纪念品”，他都不会觉得尴尬。这也正是网飞所倡导的大胆思考，敢于决策。在这种情况下，你会觉得让你站在讲台上，或通过文字把自己的失败讲出来也不是什么困难的事。你会大胆地说：“看吧，我下了这样一个赌注，可结果并不如意。”</p>
</li>
<li><p>但有些错误确实会令人感到很尴尬，尤其是因为你的判断出现重大失误，或者因为疏忽大意造成的严重错误。</p>
</li>
<li><p>如果出现这种令你感到尴尬的严重失误，你难免会想到逃避责任，这样的想法在网飞也是不可接受的。面对这样的错误，你就必须更加地坦诚。只要不是经常犯同样的错误，你把它说出来，是能够获得谅解的。但是，如果你始终只字不提，然后继续犯同样的错误（你越是否认，就越容易犯同样的错误），那最终将导致更加严重的后果。</p>
</li>
<li><p>公司不会因为这种事情解雇我们的。公司解雇的是那些不敢冒险、不敢大胆采取行动的人，还有那些不愿在公开场合谈论失败的员工。”当然，再有这种媒体推广活动，我再也不敢不事先沟通了。否则，我就真的会被解雇了。我利用假期剩余的时间，向所有人讲述了我犯的错误，以及我从中吸取的教训。我写了很多备忘录，打了很多电话。我的整个假期都在曝光，但不是在希腊海滩的阳光下。</p>
</li>
<li><p>如果你的团队具有足够高的人才密度和组织透明度，那么决策过程就能够更加迅速，且更具创新性。员工可以充分发挥想象，调查论证，最后实施计划，即使遭到上级的反对也不会影响计划的进行。</p>
</li>
</ul>
<h4 id="本章要点-4"><a href="#本章要点-4" class="headerlink" title="本章要点"></a>本章要点</h4><ul>
<li>·在追求高效和创新的公司里，重大问题的决策权应当分散在各个不同层次，而不是按等级进行分配。</li>
<li>·要让这种决策模式正常运作，领导应该让员工明白这样一个原则：“工作不是为了取悦你的上司。”</li>
<li>·新员工加入公司时，告诉他们每个人都有一把下注的筹码。有些下注会成功，有些则会失败。公司看重的是员工下注的总体结果，而不是单独某一次下注。</li>
<li>·为帮助员工做出正确的决策，应鼓励他们收集异议，交流意见，对重大的决策还要进行充分的调查论证。</li>
<li>·鼓励员工即使遭遇失败，也要敢于把失败讲出来。</li>
</ul>
<h3 id="7-员工留任测试"><a href="#7-员工留任测试" class="headerlink" title="7 员工留任测试"></a>7 员工留任测试</h3><ul>
<li><p>我们公司实行分散决策的机制，也就是说，决策者寻找最佳人选，而被选择的人又继续寻找他们认可的最佳人选，依此类推，企业就得以良好地运转。特德将这种模式称作“层级选择”，这就是建立在高人才密度基础之上的生产力。</p>
</li>
<li><p>经过讨论之后，帕蒂提议我们应该把网飞想成是一支专业运动队。</p>
</li>
<li><p>把高人才密度的工作环境比作专业运动队，我觉得十分贴切，因为职业运动员都具有以下特质：·追求卓越。负责人保证每个职位在任何时候都是最佳人选。·训练就是为了胜利。教练和队员都必须不断给予和接受坦诚的反馈。·明白光有努力是不够的。记住：如果你付出了一等努力却只收获了二等成绩，你可以赢得我们的尊重与感谢，但也不得不下场休息。</p>
</li>
<li><p>在一个高绩效的团队里，精诚合作与彼此信任缺一不可，所有队员既要个人能力突出，又要灵活配合。一名优秀队员，不能仅仅个人表现卓越，还需要有无私的精神，将团队利益置于个人得失之上。他要把握传球时机，懂得如何帮助队友，明白胜利的唯一途径就是让整个团队取得胜利。这恰恰是网飞想要培养的企业文化。从这时开始，我们就在公司宣传这样一个口号：我们是一个团队，不是一个家庭。</p>
</li>
<li><p>我们认为员工留任测试适用于公司的每个人，也包括我们自己。设想一下，要是别人坐了我的位子，公司是不是会更好？我们这样做的目的是为了让离职的人不会感到羞愧。想想曲棍球这样的奥运会项目，被替换下场的球员都会感到沮丧，但他也会因其曾拥有的高超球技和过人胆识帮助球队排名第一而受到人们的尊敬。网飞的员工离职时，我们也是一样的想法。我们永远都是朋友，离开网飞并不是一件丢人的事情。</p>
</li>
<li><p>事实证明，留任测试是行之有效的，公司各级管理者都一直在坚持这项举措。我也向我的上级——董事会提议，我自己也不应该有特权，他们不必等到我犯了错误才找人取代我。只要能提高公司的绩效，他们完全可以聘用一位更有能力的首席执行官。每个季度，我都保持着积极向上的心态，为了保住自己的职位而不断学习，努力工作。</p>
</li>
<li><p>在网飞，或许你一直在兢兢业业地工作，你全身心地投入公司的发展，也确实做出了不错的成绩，然而有一天，当你走进办公室，却突然被告知自己被解雇了……这无异于一个晴天霹雳！被解雇的原因不是来势汹汹的金融危机，也不是大规模的计划外裁员，而只是你的成绩没能达到领导的期望，因为你只是做到了称职。</p>
</li>
<li><p>如果你加入一个由10个人组成的团队，你工作的第一天就会有人告诉你，无论你干得多么好，整个团队只有两个人会得到“优秀”，7个人将获得“合格”评价，而剩下的那个人就会获得“不合格”评价。这样，员工的心思都花在内部争斗上，反倒忽略了与其他公司的竞争。</p>
</li>
<li><p>据说，有一名微软的工程师也说过：人们总是大张旗鼓地阻挠他人进行努力。在微软，我学会表面上彬彬有礼，同时向同事隐瞒必要的信息，以确保他们的排名不会超过我，这是我在微软学到的最有价值的事情。</p>
</li>
<li><p>我们鼓励公司的经理们采用员工留任测试，但我们十分谨慎，并不会采取堆栈排序这样的评估手段。无论是末位淘汰制还是“后百分之几的人必须被开除”，这些都是网飞最为排斥的规定。</p>
</li>
<li><p>更为重要的是，那些手段虽然让经理开除了表现平庸的员工，但同时也扼杀了团队。</p>
</li>
<li><p>我们要的是高绩效的员工同网飞的竞争者到市场上去拼杀，而不是自相残杀。末位淘汰制提高了人才密度，却阻碍了团队的高效协作。</p>
</li>
<li><p>幸运的是，我们不需要在高人才密度和通力合作之间做出艰难抉择，员工留任测试可以实现两者兼得。其中关键的原因在于，我们并不是一个真正的职业运动队。在网飞的团队中，每个位置并没有固定员工数量，我们不是在严格的规则下开展运动项目，我们也无须限制参与的人数，没有人会因为同事的优秀而失去自己的工作。恰恰相反，我们团队中优秀的人才越多，我们就越能创造非凡的成就；成就越丰，队伍的成长就越快；队伍越大，我们能提供的职位就越多；职位增多，我们就能为高绩效人才开辟出更广阔的施展空间。</p>
</li>
<li><p>评论：[^]所以说奈飞的留任测试和通用电气、微软自己现如今在中国公司很流行的末位淘汰制的区别在于，末尾淘汰制是在团队内部进行排名，你的竞争对手是你的同事。为了不被同事甩在后面，我们就口蜜腹剑，当面一套背后一套，从不推心置腹。这样的结果就是恶性竞争，各自为战。而留任测试中，员工的竞争对手是他自己都看不到的，市场上其他公司的任何优秀员工。他们需要在整个市场上保持竞争力，才不至于被替换掉。</p>
</li>
</ul>
<h4 id="本章要点-5"><a href="#本章要点-5" class="headerlink" title="本章要点"></a>本章要点</h4><ul>
<li>·为鼓励经理们重视绩效，要教会他们运用员工留任测试思考这样的问题：“在我的团队中，如果谁告诉我他要跳槽去别的公司从事类似的工作，我是否会尽最大努力挽留他？”·避免堆栈排序制度，因为这会导致内部竞争，破坏团队协作。</li>
<li>·一种高绩效的企业文化，应该把公司看作一支职业运动队，而不是一个家庭。要让经理在团队中培养员工的责任感，让团队富有凝聚力，让员工之间充满浓浓的情谊；同时也要果断地调整人员配置，确保每个位置的员工都是最佳人选。</li>
<li>·当你意识到不得不开除某个员工的时候，不要再为他制订绩效改进计划，那样只会让当事人感到难堪，同时消耗了企业的人力物力，可以考虑把那笔钱作为遣散费直接发给他。</li>
<li>·精简机构营造了高绩效的文化，同时可能让员工感到些许恐惧。公司可以鼓励员工进行“员工留任提示”，让他直接问上司：“如果我想要辞职，你会在多大程度上挽留我？”</li>
<li>·当一名员工被解雇之后，坦诚地向其他员工公布解雇的原因，并真诚地解答他们的困惑，这会消除他们心里的恐惧，同时也能增加他们对上司、对公司的信任。</li>
</ul>
<h3 id="8-反馈循环"><a href="#8-反馈循环" class="headerlink" title="8 反馈循环"></a>8 反馈循环</h3><ul>
<li>网飞有这样一条规则：“不在背后议论别人。”我们在别人背后的评头论足越少，导致低效和负面情绪的闲言碎语就越少，我们就越能摆脱“办公室政治”的不愉快。</li>
</ul>
<h4 id="本章要点-6"><a href="#本章要点-6" class="headerlink" title="本章要点"></a>本章要点</h4><ul>
<li>·做到坦诚就像去看牙医。就算你倡议人人都要每天刷牙，也还是有些人不会这样做；有些人刷牙的时候也会漏掉一些不顺手的地方。每6~12个月进行一次彻底的检查，保证牙齿干净，保证反馈清晰。</li>
<li>·在一个坦诚的工作环境中，绩效考核并不是最好的机制，因为绩效考核获得的反馈通常都是自上而下的，而且往往都只来自一个人（老板）。</li>
<li>·360度书面反馈是一个很好的年度反馈机制，但是要避免匿名和量化评分，不要把结果和升职加薪联系起来，并且鼓励员工自愿给出公开的意见和建议。</li>
<li>·“360度面对面”晚餐同样也是行之有效的反馈手段。留出几个小时的时间，组织者给出明确的指示，遵循4A准则，使用“开始、停止、继续”三类意见和建议，给出大约25% 的肯定意见和75%的发展性意见——所有建议应该是切实可行的，不要说空话。</li>
</ul>
<h3 id="9-情景管理而非控制管理"><a href="#9-情景管理而非控制管理" class="headerlink" title="9 情景管理而非控制管理"></a>9 情景管理而非控制管理</h3><ul>
<li><p>情景管理而非控制管理。如果在别的公司，一旦涉及大笔经费的支出，公司高层一定会牢牢抓住话语权，反复讨论之后再做定夺，而网飞却并非如此。这就像亚当解释的那样：“特德不会替我做决定，但他会设定情景，帮助我考量决策是不是符合公司的战略需要，而他预设的情景正是我决策的参考依据。”</p>
</li>
<li><p>控制型管理还是情景管理？最广为人知的决策方式就是领导拍板。领导需要审批决策，指导过程，选拔人员。有时，他可能会直接告诉员工该做什么，并且经常进行检查，纠正那些与他的意图不符的做法；有时，他也会试着给员工更多的权力，用流程控制代替直接监督。</p>
</li>
<li><p>只有在条件成熟的情况下，情景管理才能发挥作用，其中首要的条件就是公司要拥有高人才密度。</p>
</li>
<li><p>要选择控制型管理还是情景管理，你需要回答的第一个问题就是“公司员工属于哪个层次的人才”。如果你的员工工作还很吃力，你就需要加强监督，不断检查他们的工作情况，确保他们做出正确的决定；假如你拥有一支高绩效的工作团队，情景管理就能让团队获得更多的自由，同时迸发出更强的创造力。</p>
</li>
<li><p>但是，到底采用控制型还是情景管理型也不完全是由人才密度决定的，你同样需要考虑行业特点和预期目标。</p>
</li>
<li><p>实现情景管理的第三个必要条件，除了高人才密度（首要条件）、创新性目标（而非错误防范性目标）之外，你还需要“松散耦合”的体制。</p>
</li>
<li><p>与之相对的是松散耦合系统，系统中各个模块没有那么紧密的联系，可以只更改特定的模块，不必重新构建基础。这就是软件工程师更偏爱松散耦合系统的原因。在松散耦合系统中，对特定模块的修改不会影响系统的其他部分，整个系统非常灵活。</p>
</li>
<li><p>在一个组织机构中，不同团队就像是电脑系统的不同组成模块。在紧密耦合型公司，大老板做出决策并自上而下层层传递，往往导致众多部门相互牵扯。一旦某个部门出现问题，反馈必须逐级上传至大老板。而在松散耦合型公司，只要确定出现的问题不会波及其他部门，经理甚至员工本人都有权自行做出决定或解决问题。如果老板的指令需要公司自上而下逐级传递，那么这个公司采用的多半是控制型管理模式，相应的就是紧密耦合型体制。在一个紧密耦合型企业中，如果想要尝试对一个部门或一个团队进行情景管理，你会发现这种体制让你寸步难行，因为所有重要的决策都是由最高层做出的。你也许想把决策权下放给你的员工，但你做不到，所有重要的事情不仅要得到你的批准，还要得到你的上司和你上司的上司的批准。</p>
</li>
<li><p>即使公司已经实现高人才密度，并且将创新作为发展目标，但若是解决不好耦合机制的问题，情景管理可能还是无法实现。</p>
</li>
<li><p>网飞就是一家采取“知情指挥”模式的松散耦合型公司。公司的决策制定权高度分散，集中控制的流程、规则或者政策也很少，这就给了员工极大的自由度，提高了部门的灵活性，加快了整个公司的</p>
</li>
<li><p>如果想要公司在松散耦合的体制中高效运转，让员工个人也能做出重大决策，那么老板和员工必须就他们的目标达成一致。只有领导和员工认识清晰，目标一致，松散耦合的体制才能发挥作用。这种一致性能够驱动员工做出决策，以完成整个组织的使命和战略任务。所以，网飞一贯奉行的准则就是：认识一致，松散耦合</p>
</li>
<li><p>当你的员工做了一些蠢事，不要指责他们。相反，你应该问问自己，你在情景设定上犯了什么错：在阐释战略目标的时候，你有没有讲得足够清晰并且让员工受到鼓舞？你有没有阐明所有的可能性和风险，从而帮助你的团队做出正确的决策？你和员工在观点和目标上有没有达成一致？</p>
</li>
<li><p>无论哪个地区，哪个行业，大多数组织机构实行的都是这种金字塔形的决策模式。这种模式包括两个方面：一方面由老板做出决定，然后自上而下逐级传达，一直落实到金字塔底端；另一方面是低级别员工只能处理细枝末节的小问题，稍大一点的问题则需要层层上报。</p>
</li>
<li><p>但在网飞，如同我们一贯所坚持的那样，知情指挥就是决策的制定者，不是任何事情都由老板决定。老板的工作是设定情景，帮助团队做出最有利于公司的决策。我们发现，这种管理模式不再像一座金字塔，而更像一棵大树。首席执行官就是树的根部，而伸展开去的知情指挥则位于树枝顶端，负责各项具体决策的制定。</p>
</li>
<li><p>一个在松散耦合的体制下运作的机构，如果具备高人才密度，而且以创新作为首要目标，那么就不建议选择传统的控制型管理模式。与其通过监管流程减少错误，不如设定清晰的情景，统一认识，确定共同的奋斗目标，同时把决策自由交给知情指挥。</p>
</li>
</ul>
<h4 id="本章要点-7"><a href="#本章要点-7" class="headerlink" title="本章要点"></a>本章要点</h4><ul>
<li><p>·要实施情景管理，你需要拥有高人才密度；你的目标应该是创新而不是防范错误；你需要构建一套松散耦合的体制。</p>
</li>
<li><p>·一切要素到位之后，不要告诉员工应该做什么，而是应该通过讨论来设置情景，达成一致，最后让他们自己去做出正确的决定。</p>
</li>
<li><p>·如果你的员工做了一些蠢事，不要指责他们。相反，你应该问问自己，你是否在情景设定上犯了什么错误？在阐释目标和战略意图的时候，你有没有讲得足够清晰并且让大家深受鼓舞？你有没有把所有的假设和风险讲清楚，从而帮助你的团队做出正确的决策？你和员工在观点和目标上有没有达成一致？</p>
</li>
<li><p>·一个松散耦合体制下的机构应该是树形联系而非金字塔形联系。老板就像是树根，延伸出高管们组成的树干，最后支撑起做出决策的枝丫。</p>
</li>
<li><p>·如果你的员工能够利用好你和你周围的人传递出来的信息，能够自己做出决定将团队带向预期的方向，那你的情景管理就取得了成功。</p>
</li>
<li><p>我们探索了提高人才密度与坦诚度的基本要素，剔除了烦琐的政策和程序，从而为员工提供更多的自由；同时，也创造了一个高效、灵活的工作环境。大多数公司都有以下政策和流程，但网飞没有：休假制度决策审批制度经费审批制度绩效改进计划审批流程加薪池关键绩效指标目标管理差旅制度委员会决策制定合同签署相关政策工资级别薪资等级绩效奖金以上政策对员工是一种管控，而不是一种激励；但没有这样一些管控措施，企业又很容易陷入混乱。因此，你需要切实地提高员工的自律意识和责任意识；帮助他们获得足够的知识以做出明智的决定；建立反馈机制以激发员工的学习主动性。这样，企业将高效运转，给我们带来大大的惊喜。</p>
</li>
</ul>
<h3 id="10-走向全球的网飞文化"><a href="#10-走向全球的网飞文化" class="headerlink" title="10 走向全球的网飞文化"></a>10 走向全球的网飞文化</h3><ul>
<li><p>我们的4A准则是：·目的在于帮助。·反馈具有可行性。·感激与赞赏。·接受或拒绝。现在再加上第五条：·调整、适应——根据你所处的文化环境，调整你提出和接受反馈的方式，以获得你所期待的效果。</p>
</li>
<li><p>在文化中庸的国家，员工进行非正式反馈的可能性不大，可以实施更为正式的反馈机制，将反馈更多地纳入正式议程。</p>
</li>
</ul>
<h3 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h3><ul>
<li>人才密度和坦诚这两个概念贯穿本书始终，是本书两个最基本的概念。</li>
</ul>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li><p>人才密度 — 大前提！</p>
</li>
<li><p>管理放权</p>
</li>
<li><p>“情景管理模式”</p>
</li>
<li><p>“人才重于流程，创新高于效率，自由多于管控”</p>
</li>
<li><p>自由是通往责任的一条途径</p>
</li>
<li><p>“心理安全”原则？</p>
</li>
<li><p>“过期作废” 鼓励休假</p>
</li>
<li><p>惊人的判断力……判断力几乎可以解决所有模棱两可的问题，而流程做不到</p>
</li>
<li><p>营造一个完全由优秀员工组成的工作环境。</p>
</li>
<li><p>坦诚的反馈；大多数人出于本能，还是能够理解真相的价值</p>
</li>
<li><p>坦诚把握不好便会尽显丑陋</p>
</li>
<li><p>厘清什么是无私的坦诚，什么是有才华的浑蛋</p>
</li>
<li><p>坦诚的文化并不意味着不加考虑地说出自己的想法。相反，每个人都需要仔细地审视一下4A准则。</p>
<ul>
<li>“还在气头上切勿发表批评意见”“在给予纠正性反馈时要注意语气平和”，等等</li>
</ul>
</li>
<li><p>创造性工作的价值不应当通过工作时长来衡量。</p>
</li>
<li><p>人们关注的是你的成果，而不是你大量的付出</p>
</li>
<li><p>休长假，领导要带头</p>
</li>
<li><p>给员工更多自由，可以使他们更具归属感和责任感</p>
</li>
<li><p>怎么花自己的钱，就怎么花公司的钱</p>
</li>
<li><p>工作分成了操作型和创造型两类。</p>
</li>
<li><p>有利于激发创造力的，是足够高的工资，而非绩效奖金</p>
</li>
<li><p>成功了小声说，犯错了大声说</p>
</li>
<li><p>情景管理</p>
</li>
<li><p>迈向自由与责任的企业文化：人才密度 -&gt;  坦诚</p>
</li>
</ul>
<hr>
<ul>
<li>评论：发展到今天，网飞的核心竞争力既不是技术，也不是运营，而是创意。创意领域和操作性领域有个最大的不同：在操作性领域，比如面包师、会计师，一流人才创造的价值可能是普通人才的两三倍；而在创意领域，比如程序员、作家、导演，一流人才创造的价值是普通人才的几十倍、几百倍。对网飞来说，聘用一流人才并不是一种高姿态，而是一种切切实实能带来更高收益的精打细算。网飞的最佳人才策略，就是花高价聘请一个明星员工，来替代掉十个资质平平的员工。</li>
<li>除此之外还有一个原因，就是网飞面对的竞争环境。虽然网飞已经是硅谷巨头，但和超级巨无霸亚马逊、苹果、脸书相比，网飞显然还不是一个量级的。现在这些巨无霸也纷纷杀入内容领域，如果网飞不能开出市场最高薪酬，那么很可能面临人才大幅流失的危险。与其坐等员工被竞争对手挖走，不如主动出击，直接开出市场最高价。这样一来，至少能够保证一流人才不会单纯为了薪酬待遇而跳槽。</li>
<li>说到这儿，你会不会觉得，天啊，网飞员工实在是太幸福了，没有绩效考核，没有末位淘汰，还能一直拿到市场最高薪酬。这样的公司谁不想去？但是你知道吗，不少网飞员工每天上班都提心吊胆，生怕被解雇，甚至有媒体说网飞是在搞“恐惧文化”。为什么呢？因为网飞的淘汰制度非常残酷。</li>
<li>评论：不拘一格，总结我认为可以参考管理的段落，有些做法还是要看公司现状</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>软技能_代码之外的生存指南_notes</title>
    <url>/2023/03/02/20230302-ruan-ji-neng-dai-ma-zhi-wai-de-sheng-cun-zhi-nan-notes/</url>
    <content><![CDATA[<h2 id="献言"><a href="#献言" class="headerlink" title="献言"></a>献言</h2><ul>
<li>谨以本书献给所有自强不息、孜孜不倦地持续自我改进的开发人员。他们具备下列素质： 永远不会对“不错”感到心满意足永远寻求每一个机会来拓展自己的视野，探索未知事物对知识的渴求永远不会熄灭笃信软件开发并不仅仅意味着编写代码。知道失败不是结束，失败只是人生旅程上的小小一步有过挣扎，有过失败，但仍然会爬起来继续战斗拥有强烈意愿和决心，在人生的道路上不畏艰难以及最重要的，愿意一路上帮助他人。</li>
</ul>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul>
<li>不能只编写代码，还要有精彩的人生。</li>
</ul>
<h2 id="第1章-为何这本书与你先前读过的任何书籍都迥然不同"><a href="#第1章-为何这本书与你先前读过的任何书籍都迥然不同" class="headerlink" title="第1章 为何这本书与你先前读过的任何书籍都迥然不同"></a>第1章 为何这本书与你先前读过的任何书籍都迥然不同</h2><ul>
<li>我所说的“优秀的软件开发人员”，是那些能够把控自己的职业生涯、达成目标、享受生活的人。</li>
<li>如果你想真正成为一个更好的软件开发人员（或者其他真正优秀的人才），你需要把重点放在整个“人”上，而不只是你生活中的一两个领域。</li>
<li>想为这些内容分类和分组，最简易的方法是将它们看成是事业、思想、身体和精神四个方面。</li>
</ul>
<h1 id="第一篇-职业"><a href="#第一篇-职业" class="headerlink" title="第一篇 职业"></a>第一篇 职业</h1><ul>
<li><p>职业发展的驱动力一定是来自个体本身。记住：工作是属于公司的，而职业生涯却是属于你自己的。</p>
</li>
<li><p>当你为了谋生一头扎进写代码的世界时，其实你和中世纪小镇上开铁匠铺的铁匠没什么差别。</p>
</li>
<li><p>当你和别人打交道的时候，你应该知道的最重要的一个概念就是：以自己为核心，每个人都希望自己很重要。这是人类最深邃、最致命的欲望之一，也是社会和生活中取得伟大成就的主要动机。</p>
</li>
</ul>
<h3 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h3><ul>
<li><p>与主流观念相反，大多数面试官决定雇用某个人其实是基于各种各样的非技术因素。</p>
</li>
<li><p>简而言之，通过面试的最快捷的方式是让面试官对你怀有好感。达成该目标有很多方法，其中大多数可以在面试之前完成。</p>
</li>
<li><p>“破解”面试的要诀就是在面试开始之前就思考应对面试的策略。</p>
</li>
<li><p>与雇用技术高超但需要生拉硬拽才能干活的人相比，我宁愿雇用这样的开发人员：知道的东西可以少一点，但是明确知道要做什么，以及怎样去做。从某种程度上，在你可控的范围之内，面试的时候你要集中精力证明自己就是无需督促也能自动自发做好事情的员工。</p>
</li>
<li><p>你还必须要证明：在技术上你确实胜任工作。同时，如果你能说服面试官相信你非常能干，不会被困难阻挡，那么他们不仅会喜欢你，而且更有可能会录用你。</p>
</li>
</ul>
<h3 id="专业化"><a href="#专业化" class="headerlink" title="专业化"></a>专业化</h3><ul>
<li><p>专业化的规则是：专业化程度越深，潜在的机会就越少，但获得这些机会的可能性越大。</p>
</li>
<li><p>做一个技术全面、多才多艺的软件开发人员非常棒。能够使用多项技术和多种编程语言，有助于你的职业发展，能让你比那些仅了解一项技术或一种编程语言的软件开发人员更有价值。然而，这种“万金油”式的人才在市场上并不吃香。</p>
</li>
<li><p>从薪资和福利的角度评价一个潜在的工作机会是很容易的，但是从长期发展和工作环境的角度去评价可能对你更为重要。</p>
</li>
</ul>
<h3 id="大中小公司"><a href="#大中小公司" class="headerlink" title="大中小公司"></a>大中小公司</h3><ul>
<li><p>在为一家大公司工作时，你会注意到的最大的事情也许就是那里大量的规范和流程。</p>
</li>
<li><p>在大公司工作时，你要遵守这里已有的做事方式。鲁莽和“变节者”在这种企业文化里不受欢迎。</p>
</li>
<li><p>在大公司里倒是很容易就隐藏在芸芸众生之中。在我曾供职的几家大公司里里，有一些开发人员基本上终日无所事事，除非赶上一轮全公司范围内的大裁员，否则根本不会有人注意到他们。不过，这种自主权也可以被善加利用。你能够去琢磨自认为重要或有趣的项目，无需背负产品压力。</p>
</li>
<li><p>如果公司的业务重心并非软件，那自然也不会给软件开发人员足够的尊重和发展空间。这些公司的软件开发实践极有可能非常松散。</p>
</li>
<li><p>另一方面，那些以软件开发为生的公司则会更重视自己雇用的软件开发人员的价值。他们的工作环境不一定会更好，但会大不一样。</p>
</li>
<li><p>在推行敏捷软件开发方法的时候，这两类公司之间的差异非常明显。软件为非核心业务的公司在采用敏捷过程中困难重重，这是由于敏捷过程通常是由开发团队驱动的。敏捷过程需要自上而下地采纳推行，但是仅仅因为一些开发人员认为敏捷是个好主意，就让公司改变自己的做事风格，异常困难。</p>
</li>
</ul>
<h3 id="突颖而出"><a href="#突颖而出" class="headerlink" title="突颖而出"></a>突颖而出</h3><ul>
<li><p>在任何公司里能让你脱颖而出的最重要法宝就是承担更多的责任。</p>
</li>
<li><p>没有人愿意涉足的领域是搜寻机会最好的地方。</p>
</li>
<li><p>如何能让自己承担更多责任<br> 有一个不受重视的项目，你能去负责它吗？<br> 你能帮助团队里的新人快速成长吗？<br> 你能负责文档制作流程，并保证及时更新这些文档吗？<br> 哪项工作是没有人愿意去做，你愿意承担起来，并将其简化或者自动化的？</p>
</li>
<li><p>如何令自己引人注目<br>每天都记录自己的活动日志——把这个日志以周报的形式发送你的经理。<br>提供演讲或培训——选择一个对你的团队有用的话题。<br>发表意见——只要在会议上就这么做，或者只要你能得到的机会就这么做。<br>保证“曝光度”——定期与老板会面，确保你经常被注意到。</p>
</li>
<li><p>在任何公司中，最有用的就是那种看似没有克服不了的障碍的人。</p>
</li>
<li><p>有时候只要意识到自己的工作毫无前途，就需要寻找更好的机会。也许你的工作环境很艰苦，残害身心，也许裙带关系盛行，你只能原地踏步。无论什么原因，你可能都需要换工作了。</p>
</li>
</ul>
<h3 id="成为专业人士"><a href="#成为专业人士" class="headerlink" title="成为专业人士"></a>成为专业人士</h3><ul>
<li><p>成为专业人士是一种心态。如果我们总是与恐惧、自毁、拖延和自我怀疑作斗争，那么问题就是：我们正在像外行那样思考问题。外行毫不起眼，外行人废话连篇，外行屈从于逆境。专业人士可不这么想。不管怎样，他引人注目，他恪尽职守，他始终如一。</p>
</li>
<li><p>成为专业人士的全部在于：引人注目，恪尽职守，以及不屈服于挫折。</p>
</li>
<li><p>专业人士会严肃对待自己的责任和事业，愿意作出艰难的选择去做自己认为是正确的事情——往往还要自己承担代价。</p>
</li>
<li><p>作为一名专业人士需要养成的另一个强大的习惯是时间管理技能。</p>
</li>
<li><p>有时候，专业人士必须对工作的优先级做出艰难的抉择。</p>
</li>
<li><p>专业人士会评估需要完成的工作，判定优先级后再开始工作。</p>
</li>
<li><p>专业人士是通过持续不断的自我完善达到自己所追求的高品质的。</p>
</li>
</ul>
<h3 id="为自己工作"><a href="#为自己工作" class="headerlink" title="为自己工作"></a>为自己工作</h3><ul>
<li><p>如果想辞职为自己打工，需要一个切实可行的计划。你必须要想方设法积攒够足够多的收入来支撑自己，直到你的新生活步入正轨。</p>
</li>
<li><p>如果你想让自己的产品也同样成功（虽然也许在规模上达不到），首先打造一个成功的博客，使用播客、演讲、视频和其他媒体来发展自己的受众。接下来，一旦你有了受众，你就能够向这些受众销售自己的产品。你之所以购买这本书可能就是因为你已经是我博客的粉丝，或者因为关注我的其他工作而无意中发现这本书，或者你之前听过我的播客。这就是发展自己的受众的威力。</p>
</li>
<li><p>你必须明白并意识到，自己的首次创业可能会失败，很可能第二次、第三次也是如此。直到经过足够多的失败，你才可能真正成功。如果你倾尽所有投入创业，如果你为一次创业成功赌上自己的整个未来，你可能会把自己置于绝境——没有资源，甚至没有意志再去尝试一次。所以别这么做。从小处着手，作为副业开发你的第一个产品。</p>
</li>
<li><p>我们不能过分相信自己可以不受外界干扰或者能够智慧地管理时间。我们需要提前做好计划，否则会屡屡经受不住诱惑。</p>
</li>
</ul>
<h3 id="对技术保持开放"><a href="#对技术保持开放" class="headerlink" title="对技术保持开放"></a>对技术保持开放</h3><ul>
<li><p>如果你能让自己不成为某种技术的信徒，你会在职业生涯之路上走得更远。</p>
</li>
<li><p>没有理由去强烈坚持自己选择的技术就是最好的，而轻视甚至无视其他技术。如果固执己见，最终受损失的是你自己。</p>
</li>
<li><p>另一方面，如果你愿意技术保持开放的心态，而不是固守在自己已经了解的技术，声称它是最好的，你会发现有更多的机会为你敞开大门。</p>
</li>
</ul>
<h1 id="第二篇-自我营销"><a href="#第二篇-自我营销" class="headerlink" title="第二篇 自我营销"></a>第二篇 自我营销</h1><ul>
<li><p>营销就是一场争夺人们注意力的竞赛。</p>
</li>
<li><p>营销追求的是“实现价值在先，要求回报在后”。</p>
</li>
<li><p>自我营销的正确方式就是为他人提供价值。</p>
</li>
<li><p>只要营销得法，即便是“菜鸟”或者“业余爱好者”的身份都是你的优势所在——很多人都喜欢向只比自己稍微优秀一点点的人学习，因为这些人才是可望而又可及的。</p>
</li>
<li><p>自我营销的基本机制是，要想让人们追随你、倾听你，你就要带给他们价值：你能为他们的问题提供答案，甚至是给他们带去欢乐。如果你在持续自我提升的同时并没有给他人带来价值，那么你终究不会走得太远，因为每个人都会离你而去。</p>
</li>
<li><p>要打造一个品牌，你需要四个要素——品牌所要传递的信息、品牌的视觉符号、品牌的一致性和品牌的曝光率。</p>
</li>
</ul>
<h3 id="打造自己的博客"><a href="#打造自己的博客" class="headerlink" title="打造自己的博客"></a>打造自己的博客</h3><ul>
<li><p>即使你对上面提及的博客能带给你的所有好处都打了折扣，有一个好处是你无法轻易抹杀的——提高你的沟通技巧。组织自己的思想，并将其转化为文字，是一项颇具难度却也极具价值的技能。</p>
</li>
<li><p>定期写作能帮助你打磨此技能，有了很好的沟通能力会让你在生活的诸多领域受益。此外，如果你能约束自己定期更新博客，你也就在持续刷新自己的技能，保证自己处于自己所在专业领域的前沿。</p>
</li>
<li><p>作为软件开发人员，学习如何写博客实际上都能帮你写出更好的代码，因为你能更轻松地传达自己的意图。博客还能帮你更好地传达自己的想法，令想法更有说服力。</p>
</li>
</ul>
<h3 id="为他人增加价值"><a href="#为他人增加价值" class="headerlink" title="为他人增加价值"></a>为他人增加价值</h3><ul>
<li><p>不要努力成为一个成功的人，而要努力成为一个有价值的人。——阿尔伯特·爱因斯坦</p>
</li>
<li><p>当你营销自己的时候，如果你所做的一切都只是为了自己的利益而不给别人带来真正的价值，那么即使你所做的都正确无误，那也无济于事。</p>
</li>
<li><p>人们最关心的还是自己。没人想听到你的成功故事，也不想知道为什么他们要帮你获得成功，但是他们肯定想听到你会怎样帮他们获得成功。所以，要想让自我营销的所有努力奏效，基本的方法就是帮助他人获得成功。</p>
</li>
<li><p>免费内容比付费内容更容易被分享。你撰写博客、制作视频或者播客，然后将这些内容免费提供，与收费内容相比，人们更可能会分享和传播这些免费的内容。分享免费内容就跟在Twitter上发链接或发邮件一样简单。与付费内容相比，免费内容能让你触及更多的目标受众。</p>
</li>
<li><p>虽然免费做这些事情看起来是在浪费时间，但是你要把它视为对未来的一项投资。通过为人们创造价值并且免费提供这种方式自我营销，你就赢得了为他人提供价值的声誉，也为自己的未来创造了机会。这种声誉的价值是无法衡量的。它能帮你赢得更好、更高薪水的工作，获得更多的客户，或者成功地发布一款产品。</p>
</li>
<li><p>你很容易落入这样的陷阱：一直谈论自己并试图证明自己价值连城。然而，你会发现，能解决他人的问题，真正能够帮到他人，你更容易获得成功。</p>
</li>
<li><p>帮助他人实际上就是在帮助自己获得成功。</p>
</li>
</ul>
<h3 id="克服恐惧"><a href="#克服恐惧" class="headerlink" title="克服恐惧"></a>克服恐惧</h3><ul>
<li><p>如果你真的想在自我营销方面获得成功，你就一定要学着克服我们大多数人都会有的一种恐惧——看起来像个傻瓜。</p>
</li>
<li><p>如果你想成功，你必须要学会收起自己脆弱的自尊心，勇敢走出去，别害怕让自己出丑。</p>
</li>
<li><p>在我的职业生涯中，我一共错失了9000多次投篮，输掉了近300场比赛。我本来有26次绝杀的机会却投球不进。我失败了一次又一次。这就是我能够成功的原因。——迈克尔·乔丹</p>
</li>
</ul>
<h1 id="第三篇-学习"><a href="#第三篇-学习" class="headerlink" title="第三篇 学习"></a>第三篇 学习</h1><ul>
<li><p>教育就是当一个人把在学校所学全部忘光之后剩下的东西。——阿尔伯特·爱因斯坦</p>
</li>
<li><p>软件开发人员可以学到的最重要的一项技能就是自我教育能力。</p>
</li>
<li><p>无论如何，学会学习是自我教育的核心技能。</p>
</li>
<li><p>最好的方法就是付诸于实践，如果你也能承担将自己所学的内容教给别人的任务，那么你会理解得更深刻。所以，你在自我教育方面的努力，应该聚焦在如何让自己切实参与，并且尽早付诸实践。</p>
</li>
<li><p>我觉得学习知识的最好方式就是立即将其用于实践，即使你还不知道自己在做什么。</p>
</li>
</ul>
<h3 id="让学习玩起来"><a href="#让学习玩起来" class="headerlink" title="让学习玩起来"></a>让学习玩起来</h3><ul>
<li><p>如果关于某个主题你能够获得足够的知识能够操作，你就可以发挥自己心灵深处强大的创造力和好奇心。当我们能够在一件事情上尽情发挥的时候，我们的内心就更倾向于吸收更多的信息，思考更有意义的问题。这似乎有些奇怪，但事实的确如此。</p>
</li>
<li><p>本方法的关键指导原则是通过玩儿、探索以及将自己所学教给他人来学习。这一简便易行的方法更符合我们的天性——在某种程度上，抛弃了“填鸭式教学”的自主学习才是最简单和最纯粹的学习方式。</p>
</li>
</ul>
<h3 id="如何快速学习"><a href="#如何快速学习" class="headerlink" title="如何快速学习"></a>如何快速学习</h3><ul>
<li><p>我发现，为了能够掌握一门技术，我需要了解以下三个要点。<br>1．如何开始——要想开始使用自己所学的，我需要掌握哪些基本知识？<br>2．学科范围——我现在学的东西有多宏大？我应该怎么做？在开始阶段，我不需要了解每个细节，但是如果我能对该学科的轮廓有大致的了解，那么将来我就能发现更多细节。<br>3．基础知识——不止在开始阶段，要想使用一项特定的技术，我需要了解基本的用户案例和最常见的问题，也需要知道自己学的哪20%就能满足80%的日常应用。</p>
</li>
<li><p>熟知了这三个关键点后，我可以高效地学习一门技术，无需通晓全部细节。我发现，如果我了解三项主题——如何开始，我能做什么，以及相关基础知识，那么我就能随着学习深入学会所需的其他知识。</p>
</li>
<li><p>如果我想提前掌握所有知识，那只是在浪费时间，因为真正重要的内容会湮没在那些细枝末节中。</p>
</li>
<li><p>这种新方法能让我关注重点。当我确实需要了解更多细节时，我可以利用参考资料来弥补这些不足。</p>
</li>
<li><p>“十步学习法”的基本思想就是：要对自己要学的内容有个基本的了解——了解自己不知道什么就足矣。然后，利用这些信息勾勒出学习的范围，即需要学哪些内容，以及学成之后又会获得什么。依靠这些知识，你可以找出各种资源（不局限于书）来帮助自己学习。最后，你可以创建自己的学习计划，列出要去学习哪些相关课程，筛选学习材料，只保留能帮助自己达成目标的优质内容。</p>
</li>
</ul>
<h3 id="“十步学习法”体系"><a href="#“十步学习法”体系" class="headerlink" title="“十步学习法”体系"></a>“十步学习法”体系</h3><p><img src="/2023/03/02/20230302-ruan-ji-neng-dai-ma-zhi-wai-de-sheng-cun-zhi-nan-notes/%E5%8D%81%E6%AD%A5%E5%AD%A6%E4%B9%A0%E6%B3%95.jpg"></p>
<ul>
<li><p>一旦完成这些工作，你对自己要学什么和怎样学都了然于胸，你就可以把控自己的学习计划中的每个关键点，通过“学习—实践—掌握—教授”（Learning, Doing, Learning and Teaching，LDLT）的过程，获得对该学科的深刻理解，同时你也向着自己的目标前进。</p>
</li>
<li><p>“十步学习法”的第一部分是研究，它是一次性完成的。但是从第7步到第10步则是重复的过程，贯穿于你的学习计划的各个模块。这个方法非常奏效，因为它迫使你提前明确自己的学习目标，也持续不断的激励你通过实践（而不仅仅是读书或听讲座）向着目标前进。</p>
</li>
<li><p>通过“聚焦学习范围，让你关注重点内容”来学习的一种快速学习方法，它迫使你通过“自我探索”和“主动教学”的方式将真正重要的内容印刻在自己的大脑中。</p>
</li>
<li><p>在学习过程中，大家很容易犯的一个错误就是试图解决太大的问题而把自己搞得不堪重负。</p>
</li>
<li><p>你无需提前了解全部内容，你要做的首要的一件事情就是亲自操作和亲身体验。</p>
</li>
<li><p>采用这种方法，你通过探索和实践进行学习。</p>
</li>
<li><p>把那些暂时还没有答案的问题记录下来，你在下一步中会有机会找出这些问题的答案。</p>
</li>
<li><p>不要害怕回头再去操作，付出更多，因为这不仅能让你找到问题的答案，也能让你学到新东西。给自己足够多的时间去深入理解自己的主题，你可以阅读，可以实验，可以观察，也可以操作。</p>
</li>
<li><p>不过请记住，你依然没有必要把收集到的所有资料全部仔细看一遍。你只需要阅读或观看与当前所学相关的部分。我们很少能有足够的时间把一本书从头读到尾。</p>
</li>
<li><p>这些资料只是帮你自学，基本上你可以以解决在动手操作中发现的问题为主要目的。</p>
</li>
<li><p>做导师的好处<br>帮助他人时的成就感。<br>深入学习和领悟知识的途径。<br>你的徒弟有朝一日会帮到你。<br>自身的成长。<br>帮助别人成长的过程也就是自己成长的过程。</p>
</li>
<li><p>学习知识的一大方法，或许是唯一可以做到深入学习的方法，就是传道授业。</p>
</li>
<li><p>知识短板会阻碍你进步。准确识别它们的最佳方式之一就是看看自己在哪些工作上花费了大量的时间，或者一直进行重复性劳动。通常，你会发现，自己的知识短板使工作速度放缓，额外需要大量的时间完成任务。</p>
</li>
<li><p>另一种识别知识短板的方法就是，时刻都要试图了解自己不理解或不清楚的事物。你可以维护一份清单，列出自己需要去研究或者自己不清楚的所有事物，追踪有哪些主题总是不断出现在这个清单上。你会惊讶地发现这份清单的增长速度有多快。你只要对自己坦诚：如果遇到不理解的知识，不需要马上就学会，但是一定要把它添加到清单中，这样你至少可以找出自己的知识短板。</p>
</li>
<li><p>假如你在准备面试，需要明确自己要学什么，这一方法最管用。尽量找出尽可能多的你在面试中可能会被问到的问题。</p>
</li>
<li><p>检查知识短板</p>
</li>
</ul>
<p><img src="/2023/03/02/20230302-ruan-ji-neng-dai-ma-zhi-wai-de-sheng-cun-zhi-nan-notes/%E7%9F%A5%E8%AF%86%E7%9F%AD%E6%9D%BF.jpg"></p>
<h1 id="第四篇-生产力"><a href="#第四篇-生产力" class="headerlink" title="第四篇 生产力"></a>第四篇 生产力</h1><ul>
<li>产量多只表明生产效率高，只有完成正确的工作才会成为高效的人。</li>
</ul>
<h3 id="一切始于专注"><a href="#一切始于专注" class="headerlink" title="一切始于专注"></a>一切始于专注</h3><ul>
<li><p>想要达到专注工作的状态很难，但是一旦进入专注状态，就能轻松保持。</p>
</li>
<li><p>要进入专注模式，必须要克服将自己的思绪集中于单一任务时的那种痛感。除非你完全享受完成这项任务，否则这种痛感一开始会很强烈。但是，这正是关键所在。你必须要意识到，这种痛苦和不适只是暂时的，不会持续很久。</p>
</li>
</ul>
<h3 id="工作计划"><a href="#工作计划" class="headerlink" title="工作计划"></a>工作计划</h3><ul>
<li><p>我的计划都是从“季度”开始的。我把我的一年分成4个季度，每个季度3个月。在做季度计划时，我会尽力列出我想在本季度完成的每一个大项目，我还会制订一些较小的目标。我会思考我在每一周或每一天分别完成哪些工作。</p>
</li>
<li><p>每个月的第一天我会打印出当月的月历，并且规划出每天要完成的工作。</p>
</li>
<li><p>每个月我都会将该月要完成的所有任务列入计划。</p>
</li>
<li><p>每周一的早晨，我会做我的周计划。</p>
</li>
</ul>
<h3 id="番茄工作法"><a href="#番茄工作法" class="headerlink" title="番茄工作法"></a>番茄工作法</h3><ul>
<li><p>它的基本思路是：你规划出打算一天之内完成的工作，然后设置一个时长25分钟的定时器，去完成计划中的第一项任务；在这25分钟之内，你只专注于这一项任务，心无旁骛。一旦有干扰，可以用各种方法屏蔽掉干扰，但是通常你要努力保证自己完全不被打扰。总之，你不希望自己的专注的工作状态被打断。</p>
</li>
<li><p>在25分钟结束的时候，设置一个5分钟的定时器，休息一下。这就是所谓的一个“番茄钟”。每4个番茄钟后，你都需要休息一会儿，通常为15分钟。从技术上讲，如果提前完成任务，你应该将剩余时间设置为“过度学习”时间。也就是说，你需要继续对已完成的工作做出小幅改进，或者重新阅读材料以便于你能够再学一些新东西。我往往会忽略这部分，立即跳转到下一个任务。</p>
</li>
<li><p>这就是“番茄工作法”的基本流程。它就是这么简单。弗朗西斯科最初使用了一个番茄形状的厨房定时器给自己设置番茄钟</p>
</li>
<li><p>第一次使用番茄工作法的时候，我并没有严格做到它规定的要求。我只是每天用它来设置若干个“25分钟”的番茄钟。我并没有留意自己每天完成了几个番茄钟，也没有估算某项任务要用掉几个番茄钟；因此我并没有从中受益。</p>
</li>
<li><p>有一个大问题一直困扰着我：我总为自己没有做更多的事情而感到内疚。这与我一天完成多少工作无关，就好像我永远不能放松似的。我总觉得自己应该在做事，以至于坐下来玩游戏（我最喜欢的消遣之一）时我都无法享受其中，因为我觉得自己在浪费时间，我本应该做更多的工作。也许你也有同感。</p>
</li>
<li><p>这个问题的根源在于，你无法准确地评估每天到底自己完成了多少任务，也没有为自己每天到底要完成多少任务设定明确的目标。</p>
</li>
<li><p>制订任务列表全凭主观臆断，每天能够专注完成的工作量才是最重要的。</p>
</li>
<li><p>这正是番茄工作法的真谛之所在。当你在一天中为自己设置了x个番茄钟的工作目标（这一目标你完全可控）并且达成的时候，你就可以知道自己一天到底可以完成多少工作，这会让自己感觉良好，更重要的是，还能让自己放松身心。</p>
</li>
<li><p>对番茄工作法的正确理解令我的工作生活大为改观，它不仅能帮我能做更多事情，而且能让我可以尽情享受业余时间。一旦我完成了当天的目标（以番茄钟来度量的），我就可以自由自在地做自己想做的事情。</p>
</li>
<li><p>如果我觉得自己状态不错，我可能还会多做一些工作。但是，如果我想坐下来玩游戏，甚至看电影消磨时间，或者其他不费脑子的活动，我也不会感到内疚，因为我知道我已经努力工作一整天了。</p>
</li>
<li><p>如果你使用番茄工作法度过充实的一天，你完成的工作的要比平常完成的多很多。好消息是，你的生产效率更高；坏消息则是，你需要花一段时间才能适应它（我没骗你）。</p>
</li>
<li><p>我一周的目标是50～55个番茄钟。如果我可以达成目标，我就知道自己做得很好，也能希望每周都能持续改进目标。</p>
</li>
<li><p>如果你也打算采用番茄工作法，要先确保你对自己的能力有符合实际的预期。你每周工作40小时并不意味着你能完成80个番茄钟。（如果你能实现这一壮举，我会大吃一惊的。而且，坦白讲，我会担心你的心理健康。）</p>
</li>
<li><p>每人每天能够专注地、富有成效地工作的时间是有上限的。你的时间只有这么多，要怎么利用你自己说了算。</p>
</li>
</ul>
<h3 id="定额工作法"><a href="#定额工作法" class="headerlink" title="定额工作法"></a>定额工作法</h3><ul>
<li><p>我用“定额工作法”确保自己每天、每周都朝着自己最重要的目标取得明确的、可度量的进展。</p>
</li>
<li><p>我开始意识到，要想确保自己在追求目标的道路上获得持续的进展，唯一的方法就是确立一个明确的目标，规定自己要在预先确定的时间段内需要取得多大的进展。</p>
</li>
<li><p>实行定额制后，我发现自己的工作成果比以往多了很多。最大的好处在于，长期坚持这么做，我就能随着时间的推移度量并标记自己的进度。我可以确切知道自己在给定的一段时间内能够完成的工作量。</p>
</li>
<li><p>承诺是“定额工作法”的核心。除了想方设法完成自己的工作，不给自己留下任何其他的选择。在你心中，失败不是一个可以被接受的选项。因为如果你让自己失信一次，就会有第二次，很快定额在你眼中就会变得一文不值。</p>
</li>
<li><p>如果你的承诺力度不够，“定额工作法”顷刻就会分崩离析，所以你必须选择可实现、可持续的定额。不要对自己承诺自己明知不可能达到的目标，否则你就把自己逼入注定失败的绝境。开始的时候承诺可以小一点，在能够达成之后再逐步做大胆的承诺。</p>
</li>
<li><p>定额工作法的规则<br>挑选一项重复性任务。<br>明确有效时限，在此期间该任务被重复执行。<br>明确在给定的有效时限内该任务应该完成的次数的定额。<br>给自己承诺：一定要达成定额。<br>调整。调高或者调低定额，但是不能在有效时间段之内调整。</p>
</li>
<li><p>定额工作法成功的秘密可以追溯到“龟兔赛跑”的故事。以缓慢但稳定的节奏工作，要优于快速但缺乏持久和坚持的工作方式。</p>
</li>
<li><p>定额工作法还可以帮你克服意志力薄弱的问题，通过预先设定好的必须要遵循的过程，消除需要做出决策的部分。因为已经预先承诺在规定时间段内完成同一任务很多次，所以就不需要再判断要不要做某事——你知道必须要做。每一天，任何需要做决策的时刻，你都不得不被迫动用自己仅存的有限的意志力。以定额的形式将决策转变为命令，你无需再做决策，也就避免了意志力耗尽的问题。关于这一主题，可参考Kelly Mc Gonigal写的《自控力》</p>
</li>
<li><p>采取行动<br>列出自己生活中需要重复做的所有任务。特别要专注于那些目前你还无法持续完成但一旦完成就会从中受益的事情。<br>选择至少一项任务，承诺在规定时间段内要完成的额度。认真对待这一承诺，试着坚持至少5个时间段。想象一下，如果自己能坚持几个月或几年，会发生什么。</p>
</li>
</ul>
<h3 id="对自己负责"><a href="#对自己负责" class="headerlink" title="对自己负责"></a>对自己负责</h3><ul>
<li><p>让人们完成工作主要有两大动机——内部动机（来自内心的动机）和外部动机（来自外部奖励或惩罚的动机）。</p>
</li>
<li><p>内部动机要比外部动机有效得多。在内部动机的激励下工作时，我们能完成更多的工作，也更倾向于把工作做得更好。所以，秘诀是让你的主要动机来自内心而非外部。</p>
</li>
<li><p>培养出在没有人监督自己的时候也能高效工作的自我责任感非常重要。</p>
</li>
<li><p>要培养“对自己负责”的精神，首先要让自己的生活井然有序。</p>
</li>
<li><p>你可能会发现，只对自己负责的时候很容易违反自己制订的规则。在这种情况下，需要借助一点儿外力。你仍然可以制订自己的规则，因此动机还是来自内部——因为你还是规则的制订者，只是你可以让别人帮你强制执行这些规则。</p>
</li>
<li><p>请别人来监督自己履行责任，完成自己的承诺，并没有坏处。找到责任监督伙伴——理想情况下，最好是跟你有类似目标的人，这样会很有帮助。你可以告诉他你给自己制订的规则，或者你想达成的目标，通过定期互相汇报进度（不论成败），可以互相帮助对方强化责任感。</p>
</li>
<li><p>通常，想到要告诉自己的责任监督伙伴自己没能完成设定的目标，就足以阻止自己不够自律的行为。</p>
</li>
<li><p>采取行动<br>抉择一下：你想如何度过自己的一生。花点儿时间创建一些自己的规则，确保自己朝着正确的方向前进。<br>创建自己的责任制度，帮助自己严格执行规则。</p>
</li>
</ul>
<h3 id="是否多任务并行"><a href="#是否多任务并行" class="headerlink" title="是否多任务并行"></a>是否多任务并行</h3><ul>
<li><p>有的任务适合多任务并行，有的则不适合。如果你真想最大限度地提升自己的工作效率，就必须知道什么时候需要多任务并行，什么时候不需要，以及如何高效地进行多任务并行。</p>
</li>
<li><p>对于很多活动，我们可能会自认为是在进行多任务并行，但实际上我们做的不过是在不断地进行任务切换。这样的任务切换看起来确实是工作效率下降的罪魁祸首。任务切换越多，浪费的时间也就越多，因为你的大脑并不能专注于一项任务。</p>
</li>
<li><p>如果你认为自己出于专注状态时工作效率最高，且需要花些时间才能到达这种状态，你就能明白，在各种任务间快速切换并不会提高效率。</p>
</li>
<li><p>真正的多任务并行使我极大地提升了自己的生产力。如果你可以将两项任务组合起来，并且真正做到同时处理它们两个，你才能完成更多。诀窍在于搞清楚哪些任务可以被真正组合起来而不会降低单独执行每项工作的生产效率。</p>
</li>
<li><p>我发现，最有可能的就是，将一项不费脑筋的任务和一项一定程度上需要精神专注才能完成的任务组合起来。现在，我正一边听着耳机里的音乐一边打字写这一章。当然，听音乐本身并不是一项富有成效的工作，不过事实证明，在写作的时候听音乐能让我比单纯写作更富有成效。音乐似乎能让我写作更流畅，还能帮我减少其他会分散注意力的外界干扰。</p>
</li>
<li><p>再来一个更有效率的例子？我通常会尝试把体育运动与培训活动组合在一起。在健身房跑步或举重的时候，我经常会听有声读物或者播客。我发现，一边做健身活动一边听一些培训材料没有任何负面影响。通过一边健身一边听有声读物，我已经读完了很多书。</p>
</li>
<li><p>采取行动<br>停止任何并非真正的多任务并行的多任务并行。每天力争在一个时间段内只做一件事。番茄工作法对此有很大帮助。<br>一次性批量处理小任务，而不是每天或每周里做许多次。<br>找出能够真正实现多任务并行的领域。任何不需要耗费脑力的活动都可以跟其他活动结合起来。只要进行任何需要耗费脑力的活动，就将其与体育运动结合起来。</p>
</li>
</ul>
<h3 id="职业倦怠"><a href="#职业倦怠" class="headerlink" title="职业倦怠"></a>职业倦怠</h3><ul>
<li><p>提高生产力的最大障碍之一就是身体和心理上的倦怠。</p>
</li>
<li><p>项目刚开始的时候，我们总是热情高涨、精力旺盛，但是一段时间之后，即便我们再有激情，一想到它们也会让我们反胃。</p>
</li>
<li><p>如果能咬紧牙关坚持到底，如果能穿越那堵墙战胜自己，最终你会发现，简单地无视它的存在，你的倦怠感已经不治而愈。经历痛苦就是克服倦怠的秘诀。你以后还会撞到更多的墙，但每穿越它一次，你将会体验到全新的动力、充沛的活力。另外，你的竞争者的数量会越来越少。</p>
</li>
<li><p>本质上，你需要为自己创建一套确保自己继续前行的规则。<br>你需要突破这堵墙就以写这本书为例。刚开始动笔的时候我兴奋极了，想不出来有什么能比坐下来整天写“自己的书”更有趣的事情了。但是，没过多久这种新鲜感就消失殆尽。但是，你能读到这本书就证明我已然坚持到了最后。我是如何在动力和兴趣消失殆尽的时候坚持到底的呢？我为自己设定了一个时间表，并且坚决执行。无论刮风下雨，无论自己感觉如何，我都坚持每天写完一章。有些日子还会多写一点儿，但是总是保证至少一章。你可以采用类似的方法来帮自己突破阻挡了你的那堵围墙。想学会弹夏威夷四弦琴？每天留出一定的时间练习。在上第一堂课之前就制订好这样的计划——那时你的兴趣和动机都处于最高点。当你不可避免地撞到这样一堵墙的时候，这个计划能帮助你穿过它。</p>
</li>
<li><p>采取行动<br>想一想以前都有哪些项目是你付出努力却没有最终完成而半途而废了。是什么原因让你放弃的？你现在对这件事儿有什么感受？<br>下次开始新项目的时候，下定决心：你一定会完成，或者完全掌握。设定规则和约束条件，强迫自己穿过那堵不可避免的墙。<br>如果你正面临职业生涯或者个人生活中的一堵墙，试着去穿越它。想想在墙的另一侧会有怎样的收获等着你。想象自己的动机和兴趣终将获得回报。</p>
</li>
</ul>
<h3 id="时间杀手"><a href="#时间杀手" class="headerlink" title="时间杀手"></a>时间杀手</h3><ul>
<li><p>一些常见的时间杀手<br>看电视。<br>社交媒体。<br>新闻网站。<br>不必要的会议。<br>烹饪。<br>玩电子游戏（尤其是网络游戏）。<br>工间喝咖啡休息。</p>
</li>
<li><p>地雷：烹饪、工间喝咖啡休息或者其他你喜欢做的事情是在浪费时间吗？也是也不是。答案取决于你为什么做这些事情。为了享受快乐有意识地做这些事情，就不是浪费时间，只要你是因为喜欢才特意做这些事情，而不是为了逃避自己应该完成的实际工作。我曾经把玩电子游戏视为浪费时间，但是我喜欢玩电子游戏。这是否意味着我要完全放弃玩电子游戏呢？不是的。但是，当我有任务需要完成的时候，我就不能玩电子游戏。我不能用玩电子游戏来逃避自己本该完成的工作。同样的原则也适用于烹饪。也许你喜欢烹饪，为自己制作健康美食。如果是这样，那就太棒了。但是，如果你不特别喜欢烹饪，却要耗费大量时间来准备简单的一餐，那你就需要找出其他的健康饮食的方法来减少用于烹饪的时间。我的目的不是让你抛弃生活中的喜好，只是确保你没有把时间浪费在一些没必要做或者不那么喜欢做的事情上，或者吞噬掉你所有业余时间的事情上。</p>
</li>
<li><p>采取行动<br>下一周，你精心地跟踪一下自己的时间花费情况。获取精确的数字，了解每天的每小时你都是怎样花掉的。看看数据，找出你最大的2～3个时间杀手。<br>如果你有看电视的习惯，尝试离开电视一周，即尝试度过一个“无电视周”，看看如果不看电视你都会做些什么。<br>弄清楚哪些时间是可以“买回来”的，如雇人为你修剪庭院、做保洁等。（如果切断有线电视，你甚至可以用这笔省下来的钱来支付上述费用。）</p>
</li>
</ul>
<h3 id="形成惯例的重要性"><a href="#形成惯例的重要性" class="headerlink" title="形成惯例的重要性"></a>形成惯例的重要性</h3><ul>
<li><p>生产力的真正秘诀在于：长期坚持做一些小事。</p>
</li>
<li><p>他们没有意识到，横亘在自己与梦想之间的无非就是“惯例”。惯例塑造你的生活，让你变得更有生产效率，惯例是让你实现目标最强大的方式之一。你每天的行为日积月累下来，可以让你生活的每个方面都得到提升。</p>
</li>
<li><p>每天都安排时间处理这些任务，以便你可以确保它们被完成。当我在办公室工作的时候，每天我会抽出30分钟时间学习自己工作中会用到的技术，我习惯将其称为“研究时间”。</p>
</li>
<li><p>每天的生活越有条理，就越能把控自己的生活。</p>
</li>
<li><p>想想看，如果你一直对外界作出反应，如果你总是在事情出现的时候被动地处理事情而不是主动地规划，那么周围的环境会左右你的生活，而不是你自己。</p>
</li>
<li><p>例行安排示例</p>
</li>
</ul>
<p><img src="/2023/03/02/20230302-ruan-ji-neng-dai-ma-zhi-wai-de-sheng-cun-zhi-nan-notes/%E4%BE%8B%E8%A1%8C%E5%AE%89%E6%8E%92%E7%A4%BA%E4%BE%8B.jpg"></p>
<ul>
<li><p>地雷：注意不要过于沉迷于惯例你应该有自己遵循的惯例，但是也要有一定的灵活性。你可能会打乱一天的日程安排。不要忘记会有像车坏了这种不可预测的事件发生，车坏了可能会打乱你的例行安排。你需要学会从容应对这些事情。</p>
</li>
<li><p>采取行动<br>你目前有哪些惯例？跟踪一下你的日常活动，看看你已经在遵循的惯例有哪些。<br>选择一个大目标，以每个工作日为单位制订例行安排。计算一下，如果你每天都朝着这个目标前进，一年下来你会取得多大的成就。</p>
</li>
</ul>
<h3 id="培养习惯"><a href="#培养习惯" class="headerlink" title="培养习惯"></a>培养习惯</h3><ul>
<li><p>成就我们的恰恰就是那些不断重复做的事情。因此，优秀不是一种行为，而是一种习惯。——亚里士多德</p>
</li>
<li><p>我们每个人都有习惯，有好有坏。好习惯能够推动我们前进，帮助我们成长；坏习惯则阻止我们前进，阻碍我们成长。培养和养成良好的习惯可以让你不需要刻意努力就保持很高的生产效率。如同惯例可以帮我们缓慢而坚定地每次只砌好一块砖，最终建起一面巨大的墙一样，习惯也可以通过日积月累的努力，让我们前进或者后退。二者最大的区别在于，惯例是我们可以控制的，而习惯却不受控于我们。</p>
</li>
<li><p>习惯主要由三个要素构成：暗示，惯例和奖励。</p>
</li>
<li><p>我们的大脑非常善于养成习惯。我们会根据周围的事物自发地养成习惯。一件事情做的越多，越可能形成习惯。习惯的力量往往基于奖励的价值。我们都喜欢做能够带来更好回报的事情。然而，奇怪的是，可变化的奖励要比已知的标准奖励更让人着迷。这就是在赌场能看到那么多人的原因。不知道自己是否能得到奖励或者不知道奖励有多大，会形成一种很坏的习惯，即公认的“上瘾”。</p>
</li>
</ul>
<h3 id="分解任务"><a href="#分解任务" class="headerlink" title="分解任务"></a>分解任务</h3><ul>
<li><p>造成拖延的首要原因之一，同时也是造成生产力低下的祸根，就是总是在感慨一个问题：好忙啊，问题好大啊……实际上，你并没有真正试着去解决问题。当我们从任务的全貌来审视任务的时候，它们看起来比真实情况都要大，并且更吓人。</p>
</li>
<li><p>克服拖延的提高生产力的窍门：分解任务。通过将大任务分解为小任务，你会发现自己更有动力去完成它们，也更加稳妥地向着目标前进。</p>
</li>
<li><p>这些大任务或大项目给我们带来了心理上的伤害，也削弱了我们的生产力——因为我们无法看清楚未来的前景。从宏观上审视一项大型任务的全貌时，它看起来几乎是不可能完成的</p>
</li>
<li><p>大型任务给人带来沉重的心理负担。面对大问题时，我们倾向于花更多的时间思考问题本身，而不是采取行动去解决问题。人类倾向于选择阻力最小的路径。</p>
</li>
<li><p>但是拖延还不是我们不喜欢大型任务的唯一原因。任务越大，越难明确定义。</p>
</li>
<li><p>大型任务往往也很难估算完成时间。</p>
</li>
<li><p>大型任务是一种智力挑战，与小任务相比，大任务更可能导致拖延，通常描述也更少，更容易出错，也更难估算完成时间。</p>
</li>
<li><p>当把任务分解成小块的时候，这些任务就变得更易于完成，对完成任务所需的时间的估算也更精确，你也更有可能正确地完成它们。即使有些小任务没有正确完成，你也有很多机会改正，而不至过多地影响大项目。我发现，把大任务分解成小任务真是一个好主意。</p>
</li>
<li><p>在管控代码的复杂程度问题上，我们也会做一些工作。这就是我们不会将所有的代码都写入一个方法中的原因。我们会将自己的代码分解为方法、函数、变量、类以及其他结构，从而简化代码。</p>
</li>
<li><p>不管编程问题有多难，它总是可以被分解为更小的单元。如果你想要写出一个难度很大的算法，在一头扎进去写代码之前，先把这个问题分解为能够依次独立解决的小模块会更有帮助。无论应用程序多么庞大、多么复杂，它都可以被分解成一行行的代码。单独一行代码的复杂度绝对不会超过任何一位程序员的理解能力和编码水平，所以，如果你愿意将问题分解得足够小，只凭借写出单行代码的能力你就能写好任何应用程序。</p>
</li>
</ul>
<h3 id="努力工作的价值"><a href="#努力工作的价值" class="headerlink" title="努力工作的价值"></a>努力工作的价值</h3><ul>
<li><p>现实的情况是，一切有价值的东西无一不是努力工作的结果。生活中，特别是在软件开发的职业生涯中，如果你想看到成果，你就必须要学会坐下来，做好自己并不想做的工作——并且要坚持不懈。</p>
</li>
<li><p>如果真想富有成效，你就不得不学会工作的时候既聪明又努力。光有聪明是不够的。一定量的机智是必须具备的，然而要想获得真正的成功，面对挫折的时候一定量的毅力也是必要的。</p>
</li>
<li><p>努力工作总是枯燥的如果我必须猜测一下，为什么我们逃避艰苦的工作，我会说这是因为它们太枯燥了。在我刚开始写博客的时候，我很兴奋。我对这个表达自己的机会充满热情。然而，随着时间的推移，它变成了一项苦差事。如果我没有学会坚持，设法应对这项单调乏味的苦差事，我就不可能看到自己的行动的好处。</p>
</li>
<li><p>你必须认识到，你要想实现目标，要想发挥出自己的全部潜力，唯一的途径就是自愿咬紧牙关、硬着头皮、开始工作</p>
</li>
<li><p>你曾经投身到哪些艰苦的工作中？有哪些任务你会因为不喜欢而拖延？找出其中一项任务，毫不犹豫地马上去做。养成雷厉风行的习惯，并且立即在需要做的工作中付诸行动。</p>
</li>
</ul>
<h3 id="任何行动都比不采取行动好"><a href="#任何行动都比不采取行动好" class="headerlink" title="任何行动都比不采取行动好"></a>任何行动都比不采取行动好</h3><ul>
<li><p>任何行动往往都比没有行动好，特别是当你一直停滞在不愉快的情势下很长时间的时候。如果这是一个错误，至少你学到了一些东西。这样一来，它就不再是一个错误。如果你仍然选择停滞不前，那么你就学不到任何东西。</p>
</li>
<li><p>很少有人会后悔自己基于所掌握的最好的知识采取的行动，但是很多人会后悔自己没有采取行动。他们错失机会，只因为过分害羞、谨慎或者犹豫，让他们裹足不前，无所作为。</p>
</li>
<li><p>很多时候，你需要试错好多次之后才能找出正确的行动方向。在任何行动上耽误的时间越长，完成整个试错过程找出正确方向的用时也就越长。</p>
</li>
<li><p>大多数我们急于做出的选择往往都是微不足道的。我们经常试图耗费300%的努力寻找95分的解决方案，而不是满足于找到90分的解决方案。我们的生活就是这样的，我们写代码的时候也是这样的，我们甚至在决策该买什么样的电视机时也是这样的。</p>
</li>
<li><p>即使是一些看似重要的选择——改变生活的那种，用随机掷骰子的方式都比优柔寡断、无所作为要好。很多大学生认为，选择专业和选择职业都是非常重要的决定。尽管这一决定可能很重要，但也不会比其他选择更重要，有多少大学生毕业的时候只有华而不实的学位或者是泛泛而谈的专业正是因为他们没有做到当断则断呢？举棋不定、优柔寡断让他们丧失了采取行动的机会。</p>
</li>
<li><p>跑起来的汽车更容易转向</p>
</li>
<li><p>通常，要找出一个方向是错的，唯一的方法就是向着那个方向前进。如果错误的代价很小，有所作为总好过无所事事。</p>
</li>
<li><p>现在要怎么做那么，如何将上述原理现在就应用于你的生活呢？今天你要怎么采取行动？仔细查看表48-1所示的简单的检查表，看看它是否能帮你下定决心采取行动。</p>
</li>
<li><p>表48-1 采取行动时的检查表</p>
</li>
</ul>
<p><img src="/2023/03/02/20230302-ruan-ji-neng-dai-ma-zhi-wai-de-sheng-cun-zhi-nan-notes/%E9%87%87%E5%8F%96%E8%A1%8C%E5%8A%A8%E7%9A%84%E6%A3%80%E6%9F%A5%E8%A1%A8.jpg"></p>
<h1 id="第五篇-理财"><a href="#第五篇-理财" class="headerlink" title="第五篇 理财"></a>第五篇 理财</h1><ul>
<li><p>金钱只是一种工具。它会带你去往任何你想去的地方，但不会取代你成为司机。<br> ——爱思·然德（Ayn Rand）</p>
</li>
<li><p>即使你对此心存疑问，我也鼓励你认真思考一下：改变财务状况会如何显著地改变你的生活，改变你在职业生涯中所做的决定。</p>
</li>
<li><p>所谓资产，是指实用价值高于维护成本的东西。也就意味着，一样东西如果有资格被定义为“资产”，必须能够带来比自身成本更高的价值。</p>
</li>
<li><p>但是，负债的含义则恰恰相反。所谓负债，是指成本高于带来的价值的东西。也就是说，要保有“负债”，你不得不往外掏钱，但是你永远也拿不回来与自己掏出的钱一样多的钱。</p>
</li>
<li><p>关于资产，一个清晰的例子就是你持有的每个季度派发一次红利的股票。持有股票并不会花你分文，但是只要一直持有，每3个月它就会给你带来一次收入。股票自身的价格会上涨也可能会下跌，但是按照我的定义，只要它能带来红利，它就是资产。</p>
</li>
<li><p>某些东西你买来后能够给你带来产出，或者产生的价值会高于你最初的投资，而别的东西则会消耗你的收入，或者不值你为它花的钱。</p>
</li>
<li><p>如果想在财务上获得成功，就必须学会如何投资，别无选择。</p>
</li>
</ul>
<h3 id="薪酬谈判"><a href="#薪酬谈判" class="headerlink" title="薪酬谈判"></a>薪酬谈判</h3><ul>
<li><p>我强烈建议软件开发人员打造个人品牌，并积极地营销自己。</p>
</li>
<li><p>为了做到这一点，基本策略就是尽可能让自己的名字出现在各种的媒体上。写博客、做播客、写书或文章、在大会或用户组中发表演讲、制作视频教程、为开源项目贡献代码等，尽一切可能让自己的名字出现在各种场合。</p>
</li>
<li><p>获得工作的方式至关重要</p>
</li>
<li><p>第一种，你看到一份招聘启事，然后发送自己的简历去申请该职位，最好再附上一封优美的求职信。事实上，许多求职者想当然地认为这是获得工作的唯一方式。其实，这是获得工作最糟糕的一种方式。如果以这种方式获得一份工作，很难在薪酬谈判时占据有利地位，因为和雇主比起来，你处于明显的弱势。你是竭尽所能渴望求得那份工作的人。</p>
</li>
<li><p>需求最大的人在任何谈判中通常都会处于劣势。</p>
</li>
<li><p>获得工作的另一种方法是通过他人推荐。</p>
</li>
<li><p>你认识一家公司里的某个人，他们亲自推荐你应聘某个职位，最终你获得了这份工作。这种方式绝对要比自己申请职位好很多。</p>
</li>
<li><p>你的最佳状态就是：一家公司知道你，然后无需任何面试就直接为你提供一个职位。在这种情况下，你尽可以根据自己的声望为自己标价。所以，任何时候，只要有雇主直接找你，你在谈判时就拥有有利地位。</p>
</li>
<li><p>先出价者输</p>
</li>
<li><p>你必须要了解的一条重要法则就是：先出价的人会处于明显的劣势。</p>
</li>
<li><p>然而也有例外，唯一的例外会出现在雇主刻意压低价钱的时候。这种情况是非常罕见的，但是，如果你有充分的理由怀疑这种情况会发生，你可能会想先出价来设定个保底数。为什么？因为如果雇主给你的出价极低，你很难让他把价格抬高很多。当然，在这种情况下，无论你做什么，都不大可能成功。</p>
</li>
<li><p>被要求先出价该怎么办千万不要先出价。直接说“不”。</p>
</li>
</ul>
<h3 id="期权"><a href="#期权" class="headerlink" title="期权"></a>期权</h3><ul>
<li><p>期权背后的基本思想就是允许某人为在未来的某个日期买入或卖出股票的权利付费</p>
</li>
<li><p>期权从根本上说就是赋予你在未来某个日期之前以固定价格购买一定数量股票的选择权。</p>
</li>
<li><p>但你也可以购买另一种让自己在未来某个日期之前以固定价格出售一定数量股票的选择权。这种期权能让你在股价下跌的时候也赚钱，与附录B中讨论的卖空股票类似。</p>
</li>
<li><p>允许在未来一段时间内以固定价格购买股票的期权被称为“看涨期权”，允许在未来一段时间内以固定价格出售股票的期权被称为“看跌期权”。</p>
</li>
</ul>
<h3 id="房地产"><a href="#房地产" class="headerlink" title="房地产"></a>房地产</h3><ul>
<li><p>在所有个人可以做的投资中，我认为房地产投资是目前为止最好的。再没有其他投资方式像房地产一样能够保障长期收益，能够允许如此高的资本负债。</p>
</li>
<li><p>尽管房地产价格可能会大幅波动，但是我建议投资的是可租赁房产。这种房产的稳定的收入就是——租金。</p>
</li>
<li><p>你选中的这处房产属于我们所说的“以租养贷”，意思是说所有费用，包括抵押贷款、税费和保险，都由它产生的租金收入来提供保障。在这种情况下，我们假设租金能够支付全部费用，不会有多余的现金流，或现金流很少。</p>
</li>
<li><p>聪明的房地产投资（不是投机）始于认识到房地产投资是一项长期投资。如果你相信自己可以通过倒卖房产或者低价购买抵押房产而快速致富，那你终究会自食恶果。</p>
</li>
<li><p>好的物业管理公司将会管理与物业出租有关的一切事务，包括寻找租户、确定租约、筛选租户、维修保养以及收取房租等。但是找到一家好的物业管理公司是很困难的。你要货比三家，找最诚信的物业管理公司。我因为能力不足、维修费用造假和玩忽职守等问题，至少解雇了三家物业管理公司。</p>
</li>
</ul>
<h3 id="退休计划"><a href="#退休计划" class="headerlink" title="退休计划"></a>退休计划</h3><ul>
<li><p>事实是，在热带海滩上度过退休生活并非理所当然，也不只是60岁以上人群的专利。</p>
</li>
<li><p>事实上，如果你希望乐享退休生活，你必须开始为此做一些计划，并且从现在就开始计划。</p>
</li>
<li><p>一旦算出自己退休以后每个月的生活开销是多少，当你的“被动收入”达到每月所需的生活开销的时候，你就可以正式退休了。</p>
</li>
<li><p>所谓被动收入，就是不用工作就能获得的收入。你必须确保被动收入会随着通货膨胀而增加——这也是说房地产是一个很好的投资选择的主要原因。</p>
</li>
</ul>
<h3 id="债务危害"><a href="#债务危害" class="headerlink" title="债务危害"></a>债务危害</h3><ul>
<li><p>真正获得财务成功的唯一方法就是用钱生钱。</p>
</li>
<li><p>采取行动<br>列出你的所有债务的清单，把它们区分为两类：好的债务和不好的债务。<br>把不好的债务按照利率从高到低排序，计算一下多久你可以清偿所有的债务。</p>
</li>
</ul>
<h3 id="额外馈赠"><a href="#额外馈赠" class="headerlink" title="额外馈赠"></a>额外馈赠</h3><ul>
<li><p>相反，我把退休定义为“自由”，具体而言，即财务自由——一种不会囿于财务状况被迫用自己别无选择的方式将自己的时间花费在不合心意的事情上的能力。</p>
</li>
<li><p>我从不追求永远不再工作，但是我一直追求在我不想工作的时候就不工作。这就是我目前的状态。我有足够丰厚的“被动收入”去对抗通货膨胀，如果我愿意，我也可以躺在沙滩上来一杯鸡尾酒；但是，我依然可以投身自己感兴趣的项目——那只是因为我想投身于该项目，而不是因财务原因必须投身于该项目。</p>
</li>
<li><p>我的观点是，运气是必要的。我不会假装自己从来没得到幸运女神的眷顾，但在一定程度上，是你给自己创造运气。如果你脚踏实地、努力工作，总是尝试提升自己和周围的人，那你获得好运气的可能性会大大增加。等式的最后一部分是努力工作。Pluralsight的很多作者也有着和我一样的机遇。我不是说他们不努力，只是我更积极、更努力，我是Pluralsight课程库中课程最多的作者。为了让自己梦想成真，我静下心来工作到很晚，周末也不例外。</p>
</li>
<li><p>仅仅获得机遇是不够的——即便这一机会千载难逢。你必须充分利用机遇，否则再好的机遇也没用。</p>
</li>
</ul>
<h1 id="第六篇-健身"><a href="#第六篇-健身" class="headerlink" title="第六篇 健身"></a>第六篇 健身</h1><ul>
<li><p>如果你不注意自己的身体健康，老实说我并不看好你能成为顶尖的程序员。</p>
</li>
<li><p>在很长一段时间内，我都认为，在软件开发人群中教育和普及体育健身方面的知识是非常迫切的需要。在我刚开始从事编程工作时，软件开发人员的典型形象就是一个书呆子，瘦骨嶙峋，戴着一副厚厚的眼镜，活脱一付笔尖保护套的模样。现在，这一形象似乎已经改变，不过是变得更糟了。如今，很多人认为，软件开发人员都是胖胖的男士，留着络腮胡子，穿着一件脏兮兮的白色T恤还吃着比萨。</p>
</li>
<li><p>显然这两种刻板形象都是错的——有很多软件开发人员，不管是男性还是女性，都不是这种形象，但是第二种形象比第一种形象更让我害怕，因为我觉得有些开发人员已经开始认为自己应该就是那样的。本篇的目的是让你了解健身的基础知识，鼓励你打破成见，并且让你认识到，身为软件开发人员并不意味着男的不能健康，不能英俊潇洒，女的不能光彩照人。你同样可以保持好身材，可以拥有健康，但一切都始于正确的教育和坚定的信念——相信这些都是可能的。</p>
</li>
</ul>
<h3 id="破解自身健康密码"><a href="#破解自身健康密码" class="headerlink" title="破解自身健康密码"></a>破解自身健康密码</h3><ul>
<li><p>健身不仅是保持健康体魄的关键要素之一，也是灵活的、具有创造性的脑力活动的基础。——约翰·肯尼迪</p>
</li>
<li><p>健身能让你成为更好的软件开发人员。这就是原因。</p>
</li>
<li><p>自信心</p>
</li>
<li><p>从我的个人经验出发，我可以告诉你，我锻炼得越多就越健康，我在工作中的表现也越好。我注意到，当我体能最好的时候，我的注意力最集中，效率也最高。</p>
</li>
<li><p>当你总觉得疲倦、无心工作的时候，或者你觉得自己状态不佳的时候，你可能会发现，改变饮食和加强锻炼可以让你的身心同时获得新活力。</p>
</li>
<li><p>恐惧我不想马上打出恐惧牌，但我认为它仍然是如此重要，值得一提。如果你体重超标、处于亚健康状态，那你罹患各种可预防性疾病的风险就很高。</p>
</li>
<li><p>不要让自己醒悟得太晚，从现在起就认真对待。不要等到出了健康问题才开始关心自己的健康。</p>
</li>
</ul>
<h3 id="设定健身标准"><a href="#设定健身标准" class="headerlink" title="设定健身标准"></a>设定健身标准</h3><ul>
<li><p>没有目标，你永远也达不成目标，健身也不例外。正如你需要知道自己写的代码是用来做什么的一样，你也需要知道在忍饥挨饿、挥汗如雨之后，你要得到怎样的结果，否则你就是在浪费时间。</p>
</li>
<li><p>挑选一个具体的目标</p>
<ul>
<li>减肥</li>
<li>增肌</li>
</ul>
</li>
<li><p>这些应用还可以帮你找到举重或者跑步的同伴，甚至能让你开始新的节食计划，或者向朋友发起挑战。与他人交流，分享自己的经验，不论好坏，都能让你的健身之旅更乐趣无穷，并能让你持久保持动力。我发现，当我有一个举重同伴的时候我总是更勤快地跑去健身房。</p>
</li>
<li><p>计划了就一定要执行如果你能让自己持久保持动力，这确实很棒。但是，有时候不论有没有动力，你都得咬紧牙关坚持计划。一定要提前做好决定，这能给你约束，让你致力于自己想要采取的一系列行动。</p>
</li>
<li><p>试着通过提前计划，尽可能减少生活中的各种抉择。</p>
</li>
<li><p>当你的动力消失殆尽的时候，用原则来代替激励。每当我精疲力竭不想再跑步的时候，我都会用自己高度尊崇的“善始善终”原则提醒自己。为自己的人生创建一组格言，在世事艰难的时刻信守这些格言。</p>
</li>
<li><p>人生格言<br>善始善终。<br>成功者决不放弃，而放弃者永远不会成功。<br>一分耕耘，一分收获。<br>时间短暂，如果想在生命中做某件事，现在就去做。<br>一切都会过去。<br>坚持到底就是胜利。采取行动<br>列出你要健身或改善健康状况的原因。<br>从这份清单中，明确三项最重要的激励因素，打印出来并张贴在不同的地方，确保自己每天都能看到。</p>
</li>
</ul>
<h3 id="如何增长肌肉"><a href="#如何增长肌肉" class="headerlink" title="如何增长肌肉"></a>如何增长肌肉</h3><h3 id="如何获得腹肌"><a href="#如何获得腹肌" class="headerlink" title="如何获得腹肌"></a>如何获得腹肌</h3><h3 id="跑步"><a href="#跑步" class="headerlink" title="跑步"></a>跑步</h3><h3 id="站立办公"><a href="#站立办公" class="headerlink" title="站立办公"></a>站立办公</h3><h3 id="高科技健身装备"><a href="#高科技健身装备" class="headerlink" title="高科技健身装备"></a>高科技健身装备</h3><ul>
<li><p>本章介绍的都是能帮助你实现健身目标的或者能让你的健身过程更充满乐趣的科技装备。我们已经进入了全新的时代，当下我们比以往任何时候都更了解自己，了解自己身体的运转规律。这种自我认知也被称为“量化自我”。在本章中，我会带领你领略各种技术，并从中选出一些最有用的装本来帮你“量化自我”。</p>
</li>
<li><p>步行计数器和计步器我觉得从步行计数器和计步器开始说起可能比较合适，因为它们是你现在能看到的最常见的科技装备。我是拥有某种计步器的超级粉丝，因为它不仅能帮你明确自己的实际运动量是多少，还能通过了解你的运动量来改变你的行为习惯，从而让你更有活力。</p>
</li>
<li><p>它不仅能记录我的体重，还能记录我的体脂率。尽管体脂率读数的精确性有待商榷，但我更关心的是读数是如何随时间变化而变化的。尽管可能我获得的数据不够精确，但我能够看到相对变化，了解自己的体脂率是在升高还是降低。</p>
</li>
<li><p>我强烈推荐我正在用的这款体重计，因为它能让你更好地了解自己的当前体重和变化趋势。有人说有了测量才能改进。即使你每天都站在体重计上，但只有看到体重随着时间的变化曲线时，你才会真正受到触动，向着正确的方向前进。</p>
</li>
<li><p>组合设备健身科技最令人兴奋的领域莫过于组合设备了，尽管目前尚不成熟，但正被逐渐推广。这些组合设备能够通过各种传感器测量多个数据点，为你提供大量关于你的身体的信息。</p>
</li>
<li><p>耳机在我锻炼的时候，最重要的技术装备就是耳机。我经常在锻炼的时候听播客或有声书，因此我需要一副可以插入手机的好耳机。</p>
</li>
<li><p>应用我们也别忘了应用。市面上有大量针对各种锻炼目的的健身应用。</p>
</li>
</ul>
<h1 id="第七篇-精神"><a href="#第七篇-精神" class="headerlink" title="第七篇 精神"></a>第七篇 精神</h1><ul>
<li><p>精神如果你不征服自己，你就会被自己征服。——拿破仑•希尔</p>
</li>
<li><p>我们不只是一个与思想相连的躯壳。我们不能只下达指示然后就期望身体能完成执行这些指令。这个世界存在着另一股很强大的力量，它能带领我们走上成功之路，把我们推向成功。你可以按照自己的意愿随意称呼这种力量，但是为了本书的目的，我称之为精神。</p>
</li>
<li><p>我的目标是用工具武装你，征服你所面对的最强大的敌人——你自己。</p>
</li>
</ul>
<h3 id="心灵如何影响身体"><a href="#心灵如何影响身体" class="headerlink" title="心灵如何影响身体"></a>心灵如何影响身体</h3><ul>
<li><p>从心灵开始如果你不相信自己能够做到，你几乎做不成任何事情。你的思想对身体的影响有多大、对你能够获得成功的影响有多大，这是令人惊叹的。“如果你相信，你就能做到”这个观点很容易被迅速忽视，但是这个观点确实有些道理。至少，这个观点的反面更有道理：如果你不相信，你肯定不会获得成功。</p>
</li>
<li><p>那些想要改变自己信念、控制自己想法的人们，通过积极的正念可以将其想要的变为现实。</p>
</li>
<li><p>信念决定思想，思想决定言语，言语决定行动，行动决定习惯，习惯决定价值，价值决定命运。——圣雄甘地</p>
</li>
<li><p>不管这个机制是如何运转的，重要的是你要理解自己的所思所想影响并塑造了你现在的生活。你甚至不用读这一章就可以证明这一点。看看周围就知道了。</p>
</li>
<li><p>如果你真的想为自己的生活定好方向并控制好它，那你就要学会如何利用心灵的力量、思想的力量。</p>
</li>
<li><p>采取行动<br>找出心灵和身体之间的联系。试着在你自己的生活中找一个例子，什么样的想法给现实带来了积极的影响，什么样的想法又给现实带来了消极的影响？<br>你最近一次取得巨大成功的时候心态是什么样的？<br>你最近一次遭遇重大挫败的时候心态是什么样的？</p>
</li>
</ul>
<h3 id="拥有正确的心态"><a href="#拥有正确的心态" class="headerlink" title="拥有正确的心态"></a>拥有正确的心态</h3><ul>
<li><p>让我问你一个问题：你将自己的想法归类为积极的还是消极的？这可不是给你自己贴上乐观主义者或悲观主义者的标签。有很多的乐观主义者，他们在表面上满怀期望和希望，但内心却怀着各种会直接破坏他们的工作成果的负面想法和情绪。实际上，积极思考的观点有科学证据可以支撑——积极思考不只是外表乐观，而且还对健康有益，能延年益寿，并且给你的生活提供其他的好处。同时——或许是更重要的——反过来想，消极的思考会产生完全相反的效果。消极思考会对你产生实质伤害，而且会妨碍你通向成功的人生.</p>
</li>
<li><p>积极思考与现实主义是不矛盾的。事实上，积极思考在应用层面上是现实主义的最终体现，因为它是一种信念，这种信念让你有力量改变现实，让你确信你不是环境的受害者。</p>
</li>
<li><p>积极思考问题的根源是这样一种信念——你比你随处的环境更伟大。这种信念让你总能先看到事物好的一面，因为无论身处何种环境，你都有能力改变自己的未来。这是人类成就的最高信念，是世界上最强大的力量。这种信念能让你利用这种力量，这股力量就静静地躺在你的心田，却又不那么虚无缥缈。</p>
</li>
<li><p>积极的心态就是来自于这些想法的积累，随着时间的推移这些想法会由内向外地彻底改变你。当你拥有一个积极态度的时候，你就不是活在与现实分离的虚幻世界里，而是生活在一个最理想的世界里，一个你能看到的最理想的未来世界，一个你一直以来都在苦苦追求并努力实现的未来世界。</p>
</li>
<li><p>从更现实的层面来讲，积极思考就是选择从好的一面（而不是从坏的一面）去思考问题。你对生活中遇到的每一种状况都可以有自己的理解。这些状况本身并不存在“好”或者“坏”。是你自己来解释这些状况，所以是你决定它是“好”的还是“坏”的。一个持有积极心态的人看到的好的一面往往比坏的一面要多，并不是因为这些状况客观上就是好的，而是因为他们认识到他们有选择的权利。</p>
</li>
<li><p>积极性的正面作用记得当我说有真实存在的科学证据证明积极思考会对你的生活产生影响吗？我不是在开玩笑。这里有一份被证实效果的清单，这些效果都是由积极思考产生的。这些结果来自实际的科学研究：<br>发展友谊；<br>婚姻美满；<br>收入更高；<br>身体更健康；<br>延年益寿。</p>
</li>
<li><p>我知道的一个事实是，我的工作态度会直接影响我的工作表现。关于这一点，我是用自己的工作效率来做的度量。我知道，当我保持一个积极的态度时我就更愿意去面对任何障碍，把挑战看成要克服的困难，而不是消极地认为是环境把我逼到了绝境。</p>
</li>
<li><p>如何养成积极思考的习惯呢？大多数情况下，使用养成其他任何习惯的方法就能养成这个习惯——通过坚定地、持续不断地、有意识地重复做一件事情，直到由潜意识来掌握大局。</p>
</li>
<li><p>劳逸结合<br>我个人可以追踪我的许多负面情绪与我忘记休息之间的关联关系。我发现当我花时间休息后更容易保持积极心态。可能这种方法没什么大不了，但是还是值得参考。</p>
</li>
<li><p>一些帮助你养成一个积极心态的好书。如果你现在就想找到相关的书，试着看看由Norman Vincent Peale写的《积极思考就是力量》（The Power of Positive Thinking）［Touchstone，2003再版］。关键是积极思考不会从天而降，也不是一夜间就能获得的，你要付出持续的努力，将思想转向积极的方向。但这是值得付出的努力。不单是因为积极思考能让你活得更长久、更健康、更成功，还因为这绝对会让你活得更有乐趣，同时你可能会影响你周围的人同样生活得越来越有乐趣。</p>
</li>
</ul>
<h3 id="构建一个积极的自我形象"><a href="#构建一个积极的自我形象" class="headerlink" title="构建一个积极的自我形象"></a>构建一个积极的自我形象</h3><ul>
<li><p>那些不能激励自己的人一定是甘于平庸的人，无论他们的其他才能有多么令人印象深刻。——Andrew Carnegie</p>
</li>
<li><p>自我形象是在甩掉别人对你的看法，摆脱所有用来自我安慰的谎言和欺骗以后，你看到的自己的样子。</p>
</li>
<li><p>对你的大脑“重新编程”如何有目的性地对你的大脑“重新编程”？如何像我当年那样改变自我形象？公式相当简单：只需要花点儿时间，再加上持之以恒地正确执行。一开始，设定一个你想成为的清晰形象。你的大脑有惊人的能力去寻找摆在它面前的任何目标。你只需要想象一下这些目标，直到这个目标足够清晰到让你的大脑能够带领你走向你需要走向的那条道路。</p>
</li>
<li><p>为你树立一个理想形象。在你的脑海中牢固地树立起一个形象——“这就是我想要成为的形象，没有什么能够阻止我”。想象一下你自己更坚定、更有自信地走进房间；想象一下你优雅地跳跃着、奔跑着，而不是将自己绊倒；想象一下你可以激励别人，可以非常时尚。不要给自己设定任何的人为限制，除非是那些你没有办法改变的身体特征（例如，不要把自己想象成个子很高，除非这么做能让你感到更自信。只是别指望这么想真的能让你长高。）一旦你在自己的脑海中设立了这样的形象，下来的任务就是开始执行“仿佛”模式。“仿佛”你已经变成了你想变成的那个人。无论是言行举止，还是穿着打扮，都像你想成为的那个人一样，甚至像你想成为的那个人一样刷牙。不要太关注现实是怎么样的，不要太在意别人如何议论你的“变化”；相反，假装你已经达到了你想要的目标，你的新行为只是这个新个性的自然延伸。你还要给自己很多正面的肯定，这会在你潜意识深处植下你的新思维模式的种子。事实证明，正面的肯定不是胡言乱语，你的大脑会真的开始相信你告诉它很多遍的东西。还记得我说过的改变信念是多么难的一件事吗？如果持续传递一致的信息给你的大脑，你就能改变自己的信念。</p>
</li>
<li><p>我建议用一句名言或者一个肖像提醒你，你理想中的那种精神状态。让每一天都充满正面的肯定，这样就能更加确认并加强你的新信念。花一些时间，在精神层面上虚构一个你想成为的那个自己。很多体育运动员就是利用这样的过程来提高自己的成绩的。在参加重大赛事之前，他们会在脑海中做一次彩排。</p>
</li>
</ul>
<h3 id="爱情与恋爱"><a href="#爱情与恋爱" class="headerlink" title="爱情与恋爱"></a>爱情与恋爱</h3><ul>
<li><p>总的来说，我们总想得到自己得不到的东西，我们总想得到别人也想得到的东西。所以，希望越大，失望越大，你就越不可能得到。</p>
</li>
<li><p>关键是你要真正表达出这个意思。你必须要对自己表现出足够的自信，你真的相信你不需要别人给你带来快乐。你必须要相信你和别人在一起是因为你能给对方的生活带来好处，当然这并不意味着你自认为你是上帝恩赐给别人的礼物……来填补空白，但这确实意味着你对自己足够尊重，你只出现在自己想去的地方，你只想和想和你在一起的人相处。</p>
</li>
<li><p>这并不意味着保证能成功，我无法保证。但是，如果你能明白大多数情侣关系其实是“你追我逃”的微妙心理游戏作用的结果，你就会更容易找到真爱。这不只适用于爱情问题，也适用于各种人与人之间的关系。做一个绝望的、缺乏自信的人，你可能会发现自己真的孤立无援。如果你发现你面试的对象就像大街上一个垂死挣扎的乞丐一样祈求你施舍给他工作岗位，你也会觉得他很惹人生厌。</p>
</li>
<li><p>太多人会犯这样的错误——挑选一个人，然后把他&#x2F;她当作理想人选放在神龛上，时刻想念着那个能让他们觉得“开心”的完美女生或者男生。假设只有这么一个完美的人，这种想法不但荒谬而且缺乏策略。如果扩大搜索范围，你的机会更好。</p>
</li>
<li><p>所以，请不要害怕失败，哪怕失败很多次；不要害怕被拒绝，没什么大不了的。最差的情况又能差到哪里？你可能就像去敲开一扇扇门的销售员，他们面对上百扇甩向他们的门，只为做成一笔交易。你要知道，你每天需要做的就是完成一笔交易。</p>
</li>
<li><p>除此之外，所有那些拒绝最终都会把你带到一个想和你在一起的人那里，这总比和不想和你在一起的人在一起要好很多。</p>
</li>
</ul>
<h3 id="私房成功书单"><a href="#私房成功书单" class="headerlink" title="私房成功书单"></a>私房成功书单</h3><ul>
<li><p>人性的弱点</p>
</li>
<li><p>让别人做你想做的事情的唯一方法就是让他们自己也想做这件事。</p>
</li>
<li><p>Napoleon Hill的《思考致富》（Think and Grow Rich）［Wilder Publications, 2007］</p>
</li>
<li><p>Robert Kiyosaki的《穷爸爸，富爸爸》（Rich Dad, Poor Dad）［Demco Media，2000］这是另外一本改变我生活的书，它改变了我对金钱和财富的看法。这本书改变了我对钱是如何运作的认识，改变了我对“拥有一份工作”以及“为别人工作意味着什么”的看法。读完这本书之后，我清楚地理解了建立资产和减少自己的开销有多么重要。</p>
</li>
</ul>
<h3 id="积极面对失败"><a href="#积极面对失败" class="headerlink" title="积极面对失败"></a>积极面对失败</h3><ul>
<li><p>跌倒七次，爬起来八次。——日本谚语</p>
</li>
<li><p>为什么我们总是害怕失败畏惧失败似乎是大多数人的本能。人都喜欢做自己擅长的事情，逃避做那些自己不能胜任的或是缺乏技能的事情。我们似乎与生俱来就畏惧失败。</p>
</li>
<li><p>如果非要我猜猜为什么大多数人如此害怕失败，我不得不说这可能是基于保护脆弱的自尊的想法。或许我们害怕失败就是因为我们太过将失败归咎于个人，我们认为在特定领域下的失败是个人价值的流逝。</p>
</li>
<li><p>我认为，对“失败”性质的误解还会助长这种对个人价值伤害的恐惧感。</p>
</li>
<li><p>即使我们知道失败并不是终点，我们似乎也能感受到这一点。我们往往太过较真，把失败看得太重。因为我们接受过把失败看作通往成功道路——很多情况下这也是唯一的一条道路——的训练，所以我们不惜任何代价地避免失败。</p>
</li>
<li><p>失败并不是被打败</p>
</li>
<li><p>失败不同于被打败。失败是暂时的，被打败是永恒的。失败是那些碰巧发生在你身上的——你不能完全控制它。被打败却是你可以选择的——是对失败的某种程度的接受。</p>
</li>
<li><p>要实现不畏惧失败，第一步就是真正意识到失败不是终点——除非你选择把它看作是终点。生活不易，你随时都会被击垮，但是否要重新站起来却完全取决于你自己。它取决于你是否决定为自己最值得拥有的东西战斗，取决于你是否要享受获得成功后的喜悦和乐趣，大多数情况下，它来自于战胜困难的成就感。</p>
</li>
<li><p>如果在第一次受挫败被打死的时候你就扔掉了控制器，会发生什么？某种程度上，从很多次失败中获得的经验反而让你最终获得了成功的体验，这是不是更令你乐在其中？如果是这样，你为什么要把失败当作是一种永恒的状态而逃避生活中的失败呢？你不能指望拿起电玩遥控器，不经历掉下陷阱或者被火球烧焦就能通关，那么你为什么要指望一生不经历失败呢？</p>
</li>
<li><p>失败是通往成功的必经之路不要畏惧失败，要拥抱失败。不只是因为失败和被打败不同，还因为失败是通往成功的必经之路。生活中所有值得拥有、值得去完成的事情都需要经历失败。问题是，我们学到的都是用负面的视角去看待失败。上学的时候，作业得了F，这被看为退步。没有人教你要把这个失败看作能让你离自己的目标越来越近的学习经验，你反而会被告知这整个都是负面的事情。现实生活不是那样的。我不是说你不应该为了考试而学习，也不是说为了获得学习经验和塑造个性而一定要努力考一个F，我想说的是，在现实生活中失败通常是必要的里程碑，它能带领我们离成功越来越近。在现实世界里，当你在某件事上失败的时候，你从中学到了经验并且有可能成长。我们的大脑就是被这样训练的。如果你曾经试过学习如何玩杂耍，或者打篮球，或者其他需要相互配合的体育活动，你会知道在成功前会失败很多次。</p>
</li>
<li><p>学会拥抱失败重申一遍，我必须要说，即使你在本书中什么都没有学到，那也要记下下面这条建议：学会拥抱失败、期待失败、接受失败，并准备直面失败。只是不畏惧失败还不够，还要主动寻觅失败。想成长就必须把自己放在保证会失败的环境中。我们常常会因为停止做那些对我们有挑战或者危险的事情而停滞不前。我们寻找生活中的温室，关上小屋的门，拉上窗户，任凭外面狂风暴雨，我们绝不冲到雨中。但是，有时候你需要被淋湿，有时候你需要把自己放到一个不舒服的环境下强迫自己成长，有时候你需要积极地走出去寻找这样的环境，要知道，你越将你的船驶向失败，将你吹向失败的另外一面（成功）的风就会越强。要如何拥抱失败？要如何说服自己跳入波涛汹涌的大海？从接受失败是生活的一部分开始。你必须明白，在生活中你要面对很多失败，很多是不可避免的，任何事情第一次做都不可能做到完美，你会犯错。你还要明白，就算失败也没关系。犯错也没关系。你可以尝试避免犯错，但是不要因为害怕伤害自尊而以付出错失良机为代价。一旦你意识到失败是好事，失败并不能定义你的价值而你对待失败的态度恰恰才能说明你的价值，你才会真正学会对失败无所畏惧。最后，我还是要建议你将自己暴露在失败的环境里。去做那些让你不舒服的事情。在本书的前面我们讨论过不要害怕看起来像个傻瓜，对待失败我也要说一样的话。事实上，这两个观点是紧密相连的。走出去，有目的地去把自己放在那些不可避免地会导致某种失败的困境中。但关键是不要放弃——让失败点亮通往成功的道路。去经历尽可能多的失败吧，畏惧失败本身才会让你失去克服困难的能力。</p>
</li>
<li><p>我要留给你最后一句关于失败的话，摘自Napoleon Hill的《思考致富》一书：“大多数伟大的人取得的最大成功与他们所经历的最大失败只有一步之遥。”</p>
</li>
<li><p>采取行动<br>对失败的恐惧是如何让你退缩的？想想生活中那些你想做但由于一时犹豫或者自尊受损而没有做的事情。<br>承诺至少做一件因为害怕失败而一直回避的事情。不要敷衍了事。很多人明知道有些事会失败还去“尝试”，这样做不会让他们真正失败，因为“没有真正尝试过”才会是失败。真的去尝试，真的去体验失败吧。</p>
</li>
</ul>
<h3 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h3><ul>
<li><p>好吧，就到这里吧。我们终于来到了这本书的结尾。之所以说“我们”，是因为我希望你把读这本书当作是跟我写这本书一样的冒险旅程。当我开始动手写这本书的时候，我并不知道写一本这么长、这么厚的书这么难。我只知道我想要写一本书，分享我在自己作为软件开发人员的职业生涯中已经学到的一些重要的经验和教训——并不是关于如何编写优质代码、推动职业生涯上进的经验，而是关于如何做好更全面的人的经验，以及如何把我的人生价值发挥到最大同时又有利于他人的经验。我不是天才。我甚至都不是一位能够在反思他几十年的生活经验之后给你可以受益50年的智慧的长者，所以不要把我的这本书当作福音。这本书就是我的经验以及到目前为止让我获得成功的关键要素的分享。希望你能从中找到一些有用的东西，即便你可能不同意书中的所有观点——那也没关系。这正是这本书的要点。你不能把别人说的话都当作福音。没有人可以垄断真理。现实中，很大程度上，正是你自己发现了真理。这并不意味着你可以忽视这世界上的公认真理、只管自行其是，但这意味着你可以决定你想要过怎样的生活，你该怎样去生活。如果你能学会管理诸如成功、理财、健身以及自己的心理状态等事务的基本原则，你就可以利用这些原则来塑造你自己的现实世界。希望在读完这本书之后，你已经得出结论：那些你过去已经被告知的关于“你该如何生活”的狭窄的、笔直的道路，如你要取得好成绩、尽量不要搞砸了、上大学、找份工作然后安心工作50多年直到退休吧……并不是你可以走下去的唯一道路。当然，你也可以继续沿着过去被告知的那条道路前进，只要你愿意；不过，如果你正在读这本书，我相信你已经意识到，生活原本要比你所厌恶的朝九晚五的工作丰富多彩得多。希望这本书已经让你意识到，全世界都是你的机会，都在你的掌控之下。你可以更好地管理自己的职业生涯，可以从中获益更多，甚至可以把自己的职业生涯带向全新的方向，可以学会实际构建自己的个人品牌、营销自己——把自己的软件开发职业生涯提升到一个认为不可能达到的全新高度，让自己有机会影响更多的人。希望这本书教会了你学习和吸收信息的新方法，给了你足够的信心去超越自我——不只是为了学到东西而去学习，还要把你学到的知识与他人分享、使他人受益，不管你是沿着哪条路径前进。希望这本书能够激励你更有成效，更谨慎地管理和善用你的时间，并且能够激励你看到努力工作的价值，并付诸于实践——即使是在你觉得缺乏动力继续前行的时候。希望这本书能激励你以某种方式去健身，更好地照顾自己的身体健康，使你意识到实际上你也可以保持身材，并不因为你是软件开发人员就不能成为健壮的、运动型的人，只要你愿意，你至少可以主动控制自己的健康。最后，我希望这本书已经帮你意识到意志力是多么强大、多么重要，你的头脑可以作为一种工具，要么推动你前进，要么在你来不及做出反应、来不及应用自己所学的时候就摧毁你的前程。我希望这本书可以让你意识到你有能力成为你想成为的人，你也可以通过积极思考和坚持到底的力量重新塑造自己。</p>
</li>
<li><p>是的，这些都是任何一本书都向往的崇高目标，尤其是一本与软件开发有关的书。不过，只要我能在一些很小的地方帮到你，让你改善了自己的生活哪怕一点点，我都会认为这是一场胜利。在你放下这本书之前，我有一个小小的请求：如果你发现这本书对自己有帮助，如果你认为其他人也可能会从中受益，请把它分享给别人。我这么说不是为了提高这本书的销量——尽管我很愿意这么做，但是着手写这本书真不是为了赚钱——我花500小时可以做很多很多更有利可图的事情，写这本书只是因为我认为我们不仅应该不遗余力地做好一个软件开发人员，而且应该做好一个人：去帮助他人。感谢你抽出时间来阅读这本书，并真诚地希望你能在本书中发现一些永久的价值。John Sonmez，<a href="http://simpleprogrammer.com/">http://simpleprogrammer.com</a></p>
</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>《枪炮、病菌与钢铁：人类社会的命运》-笔记</title>
    <url>/2020/12/19/20201219-qiang-pao-bing-jun-yu-gang-tie-ren-lei-she-hui-de-ming-yun-bi-ji/</url>
    <content><![CDATA[<ul>
<li>为什么最后带来枪炮、凶恶的病菌和钢铁的竟是欧洲人，而不是非洲人或印第安人？</li>
<li>对本书来说，这样的一句话就是：“不同民族的历史遵循不同的道路前进，其原因是民族环境的差异，而不是民族自身在生物学上的差异。”</li>
</ul>
<h3 id="第一章-走上起跑线"><a href="#第一章-走上起跑线" class="headerlink" title="第一章 走上起跑线"></a>第一章 走上起跑线</h3><ul>
<li>随着人类在澳大利亚&#x2F;新几内亚的定居，现在人类已占据了可以居住的5个大陆中的3个。（在本书中，我始终把欧亚大陆算作一个大陆，我没有把南极大陆计算在内，因为南极大陆直到19世纪才有人到达，而且从来没有任何自给自足的居民。）这样就只剩下两个大陆：北美洲和南美洲。它们无疑是最后两个有人定居的大陆，这原因很明显，因为从旧世界到达美洲要么用船（甚至在印度尼西亚直到4万年前才有证据表明已有了船，而欧洲要晚得多才有船）去渡海，要么得先占有西伯利亚（直到大约2万年前才有人居住）以便通过白令陆桥。</li>
<li>克罗维的猎人们在美洲向南推进，遇到了以前从未见过人的大型动物。他们可能发现这些美洲动物很容易杀死，于是就把它们消灭了。</li>
<li>在可以住人的5个大陆中，北美洲和南美洲是人类史前史最短的两个大陆。</li>
<li>在过去的700年中，唯一的无人居住、等待欧洲探险者光顾的地区就只剩下大西洋和印度洋中那些最偏远的岛屿（如亚速尔群岛和塞舌尔群岛）和南极大陆了。</li>
<li>如果现代人类的确是在大约10万年前出现在非洲，然后向其他大陆扩散，那么其他地方在这期间积累起来的优势都会被一扫而光，从而使非洲人取得新的领先优势。而且，人类遗传的多样性以非洲为最高；也许更多样的人类集体会带来更多样的发明创造。不过，我们的这位考古学家那时可能会想：就本书的论题来说，究竟什么是“领先优势”？</li>
</ul>
<h3 id="第二章-历史的自然实验"><a href="#第二章-历史的自然实验" class="headerlink" title="第二章 历史的自然实验"></a>第二章 历史的自然实验</h3><ul>
<li>一般地说，人口越多，人口密度越高，技术和组织就越复杂，专业程度就越高。简言之，人口密度高时，只有一部分人最后成为农民，但他们被调动起来去专门从事集约型的粮食生产，从而生产出剩余粮食去养活非生产者。能够调动农民的非生产者包括首领、神职人员、官员和战士。</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>人口密度的重要性！</li>
</ul>
<h3 id="第三章-卡哈马卡的冲突"><a href="#第三章-卡哈马卡的冲突" class="headerlink" title="第三章 卡哈马卡的冲突"></a>第三章 卡哈马卡的冲突</h3><ul>
<li>现代最大的人口变迁是欧洲人对新大陆的移民，以及随之发生的对美洲土著（美洲印第安人）的征服、土著人数的减少或完全消失。</li>
<li>阿塔瓦尔帕在卡哈马卡的出现突出了世界史上的一个关键因素：具有相当免疫力的入侵民族把疾病传染给没有免疫力的民族。天花、麻疹、流行性感冒、斑疹伤寒、腺鼠疫以及其他一些在欧洲流行的传染病，毁灭了其他大陆的许多民族，从而在欧洲人的征服中起了一种决定性的作用。</li>
<li>我并不是要暗示历史上疾病的作用只限于为欧洲人的扩张铺平道路。疟疾、黄热病以及热带非洲、印度、东南亚和新几内亚的一些其他疾病，是欧洲在这些热带地区进行殖民的最大障碍。</li>
<li>皮萨罗成功的直接原因包括：以枪炮、钢铁武器和马匹为基础的军事技术；欧亚大陆的传染性流行病；欧洲的航海技术；欧洲国家集中统一的行政组织和文字。</li>
<li>为什么这种直接优势总是在欧洲一边，而不是在新大陆一边。为什么不是印加人发明枪炮和钢刀，骑上像战马一样的令人生畏的牲口，携带对欧洲人来说没有抵抗力的疾病，修造远洋船只和建立先进的行政组织，并能从几千年有文字记载的历史吸取经验？</li>
</ul>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><ul>
<li>病菌的影响</li>
</ul>
<h3 id="第四章-农民的力量"><a href="#第四章-农民的力量" class="headerlink" title="第四章 农民的力量"></a>第四章 农民的力量</h3><ul>
<li>从间接的意义说，粮食生产是枪炮、病菌和钢铁发展的一个先决条件。</li>
<li>第一个因果关系是最直接的因果关系：能够获得更多的可消耗的卡路里就意味着会有更多的人。在野生的动植物物种中，只有很少一部分可供人类食用，或值得猎捕或采集。<br><img src="/2020/12/19/20201219-qiang-pao-bing-jun-yu-gang-tie-ren-lei-she-hui-de-ming-yun-bi-ji/pic1.jpg"></li>
<li>通往使某些民族能够征服另一些民族的近似因素（如枪炮、马匹和疾病）的因果关系链。例如，人类的各种各样疾病是在有许多适于驯化的动植物物种的地区演化的，这一部分是由于生产出的农作物和饲养的牲畜帮助养活了使流行疾病得以保持的人口稠密的社会；一部分是由于这些疾病是从驯化的动物身上的病菌演化而来。</li>
<li>作为传统社会中的一个燃料来源，动物粪便也有其价值。此外，最大的驯化哺乳动物与驯化植物相互作用，以增加粮食产量，这表现在它们可以用来拉犁，从而使人们可以去耕种以前如用来耕种则代价太高的土地。</li>
<li>许多狩猎采集社会里的人经常跑来跑去寻找野生食物，但农民必须留在他们的田地和果园附近。因此而产生的固定居所由于缩短了生育间隔期而促使人口变得更稠密起来。</li>
<li>事实上，到处流浪的以狩猎采集为生的人通过哺乳期无月经、禁欲、杀婴和堕胎等办法，把孩子出生的间隔安排为大约每4年一个。相比之下，定居的部族由于没有在迁移途中携带小孩这种问题的限制，他们可以多生多养，只要养得活就行。</li>
<li>评论：采集社会时期的人类同样采取抛弃弱小，这样做用现代评价标准就是灭绝人性，但在当时是不得不采取的手段。</li>
<li>定居生活的另一个结果是人们可以把多余的粮食贮藏起来，因为如果人们不能留在附近看管贮藏的粮食，那么贮藏就是毫无意义的。虽然有些到处流浪的狩猎采集部族可能偶尔也把几天吃不完的食品收藏起来，但这种富余对他们几乎毫无用处，因为他们不能保护它。但贮藏的粮食对于养活不生产粮食的专门人材是必不可少的，而对于养活全村社的人肯定是必不可少的。因此，到处流浪的狩猎采集社会几乎没有或完全没有这类专职的专门人材，这种人材首先出现在定居社会中。</li>
<li>一旦有了粮食储备，行政上层人物就可以控制别人生产的粮食，维护征税的权利，无需去养活自己，而以全部时间从事行政活动</li>
<li>通过税收建立剩余粮食储备，除了养活国王和官员外，还能养活其他专职的专门人材。与征服战争关系最直接的是，剩余粮食储备可以用来养活职业军人。这是不列颠帝国最终打败新西兰武装精良的本土毛利人的决定性因素。</li>
<li>至此，我已着重指出了作为粮食的农作物和家畜的直接和间接的价值。然而，它们还有其他用途，例如帮我们保暖和向我们提供有价值的材料。农作物和家畜生产出的天然纤维，可以用来做衣服、毯子、网和绳子。</li>
<li>驯化的大型哺乳动物在19世纪铁路发展起来之前成为我们主要的陆路运输手段，从而进一步使人类社会发生了革命性的剧变。最后以蒙古人于公元13世纪和14世纪征服亚洲和俄罗斯的许多地方而达到高潮。只是由于在第一次世界大战中采用了卡车和坦克，马的作用才最后被取代，而不再是战争中主要的突击手段和快速运输的工具。</li>
<li>在征服战争中同样重要的是在驯养动物的社会中演化的病菌。像天花、麻疹和流行性感冒这类传染病作为人类的专化病菌出现了，它们原是动物所感染的十分类似的祖代病菌由于突变而衍生出来的<br>驯养动物的人成了这些新演化出来的病菌的第一个受害者，而这些人接着又逐步形成了对这些新的疾病的强大的抵抗力。当这些有部分免疫力的人与以前从来没有接触过这种病菌的人接触时，流行病于是产生了，99%的以前没有接触过这种病菌的人因之而丧命。从驯养的动物那里最后获得的病菌，在欧洲人对美洲、澳大利亚、南非和太平洋诸岛的土著的征服中起了决定性的作用。</li>
<li>总之，动植物的驯化意味着人类的粮食越来越多，因而也就意味着人口越来越稠密。因此而带来的粮食剩余和（在某些地区）利用畜力运输剩余粮食，成了定居的、行政上集中统一的、社会等级分明的、经济上复杂的、技术上富有革新精神的社会的发展的先决条件。因此，能否利用驯化的动植物，最终说明了为什么帝国、知书识字和钢铁武器在欧亚大陆最早发展起来，而在其他大陆则发展较晚，或根本没有发展起来。</li>
</ul>
<h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><ol>
<li>粮食生产的重要</li>
<li>定居生活</li>
<li>病菌的产生</li>
</ol>
<h3 id="第五章-历史上的穷与富"><a href="#第五章-历史上的穷与富" class="headerlink" title="第五章 历史上的穷与富"></a>第五章 历史上的穷与富</h3><ul>
<li>为什么粮食生产首先在看似相当贫瘠的土地上形成，只是到后来才在今天最肥沃的农田和牧场发展起来？所有这些问题都涉及不同的发展阶段，而正是这些不同的发展阶段决定了哪些民族成了历史上的贫穷民族，哪些民族成了历史上的富有民族。<br><img src="/2020/12/19/20201219-qiang-pao-bing-jun-yu-gang-tie-ren-lei-she-hui-de-ming-yun-bi-ji/pic2.jpg"></li>
<li>世界上只有几个地区发展了粮食生产，而且这些地区发展粮食生产的时间也差异甚大。一些邻近地区的狩猎采集族群从这些核心地区学会了粮食生产，而其他一些邻近地区的族群则被来自这些核心地区的粮食生产者所更替了——更替的时间仍然差异甚大。最后，有些族群虽然生活在一些生态条件适于粮食生产的地区，但他们在史前期既没有发展出农业，也没有学会农业；他们始终以狩猎采集为生，直到现代世界最后将他们淘汰。在粮食生产上具有领先优势的那些地区里的族群，因而在通往枪炮、病菌和钢铁的道路上也取得了领先的优势。其结果就是富有社会与贫穷社会之间一系列的长期冲突。</li>
</ul>
<h3 id="第六章-种田还是不种田"><a href="#第六章-种田还是不种田" class="headerlink" title="第六章 种田还是不种田"></a>第六章 种田还是不种田</h3><ul>
<li>由于粮食生产较狩猎采集有更高的每英亩可摄入卡路里数，人口密度也倾向于更高。而在另一方面，整个更新世后期的人口密度本来就在持续上升，归因于人类采集加工野生食物的技术进步。随着人口增长，粮食生产越来越受青睐，因为它提供了给养所有人所必需的粮食增产。这就是说，采纳粮食生产为所谓的自身催化过程提供了例证——这是一个在正反馈循环中自身催化的过程，这个过程一旦开始，速度就越来越快。人口密度的逐步增加，迫使人们去奖励那些无意中增加了粮食产量的人，以获得更多的粮食。一旦人们开始生产粮食并过定居的生活，他们就能够缩短生育间隔期，生出更多的人来，从而也就需要更多的粮食。粮食生产与人口密度之间的这种双向关系，说明了一种矛盾的现象，即粮食生产一方面增加了每英亩可摄入的卡路里的数量，一方面却又使这些粮食生产者的营养不及他们所承继的那些以狩猎采集为生的人。这种矛盾之所以产生，是因为人口密度的增加速度要稍高于粮食的增加速度。</li>
</ul>
<h3 id="第七章-怎样识别杏仁"><a href="#第七章-怎样识别杏仁" class="headerlink" title="第七章 怎样识别杏仁"></a>第七章 怎样识别杏仁</h3><ul>
<li>植物驯化可以定义为：栽种某一植物并由此有意或无意地使其发生不同于其野生祖先的、更有利于人类消费的遗传变化。</li>
<li>不同的植物由于十分不同的或甚至相反的特点而得到选择。有些植物（如向日葵）由于大得多的种子而得到选择，而另一些植物（如香蕉）则由于种子小或没有种子而得到选择。选择生菜则取其茂盛的叶子而舍其种子或果实；选择小麦和向日葵则取其种子而舍其叶；选择南瓜则取其果实而舍其叶。特别有意思的是，由于不同的目的，对于一种野生植物可以有不同的选择，从而产生了外观十分不同的作物。</li>
<li>新月沃地的小麦和大麦是被称之为谷物（属禾本科）的那类作物的代表，而新月沃地的豌豆和兵豆则是豆类（属豆科，包括大豆）的代表。谷类作物的优点是生长快，碳水化合物含量高，每公顷耕地可产1吨食物。因此，今天的谷物占人类消耗的全部卡路里的半数以上，并包括现代世界上12种主要作物中的5种（小麦、玉米、稻米、大麦和高粱）。许多谷类作物蛋白质含量低，但这一缺陷可以由豆类来弥补，因为豆类的蛋白质通常达25%（大豆为38%）。因此，谷物和豆类一起为均衡饮食提供了许多必不可少的成分。</li>
</ul>
<h3 id="第八章-问题在苹果还是在印第安人"><a href="#第八章-问题在苹果还是在印第安人" class="headerlink" title="第八章 问题在苹果还是在印第安人"></a>第八章 问题在苹果还是在印第安人</h3><ul>
<li>人类历史的主要事实之一，是西南亚的那个叫做新月沃地的地区（因其在地图上的新月状高地而得名，见图8.1）在人类发展早期的重要性。那个地区似乎是包括城市、文字、帝国以及我们所说的文明（不论是福是祸）在内的一连串新情况发生的地方。而所有这些新情况之所以发生，都是由于有了稠密的人口，有了剩余粮食的贮存，以及可以养活不从事农业的专门人材，凡此种种之所以可能又都是由于出现了以作物栽培和牲口饲养为形式的粮食生产。粮食生产是新月沃地出现的那些重要新事物中的第一个新事物。因此，如果想要了解现代世界的由来，就必须认真对待这样的问题，即为什么新月沃地的驯化动植物使它获得了如此强大的领先优势。</li>
<li>原来地中海气候带，尤其是在新月沃地那个地区，具有胜过其他地中海气候带的5个有利条件。第一，欧亚大陆西部显然是世界上属于地中海气候带的最大地区。因此，那里的野生动植物品种繁多，超过了澳大利亚西南部和智利这些比较小的地中海气候带。第二，在地中海气候带中，欧亚大陆西部的地中海气候带的气候变化最大，每一季、每一年气候都有不同。这种气候变化有利于植物群中数量特别众多的一年生植物的演化。物种多和一年生植物多这两个因素结合起来，就意味着欧亚大陆西部的地中海气候带显然是一年生植物品种最繁多的地区。智利的地中海型气候带只有2种，加利福新月沃地的地中海气候带的第三个有利条件，是它在短距离内高度和地形的富于变化。它的高度从地球上的最低点（死海）到18000英尺的高山（在德黑兰附近），应有尽有，从而保证了环境的相应变化，也因此保证品种繁多的野生植物可供成为作物的祖先。</li>
<li>地球上不同地区的当地作物并不是同样多产的。</li>
<li>采纳粮食生产涉及粮食生产的生活方式与狩猎采集的生活方式之间的竞争。而受到损害的则是那些没有这种机会或意愿的部落。因此，新几内亚土生土长的粮食生产所受到的限制与新几内亚的族群没有任何关系，而是与新几内亚的生物区系和环境有着最密切的关系。</li>
<li>事实上，在整个大陆和其他一些包含数以百计的互相竞争的广大地区，有些社会对新事物可能比较开放，有些社会对新事物可能比较抵制。那些接受新作物、新牲畜或新技术的社会因而可能吃得更好，繁殖得更快，从而取代、征服或杀光那些抵制新事物的社会。</li>
<li>澳大利亚这个据称最“落后的”大陆很好地说明了这个问题。澳大利亚东南部是这个大陆上水源充足、最适合粮食生产的地方。那里的土著社会在最近的几千年里似乎一直在按照一种可能最终导致本地粮食生产的发展轨迹在演化。它们已经建立了过冬的村庄。它们已经开始加强利用它们的环境，建造渔栅、编织渔网，甚至挖掘长长的水渠来从事渔业生产。如果欧洲人没有在1788年向澳大利亚殖民，从而中途破坏了那个独立的发展轨迹，那么澳大利亚土著也许不消几千年就可成为粮食生产者，照料一池池驯化了的鱼，种植驯化了的澳大利亚薯蓣和小籽粒的禾本科植物。根据这一点，我现在就能够回答包含在本章标题里的那个问题。我提出的那个问题是：北美印第安人未能驯化北美苹果的原因是在印第安人还是在苹果。</li>
<li>在欧洲人到达时印第安人仍未能驯化北美的苹果，其原因不在印第安人，也不在苹果。就苹果驯化必要的生物条件而言，北美印第安农民和欧亚大陆农民一样，北美的野生苹果也和欧亚大陆的野生苹果一样。事实上，本章读者现在正在津津有味地吃着的从超市上买来的苹果，有些品种就是不久前将欧亚大陆的苹果同北美的野生苹果进行杂交而培育出来的。印第安人未能驯化苹果的原因却是在于印第安人所能得到的整个野生动植物组合。这个组合的微弱的驯化潜力，就是北美粮食生产很晚才开始的主要原因。</li>
</ul>
<h4 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h4><ol>
<li>新月沃地(地中海气候)</li>
<li>美洲整个野生动植物组合，微弱的驯化潜力。</li>
</ol>
<h3 id="第九章-斑马、不幸的婚姻和安娜·卡列尼娜原则"><a href="#第九章-斑马、不幸的婚姻和安娜·卡列尼娜原则" class="headerlink" title="第九章 斑马、不幸的婚姻和安娜·卡列尼娜原则"></a>第九章 斑马、不幸的婚姻和安娜·卡列尼娜原则</h3><ul>
<li>驯养的大型哺乳动物对那些拥有它们的人类社会产生重大影响的那许多方面。最显著的是，这些动物提供了肉食、奶制品、肥料、陆上运输、皮革、军事突击手段、犁具牵引、毛绒以及使先前没有抵抗力的民族失去生命的病菌。</li>
<li>各大陆之间野生祖先的这种十分不均匀的分布，成了欧亚大陆人而不是其他大陆的人最后得以拥有枪炮、病菌和钢铁的一个重要原因。</li>
<li>欧亚大陆何以一直是大型哺乳动物驯化的主要场所，对这个问题的部分解释是：它是一个一开始就拥有最多的可供驯化的野生哺乳动物的大陆，在过去的40000年中，那里这样的动物因绝种而消失的也最少。</li>
<li>在驯化动物方面现代尝试的失败，提供了最后一个证据，表明过去在驯化剩下的大批候补野生动物方面的失败是由于这些动物本身的缺点，而不是由于古代人的缺点。</li>
<li>每一次某种动物在吃某种植物或另一种动物时，食物生物量转换为取食者生物量的效率远远低于100%：通常在10%左右。就是说，要花费10000磅左右的玉米才能喂养出一头1000磅重的牛。</li>
<li>动物的日常食物、生长速度、交配习惯、性情、容易受惊的倾向以及群居组织的几个不同的特点。只有很少一部分野生哺乳动物由于在上述所有这些方面都能协调一致而最终得以和人类结成美满的婚姻。</li>
<li>欧亚大陆的民族碰巧比其他大陆的民族继承了多得多的可驯化的大型野生的哺乳类食草动物。这一结果及其为欧亚大陆社会带来的全部利益，来自哺乳动物地理学、历史和生物学这3个基本事实。</li>
<li>欧亚大陆由于其广大面积和生态的多样性，一开始就拥有最多的可供驯化的候补动物。其次，澳大利亚和美洲，而不是欧亚大陆或非洲，在更新世晚期动物灭绝的大规模浪潮中失去了它们大多数可供驯化的候补动物——这可能是因为前两个大陆的哺乳动物不幸首先突然接触到人类，而且这时已是我们的进化史的后期阶段，我们的狩猎技巧已经得到了高度的发展。</li>
</ul>
<h4 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h4><ul>
<li>欧亚大陆的民族碰巧比其他大陆的民族继承了多得多的可驯化的大型野生的哺乳类食草动物。</li>
</ul>
<h3 id="第十章-辽阔的天空与偏斜的轴线"><a href="#第十章-辽阔的天空与偏斜的轴线" class="headerlink" title="第十章 辽阔的天空与偏斜的轴线"></a>第十章 辽阔的天空与偏斜的轴线</h3><ul>
<li>轴线走向的差异所产生的巨大的、有时是悲剧性的后果。轴线走向影响了作物和牲口的传播速度，可能还影响文字、车轮和其他发明的传播速度。</li>
<li>某种作物的迅速传播可能不但抢先阻止了同一植物的野生祖先在其他某个地方的驯化，而且也阻止了有亲缘关系的野生植物的驯化。</li>
<li>许多不同的现象归结为同一个结论：粮食生产从西南亚向外传播的速度要比在美洲快，而且也可能比在非洲撒哈拉沙漠以南的地区快。这些现象包括：粮食生产完全未能到达某些生态条件适合于粮食生产的地区；粮食生产传播的速度和选择性方面存在着差异；以及最早驯化的作物是否抢先阻止了对同一种植物的再次驯化或对近亲植物的驯化方面也存在着差异。</li>
<li>提出所有这些差异，并不就是说分布很广的作物是值得赞美的，也不是说这些差异证明了欧亚大陆早期农民具有过人的智慧。这些差异只是反映了欧亚大陆轴线走向与美洲或非洲大陆轴线相比较的结果。历史的命运就是围绕这些轴线旋转的。</li>
</ul>
<h3 id="第十一章-牲畜的致命礼物"><a href="#第十一章-牲畜的致命礼物" class="headerlink" title="第十一章 牲畜的致命礼物"></a>第十一章 牲畜的致命礼物</h3><ul>
<li>粮食生产这个终极原因是如何导致病菌、文化修养、技术和集中统一的政府这些直接原因的。</li>
<li>过去战争中的胜利者并不总是那些拥有最优秀的将军和最精良的武器的军队，而常常不过是那些携带有可以传染给敌人的最可怕病菌的军队。</li>
<li>虽然被那些杀人不眨眼的西班牙征服者杀死的印第安人不计其数，但凶恶的西班牙病菌杀死的印第安人却要多得多。为什么在欧洲和美洲之间这种可怕的病菌的交流是这样不对等？为什么印第安人的疾病没有大批杀死西班牙入侵者，并传回欧洲，消灭掉欧洲95%的人口？同样的问题也出现在被欧亚病菌大批杀死的其他土著身上，以及企图征服亚非热带地区的欧洲人身上。</li>
<li>作为流行病有几个共同的特点。首先，它们从一个受感染的人迅速而高效地传给近旁健康的人，结果使整个人口在很短时间内受到感染。其次，它们都是“急性”病：在很短时间内，你要么死掉，要么完全康复。第三，我们当中的确获得康复的那些幸运的人产生了抗体，使我们在很长时间内，也可能是一辈子不用担心这种病会复发。最后，这些病往往只在人类中传播；引起这些病的病菌往往不是生活在土壤中或其他动物身上。所有这4个特点也适用于美国人所认为的那些习见的儿童急性传染病，其中包括麻疹、风疹、急性腮腺炎、百日咳和天花。这4个特点结合起来往往造成了某种疾病的流行，其原因不难理解。简单地说，情况是这样的：病菌的迅速传播和症状的迅速发展，意味着当地人口中的每一个人很快就受到感染，之后不久他或者死去，或者康复并获得免疫力。仍然会受到感染的人都不会活下来。但由于这种病菌除了在活人体内是不可能生存的，所以人死了这种病也就消失了，直到又一批儿童达到易受感染的年纪——直到一个受到感染的外来人使一场流行病重新开始。</li>
<li>关于这些疾病是怎样流行起来的，有一个典型的事例是大西洋上叫做法罗群岛[插图]的与世隔绝的岛屿上的麻疹病史。1781年，一场严重的麻疹流行病到达法罗群岛，接着又消失了，其后该群岛就不再有麻疹发生，直到1846年，一个受到感染的木匠从丹麦坐船到来。不出3个月，法罗群岛的几乎全部人口（7782人）都得了麻疹，于是有的人死去，有的人康复，麻疹病毒又一次消失，直到下一次流行。一些研究表明，麻疹可能会在任何少于50万人的人口中消失。只有在比较多的人口中，这种病才会从一个地区转移到另一个地区，直到原先受感染地区里出生的婴儿达到足够的数目，麻疹又会卷土重来。适用于法罗群岛上麻疹的情况，也适用于世界上其他一些我们所熟悉的急性传染病。为了维持自身的存在，这些病需要有足够多的人口，足够拥挤的稠密人口，这样，到这种病不然就会衰退的时候，又有一大批易受感染的儿童成为感染对象。因此，麻疹和一些类似的疾病也叫做人群病。</li>
<li>人群病不可能在小群狩猎采集族群和刀耕火种的农民中存在下去。现代亚马孙河地区印第安人和太平洋岛民的悲惨经历表明，整个小部落可能被一个外来人带来的一种流行病几乎全部消灭——因为这个小部落中没有一个人有任何抵抗这种病菌的抗体。小部落人口少，这一点不但说明了为什么他们承受不住从外面带来的流行病，而且也说明了为什么他们没有能演化出自己的流行病去回敬外来人。</li>
<li>为什么农业的出现会成为我们人群传染病形成的开端？其中一个原因前面已经提到，那就是农业比狩猎采集的生活方式维持了高得多的人口密度——平均要高10倍到100倍。另外，狩猎采集族群经常变换营地，留下了一堆堆排泄物，上面聚集了大量病菌和寄生虫的幼虫。但农民是定居的，他们生活在自己排放出来的污水之中，从而为病菌从一个人的身体进入另一个人的饮用水源提供了捷径。有些农业人口把自己的粪便收集起来，当作肥料撒到人们劳动的田里，从而使粪便中的病菌和寄生虫去感染新的受害者变得甚至更加容易。</li>
<li>在动物中，流行病同样需要稠密的大种群，而不是只去折磨任何某一只动物：这些流行病主要发生在需要有大的种群的群居动物中。因此，当我们驯养牛和猪这类群居动物时，它们已经受到了一些流行病的折磨，只不过在等待着转移给我们罢了。所有这些病菌仍然处在向人类病原体演化的早期阶段。</li>
<li>美洲之所以未能出现流行的致命的人群病的主要原因就一定会变得很清楚。这个问题就是，想象一下这些疾病可能会从什么病菌演化而来？我们已经看到，欧亚大陆的人群病是从欧亚大陆驯化的群居动物的疾病演化而来的。尽管欧亚大陆有许多这样的动物，但在美洲驯化的动物只有5种：墨西哥和美国西南部的火鸡、安第斯山脉地区的美洲驼&#x2F;羊驼和豚鼠、热带南美的美洲家鸭和整个美洲的狗。反过来，我们也看到，新大陆驯化动物的这种极端缺乏，反映了用以启动驯化的野生动物的缺乏。在大约13000年前上一次冰期结束时，美洲有大约80%的大型野生哺乳动物便已灭绝了。</li>
<li>源于动物的疾病在历史上的重要性，远远超过了旧大陆与新大陆之间的冲突。欧亚大陆的病菌在大量消灭世界上其他许多地方的土著民族方面起了关键的作用。</li>
<li>毫无疑问，欧洲人在武器、技术和行政组织方面拥有对他们所征服的大多数非欧洲民族的巨大优势。但仅仅这种优势还不能完全说明开始时那么少的欧洲移民是如何取代美洲和世界上其他一些地区那么多的土著的。如果没有欧洲送给其他大陆的不祥礼物——从欧亚大陆人与家畜的长期密切关系中演化出来的病菌，这一切也许是不会发生的。</li>
</ul>
<h4 id="总结-5"><a href="#总结-5" class="headerlink" title="总结"></a>总结</h4><ol>
<li>流行病(人群病)</li>
</ol>
<h3 id="第十二章-蓝图和借用字母"><a href="#第十二章-蓝图和借用字母" class="headerlink" title="第十二章 蓝图和借用字母"></a>第十二章 蓝图和借用字母</h3><ul>
<li>知识带来力量。因此，文字也给现代社会带来了力量，用文字来传播知识可以做到更准确、更大量和更详尽，在地域上可以做到传播得更远，在时间上可以做到传播得更久。</li>
<li>文字同武器、病菌和集中统一的行政组织并驾齐驱，成为一种现代征服手段。</li>
<li>发明的传播形式有一系列形式。形式的一端是“蓝图复制”，就是对现有的一幅详尽的蓝图进行复制或修改。另一端是“思想传播”，就是仅仅把基本思想接受过来，然后必须去重新创造细节。</li>
<li>虽然蓝图的复制和修改是传播技术的最直接的选择，但有时候这种选择不一定能够得到。蓝图可能被隐藏起来，而且不是深于此道的人对蓝图也不一定能够读懂。对于在远处某个地方发明了某个东西，人们可能有所耳闻，但详细情况则可能无从知晓。也许所知道的只是这样的基本思想：某人以某种方法成功地取得了某种最后的成果。然而，知道了这一点，可能就是通过思想传播去启发别人设计他们自己的取得此种成果的途径。</li>
<li>大多数有文字的社会之所以获得文字，或是通过向邻近的社会借用，或是由于受到它们的启发而发明出文字，而不是靠自己独立创造出来的。</li>
<li>文字史引人注目地表明了类似的情况：地理和生态条件影响了人类发明的传播。</li>
</ul>
<h3 id="第十三章-需要之母"><a href="#第十三章-需要之母" class="headerlink" title="第十三章 需要之母"></a>第十三章 需要之母</h3><ul>
<li>事实上，许多发明或大多数发明都是一些被好奇心驱使的人或喜欢动手修修补补的人搞出来的，当初并不存在对他们所想到的产品的任何需要。一旦发明了一种装置，发明者就得为它找到应用的地方。只有在它被使用了相当一段时间以后，消费者才会感到他们“需要”它。还有一些装置本来是只为一个目的而发明出来的，最后却为其他一些意料之外的目的找到了它们的大多数用途。</li>
<li>寻求使用的这些发明包括现代大多数重大的技术突破，从飞机和汽车到内燃机和电灯泡再到留声机和晶体管，应有尽有。了解到这一点，也许会令人感到吃惊。因此，发明常常是需要之母，而不是相反。</li>
<li>有一项大发明最终得到使用，就会有不计其数的其他发明得不到使用。甚至有些发明当初本来是为了满足特定的需要而设计的，后来可能在满足意外需要方面证明是更有价值的。虽然詹姆士·瓦特设计他的蒸汽机是为了从煤矿里抽水，但它很快就为棉纺厂提供动力，接着又（以大得多的利润）推动着机车和轮船前进。</li>
<li>技术的发展是长期积累的，而不是靠孤立的英雄行为；技术在发明出来后大部分都得到了使用，而不是发明出来去满足某种预见到的需要。</li>
<li>一旦发明家发现了一项新技术的用途，下一步就是说服社会来采用它。仅仅有一种更大、更快、更有效的工作装置还不能保证人们会乐于接受。无数的此类技术要么根本没有被采用，要么只是在长期的抵制之后才被采用。</li>
<li>即使在同一个大陆上，各社会之间在发展和接受新事物方面也是大不相同的。即使是在同一个社会内，在时间上也会有所不同。在任何时候，在任何大陆上都有富于创新精神的社会，也有保守的社会。此外，在同一个地区内，对新事物的接受能力迟早会产生波动。</li>
<li>一个用途广泛的发明在一个社会出现后，接着它便往往以两种方式向外传播。一种方式是：其他社会看到或听说了这个发明，觉得可以接受，于是便采用了。另一种方式是：没有这种发明的社会发现与拥有这种发明的社会相比自己处于劣势，如果这种劣势大到一定程度，它们就会被征服并被取而代之。</li>
<li>在发明的传播中最容易接受发明的社会是大陆上的一些根基深厚的社会。在这些社会中技术发展最快，因为它们不但积累了自己的发明，而且也积累了其他社会的发明。</li>
<li>我们往往想当然地认为，有用的技术一旦获得，就必然会流传下去，直到有更好的技术来取而代之。事实上，技术不但必须获得，而且也必须予以保持，而这也取决于许多不可预测的因素。任何社会都要经历一些社会运动和时尚，此时一些没有经济价值的东西变得有价值起来，而一些有用的东西也变得暂时失去了价值。今天，当地球上几乎所有社会相互联系在一起的时候，我们无法想象某种时尚会发展到使人们竟然抛弃一项重要的技术。一个著名的例子是日本放弃枪支。</li>
<li>在同时代的欧洲也有一些鄙视枪支并竭力限制枪支使用的统治者。但这些限制措施在欧洲并未发生多大作用，因为任何一个欧洲国家，哪怕是短暂地放弃了火器，很快就会被用枪支武装起来的邻国打垮。只是因为日本是一个人口众多的孤立的海岛，它才没有因为拒绝这种具有巨大作用的新军事技术而受到惩罚。日本拒绝枪支和中国抛弃远洋船只（以及抛弃机械钟和水力驱动纺纱机），是历史上孤立或半孤立社会技术倒退的著名例子。</li>
<li>在这漫长的加速发展的历史中，我们可以挑出两次意义特别重大的飞跃。第一次飞跃发生在100000年到50000年前，其所以能够发生，大概是由于我们身体的遗传变化，即人体的现代解剖学进化使现代语言或现代大脑功能或两者成为可能。这次飞跃产生了骨器、专用石器和复合工具。第二次飞跃来自我们选定的定居生活方式，这种生活方式在世界的不同地区发生的时间不同，在有些地区早在13000年前就发生了，在另一些地区即使在今天也还没有发生。就大多数情况而言，选定定居的生活方式是同我们采纳粮食生产联系在一起的，因为粮食生产要求我们留在我们的作物、果园和剩余粮食储备的近旁。</li>
<li>定居生活对技术史具有决定性的意义，因为这种生活使人们能够积累不便携带的财产。四处流浪的狩猎采集族群只能拥有可以携带的技术。如果你经常迁移而且又没有车辆或役畜，那么你的财产就只能是小孩、武器和最低限度的其他一些便于携带的小件必需品。你在变换营地时不能有陶器和印刷机之类的累赘。这种实际困难或许可以说明何以有些技术出现得惊人地早，接着停了很长时间才有了进一步的发展。</li>
</ul>
<h4 id="总结-6"><a href="#总结-6" class="headerlink" title="总结"></a>总结</h4><ol>
<li>发明常常是需要之母，而不是相反。</li>
<li>不接受新事物，很可能会被征服并被取而代之。</li>
<li>日本放弃枪支；</li>
<li>定居生活的意义；</li>
</ol>
<h4 id="总结-重点"><a href="#总结-重点" class="headerlink" title="总结(重点!!!)"></a>总结(重点!!!)</h4><ul>
<li>现在，让我们来总结一下，粮食生产开始的时间、技术传播的障碍和人口的多寡这3大因素的变化，是怎样直接导致我们所看到的各大陆之间在技术发展方面的差异的。</li>
<li>欧亚大陆（实际上也包括北非在内）是世界上最大的陆块，包含有数量最多的互相竞争的社会。它也是最早开始拥有粮食生产的两个中心的陆块，这两个中心就是新月沃地和中国。它的东西向的主轴线，使欧亚大陆一个地区采用的许多发明得以较快地传播到欧亚大陆具有相同纬度和气候的其他地区的社会。它的沿次轴线（南北轴线）的宽度，同美洲巴拿马地峡的狭窄形成了对照。它没有把美洲和非洲的主轴线切断的那种严峻的生态障碍。因此，对技术传播的地理和生态障碍，在欧亚大陆没有在其他大陆那样严峻。由于所有这些因素，后更新世技术的加速发展，在欧亚大陆开始得最早，从而导致了本地最大的技术积累。</li>
<li>北美洲和南美洲在传统上被看作是两个不同的大陆，但它们连接在一起已有几百万年之久，有着类似的历史问题，因此可以把它们放在一起来考虑，以便和欧亚大陆相比较。美洲构成了世界上第二大的陆块，但比欧亚大陆小得多。不过，它们在地理和生态上却支离破碎：巴拿马地峡宽不过40英里，等于在地理上把美洲给腰斩了，就像这个地峡上的达里安雨林和墨西哥北部的沙漠在生态上所做的那样。墨西哥北部的沙漠把中美洲人类的先进社会同北美洲的社会分隔开了，而巴拿马地峡则把中美洲的先进社会同安第斯山脉地区和亚马孙河地区的社会分隔开了。此外，美洲的主轴线是南北走向，从而使大部分的技术传播不得不逆纬度（和气候）的梯度而行，而不是在同一纬度内发生。例如，轮子是在中美洲发明的，而美洲驼是不迟于公元前3000年在安第斯山脉中部驯化的，但过了5000年，美洲的这唯一的役畜和唯一的轮子仍然没有碰头，虽然中美洲玛雅社会同印加帝国北部边界之间的距离（1200英里）比同时享有轮子和马匹的法国同中国之间6000英里的距离要短得多。在我看来，这些因素足以说明美洲在技术上落后于欧亚大陆这个事实。</li>
<li>非洲撒哈拉沙漠以南地区是世界上第三大的陆块，但比美洲小得多。在人类的大部分历史中，到欧亚大陆比到美洲容易多了，但撒哈拉沙漠仍然是一个主要的生态障碍，把非洲撒哈拉沙漠以南地区同欧亚大陆和北非隔开。非洲的南北轴线造成了欧亚大陆与非洲撒哈拉沙漠以南地区之间以及撒哈拉沙漠以南地区本身内部技术传播的又一障碍。作为后一障碍的例子，陶器和炼铁术出现在或到达非洲撒哈拉沙漠以南的萨赫勒地带（赤道以北），至少同它们到达西欧一样早。然而，陶器直到公元元年才到达非洲的南端，而冶金术在从欧洲由海路到达非洲南端时，还不曾由陆路传播到那里。最后，澳大利亚是最小的一个大陆。澳大利亚大部分地区雨量稀少，物产贫乏，因此，就其所能养活的人口来说，它实际上就显然甚至更小。它也是一个最孤立的大陆。加之，粮食生产也从来没有在澳大利亚本地出现过。这些因素加在一起，就使澳大利亚成为唯一的在现代仍然没有金属制品的大陆。</li>
<li>人口多意味着搞发明的人和互相竞争的社会也多。</li>
<li>各大陆之间在面积、人口、技术传播的难易程度和粮食生产的开始时间等方面存在着差异，而这些差异又对技术的出现产生了种种影响，但所有这些影响都被夸大了，因为技术可以催化自身。欧亚大陆在开始时的巨大优势因此就变成了自1492年[插图]起的巨大的领先优势——其原因是欧亚大陆独特的地理条件，而不是那里的人特别聪明。我所认识的那些新几内亚人中就有潜在的爱迪生。不过，他们把自己的聪明才智用于解决适合自己情况的技术问题：不靠任何进口物品而在新几内亚丛林中生存的问题，而不是发明留声机的问题。</li>
</ul>
<h3 id="第十四章-从平等主义到盗贼统治"><a href="#第十四章-从平等主义到盗贼统治" class="headerlink" title="第十四章 从平等主义到盗贼统治"></a>第十四章 从平等主义到盗贼统治</h3><ul>
<li><p>有些社会最早实现了集中统一的政府和有组织的宗教，而这些社会的子孙后代最后主宰了现代世界。政府和宗教就是这样结合起来发挥了作用，它们是产生历史最广泛模式的4组主要的直接动力之一，另外3组动力是病菌、文字和技术。</p>
</li>
<li><p>超越族群的那些阶段中的第一个阶段是部落。部落与族群的区别是它比较大（一般有几百人，而不是几十人），而且通常有固定的居住地。然而，有些部落，甚至有些由酋长管辖的部落，却是由随季节而迁移的牧人组成的部落是由不止一个的得到正式承认的亲属群体所组成，这些群体称为氏族，氏族之间互相通婚。土地属于某个氏族，不属于整个部落。然而，部落的人数仍然很少，每一个人都知道另外每一个人的名字和他的各种亲属关系。对人类其他类型的群体来说也是一样，在一个群体里如要做到彼此了解，这个群体的人数最多似乎以“几百人”为宜。</p>
</li>
<li><p>早期的国王本人就是国家宗教的领袖，否则就另外设立一个大祭司。美索不达米亚的寺庙不但是宗教活动的中心，而且也是经济再分配、文字和手工技术的中心。</p>
</li>
<li><p>同样明显的是，国家在与较简单的实体发生冲突时所以能取得胜利，部分原因是国家拥有武器和其他技术方面的优势，同时也拥有人口数量上的优势。但酋长管辖地和国家还有另外两个固有的潜在优势。首先，中央决策者拥有集中军队和资源的优势。其次，许多国家的官方宗教和爱国热忱使它们的军队在作战中视死如归，心甘情愿地为国捐躯。在现代国家中，乐于为国牺牲的思想由我们的学校、教会和政府大力灌输给我们公民，使我们忘记了它标志着同以往人类历史的彻底决裂。</p>
</li>
<li><p>“几百人”是个界限，在这个界限内每个人能够认识另外每个人，一旦超过这个界限，越来越多的两人组合就成了一对对没有亲属关系的陌生人了。当陌生人打架时，在场的人很少会是打架双方的朋友或亲属，没有什么私利要他们去制止打架。相反，如果许多旁观者是打架一方的朋友或亲属，他们就会站在他的一边，这样，本来是两个人的打架结果就逐步升级为一场乱哄哄的群殴。因此，一个继续把冲突交给全体成员去解决的大型社会必然会分崩离析。随着人口的增加，共同决策越来越难以做到。</p>
</li>
<li><p>部落之间进行征服或兼并以达到了酋长管辖地的规模，酋长管辖地之间进行征服或兼并以达到了国家的规模，国家之间进行征服或兼并以形成帝国。更一般地说，大的单位可能拥有对各个小的单位的某种优势。小型社会的领袖和大型社会的领袖一样，珍惜自己的独立和特权。合并的发生不外乎下面的两种方式之一：在外力的威胁下合并，或通过实际的征服。</p>
</li>
<li><p>战败民族的命运取决于人口的密度，这有3种可能的后果：凡是人口密度很低的地方，就像在狩猎采集族群占据的地区所常见的那样，战败群体的幸存者只要离开他们的敌人远一点就行了。新几内亚和亚马孙河地区游牧部族之间战争的结果往往就是这样。凡是人口密度中等的地方，就像粮食生产部落占据的地区那样，没有大片空旷的地方可以让战败族群的幸存者逃避。但是，</p>
</li>
<li><p>没有集约型粮食生产的部落社会不使用奴隶，也不能生产出可以作为很大一部分贡品的足够的剩余粮食。因此，战败部落的幸存者对胜利者来说毫无用途，除非娶他们的女人为妻。战败的男人都被杀死了，他们的地盘也可能为胜利者所占有。</p>
</li>
<li><p>凡是人口密度高的地方，就像国家或酋长管辖地所占有地区那样，被打败的人仍然无处可逃，但胜利者不杀死他们而有了利用他们的两种选择。由于酋长管辖地社会和国家社会已出现了经济专业化，被打败的人可以当奴隶来使用，就像在《圣经》时代通常发生的那样。或者，由于许多这样的社会已经有了能够生产大量剩余粮食的集约型粮食生产系统，胜利者可以让战败者仍然从事原来的劳作，只是剥夺了他们的政治自主权，要他们定期地用粮食或货物来纳贡，并把他们的社会合并入获胜的国家或酋长管辖地。</p>
</li>
<li><p>粮食生产及社会之间的竞争与混合，产生了征服的直接原动力：病菌、文字、技术和中央集权的政治组织。这些原动力往往是相互联系着一起出现的，不过这种联系并不是绝对的。</p>
</li>
</ul>
<h4 id="总结-7"><a href="#总结-7" class="headerlink" title="总结"></a>总结</h4><ol>
<li>中央集权政治组织</li>
<li>精神控制手段</li>
<li>大型社会必须要有复杂组织主要有四个原因：陌生人之间的人际冲突调节，共同决策越来越难做到，货物交换变得复杂，土地面积不变人口的增加使得人们从别的地区获得需要品。</li>
</ol>
<h3 id="第十五章-耶利的族人"><a href="#第十五章-耶利的族人" class="headerlink" title="第十五章 耶利的族人"></a>第十五章 耶利的族人</h3><ul>
<li>澳大利亚是最干燥、最小、最平坦、最贫瘠、气候最变化无常、生物品种最稀少的大陆。</li>
<li>由于新几内亚人是粮食生产者，不是以狩猎采集为生的人，所以他们的平均人口密度比澳大利亚人高得多：新几内亚的面积只有澳大利亚的十分之一，但它所养活的当地人口却数倍于澳大利亚。</li>
<li>新几内亚有几个不利于它的生物因素和地理因素。首先，虽然本地的粮食生产的确是在新几内亚高原地区出现的，但我们已在第八章中看到，它产出的蛋白质很少。当地的主食都是低蛋白的根用作物，而仅有的驯化动物（猪和鸡）的产量又太低，不能为人们提供大量的蛋白质。既然无法把猪或鸡套起来拉车，高原地区的居民除了两臂力气外，仍然没有其他动力来源，而且也未能发展出流行疾病以击退终于侵入的欧洲人。对高原地区人口数量的第二个限制，是能够利用的土地面积有限：新几内亚高原地区只有几处宽阔的谷地（最显著的是瓦吉谷地和巴利姆谷地）能够养活稠密的人口。第三个限制是这样的现实，即4000英尺至9000英尺之间的中间山地森林地带，是新几内亚唯一适于集约型粮食生产的高程地带。在9000英尺以上的新几内亚高山生境根本没有任何粮食生产，在4000英尺至1000英尺之间的山坡上几乎没有什么粮食生产，而在低地地区也只有低密度的刀耕火种农业。因此，在不同海拔高度专门从事不同类型粮食生产的一些社会之间对粮食的大规模经济交换，在新几内亚从未发展起来。在安第斯山脉、阿尔卑斯山脉和喜马拉雅山脉，这种交换不但向各个海拔高度的人提供一种比较均衡的饮食，从而增加了这些地区的人口密度，而且也促进了地区的经济和政治一体化。</li>
<li>任何在澳大利亚本地出现的粮食生产，都可能会由于可驯化的动植物的缺乏以及土壤贫瘠和气候恶劣而受到限制。流浪的生活、狩猎采集的生活方式以及对住所和财物的最小的投资，是因受澳大利亚厄尔尼诺南移影响而无法预知可以得到何种资源时的明智的适应行为。在当地条件恶化时，土著居民只是迁往一个暂时条件较好的地区。</li>
</ul>
<h4 id="总结-8"><a href="#总结-8" class="headerlink" title="总结"></a>总结</h4><ul>
<li>新几内亚地区环境比澳大利亚大陆好，相对比较”先进”，但还是比不上亚欧大陆。</li>
<li>总结一下，新几内亚社会发展落后的几大原因：一是可供驯化的动植物品种少且蛋白质低；二是可利用的土地资源少；三是（基于以上原因）人口少密度低，且分散化严重，彼此争斗不休；四是外部地理的隔绝，难以传入借鉴先进的技术和思想。</li>
</ul>
<h3 id="第十六章-中国是怎样成为中国人的中国的"><a href="#第十六章-中国是怎样成为中国人的中国的" class="headerlink" title="第十六章 中国是怎样成为中国人的中国的"></a>第十六章 中国是怎样成为中国人的中国的</h3><ul>
<li>近代民族大熔炉这一普遍现象的重大例外是世界上人口最多的国家——中国。</li>
<li>中国过去也曾经是形形色色、变化多端的，就像其他所有人口众多的国家现在仍然表现出来的那样。中国的不同之处仅仅在于它在早得多的时候便已统一了。</li>
<li>虽然中国的南北梯度妨碍了作物的传播，但这种梯度在中国不像在美洲或非洲那样成为一种障碍，因为中国的南北距离较短；同时也因为中国的南北之间既不像非洲和墨西哥北部那样被沙漠阻断，也不像中美洲那样被狭窄的地峡隔开。倒是中国由西向东的大河（北方的黄河、南方的长江）方便了沿海地区与内陆之间作物和技术的传播，而中国东西部之间的广阔地带和相对平缓的地形最终使这两条大河的水系得以用运河连接起来，从而促进了南北之间的交流。所有这些地理因素促成了中国早期的文化和政治统一，而西方的欧洲虽然面积和中国差不多，但地势比较高低不平，也没有这样连成一体的江河，所以欧洲直到今天都未能实现文化和政治的统一。</li>
<li>在中国，有些新事物是由南向北传播的，尤其是铁的冶炼和水稻的栽培。但主要的传播方向是由北向南。这个趋向在文字上表现得最为明显：欧亚大陆西部曾产生过太多的书写系统，如苏美尔的楔形文字、埃及的象形文字、赫梯文字[插图]、弥诺斯文字和闪语字母。中国则不同，它只产生了一种得到充分证明的书写系统。它在华北得到完善，并流传各地，预先制止了任何其他不成熟的书写系统的发展或取而代之，最后演化为今天仍在中国使用的文字。</li>
<li>中国的3个最早的王朝——夏、商、周都是在公元前第二个一千年间在华北兴起的。现存的公元前第一个千年的著作表明，当时的华夏族就已常常（就像今天许多人仍然在做的那样）觉得在文化上比非华夏族的“野蛮人”优越，而华北人也常常甚至把华南人也看作野蛮人。</li>
<li>由于东亚最早的农民所取得的成就，中国成了中国人的中国。</li>
</ul>
<h4 id="总结-9"><a href="#总结-9" class="headerlink" title="总结"></a>总结</h4><ol>
<li>南北距离较短，且无地理隔离</li>
<li>很早就文化统一</li>
<li>有粮食生产</li>
</ol>
<h3 id="第十七章-驶向波利尼西亚的快艇"><a href="#第十七章-驶向波利尼西亚的快艇" class="headerlink" title="第十七章 驶向波利尼西亚的快艇"></a>第十七章 驶向波利尼西亚的快艇</h3><ul>
<li>南岛语系的4个语族中有3个集中在台湾，这表明台湾就是今天各地南岛语的故乡，在过去几千年的大部分时间里，这些语言一直在台湾使用，因此有最长的时间来产生分化。这样看来，从马达加斯加到复活节岛，所有其他南岛语可能都起源于台湾向外的人口扩张。</li>
<li>南岛人在新几内亚地区扩张的结果与在印度尼西亚和菲律宾扩张的结果全然不同。在印度尼西亚和菲律宾，当地的人口消失了——大概是被这些入侵者赶走、杀死、用传染病害死或甚至同化了。而在新几内亚，当地的人口多半把这些入侵者挡在外面。</li>
<li>中国的华南人发展了本地的粮食生产和技术，接受了华北的文字、更多的技术和政治组织，又进而向热带东南亚和台湾移民，大规模地取代了这些地区的原有居民。</li>
<li>与澳大利亚和美洲不同，东亚和大多数太平洋岛屿仍然为东亚民族和太平洋民族所占有。</li>
</ul>
<h4 id="总结-10"><a href="#总结-10" class="headerlink" title="总结"></a>总结</h4><ul>
<li>学会粮食生产的重要性。可以很大程度确保最终不会被替代。</li>
</ul>
<h3 id="第十八章-两个半球的碰撞"><a href="#第十八章-两个半球的碰撞" class="headerlink" title="第十八章 两个半球的碰撞"></a>第十八章 两个半球的碰撞</h3><ul>
<li>过去13000年中最大的人口更替是新、旧大陆社会之间新近的碰撞引起的。我们在第三章看到，这种碰撞的最富戏剧性也最具决定性的时刻，是皮萨罗的小小西班牙军队俘虏了印加帝国皇帝阿塔瓦尔帕。阿塔瓦尔帕是最大、最富有、人口最多、管理和技术最先进的印第安国家的独裁统治者，他的被俘成了欧洲人征服美洲的象征，因为造成这一事件的相同的各种近似因素，也是欧洲人征服其他印第安社会的部分原因。</li>
<li>为什么是欧洲人到达了印第安人的国家并征服了它，而不是相反？我们讨论的起始点就是把欧亚大陆社会和印第安社会作一比较，时间是到公元1492年即哥伦布“发现”美洲的那一年为止。</li>
<li>粮食生产方面的这些差异，构成了欧亚大陆社会与印第安社会之间差异的一个重要的终极原因。在由此而产生的实现征服的近似因素中，最重要的因素包括病菌、技术、政治组织和文字方面的差异。</li>
<li>其中与粮食生产方面的差异关系最直接的差异是病菌。有些传染病经常光顾人口拥挤的欧亚大陆社会，许多欧亚大陆人因而逐步形成了免疫力或遗传抵抗力。这些传染病包括历史上所有最致命的疾病：天花、麻疹、流行性感冒、瘟疫、肺结核、斑疹伤寒、霍乱、疟疾和其他疾病。对照这个令人望而生畏的疾病名单，唯一可以有把握归之于哥伦布以前印第安人社会的群众传染病是非梅毒密螺旋体病。</li>
<li>大陆之间在有害的病菌方面的这种差异竟是来自有用的牲畜方面的差异。在拥挤的人类社会引起传染病的大多数病菌，是从引起家畜传染病的那些十分相似的祖代病菌演化而来的，而在大约10000年前，粮食生产者就已开始每天同这些家畜进行密切的接触了。</li>
<li>在帮助欧洲征服美洲的一些直接因素中，可与病菌相提并论的是技术的各方面的差距。这些差距归根到底是由于欧亚大陆有历史悠久得多的依靠粮食生产的人口稠密、经济专业化、政治集中统一、相互作用、相互竞争的社会。</li>
<li>为什么所有主要发展结果的发展轨迹在年代上美洲要晚于欧亚大陆？这有4组原因：起步晚，可用于驯化的野生动植物系列比较有限，较大的传播障碍，以及稠密的人口在美洲生活的地区可能比在欧亚大陆小，或者可能比在欧亚大陆孤立。</li>
<li>与欧亚大陆始终如一的东西宽度不同，新大陆在中美洲的那一段特别是在巴拿马变窄了。尤其是，美洲被一些不适于粮食生产也不适于稠密人口的地区分割开来。<br>这些生态障碍包括：把中美洲社会同安第斯山脉地区和亚马孙河地区社会分隔开来的巴拿马地峡雨林；把中美洲社会同美国西南部和东南部社会分隔开来的墨西哥北部沙漠；把美国西南部同东南部分隔开来的得克萨斯州干旱地区；把本来可能适于粮食生产的美国太平洋沿岸地区隔开的沙漠和高山。因此，在中美洲、美国东部、安第斯山脉地区和亚马孙河地区这些新大陆的中心之间，完全没有家畜、文字和政治实体方面的交流，以及只有在作物和技术方面的有限的缓慢的交流。</li>
<li>起源于东地中海的字母从英格兰到印度尼西亚，传遍了欧亚大陆的各个复杂社会，只有东亚地区是例外，因为中国书写系统派生出来的文字已在那里占主导地位。</li>
<li>我们已经找到了3组有利于欧洲人入侵美洲的终极因素：欧亚大陆人类定居时间长的领先优势；由于欧亚大陆可驯化的野生植物尤其是动物的资源比较丰富而引起的比较有效的粮食生产；欧亚大陆范围内对传播交流的地理和生态障碍并非那样难以克服。</li>
<li>在不适宜大部分粮食生产的纬度过高地区，在欧洲穷国之一的无力支持下，几个古挪威人手中的铁器没有斗得过爱斯基摩人和印第安狩猎采集族群手中的石器、骨器和木器，要知道这后两种人是世界上掌握在北极地区生存技巧的最杰出的大师！在适合欧洲的粮食生产和欧洲人生理机能的气候最温和的地区，人口众多的印第安社会被消灭了。</li>
</ul>
<h4 id="总结-11"><a href="#总结-11" class="headerlink" title="总结"></a>总结</h4><ul>
<li>粮食生产差异－&gt;病菌差异</li>
<li>在帮助欧洲征服美洲的一些直接因素中，可与病菌相提并论的是技术的各方面的差距。这些差距归根到底是由于欧亚大陆有历史悠久得多的依靠粮食生产的人口稠密、经济专业化、政治集中统一、相互作用、相互竞争的社会。</li>
<li>3组有利于欧洲人入侵美洲的终极因素：欧亚大陆人类定居时间长的领先优势；由于欧亚大陆可驯化的野生植物尤其是动物的资源比较丰富而引起的比较有效的粮食生产；欧亚大陆范围内对传播交流的地理和生态障碍并非那样难以克服。</li>
</ul>
<h3 id="第十九章-非洲是怎样成为黑人的非洲的"><a href="#第十九章-非洲是怎样成为黑人的非洲的" class="headerlink" title="第十九章 非洲是怎样成为黑人的非洲的"></a>第十九章 非洲是怎样成为黑人的非洲的</h3><ul>
<li><p>在白人殖民主义者来到之前，已经生活在非洲的不仅有黑人，还有（我们将要看到）世界上6大人种中的5种，其中3种只生活在非洲。世界上的语言，有四分之一仅仅在非洲才有人说。没有哪一个大陆在人种的多样性方面可以与非洲相提并论。</p>
</li>
<li><p>非洲多样化的人种来自它的多样化的地理条件和悠久的史前史。非洲是唯一的地跨南北温带的大陆，同时它也有几处世界上最大的沙漠、最大的热带雨林和最高的赤道山脉。人类在非洲生活的时间比在任何其他地方都要长得多。</p>
</li>
<li><p>到公元1000年，这5个主要的人类群体已经把非洲当作自己的家园。外行人不严密地把他们称为黑人、白人、非洲俾格米人、科伊桑人和亚洲人。</p>
</li>
<li><p>地球上所有人类群体只要和其他每一个群体中的人接触，就会发生婚配关系。</p>
</li>
<li><p>俾格米人的家园被淹没在入侵的黑人农民的汪洋大海之中，硕果仅存的一些俾格米人采用了这些农民的语言，而他们原来的语言只在某些词和发音上留下了一些蛛丝马迹。</p>
</li>
<li><p>科伊桑人和俾格米人之所以未能发展出农业，不是由于他们没有农民的资格，而仅仅是由于碰巧非洲南部的野生植物大都不适于驯化。无论是班图农民还是白人农民，尽管他们继承了几千年的农业经验，后来还是没有能把非洲南部的本地植物培育成粮食作物。</p>
</li>
<li><p>至于非洲的驯化动物，概括地介绍起来可以比介绍植物快得多，因为那里的驯化动物实在太少。</p>
</li>
<li><p>现代南非的问题至少一部分源自地理上的偶然因素。好望角科伊桑人的家园碰巧很少有适于驯化的野生植物；班图人碰巧从他们5000年前的祖先那里继承了适应夏雨的作物；而欧洲人碰巧从他们近10000年前的祖先那里继承了适应冬雨的作物。</p>
</li>
<li><p>正如他们与印第安人遭遇时的情况一样，进入非洲的欧洲人拥有三重优势：枪炮和其他技术、普及的文化以及为维持探险和征服的昂贵计划所必不可少的政治组织。从历史上看，所有这三者都来自粮食生产的发展。但粮食生产在非洲撒哈拉沙漠以南地区被延误了（与欧亚大陆相比），其原因是非洲缺少可以驯化的本地动植物物种，它的适于本地粮食生产的小得多的面积，以及它的妨碍粮食生产和发明的传播的南北轴向。第二个因素是非洲撒哈拉沙漠以南地区和欧亚大陆之间在可驯化的植物方面的一种虽然不是那样极端但也相当大的差异。第三个因素是非洲的面积仅及欧亚大陆的面积的一半左右。</p>
</li>
<li><p>总之，欧洲在非洲的殖民并不像某些白人种族主义者所认为的那样与欧洲民族和非洲民族本身之间的差异有关。恰恰相反，这是由于地理学和生物地理学的偶然因素所致——特别是由于这两个大陆之间不同的面积、不同的轴线方向和不同的动植物品种所致。就是说，非洲和欧洲的不同历史发展轨迹归根到底来自它们之间的“不动产”的差异。</p>
</li>
<li><p>非洲历史悠久，是人类生活时间最长的大陆，拥有世界上最大的沙漠、最大的热带雨林和最高的赤道山脉，人种多样化，世界上6大人种有5种生活在非洲（其中3种只生活在非洲），语言、文化也是世界最复杂的。但非洲过去没有文字，使得我们很难正确还原非洲历史。</p>
</li>
<li><p>非洲的5个主要人类群体：黑人、白人、俾格米人、科伊桑人、亚洲人，在1000年已经定居在非洲。其中俾格米人与黑人一样有着深色皮肤和浓密头发，但身材矮小得多、批复为红色较多黑色较少、体毛较多、前额眼镜和牙齿较突出，分布在中非的雨林中，大多过着狩猎采集生活；科伊桑人以前分布在非洲南部，他们皮肤微黄，头发浓密且卷曲，由于被欧洲殖民者入侵，科伊桑人数量大大减少，幸存者与欧洲人生下混血种；非洲白人主要分布在北部，因为与近东和欧洲邻近地区往来较多。</p>
</li>
<li><p>非洲落后于欧亚大陆的原因与美洲类似：缺乏可驯化的动物，驯化的植物无法大规模种植，撒哈拉沙漠阻止了南北的传播，大陆面积较小。归根到底也是地理学和生物地理学的偶然因素所致。</p>
</li>
<li><p>非洲是怎样成为黑人的非洲的：天意。黑人的这个部落在恰当的时间和恰当的地点得到了恰当的作物，促进了人口和其他一切的增长，开始了“淹没”。</p>
</li>
</ul>
<h4 id="总结-12"><a href="#总结-12" class="headerlink" title="总结"></a>总结</h4><ul>
<li>非洲有粮食生产（黑人），但有地理原因，没能发展壮大。所以也没被完全替换。</li>
</ul>
<h3 id="尾声-人类史作为一门科学的未来"><a href="#尾声-人类史作为一门科学的未来" class="headerlink" title="尾声 人类史作为一门科学的未来"></a>尾声 人类史作为一门科学的未来</h3><ul>
<li><p>耶利的问题触及了人类现状的实质，也是更新世后人类历史的关键所在。既然我们已经完成了这次对各大陆的短暂的巡视，我们将怎样来回答耶利呢？我会对耶利这样说：各大陆民族长期历史之间的显著差异，不是源自这些民族本身的天生差异，而是源自他们环境的差异。</p>
</li>
<li><p>耶利的问题触及了人类现状的实质，也是更新世后人类历史的关键所在。既然我们已经完成了这次对各大陆的短暂的巡视，我们将怎样来回答耶利呢？我会对耶利这样说：各大陆民族长期历史之间的显著差异，不是源自这些民族本身的天生差异，而是源自他们环境的差异。我猜想，如果在更新世晚期能够使澳大利亚土著人口和欧亚大陆土著人口互换位置，那么，原来的澳大利亚土著现在可能不但占领了欧亚大陆，而且也占领了美洲和澳大利亚的大部分地区，而原来的欧亚大陆土著现在可能已沦为澳大利亚的一些遭受蹂躏的零星分散的人口。对于这种说法，你一开始可能会认为毫无意义而不屑一顾，因为这个实验是想象出来的，而我所说的那种结果也是不可能被证明的。但历史学家却能用回溯试验法对有关的假说进行评价。</p>
</li>
<li><p>第一组差异是各大陆在可以用作驯化的起始物种的野生动植物品种方面的差异。这是因为，粮食生产之所以具有决定性的意义，在于它能积累剩余粮食以养活不从事粮食生产的专门人材，同时也在于它能形成众多的人口，从而甚至在发展出任何技术和政治优势之前，仅仅凭借人多就可以拥有军事上的优势。由于这两个原因，从小小的不成熟的酋长管辖地阶段向经济上复杂的、社会上分层次的、政治上集中的社会发展的各个阶段，都是以粮食生产为基础的。但大多数野生的动植物品种证明是不适于驯化的：粮食生产的基础一直是比较少的几种牲畜和作物。原来，各大陆在可以用于驯化的野生动植物的数量方面差异很大，因为各大陆的面积不同，而且在更新世晚期大型哺乳动物灭绝的情况也不同。大型哺乳动物灭绝的情况，在澳大利亚和美洲要比在欧亚大陆或非洲严重得多。因此，就生物物种来说，欧亚大陆最为得天独厚，非洲次之，美洲又次之，而澳大利亚最下，就像耶利的新几内亚那种情况（新几内亚的面积为欧亚大陆的七十分之一，而且其原来的大型哺乳动物在更新世晚期即已灭绝）。</p>
</li>
<li><p>在每一个大陆，动植物的驯化集中在只占该大陆总面积很小一部分的几个条件特别有利的中心地。就技术创新和政治体制来说，大多数社会从其他社会获得的要比它们自己发明的多得多。因此，一个大陆内部的传播与迁移，对它的社会的发展起着重要的促进作用，而从长远来看，由于毛利人的新西兰火枪战争以如此简单的形式所揭示的过程，这些社会又（在环境许可的情况下）分享彼此的发展成果。就是说，起初缺乏某种有利条件的社会或者从拥有这种条件的社会那里得到，或者（如果做不到这一点）被其他这些社会所取代。</p>
</li>
<li><p>因此，第二组因素就是那些影响传播和迁移速度的因素，而这种速度在大陆与大陆之间差异很大。在欧亚大陆速度最快，这是由于它的东西向主轴线和它的相对而言不太大的生态与地理障碍。对于作物和牲畜的传播来说，这个道理是最简单不过的，因为这种传播大大依赖于气候因而也就是大大依赖于纬度。同样的道理也适用于技术的发明，如果不用对特定环境加以改变就能使这些发明得到最充分的利用的话。传播的速度在非洲就比较缓慢了，而在美洲就尤其缓慢，这是由于这两个大陆的南北向主轴线和地理与生态障碍。在传统的新几内亚，这种传播也很困难，因为那里崎岖的地形和高山漫长的主脉妨碍了政治和语言统一的任何重大进展。</p>
</li>
<li><p>与影响大陆内部传播的这些因素有关的，是第三组影响大陆之间传播的因素，这些因素也可能有助于积累一批本地的驯化动植物和技术。大陆与大陆之间传播的难易程度是不同的，因为某些大陆比另一些大陆更为孤立。在过去的6000年中，传播最容易的是从欧亚大陆到非洲撒哈拉沙漠以南地区，非洲大部分牲畜就是通过这种传播得到的。但东西两半球之间的传播，则没有对美洲的复杂社会作出过任何贡献，这些社会在低纬度与欧亚大陆隔着宽阔的海洋，而在高纬度又在地形和适合狩猎采集生活的气候方面与欧亚大陆相去甚远。对于原始的澳大利亚来说，由于印度尼西亚群岛的一道道水上障碍把它同欧亚大陆隔开，欧亚大陆对它的唯一的得到证明的贡献就是澳洲野狗。</p>
</li>
<li><p>第四组也是最后一组因素是各大陆之间在面积和人口总数方面的差异。更大的面积或更多的人口意味着更多的潜在发明者，更多的互相竞争的社会，更多的可以采用的发明创造——以及更大的采用和保有发明创造的压力，因为任何社会如果不这样做就往往会被竞争对手所淘汰。</p>
</li>
<li><p>非洲的俾格米人和其他许多被农民取代的狩猎采集群体，就曾碰到这样的命运。相反的例子是格陵兰岛上顽固保守的古挪威农民，他们也碰到了被爱斯基摩狩猎采集族群所取代的命运，因为在格陵兰的条件下，这些爱斯基摩人的生存方法和生存技术都比这些古挪威人优越得多。在全世界的陆块中，欧亚大陆的面积最大，相互竞争的社会的数量也最多，澳大利亚和新几内亚在这方面就差得多，而塔斯马尼亚更是瞠乎其后。美洲的总面积虽然很大，但却在地理上和生态上支离破碎，实际上就像几个没有紧密联系的较小的大陆。这4组因素构成了环境的巨大差异，这些差异可以客观地用数量来表示，而且不会引起争议。</p>
</li>
<li><p>所有的人类社会都拥有有发明才能的人。事情恰恰是有些环境比另一些环境提供了更多的起始物种和利用发明的更有利的条件。</p>
</li>
<li><p>在欧亚大陆范围内，为什么是欧洲社会，即在美洲和澳大利亚殖民的那些社会，而不是新月沃地的社会或中国和印度的社会，在技术上领先，并在现代世界上占据政治和经济的支配地位？如果一个历史学家生活在从公元前8500年到公元1450年的任何一段时间内，如果他当时试图预测未来的历史发展轨迹，他肯定会认为，欧洲最终的支配地位是最不可能发生的结果，因为欧洲在过去那1万年的大部分时间里是旧大陆的那3个地区中最落后的一个地区。</p>
</li>
<li><p>从公元前8500年开始，直到公元500年后希腊与意大利的先后兴起这一段时间里，欧亚大陆西部几乎所有的重大发明——动物驯化、植物驯化、文学、冶金术、轮子、国家等等——都是在新月沃地或其附近出现的。在水磨于大约公元900年后大量传播之前，阿尔卑斯山以西或以北的欧洲没有对旧大陆的技术或文明作出过任何有意义的贡献，它只是一个从地中海以东、新月沃地和中国接受发展成果的地方。甚至从公元1000年到1450年，科学和技术绝大多数都是从印度与北非之间的伊斯兰社会传入欧洲，而不是相反。就在那几个世纪中，中国在技术上走在世界的前列，几乎和新月沃地一样早地开始了粮食生产。那么，为什么新月沃地和中国把它们几千年的巨大的领先优势最后让给了起步晚的欧洲？当然，人们可以指出促使欧洲兴起的一些直接因素：它的商人阶级、资本主义和对发明的专利保护的逐步形成，它未能产生的专制独裁君主和使人不堪重负的税收，以及它的希腊——犹太教——基督教的批判经验主义调查研究的传统。不过，对于所有这些直接原因，人们一定会提出关于终极原因的问题：为什么这些直接因素出现在欧洲，而不是出现在中国或新月沃地？</p>
</li>
<li><p>新月沃地和东地中海社会不幸在一个生态脆弱的环境中兴起。它们破坏了自己的资源基础，无异于生态自杀。从东方（新月沃地）最古老的社会开始，每一个东地中海社会都在轮流地自挖墙脚，而就在这个过程中，权力西移了。欧洲北部和西部没有遭到同样的命运，这不是因为那里的居民比较明智，而是因为他们运气好，碰巧生活在一个雨量充沛、植被再生迅速的好环境里。在粮食生产传入7000年之后，欧洲北部和西部的广大地区今天仍能维持高产的集约农业。事实上，欧洲是从新月沃地得到它的作物、牲畜、技术和书写系统的，而新月沃地后来反而使自己失去了作为一个主要的权力和发明中心的地位。这就是新月沃地失去它对欧洲的巨大的早期领先优势的情形。</p>
</li>
<li><p>为什么中国也失去了这种领先优势呢？中国的落后起初是令人惊讶的，因为中国拥有无可置疑的有利条件：粮食生产的出现似乎同在新月沃地一样早；从华北到华南，从沿海地区到西藏高原的高山地区的生态多样性，产生了一批不同的作物、动物和技术；幅员广阔，物产丰富，养活了这一地区世界上最多的人口；一个不像新月沃地那样干旱或生态脆弱的环境，使中国在将近10000年之后仍能维持高产的集约农业，虽然它的环境问题日益增多，而且比欧洲西部严重。</p>
</li>
<li><p>这些有利条件和领先优势使得中世纪的中国在技术上领先世界。中国一长串重大的技术第一包括铸铁、罗盘、火药、纸、印刷术以及前面提到过的其他许多发明。它在政治权力、航海和海上管制方面也曾在世界上领先。15世纪初，它派遣宝船队[插图]横渡印度洋，远达非洲东海岸，每支船队由几百艘长达400英尺的船只和总共28000名船员组成。这些航行在时间上也比哥伦布率领3艘不起眼的小船渡过狭窄的大西洋到达美洲东海岸要早好几十年。法斯科·达·伽马率领他的3艘不起眼的小船，绕过非洲的好望角向东航行，使欧洲开始了对东亚的殖民。为什么中国的船只没有在伽马之前绕过好望角向西航行并在欧洲殖民？为什么中国的船只没有横渡太平洋到美洲西海岸来殖民？简而言之，为什么中国把自己在技术上的领先优势让给原先十分落后的欧洲呢？</p>
</li>
<li><p>中国西洋舰队的结局给了我们一条线索。从公元1405年到1433年，这些船队一共有7次从中国扬帆远航。后来，由于世界上任何地方都可能发生的局部政治变化，船队出海远航被中止了：中国朝廷上的两派（太监和反对他们的人）之间发生了权力斗争。前一派支持派遣和指挥船队远航。因此，当后一派在权力斗争中取得上风时，它停止派遣船队，最后还拆掉船坞并禁止远洋航运。这一事件使我们想起了19世纪80年代伦敦的扼杀公共电灯照明的立法、第一次和第二次世界大战之间美国的孤立主义和许多国家全都由于局部的政治争端而引发的许多倒退措施。但在中国，情况有所不同，因为那整个地区在政治上是统一的。一个决定就使整个中国停止了船队的航行。那个一时的决定竟是不可逆转的，因为已不再有任何船坞来造船以证明那个一时决定的愚蠢，以及用作重建新船坞的中心。</p>
</li>
<li><p>现在来对比一下中国的这些事件，和探险船队开始从政治上分裂的欧洲远航时所发生的事情。克里斯托弗·哥伦布出生在意大利，后来转而为法国的昂儒公爵服务，又后来改事葡萄牙国王。哥伦布曾请求国王派船让他向西航行探险。他的请求被国王拒绝了，于是他就求助于梅迪纳——塞多尼亚公爵，也遭到了拒绝，接着他又求助于梅迪纳——塞利伯爵，依然遭到拒绝，最后他又求助于西班牙的国王和王后，他们拒绝了他的第一次请求，但后来在他再次提出请求时总算同意了。如果欧洲在这头3个统治者中任何一个的统治下统一起来，它对美洲的殖民也许一开始就失败了。事实上，正是由于欧洲是分裂的，哥伦布才成功地于第五次在几百个王公贵族中说服一个来赞助他的航海事业。一旦西班牙这样开始了欧洲对美洲的殖民，其他的欧洲国家看到财富滚滚流入西班牙，立刻又有6个欧洲国家加入了对美洲殖民的行列。对于欧洲的大炮、电灯照明、印刷术、小型火器和无数的其他发明，情况也是如此：每一项发明在欧洲的一些地方由于人们的习性起先或者被人忽视，或者遭人反对，但一旦某个地区采用了它，它最后总能传播到欧洲的其余地区。</p>
</li>
<li><p>欧洲分裂所产生的这些结果与中国统一所产生的结果形成了鲜明的对比。除了作出停止海外航行的决定外，中国的朝廷还作出停止其他一些活动的决定：放弃开发一种精巧的水力驱动的纺纱机，在14世纪从一场产业革命的边缘退了回来，在制造机械钟方面领先世界后又把它拆毁或几乎完全破坏了，以及在15世纪晚期以后不再发展机械装置和一般技术。统一的这些潜在的有害影响在现代中国又死灰复燃，特别是20世纪60年代和70年代“文化大革命”中的那种狂热，当时一个或几个领导人的决定就把全国的学校系统关闭了5年之久。</p>
</li>
<li><p>中国的经常统一与欧洲的永久分裂都由来已久。</p>
</li>
<li><p>现代中国的最肥沃地区于公元前221年第一次在政治上统一起来，并从那时以来的大部分时间里一直维持着这个局面。中国自有文字以来就一直只有一种书写系统，长期以来只有一种占支配地位的语言，以及2000年来牢固的文化统一。相比之下，欧洲与统一始终相隔十万八千里：14世纪时它仍然分裂成1000个独立的小国，公元1500年有小国500个，20世纪80年代减少到最低限度的25国，而现在就在我写这句话的时候又上升到将近40个国家。欧洲仍然有45种语言，每种语言都有自己的经过修改的字母表，而文化的差异甚至更大。欧洲内部的分歧今天在继续挫败甚至是想要通过欧洲经济共同体（EEC）来实现欧洲统一的并不过分的企图，这就表明欧洲对分裂的根深蒂固的执著。</p>
</li>
<li><p>了解中国把政治和技术的卓越地位让给欧洲的关键所在就是去了解中国的长期统一和欧洲的长期分裂的问题。答案又一次用地图表示出来（见下图）。欧洲海岸线犬牙交错，它有5大半岛，每个半岛都近似孤悬海中的海岛，在所有这些半岛上形成了独立的语言、种族和政府：希腊、意大利、伊比利亚半岛、丹麦和挪威&#x2F;瑞典。中国的海岸线则平直得多，只有附近的朝鲜半岛才获得了作为单独岛屿的重要性。欧洲有两个岛（大不列颠岛和爱尔兰岛），它们的面积都相当大，足以维护自己的政治独立和保持自己的语言和种族特点，其中的一个岛（大不列颠岛）因为面积大，离欧洲大陆又近，所以成了一个重要的欧洲独立强国。</p>
</li>
<li><p>但即使是中国的两个最大的岛——台湾岛和海南岛，面积都不到爱尔兰岛的一半，这两个岛都不是重要独立的政体；而日本在地理上的孤立地位使它在现代以前一直处于与亚洲大陆的政治隔绝状态，其程度远远超过了大不列颠与欧洲大陆的政治隔绝状态。欧洲被一些高山（阿尔卑斯山脉、比利牛斯山脉、喀尔巴阡山脉和挪威边界山脉）分隔成一些独立的语言、种族和政治单位，而中国在西藏高原以东的山脉则不是那样难以克服的障碍。中国的中心地带从东到西被肥沃的冲积河谷中两条可通航的水系（长江和黄河）连接了起来，从南到北又由于这两大水系（最后有运河连接）之间比较方便的车船联运而成为一体。因此，中国很早就受到了地域广阔的两个高生产力核心地区的决定性影响，而这两个地区本来彼此只有微不足道的阻隔，最终又合并为一个中心。欧洲的两条最大的河流——莱茵河与多瑙河则比较小，在欧洲流经的地方也少得多。与中国不同，欧洲有许多分散的小的核心地区，没有一个大到足以对其他核心地区产生长期的决定性影响，而每一个地区又都是历史上一些独立国家的中心。中国一旦于公元前221年最后获得统一，就再没有任何其他的独立国家有可能在中国出现并长期存在下去。虽然在公元前221年后有几个时期出现了分裂局面，但最后总是重新归于统一。但欧洲的统一就连查理曼[插图]、拿破仑和希特勒这些下定决心的征服者都无能为力；甚至罗马帝国在其鼎盛时期所控制的地区也没有超过欧洲的一半。因此，地理上的四通八达和非常一般的内部障碍，使中国获得了一种初始的有利条件。华北、华南、沿海地区和内陆的不同作物、牲畜、技术和文化特点，为中国的最后统一作出了贡献。例如，黍的栽培、青铜技术和文字出现在华北，而水稻的栽培和铸铁技术则出现在华南。我用本书的很大篇幅着重讨论了在没有难以克服的障碍的情况下技术的传播问题。但中国在地理上的四通八达最后却成了一个不利条件，某个专制君主的一个决定就能使改革创新半途而废，而且不止一次地这样做了。相比之下，欧洲在地理上的分割形成了几十个或几百个独立的、相互竞争的小国和发明创造的中心。如果某个国家没有去追求某种改革创新，另一个国家会去那样做的，从而迫使邻国也这样去做，否则就会被征服或在经济上处于落后地位。欧洲的地理障碍足以妨碍政治上的统一，但还不足以使技术和思想的传播停止下来。欧洲还从来没有哪一个专制君王能够像在中国那样切断整个欧洲的创造源泉。</p>
</li>
<li><p>这些比较表明，地理上的四通八达对技术的发展既有积极的影响，也有消极的影响。因此，从长远来看，在地理便利程度不太高也不太低而是中等适度的地区，技术可能发展得最快。中国、欧洲，可能还有印度次大陆的过去1000多年的技术发展过程便是例子，它分别表明了高、中、低3种不同程度的地理便利条件所产生的实际效果。</p>
</li>
<li><p>新月沃地的居间的地理位置，控制了把中国和印度与欧洲连接起来的贸易路线，以及中国距离欧亚大陆其他先进的文明国家路途遥远，使中国实际上成为一个大陆内的一个巨大孤岛。中国的相对孤立状态与它先是采用技术后来又排斥技术这种做法有着特别重要的关系，这使人想起了塔斯马尼亚岛和其他岛屿排斥技术的情形（第十三章和第十五章）。不过，这一简略的讨论至少可以表明，环境因素不但与历史的最广泛模式有关，而且也与较小规模和较短时期的历史模式有关。</p>
</li>
<li><p>新月沃地和中国的历史还为现代世界留下了一个有益的教训：环境改变了，过去是第一并不能保证将来也是第一</p>
</li>
<li><p>物理学家和化学家能够在宏观的层次上系统地阐述带有普遍性的决定论的规律，但生物学家和历史学家只能系统地阐述统计学上的趋势。</p>
</li>
<li><p>历史系统尽管有其终极的确定性，但其复杂性和不可预测性是不待言的。描述这种复杂性和不可预测性的另一个办法就是指出，长长的一连串因果关系可能把最后结果同存在于那一科学领域之外的终极原因分开。例如，一颗小行星对地球的撞击可能导致了恐龙的灭绝，但那颗小行星的轨道却是完全由古典力学的定律决定的。但如果有古生物学家生活在6700万年前，他们也不可能预测到恐龙的灭亡迫在眉睫，因为小行星属于一个在其他方面都与恐龙生物学关系疏远的科学领域研究的对象。同样，公元1300年至1500年之间的小冰期也是格陵兰岛上古挪威人灭绝的部分原因，但没有哪个历史学家，也许甚至也没有哪一个现代气候学家能够预测到小冰期的到来。</p>
</li>
<li><p>因此，历史学家在确定人类社会史的因果关系时所碰到的困难，大致上类似于天文学家、气候学家、生态学家、演化生物学家、地质学家和古生物学家所碰到的困难。</p>
</li>
</ul>
<h3 id="日本人乃何许人也"><a href="#日本人乃何许人也" class="headerlink" title="日本人乃何许人也"></a>日本人乃何许人也</h3><ul>
<li>至于阿伊努人，他们独特的相貌也招致了关于其由来和亲缘的众多研究，数量之多超过了地球上任何其他的民族。阿伊努男子胡须浓密，体毛之丰居各人种之首。这个体征，加上其它一些遗传性状如指纹和耳垢类型，使得他们常常被归入不知何故从欧亚东迁最终落脚日本的高加索人种（即所谓白人）。但是，纵观其基因特征，阿伊努人和包括日本人、朝鲜人和冲绳人这些东亚人种还是有瓜葛。</li>
<li>阿伊努人是日本以采集涉猎为生的原住民后代，而日本人则是晚近从亚洲大陆而来的入侵者。</li>
<li>边境之外的日本最北端岛屿北海道和居住在那里的阿伊努涉猎采集者甚至都不被视为日本国的一部分，直到19世纪这里才加入日本。</li>
<li>来自朝鲜的移民确实对现代日本民族作出了巨大贡献，虽然我们尚不能确信起因是因为移民本就人数众多，还是因为数量不多的移民凭借高速人口增长而扩张的结果。阿伊努人的基因更接近日本古代绳纹居民，又掺杂了弥生殖民者和现代日本人的朝鲜基因。</li>
<li>早期的朝鲜编年史告诉我们，不同的王国拥有不同的语言。虽然被新罗打败的两个王国的语言已鲜为人知，但作为战败国之一的高句丽（Koguryo），其留存下的少数几个词汇与古日语词汇的近似程度远胜于现代朝鲜语词汇。在政治统一进程到达三足鼎立的阶段之前，公元前400年的朝鲜语，也许多样性更甚。我怀疑公元前400年传入日本并发展成为现代日语的朝鲜语，与发展成为现代朝鲜语的新罗语大不相同。因此，现代日本人和朝鲜人之间的外形和基因的相似性远超两种语言的近似性，我们对此不应该感到奇怪。</li>
<li>考虑到日本民族和朝鲜民族目前的相互仇视，这个结论很可能在日本和朝鲜都同样不受欢迎。历史给了他们对彼此产生厌恶的充分原因，而其中又尤以朝鲜人对日本人的厌恶为甚。正如阿拉伯人和犹太人，朝鲜人和日本人是血脉相连的民族，但又深陷积怨的迷障。而积怨具有双向的毁灭性，这一点在东亚和中东都是如此。即便日本人和朝鲜人都不愿意承认，事实上，他们就像一对共享了成长岁月的孪生兄弟。在很大程度上，东亚的政治前景取决于他们是否能够成功地重新找回联系彼此的古老纽带。</li>
</ul>
<h4 id="总结-13"><a href="#总结-13" class="headerlink" title="总结"></a>总结</h4><ol>
<li>日本来自朝鲜的移民</li>
<li>和日本当地其他族融合并替换</li>
</ol>
<h3 id="附录-2003后记：《枪炮、病菌与钢铁》今日谈"><a href="#附录-2003后记：《枪炮、病菌与钢铁》今日谈" class="headerlink" title="附录 2003后记：《枪炮、病菌与钢铁》今日谈"></a>附录 2003后记：《枪炮、病菌与钢铁》今日谈</h3><ul>
<li>公元前400年左右，朝鲜农民扩张到了日本西南，继而朝着日本列岛的东北挺进。迁移的农民带来了精细的水稻农业和铁制工具，并与日本原住民（现代阿伊努人的祖先）融合产生了现代日本人，就像扩张的新月沃地农民与欧洲的土著狩猎采集人群融合产生了现代欧洲人。</li>
<li>我认为欧洲超越中国的背后原因，比多数历史学家所提出的直接因素要来得深远（例如中国的儒家理论vs.欧洲的犹太基督教传统，西方科学的崛起，欧洲重商主义和资本主义的崛起，英国的毁林兴矿等等）。在上述以及其他直接因素背后，我看到了一个“最优分裂原则”：伴随着欧洲始终的分裂，导致中国较早统一并保持相对统一的终极地理因素。促成技术、科学的进步，带来推动各国竞争，以可替代的资源支持并提供给发明者，并为他们提供可躲避迫害的庇护所，并由此孕育资本主义的，不是中国的统一，而是欧洲的分裂。历史学家们后来也向我指出，欧洲的分裂，中国的统一，还有欧洲和中国的相对优势之复杂程度，都超出我书中的讲述。可以被分成“欧洲”和“中国”的政治&#x2F;社会半径的地理边界在过去几个世纪内一直处于变动之中。直到至少15世纪以前，中国在技术上一直走在欧洲前面，在未来也有可能重续辉煌，那样的话，“为什么是欧洲，而非中国？”的问题可能就只是一种转瞬即逝的现象，没有深层原因可挖。政治分裂的复杂影响远不止提供一个用于竞争的建设性平台，例如，竞争有可能是建设性的，也有可能是破坏性的（想想一战和二战）。分裂本身是个多层面而非单一的概念，其对于创新的影响力依赖于自由等要素，如此，创意和人员才能在各个碎片之间跨界流动，不管这些碎片是独一无二的，还是彼此的克隆。至于分裂是否最优也随使用的最优衡量尺度而异，对于技术创新最优的政治分裂程度，也许就经济生产力、政治稳定或人类福祉而言并非最优。</li>
<li>印度在地理上较欧洲更为分裂，但是其技术创新却不及欧洲。这让我想到了“最优分裂原则”：创新在带有最优中间程度分裂的社会里发展得最快：太过统一的社会处于劣势，太过分裂的社会也不占优。</li>
</ul>
<hr>
<h3 id="不完全总结"><a href="#不完全总结" class="headerlink" title="不完全总结"></a>不完全总结</h3><h4 id="美洲落后的原因？"><a href="#美洲落后的原因？" class="headerlink" title="美洲落后的原因？"></a>美洲落后的原因？</h4><ol>
<li>整个野生动植物组合微弱的驯化潜力；</li>
<li>南北轴线，且南北接触地狭小，地理和生态上却支离破碎 (影响传播)；</li>
<li>人少和可驯化动植物少导致不能产生很多流行病</li>
</ol>
<h4 id="澳大利亚落后的原因？"><a href="#澳大利亚落后的原因？" class="headerlink" title="澳大利亚落后的原因？"></a>澳大利亚落后的原因？</h4><ol>
<li>澳大利亚是最干燥、最小、最平坦、最贫瘠、气候最变化无常、生物品种最稀少的大陆;澳大利亚是最小的一个大陆。澳大利亚大部分地区雨量稀少，物产贫乏，因此，就其所能养活的人口来说，它实际上就显然甚至更小。它也是一个最孤立的大陆。</li>
</ol>
<h4 id="非洲落后的原因？"><a href="#非洲落后的原因？" class="headerlink" title="非洲落后的原因？"></a>非洲落后的原因？</h4><p>1.表面上是一个大陆，实际上由于气候和地形原因，隔离成很多个地区(影响传播);<br>撒哈拉沙漠仍然是一个主要的生态障碍，把非洲撒哈拉沙漠以南地区同欧亚大陆和北非隔开。非洲的南北轴线造成了欧亚大陆与非洲撒哈拉沙漠以南地区之间以及撒哈拉沙漠以南地区本身内部技术传播的又一障碍。</p>
<h4 id="欧亚大陆"><a href="#欧亚大陆" class="headerlink" title="欧亚大陆"></a>欧亚大陆</h4><ol>
<li>欧亚大陆何以一直是大型哺乳动物驯化的主要场所，对这个问题的部分解释是：它是一个一开始就拥有最多的可供驯化的野生哺乳动物的大陆，在过去的40000年中，那里这样的动物因绝种而消失的也最少。</li>
<li>东西轴线，同纬度易于传播</li>
</ol>
<h4 id="各大陆的差异"><a href="#各大陆的差异" class="headerlink" title="各大陆的差异"></a>各大陆的差异</h4><ul>
<li>各大陆之间在面积、人口、技术传播的难易程度和粮食生产的开始时间等方面存在着差异，而这些差异又对技术的出现产生了种种影响，但所有这些影响都被夸大了，因为技术可以催化自身。欧亚大陆在开始时的巨大优势因此就变成了自1492年[插图]起的巨大的领先优势——其原因是欧亚大陆独特的地理条件，而不是那里的人特别聪明。</li>
<li>第一组差异是各大陆在可以用作驯化的起始物种的野生动植物品种方面的差异。</li>
<li>第二组因素就是那些影响传播和迁移速度的因素，而这种速度在大陆与大陆之间差异很大。</li>
<li>与影响大陆内部传播的这些因素有关的，是第三组影响大陆之间传播的因素，这些因素也可能有助于积累一批本地的驯化动植物和技术。大陆与大陆之间传播的难易程度是不同的，因为某些大陆比另一些大陆更为孤立。</li>
<li>第四组因素是各大陆之间在面积和人口总数方面的差异。更大的面积或更多的人口意味着更多的潜在发明者，更多的互相竞争的社会，更多的可以采用的发明创造</li>
</ul>
<h4 id="欧洲领先的原因"><a href="#欧洲领先的原因" class="headerlink" title="欧洲领先的原因"></a>欧洲领先的原因</h4><ul>
<li>在欧亚大陆范围内，为什么是欧洲社会，即在美洲和澳大利亚殖民的那些社会，而不是新月沃地的社会或中国和印度的社会，在技术上领先，并在现代世界上占据政治和经济的支配地位？如果一个历史学家生活在从公元前8500年到公元1450年的任何一段时间内，如果他当时试图预测未来的历史发展轨迹，他肯定会认为，欧洲最终的支配地位是最不可能发生的结果，因为欧洲在过去那1万年的大部分时间里是旧大陆的那3个地区中最落后的一个地区。</li>
<li>新月沃地和东地中海社会不幸在一个生态脆弱的环境中兴起。它们破坏了自己的资源基础，无异于生态自杀。</li>
<li>但在中国，情况有所不同，因为那整个地区在政治上是统一的。一个决定就使整个中国停止了船队的航行。那个一时的决定竟是不可逆转的，因为已不再有任何船坞来造船以证明那个一时决定的愚蠢，以及用作重建新船坞的中心。</li>
<li>事实上，正是由于欧洲是分裂的，哥伦布才成功地于第五次在几百个王公贵族中说服一个来赞助他的航海事业。一旦西班牙这样开始了欧洲对美洲的殖民，其他的欧洲国家看到财富滚滚流入西班牙，立刻又有6个欧洲国家加入了对美洲殖民的行列。对于欧洲的大炮、电灯照明、印刷术、小型火器和无数的其他发明，情况也是如此：每一项发明在欧洲的一些地方由于人们的习性起先或者被人忽视，或者遭人反对，但一旦某个地区采用了它，它最后总能传播到欧洲的其余地区。</li>
<li>欧洲分裂所产生的这些结果与中国统一所产生的结果形成了鲜明的对比。除了作出停止海外航行的决定外，中国的朝廷还作出停止其他一些活动的决定：放弃开发一种精巧的水力驱动的纺纱机，在14世纪从一场产业革命的边缘退了回来，在制造机械钟方面领先世界后又把它拆毁或几乎完全破坏了，以及在15世纪晚期以后不再发展机械装置和一般技术。统一的这些潜在的有害影响在现代中国又死灰复燃，特别是20世纪60年代和70年代“文化大革命”中的那种狂热，当时一个或几个领导人的决定就把全国的学校系统关闭了5年之久。</li>
<li>中国的经常统一与欧洲的永久分裂都由来已久。</li>
<li>欧洲海岸线犬牙交错，它有5大半岛，每个半岛都近似孤悬海中的海岛，在所有这些半岛上形成了独立的语言、种族和政府：希腊、意大利、伊比利亚半岛、丹麦和挪威&#x2F;瑞典。中国的海岸线则平直得多，只有附近的朝鲜半岛才获得了作为单独岛屿的重要性。欧洲有两个岛（大不列颠岛和爱尔兰岛），它们的面积都相当大，足以维护自己的政治独立和保持自己的语言和种族特点，其中的一个岛（大不列颠岛）因为面积大，离欧洲大陆又近，所以成了一个重要的欧洲独立强国。</li>
<li>中国在地理上的四通八达最后却成了一个不利条件，某个专制君主的一个决定就能使改革创新半途而废，而且不止一次地这样做了。相比之下，欧洲在地理上的分割形成了几十个或几百个独立的、相互竞争的小国和发明创造的中心。如果某个国家没有去追求某种改革创新，另一个国家会去那样做的，从而迫使邻国也这样去做，否则就会被征服或在经济上处于落后地位。欧洲的地理障碍足以妨碍政治上的统一，但还不足以使技术和思想的传播停止下来。欧洲还从来没有哪一个专制君王能够像在中国那样切断整个欧洲的创造源泉。</li>
<li>地理上的四通八达对技术的发展既有积极的影响，也有消极的影响。因此，从长远来看，在地理便利程度不太高也不太低而是中等适度的地区，技术可能发展得最快。中国、欧洲，可能还有印度次大陆的过去1000多年的技术发展过程便是例子，它分别表明了高、中、低3种不同程度的地理便利条件所产生的实际效果。</li>
<li>新月沃地的居间的地理位置，控制了把中国和印度与欧洲连接起来的贸易路线，以及中国距离欧亚大陆其他先进的文明国家路途遥远，使中国实际上成为一个大陆内的一个巨大孤岛。中国的相对孤立状态与它先是采用技术后来又排斥技术这种做法有着特别重要的关系</li>
<li>新月沃地和中国的历史还为现代世界留下了一个有益的教训：环境改变了，过去是第一并不能保证将来也是第一</li>
<li>“最优分裂原则”：创新在带有最优中间程度分裂的社会里发展得最快：太过统一的社会处于劣势，太过分裂的社会也不占优。</li>
<li>总结：<ol>
<li>过于统一</li>
<li>“最优分裂原则”；有时需要多种声音，多样化，才能更加健康发展。</li>
</ol>
</li>
</ul>
<h4 id="中国落后的原因？"><a href="#中国落后的原因？" class="headerlink" title="中国落后的原因？"></a>中国落后的原因？</h4><ol>
<li>中央集权决策错误闭关锁国</li>
<li>日本拒绝枪支和中国抛弃远洋船只（以及抛弃机械钟和水力驱动纺纱机），是历史上孤立或半孤立社会技术倒退的著名例子。</li>
</ol>
<h4 id="新月沃地落后的原因？"><a href="#新月沃地落后的原因？" class="headerlink" title="新月沃地落后的原因？"></a>新月沃地落后的原因？</h4><ul>
<li>新月沃地从领先到落后欧洲发展的原因：农业领先优势从技术传到西方后，由于西方的面积地域优势，逐步发展起来，并超过了新月沃地。另一方面，由于新月沃地过渡自然砍伐破坏，地貌上发生了根本性的变化，成为了沙漠，不利于更长久的发展，最终落后于欧洲。</li>
</ul>
<h3 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>一旦发明家发现了一项新技术的用途，下一步就是说服社会来采用它。仅仅有一种更大、更快、更有效的工作装置还不能保证人们会乐于接受。无数的此类技术要么根本没有被采用，要么只是在长期的抵制之后才被采用。(现在的游戏直播，打赏，虚拟主播等，都是想办法让用户逐步接受)</li>
<li>事实上，在整个大陆和其他一些包含数以百计的互相竞争的广大地区，有些社会对新事物可能比较开放，有些社会对新事物可能比较抵制。那些接受新作物、新牲畜或新技术的社会因而可能吃得更好，繁殖得更快，从而取代、征服或杀光那些抵制新事物的社会。（接收新事物才不会被淘汰）</li>
<li>流行病(人群病)。拥有流行病的族类是战胜没流行病族类的重要因素。<ul>
<li>拥有流行病首先要死一部分人，你愿意成为拥有你族类的炮灰吗？</li>
<li>如果处于无流行病的族群，那么可能当前是好的，但是对你后代不利；有流行病的族类则相反；</li>
<li>族类之间相互融合，有时很难说清你究竟属于哪个族类；</li>
<li>认清你觉得最重要的事情或人，作出相应的选择；在某些大环境下，作出选择后，可能需要欺骗自己，以更好的实施，保持政治正确；族类的精神控制</li>
</ul>
</li>
<li>“最优分裂原则”</li>
<li>一个人的命运，要靠自我奋斗，但也要考虑到历史的进程。外部环境则是历史进程的基础与原生动力。</li>
</ol>
<h4 id="其他网友"><a href="#其他网友" class="headerlink" title="其他网友"></a>其他网友</h4><ul>
<li>读到这里对教育有了一些思考，终归还是要把孩子放出去多与其他人接触交流合作，才会受到伤害，才会由此产生自我认知，才会成长。而如果只是把孩子孤立起来，与社会少有接触，那就会像免疫力差的一碰即亡。</li>
<li>人总是要吃饱饭才有力气干活，事实证明当劳动的效率越高，人们获得的能量也就越多也就促进了文明的发展，毕竟只有劳动之后的能量有剩余才能够养得起专职人员。</li>
<li>让一群各自为战的人团结起来的最好办法    就是树立一个共同的敌人和威胁！</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>《SRE：Google运维解密》-笔记</title>
    <url>/2021/07/05/20210705-sre-google-yun-wei-jie-mi-bi-ji/</url>
    <content><![CDATA[<h2 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h2><ul>
<li>可靠性就像安全性，越早关注越好。</li>
<li>这就意味着一些小型创业公司，在应付日常面临的种种挑战时，也应该抽出一部分精力来面对可靠性这个话题。这与盖房子有些类似，如果一开始将整个地基打好并保持继续修缮，要比盖好房子之后再重新修改设计要容易得多</li>
<li>Margaret 曾经说过：“无论对一个软件系统运行原理掌握得多么彻底，也不能阻止人犯意外错误。”</li>
<li>只有靠着对细节的不懈关注，做好充足的灾难预案和准备工作，时刻警惕着，不放过一切机会去避免灾难发生。这就是SRE 最重要的理念！</li>
</ul>
<h2 id="第1章-介绍"><a href="#第1章-介绍" class="headerlink" title="第1章 介绍"></a>第1章 介绍</h2><ul>
<li>不能将碰运气当成战略。</li>
</ul>
<h3 id="Google的解决之道：SRE"><a href="#Google的解决之道：SRE" class="headerlink" title="Google的解决之道：SRE"></a>Google的解决之道：SRE</h3><ul>
<li><p>SRE就是让软件工程师来设计一个新型运维团队的结果。</p>
</li>
<li><p>目前来看，UNIX 系统内部细节和1～3层网络知识是Google最看重的两类额外的技术能力。</p>
<ul>
<li>（a）对重复性、手工性的操作有天然的排斥感。</li>
<li>（b）有足够的技术能力快速开发出软件系统以替代手工操作。</li>
</ul>
</li>
<li><p>从本质上来说，SRE 就是在用软件工程的思维和方法论完成以前由系统管理员团队手动完成的任务。这些SRE倾向于通过设计、构建自动化工具来取代人工操作。</p>
</li>
<li><p>Google的经验法则是，SRE团队必须将50%的精力花在真实的开发工作上。</p>
</li>
<li><p>由于SRE模型中为了提高可靠性需要采取一些与常规做法违背的做法，所以需要强有力的管理层支持才能推行下去。例如：由于一个季度内的错误预算耗尽而停止发布新功能的决定，可能需要管理层的支持才能让产品研发部门重视起来。</p>
</li>
<li><p>我们可以认为DevOps是SRE核心理念的普适版，可以用于更广范围内的组织结构、管理结构和人员安排。同时，SRE是DevOps模型在Google的具体实践，带有一些特别的扩展。</p>
</li>
</ul>
<h3 id="SRE方法论"><a href="#SRE方法论" class="headerlink" title="SRE方法论"></a>SRE方法论</h3><ul>
<li><p>一般来说，SRE团队要承担以下几类职责：可用性改进，延迟优化，性能优化，效率优化，变更管理，监控，紧急事务处理以及容量规划与管理。</p>
</li>
<li><p>事后总结应该包括以下内容：事故发生、发现、解决的全过程，事故的根本原因，预防或者优化的解决方案。</p>
</li>
<li><p>Google 的一项准则是“对事不对人”，事后总结的目标是尽早发现和堵住漏洞，而不是通过流程去绕过和掩盖它们。</p>
</li>
<li><p>一般来说，任何软件系统都不应该一味地追求100% 可靠。因为对最终用户来说，99.999% 和 100% 的可用性是没有实质区别的</p>
</li>
<li><p>如果100% 不是一个正确的可靠性目标，那么多少才是呢？这其实并不是一个技术问题，而是一个产品问题。</p>
</li>
<li><p>如果一个服务的可靠性目标是99.99%，那么错误预算就是 0.01%。这意味着产品研发部门和SRE部门可以在这个范围内将这个预算用于新功能上线或者产品的创新等任何事情。错误预算可以用于什么范畴呢？研发团队需要用这个预算上线新功能，吸引新用户。理想情况下，我们应该使用错误预算来最大化新功能上线的速度，同时保障服务质量。这个基本模型建立起来之后，许多常见的战术策略，例如灰度发布、1% AB测试等就全说得通了。这些战术性手段都是为了更合理地使用整个服务的错误预算。通过引进“错误预算”的概念，我们解决了研发团队和SRE团队之间的组织架构冲突。SRE团队的目标不再是 “零事故运行”,SRE团队和产品研发团队目标一致，都是在保障业务服务可靠性需求的同时尽可能地加快功能上线速度。这个改动虽小，意义却很大。一次“生产事故”不再是一件坏事，而仅仅是创新流程中一个不可避免的环节，两个团队通过协作共同管理它。</p>
</li>
<li><p>一个需要人工阅读邮件和分析警报来决定目前是否需要采取某种行动的系统从本质上就是错误的。监控系统不应该依赖人来分析警报信息，而是应该由系统自动分析，仅当需要用户执行某种操作时，才需要通知用户。</p>
</li>
<li><p>一个监控系统应该只有三类输出。紧急警报（alert）意味着收到警报的用户需要立即执行某种操作，目标是解决某种已经发生的问题，或者是避免即将发生的问题。工单（ticket）意味着接受工单的用户应该执行某种操作，但是并非立即执行。系统并不能自动解决目前的情况，但是如果一个用户在几天内执行这项操作，系统不会受到任何影响。日志（logging）平时没有人需要关注日志信息，但是日志信息依然被收集起来以备调试和事后分析时使用。正确的做法是平时没人会去主动阅读日志，除非有特殊需要。</p>
</li>
<li><p>任何需要人工操作的事情都只会延长恢复时间。一个可以自动恢复的系统即使有更多的故障发生，也要比事事都需要人工干预的系统可用性更高。当不可避免地需要人工介入时，我们也发现与“船到桥头自然直”的态度相比，通过事先预案并且将最佳方法记录在“运维手册（playbook）”上通常可以使MTTR 降低3倍以上。初期几个万能的工程师的确可以解决生产问题，但是长久看来一个手持“运维宝典”经过多次演习的on-call工程师才是正确之路。</p>
</li>
<li><p>虽然不论多么完备的“运维手册”也无法替代人的创新思维，但是在巨大的时间压力和产品压力下，运维手册中记录的清晰调试步骤和分析方法对处理问题的人是不可或缺的。因此，Google SRE将大部分工作重心放在“运维手册”的维护上，同时通过“Wheel of Misfortune”等项目[2]不断培训团队成员。</p>
</li>
<li><p>变更管理SRE的经验告诉我们，大概 70% 的生产事故由某种部署的变更而触发。变更管理的最佳实践是使用自动化来完成以下几个项目：● 采用渐进式发布机制。● 迅速而准确地检测到问题的发生。● 当出现问题时，安全迅速地回退改动。</p>
</li>
<li><p>容量规划有几个步骤是必需的：● 必须有一个准确的自然增长需求预测模型，需求预测的时间应该超过资源获取的时间。● 规划中必须有准确的非自然增长的需求来源的统计。● 必须有周期性压力测试，以便准确地将系统原始资源信息与业务容量对应起来。</p>
</li>
</ul>
<h3 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>尽早关注安全性；关注细节和充分的准备</li>
<li>自动化工具替代人工操作</li>
<li>事后总结的若干要点；事后总结“对事不对人”</li>
<li>使用错误预算来最大化新功能上线的速度；目标不再是 “零事故运行”</li>
<li>自动恢复的系统；事先预案和“运维手册；自动化减少人为事故</li>
<li>容量规划；周期性压力测试和调整</li>
</ol>
<hr>
<h2 id="第3章-拥抱风险"><a href="#第3章-拥抱风险" class="headerlink" title="第3章 拥抱风险"></a>第3章 拥抱风险</h2><ul>
<li><p>你可能认为Google会试图构建一个百分之百可靠的服务。事实证明，超过一定值后，再提高可靠性对于一项服务（和它的用户）来说，结果可能会更差而不是更好！极端的可靠性会带来成本的大幅提升：过分追求稳定性限制了新功能的开发速度和将产品交付给用户的速度，并且很大程度地增加了成本，这反过来又减少了一个团队可以提供的新功能的数量。</p>
</li>
<li><p>此外，用户通常不会注意到一项服务在高可靠性和极端可靠性之间的差异，因为用户体验主要是受较不可靠的组件主导，例如手机移动网络或者他们正在使用的设备。简单地说，用户在一个有着99%可靠性的智能手机上是不能分辨出99.99%和99.999%的服务可靠性的区别的！基于这一点，SRE旨在寻求快速创新和高效的服务运营业务之间的风险的平衡，而不是简单地将服务在线时间最大化。这样一来，我们可以优化用户的整体幸福感，平衡系统的功能、服务和性能。</p>
</li>
</ul>
<h3 id="管理风险"><a href="#管理风险" class="headerlink" title="管理风险"></a>管理风险</h3><ul>
<li>不可靠的系统会很快侵蚀用户的信心，所以我们想要减少系统出故障的几率。然而，经验表明，在构建系统的过程中，可靠性进一步提升的成本并不是线性增加的—可靠性的下一个改进可能比之前的改进成本增加100倍。</li>
</ul>
<h3 id="度量服务的风险"><a href="#度量服务的风险" class="headerlink" title="度量服务的风险"></a>度量服务的风险</h3><ul>
<li><p>Google标准做法是通过一个客观的指标来体现一个待优化的系统属性。</p>
</li>
<li><p>可用性&#x3D;系统正常运行时间&#x2F;（系统正常运行时间+停机时间）</p>
</li>
<li><p>在Google内部，基于时间的可用性通常是毫无意义的。<br>我们通过请求成功率来定义服务可用性。<br>可用性&#x3D;成功请求数&#x2F;总的请求数</p>
</li>
<li><p>使用请求成功率指标量化计划外停机时间使得这种指标更适合在不直接服务终端用户的系统中使用。</p>
</li>
<li><p>通常，我们会为一项服务设定季度性的可用性目标，每周甚至每天对性能进行跟踪。我们通过寻找、跟踪和调整重要的、不可避免的偏差来使服务达到一个高层次的可用性目标。</p>
</li>
</ul>
<h3 id="服务的风险容忍度"><a href="#服务的风险容忍度" class="headerlink" title="服务的风险容忍度"></a>服务的风险容忍度</h3><ul>
<li><p>为了辨别服务的风险容忍度，SRE必须与产品负责人一起努力，将一组商业目标转化为明确的可以实现的工程目标。</p>
</li>
<li><p>尽管当时YouTube已经有了一个很出色的产品，但它仍然在不断变化和快速发展着。因此，我们为YouTube设定了一个相比我们企业的产品更低的可用性目标，因为快速发展更加重要。</p>
</li>
<li><p>对于一项给定的服务的故障预期是另一个需要重点考虑的因素。我们的业务对于服务的停机时间的容忍程度有多高？持续的低故障率或者偶尔发生的全网中断哪一个会更糟糕？这两种类型的故障可能会导致绝对数量上完全相同的错误被返回，但可能对于业务的影响相差很大。下面这个例子说明了一个提供私人信息的系统中自然发生的完全和部分服务中断的区别。假设有一个联系人管理应用程序，一种情况是导致用户头像显示失败的间歇性故障，另一种情况是将A用户的私人联系列表显示给B用户的故障。第一种情况显然是一个糟糕的用户体验，SRE会努力去快速地解决这个问题。然而，在第二种情况下，暴露私人数据的风险可能会破坏基本的用户信任。因此，在第二种情况下，在进行调试和事后的数据清理时，完全停止该服务更加恰当。</p>
</li>
<li><p>对于Google提供的其他服务，有时候，我们可以接受计划内的常规的服务中断。几年前，Ads前端曾经就是这样的一种服务。它是广告商和网站创建者用来建立、配置、运行和监控他们的广告活动的服务。因为这项工作大部分发生在正常工作时间内，我们认为维修窗口中发生的偶然的、正常的、计划之中的故障是可以接受的，并且我们把这些故障看作计划内停机时间，而不是计划外停机时间。</p>
</li>
</ul>
<h3 id="使用错误预算的目的"><a href="#使用错误预算的目的" class="headerlink" title="使用错误预算的目的"></a>使用错误预算的目的</h3><ul>
<li><p>产品研发的绩效是如何很大程度通过产品研发速度体现的，这会激励员工尽可能快地创建新的代码。同时， SRE 的绩效表现取决于该服务的可靠性，这意味着SRE 会对高频率的更改提出抗议。两个团队之间的信息不对称进一步加剧了这种内在的紧张局势。产品开发者更了解编写和发布他们的代码所需的时间，而SRE则更关注服务可靠性程度（以及生产环境中的其他相关事项）。</p>
</li>
<li><p>软件对故障的容忍度对意外事件的容忍程度有多高？做得太少，我们就只能设计出一个脆弱无用的产品。做得太多，我们的产品可能没有人会使用（但运行非常稳定）。</p>
</li>
<li><p>测试新发布的代码的最好做法就是在一个典型工作负载的服务子集中进行测试，这种做法通常被称为金丝雀测试。</p>
</li>
<li><p>一项决策越是基于数据做出的，常常就越好。</p>
</li>
<li><p>错误预算提供了一个明确的、客观的指标来决定服务在一个单独的季度中能接受多少不可靠性。这个指标在SRE与产品研发部门的谈判中将政治因素排除。</p>
</li>
<li><p>我们的实际做法如下：● 产品管理层定义一个SLO，确定一项服务在每个季度预计的正常运行时间。● 实际在线时间是通过一个中立的第三方来测算的：我们的监控系统。● 这两个数字的差值就是这个季度中剩余的不可靠性预算。● 只要测算出的正常在线时间高于SLO，也就是说，只要仍然有剩余的错误预算，就可以发布新的版本。</p>
</li>
<li><p>错误预算的主要好处就是它能够激励产品研发和SRE一起找出创新和可靠性之间合理的平衡点。</p>
</li>
<li><p>只要系统符合SLO，就可以继续发行新版本。如果频繁地违反SLO 导致错误预算被耗尽，那么发布就会暂停，同时需要在系统测试和开发环节投入更多资源使得系统更有弹性，以使性能得到提升。</p>
</li>
<li><p>有比这种简单的开&#x2F;关技术更巧妙和有效的方法：[2]例如，当SLO 违规导致错误预算接近耗尽时，将发布的速度减慢，或者回退到上一版本。</p>
</li>
<li><p>例如，如果产品研发人员想要在测试上节约时间或者想要提高发布速度并且SRE 表示反对时，那么就可以通过错误预算指导决策。当预算剩余很多时，产品研发人员就可以承担更多的风险。如果预算接近耗尽，产品研发人员自身将会推动更多的测试或者放慢发布的速度，因为他们不想冒着用尽预算的风险和拖延他们的程序上线。实际上，产品开发团队这样就开始进行自我监管。他们知道预算还剩多少，并且可以控制自己的风险。（当然，这要求SRE在SLO达不到的时候有权停止程序的发布。）如果网络中断或者数据中心发生故障影响了SLO，怎么办？这样的事件也会给错误预算带来不良的影响，会使本季度剩余部分的发布将会减少。整个团队会支持这种发布频率的降低，因为每个人都有义务保障服务正常运行。</p>
</li>
<li><p>利用错误预算可以同时找到制定得过高的可用性目标，显示出它们所导致的灵活性和创新速度方面的问题。如果团队无法发布新的功能，他们可以选择降低SLO（从而增加错误预算）来提高创新速度。</p>
</li>
<li><p>管理服务的可靠性主要在于管理风险，而且管理风险的成本可能很高。</p>
</li>
<li><p>● 100%可能永远都不是一个正确的可靠性目标：不仅是不可能实现的，而且它通常比一项服务的用户期望的可靠性大得多。我们要将服务风险和愿意承担的业务风险相匹配。● 错误预算在SRE和产品研发团队之间调整激励，同时强调共同责任。错误预算使得讨论发布速率更容易，同时可有效地减少任何关于事故的讨论。这样，多个团队可以毫无怨言地对生产环境风险度达成一致。</p>
</li>
</ul>
<hr>
<h2 id="第4章-服务质量目标"><a href="#第4章-服务质量目标" class="headerlink" title="第4章 服务质量目标"></a>第4章 服务质量目标</h2><ul>
<li><p>如果不详细了解服务中各种行为的重要程度，并且不去度量这些行为的正确性的话，就无法正确运维这个系统，更不要说可靠地运维了</p>
</li>
<li><p>我们需要利用一些主观判断结合过去的经验以及对服务的理解来定义一些服务质量指标（SLI）、服务质量目标（SLO），以及服务质量协议（SLA）。</p>
</li>
</ul>
<h3 id="服务质量术语"><a href="#服务质量术语" class="headerlink" title="服务质量术语"></a>服务质量术语</h3><ul>
<li><p>SLO的选择和公布可以帮助设立用户对服务质量的预期。</p>
</li>
<li><p>该策略可以应对那些没有根据的抱怨—“服务太慢了”。如果没有一个明确的SLO，用户经常会按照自己的理解设置一个服务性能的预期，即使这可能跟运维人员或者设计者所想的完全不同。这种问题可能会导致对某个服务的过度依赖—用户错误地认为这个服务会比实际情况更可靠</p>
</li>
<li><p>由于真正的全球Chubby服务故障出现的频率太低，以至于其他服务负责人开始认为全球Chubby服务永远不会出故障，从而不停地将更多的服务依赖于此。<br>Chubby全球服务的高可靠性实际上提供了一种安全假象，因为这些服务实际上在Chubby全球服务不可用的时候不能正常工作，不管这种情况是多么罕见。</p>
</li>
<li><p>每个季度，如果真实故障没有将可用性指标降低到SLO之下，SRE会有意安排一次可控的故障，将服务停机。利用这种方法，我们可以很快找出那些对Chubby全球服务的不合理依赖，强迫服务的负责人尽早面对这类分布式系统的天生缺陷。</p>
</li>
<li><p>不管某个服务是否具有SLA，定义SLI与SLO，并且用它们来管理服务质量都是很有价值的。</p>
</li>
</ul>
<h3 id="指标在实践中的应用"><a href="#指标在实践中的应用" class="headerlink" title="指标在实践中的应用"></a>指标在实践中的应用</h3><ul>
<li><p>只有理解用户对系统的真实需求才能真正决定哪些指标是否有用。指标过多会影响对那些真正重要的指标的关注，而选择指标过少则会导致某些重要的系统行为被忽略。一般来说，四五个具有代表性的指标对系统健康程度的评估和关注就足够了。</p>
</li>
<li><p>常见的服务，根据它们的相关SLI通常会归类为以下几个大类。● 用户可见的服务系统，例如莎士比亚搜索服务的前端服务器通常关心可用性、延迟，以及吞吐量。换句话说：是否能正常处理请求？每个请求花费的时间是多少？多少请求可以被处理？● 存储系统通常强调：延迟、可用性和数据持久性。换句话说：读写数据需要多少时间？我们是否可以随时访问数据？数据是否一段时间内还能被读取？扩展讨论参见第26章。● 大数据系统，例如数据处理流水线系统，一般来说关心吞吐量和端到端延迟。换句话说：处理了多少数据？数据从输入到产出需要多少时间？（某些流水线任务还会关注某个单独处理阶段的延迟。）● 所有的系统都应该关注：正确性。是否返回了正确的回复，是否读取了正确的数据，或者进行了正确的数据分析操作。正确性是系统健康程度的一个重要指标，但是它更关注系统内部的数据，而不是系统本身，所以这通常不是SRE直接负责的。指标的收集利用某种监控系统，大部分指标数据都在服务器端被收集，例如Borgmon（具体参见第10章）或者Prometheus。或者利用某种日志分析系统，例如分析日志中HTTP 500回复所占的比例。然而，某些系统可以加入对客户端数据的收集，否则可能会错失一些不影响服务器端指标，但是对用户产生影响的问题。例如，只关注莎士比亚服务器搜索后端的延迟可能会错失由页面JavaScript脚本导致的用户可见的延迟问题。在这个例子中，度量页面在浏览器中可用的延迟是度量用户体验的一个更好的指标。</p>
</li>
<li><p>平均请求延迟可能看起来很简单，但是却掩盖了一个重要的细节；很可能大部分请求都是很快的，但是长尾请求速度却很慢。</p>
</li>
<li><p>大部分指标都应该以“分布”，而不是平均值来定义。</p>
</li>
<li><p>响应时间的分布越分散，意味着普通用户受到长尾请求延迟的影响就越明显，这可能预示了负载过高情况下出现的排队问题。</p>
</li>
<li><p>一般来说，SRE更倾向于分析一组数据的百分比分布，而非其算术平均值。长尾效应比算术平均值更有特点，使用百分比分布能够更清晰地进行分析。因为计算机系统的本身特质决定，数据是具有特定分布特点的 ——例如，请求延迟必须大于0，同时如果超时设置为1000ms，则不可能有成功请求超过这个时间。因此，我们不能假设算术平均值和中位数是相等的——它们甚至可能相差甚远！</p>
</li>
<li><p>汇总间隔：每1分钟汇总一次● 汇总范围：集群中的全部任务● 度量频率：每10秒一次● 包含哪些请求：从黑盒监控任务发来的HTTP GET请求● 数据如何获取：通过监控系统获取服务器端信息得到● 数据访问延迟：从收到请求到最后一个字节被发出</p>
</li>
</ul>
<h3 id="目标在实践中的应用"><a href="#目标在实践中的应用" class="headerlink" title="目标在实践中的应用"></a>目标在实践中的应用</h3><ul>
<li><p>我们应该从思考（或者调研）用户最关心的方面入手，而非从现在能度量什么入手。</p>
</li>
<li><p>不要仅以目前的状态为基础选择目标</p>
</li>
<li><p>了解系统的各项指标和限制非常重要，但是仅仅按照当前系统的标准制定目标，而不从全局出发，可能会导致团队被迫长期运维一个过时的系统，没有时间去推动架构重构等任务。</p>
</li>
<li><p>避免绝对值虽然要求系统可以在没有任何延迟增长的情况下无限扩张，或者“永远”可用是很诱人的，但是这样的要求是不切实际的。就算有一个系统能够做到这一点，它也需要花很长时间来设计和构建，同时运维也很复杂—最关键的是，这可能比用户可以接受的（甚至是很开心地接受的）标准要高太多。</p>
</li>
<li><p>不要追求完美我们可以随着时间流逝了解系统行为之后优化SLO的定义。刚开始可以以一个松散的目标开始，逐渐收紧。这比一开始制定一个困难的目标，在出现问题时放松要好得多。</p>
</li>
<li><p>如果服务一切正常，可能力量应该花在其他的优先级上，例如消除技术债务、增加新功能，或者引入其他产品等。</p>
</li>
</ul>
<h3 id="个人总结-1"><a href="#个人总结-1" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>没有根据的抱怨—“服务太慢了”；指标制定</li>
<li>大部分指标都应该以“分布”，而不是平均值来定义。</li>
<li>如果服务一切正常，可能力量应该花在其他的优先级上，例如消除技术债务、增加新功能，或者引入其他产品等。</li>
</ol>
<hr>
<h2 id="第5章-减少琐事"><a href="#第5章-减少琐事" class="headerlink" title="第5章 减少琐事"></a>第5章 减少琐事</h2><ul>
<li><p>如果系统正常运转中需要人工干预，应该将此视为一种Bug。</p>
</li>
<li><p>“正常”的定义会随系统的进步而不断改变。要把更多的时间花费在长期项目研发上而非日常运维中。因为术语日常运维可能会被误解，我们在这里使用一个专门的词语——琐事（toil）。</p>
</li>
</ul>
<h3 id="琐事的定义"><a href="#琐事的定义" class="headerlink" title="琐事的定义"></a>琐事的定义</h3><ul>
<li><p>琐事不仅仅代表“我不喜欢做的工作”。</p>
</li>
<li><p>到底什么是琐事？琐事就是运维服务中手动性的，重复性的，可以被自动化的，战术性，没有持久价值的工作。而且，琐事与服务呈线性关系的增长。并不是每件琐事都有以上全部特性，但是，每件琐事都满足下列一个或多个属性：手动性</p>
</li>
<li><p>例如手动运行脚本以便自动执行一些任务。运行一个脚本可能比手动执行脚本中的每一步要快，但具体运行脚本所花费的手动的时间（而非脚本所需要的运行时间）应该被认为是琐事。重复性的如果某件事是第一次做，甚至第二次做，都不应该算作琐事。琐事就是不停反复做的工作。如果你正在解决一个新出现的问题或者寻求一种新的解决办法，不算作琐事。</p>
</li>
<li><p>可以被自动化的如果计算机可以和人类一样能够很好地完成某个任务，或者通过某种设计变更来彻底消除对某项任务的需求，这项任务就是琐事。如果主观判断是必需的，那么很大程度上这项任务不属于琐事。[8]</p>
</li>
<li><p>战术性的琐事是突然出现的、应对式的工作，而非策略驱动和主动安排的。处理紧急警报是琐事。我们可能永远无法完全消除这种类型的工作，但我们必须继续努力减少它。没有持久价值如果在你完成某项任务之后，服务状态没有改变，这项任务就很可能是琐事。如果这项任务会给服务带来永久性的改进，它就不是琐事。一些繁重的工作—比如挖掘遗留代码和配置并且将它们清理出去也不是琐事。与服务同步线性增长如果在工作中所涉及的任务与服务的大小、流量或用户数量呈线性增长关系，那这项任务可能属于琐事。一个良好管理和设计的服务应该至少可以应对一个数量级的增长，而不需要某些一次性工作（例如增加资源）之外的额外工作。</p>
</li>
</ul>
<h3 id="为什么琐事越少越好"><a href="#为什么琐事越少越好" class="headerlink" title="为什么琐事越少越好"></a>为什么琐事越少越好</h3><ul>
<li><p>SRE的一个公开目标是保持每个SRE的工作时间中运维工作（即琐事）的比例低于50%。SRE至少花50%的时间在工程项目上，</p>
</li>
<li><p>以减少未来的琐事或增加服务功能。增加服务功能包括提高可靠性、性能，或利用率，同时也会进一步消除琐事。</p>
</li>
</ul>
<h3 id="什么算作工程工作"><a href="#什么算作工程工作" class="headerlink" title="什么算作工程工作"></a>什么算作工程工作</h3><ul>
<li>工程工作通常是有创新性和创造性的，着重通过设计来解决问题，解决方案越通用越好。</li>
</ul>
<h3 id="琐事繁多是不是一定不好"><a href="#琐事繁多是不是一定不好" class="headerlink" title="琐事繁多是不是一定不好"></a>琐事繁多是不是一定不好</h3><ul>
<li><p>琐事不会总是让每个人都不开心，特别是不太多的时候。已知的和重复性的工作有一种让人平静的功效。完成这些事可以带来一种满足感和快速胜利感。琐事可能是低风险低压力的活动，有些员工甚至喜欢做这种类型的工作。</p>
</li>
<li><p>琐事的存在并不总是坏事，但是每个人都必须清楚，在SRE所扮演的角色中，一定数量的琐事是不可避免的，这其实是任何工程类工作都具有的特点。少量的琐事存在不是什么大问题。但是一旦琐事的数量变多，就会有害了。如果琐事特别繁重，那就应该非常担忧，大声抱怨。在许多琐事有害的原因中，有如下因素需要考虑：职业停滞如果花在工程项目上的时间太少，你的职业发展会变慢，甚至停滞。Google确实会奖励做那些脏活累活的人，但是仅仅是该工作是不可避免，并有巨大的正面影响的时候才会这样做。没有人可以通过不停地做脏活累活满足自己的职业发展。</p>
</li>
<li><p>士气低落每个人对自己可以承担的琐事限度有所不同，但是一定有个限度。过多的琐事会导致过度劳累、厌倦和不满。另外，牺牲工程实践而做琐事会对SRE组织的整体发展造成损害。</p>
</li>
<li><p>原因如下：造成误解。我们努力确保每个SRE以及每个与SRE一起工作的人都理解SRE是一个工程组织。如果个人或者团队过度参与琐事，会破坏这种角色，造成误解。进展缓慢琐事过多会导致团队生产力下降。如果SRE团队忙于为手工操作和导出数据救火，新功能的发布就会变慢。开创先例如果SRE过于愿意承担琐事，研发同事就更倾向于加入更多的琐事，有时候甚至将本来应该由研发团队承担的运维工作转给SRE来承担。其他团队也会开始指望SRE接受这样的工作，这显然是不好的。促进摩擦产生即使你个人对琐事没有怨言，你现在的或未来的队友可能会很不开心。如果团队中引入了太多的琐事，其实就是在鼓励团队里最好的工程师开始寻找其他地方提供的更有价值的工作。违反承诺那些为了项目工程工作而新入职的员工，以及转入SRE的老员工会有被欺骗的感觉，这非常不利于公司的士气。</p>
</li>
</ul>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul>
<li>如果我们都致力于每一周通过工程工作消除一点琐事，就可以持续性地整顿服务。我们就可以将更多的力量投入到扩大服务规模的工程工作上去，或者是进行下一代的服务的架构设计，又或者是建立一套跨SRE使用的工具链。让我们多创新，少干琐事吧！</li>
</ul>
<h3 id="个人总结-2"><a href="#个人总结-2" class="headerlink" title="个人总结"></a>个人总结</h3><ul>
<li>琐事应该尽量自动化，把时间创造性的事情上！</li>
</ul>
<hr>
<h3 id="为什么要监控"><a href="#为什么要监控" class="headerlink" title="为什么要监控"></a>为什么要监控</h3><ul>
<li>紧急警报的处理会占用员工的宝贵时间。如果该员工正在工作时间段，该警报的处理会打断他原本的工作流程。如果该员工正在家，紧急警报的处理则会影响他的个人生活，甚至是把他从睡眠中叫醒。当紧急警报出现得太频繁时，员工会进入“狼来了”效应，怀疑警报的有效性甚至忽略该警报，有的时候在警告过多的时候甚至会忽略掉真实发生的故障。由于无效信息太多，分析和修复可能会变慢，故障时间也会相应延长。高效的警报系统应该提供足够的信息，并且误报率非常低。</li>
</ul>
<h3 id="对监控系统设置合理预期"><a href="#对监控系统设置合理预期" class="headerlink" title="对监控系统设置合理预期"></a>对监控系统设置合理预期</h3><ul>
<li>但是监控系统中最重要的一点就是整个“生产故障，人工处理紧急警报，简单定位和深入调试”过程必须要保持非常简单，必须能被团队中任何一个人所理解。</li>
</ul>
<h3 id="现象与原因"><a href="#现象与原因" class="headerlink" title="现象与原因"></a>现象与原因</h3><ul>
<li><p>监控系统应该解决两个问题：什么东西出故障了，以及为什么出故障。</p>
</li>
<li><p>“现象”和“原因”的区分是构建信噪比高的监控系统时最重要的概念</p>
</li>
</ul>
<h3 id="黑盒监控与白盒监控"><a href="#黑盒监控与白盒监控" class="headerlink" title="黑盒监控与白盒监控"></a>黑盒监控与白盒监控</h3><ul>
<li><p>黑盒监控是面向现象的，代表了目前正在发生的—而非预测会发生的—问题，即“系统现在有故障”。白盒监控则大量依赖对系统内部信息的检测，如系统日志、抓取提供指标信息的HTTP节点等。白盒监控系统因此可以检测到即将发生的问题及那些重试所掩盖的问题等。</p>
</li>
<li><p>这里应该注意，在一个多层系统中，某一个服务的现象是另外一个服务的原因。</p>
</li>
<li><p>白盒监控有时是面向现象的，有时是面向原因的，这取决于白盒系统所提供的信息。</p>
</li>
<li><p>黑盒监控可以保证系统只在某个问题目前正在发生，并且造成了某个现象时才会发出紧急警报。</p>
</li>
</ul>
<h3 id="4个黄金指标"><a href="#4个黄金指标" class="headerlink" title="4个黄金指标"></a>4个黄金指标</h3><ul>
<li><p>监控系统的4个黄金指标分别是延迟、流量、错误和饱和度（saturation）。</p>
</li>
<li><p>延迟增加是饱和度的前导现象。99% 的请求延迟（在某一个小的时间范围内，例如一分钟）可以作为一个饱和度早期预警的指标。</p>
</li>
<li><p>如果我们度量所有这4个黄金指标，同时在某个指标出现故障时发出警报（或者对于饱和度来说，快要发生故障时），能做到这些，服务的监控就基本差不多了。</p>
</li>
</ul>
<h3 id="关于长尾问题"><a href="#关于长尾问题" class="headerlink" title="关于长尾问题"></a>关于长尾问题</h3><ul>
<li>区分平均值的“慢”和长尾值的“慢”的一个最简单办法是将请求按延迟分组计数（可以用来制作直方图）：延迟为0～10ms之间的请求数量有多少，30～100ms之间，100～300ms之间等。</li>
</ul>
<h3 id="度量指标时采用合适的精度"><a href="#度量指标时采用合适的精度" class="headerlink" title="度量指标时采用合适的精度"></a>度量指标时采用合适的精度</h3><ul>
<li><p>如果我们的监控目标需要高精度数据，但是却不需要极低的延迟，可以通过一些内部采样机制外部汇总的方式降低成本。</p>
</li>
<li><p>这种方式使我们可以观测到短暂的CPU热点，但是又不需要为此付出高额成本进行收集和保留高精度数据</p>
</li>
</ul>
<h3 id="简化，直到不能再简化"><a href="#简化，直到不能再简化" class="headerlink" title="简化，直到不能再简化"></a>简化，直到不能再简化</h3><ul>
<li>那些不常用的数据收集、汇总，以及警报配置应该定时删除（某些SRE团队的标准是一个季度没有用到一次即将其删除）。</li>
</ul>
<h3 id="将上述理念整合起来"><a href="#将上述理念整合起来" class="headerlink" title="将上述理念整合起来"></a>将上述理念整合起来</h3><ul>
<li>● 每当收到紧急警报时，应该立即需要我进行某种操作。每天只能进入紧急状态几次，太多就会导致“狼来了”效应。● 每个紧急警报都应该是可以具体操作的。● 每个紧急警报的回复都应该需要某种智力分析过程。如果某个紧急警报只是需要一个固定的机械动作，那么它就不应该成为紧急警报。● 每个紧急警报都应该是关于某个新问题的，不应该彼此重叠。</li>
</ul>
<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><ul>
<li>E-mail警报的价值通常极为有限，很容易变成噪声。我们应该倾向于构建一个良好的监控台页面，直接显示所有的非紧急的异常情况。</li>
</ul>
<h3 id="个人总结-3"><a href="#个人总结-3" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>避免太多“紧急警报”造成“狼来了”效应</li>
<li>监控系统应该解决两个问题：什么东西出故障了，以及为什么出故障。</li>
<li>监控系统的4个黄金指标分别是延迟、流量、错误和饱和度（saturation）。</li>
</ol>
<hr>
<h3 id="自动化的价值"><a href="#自动化的价值" class="headerlink" title="自动化的价值"></a>自动化的价值</h3><ul>
<li>任何一个人或者一群人执行数百次动作时，不可能保证每次都用同样的方式进行：没有几个人能像机器一样永远保持一致。这种不可避免的不一致性会导致错误、疏漏、数据质量的问题和可靠性问题。在这个范畴内—一致性地执行范围明确、步骤已知的程序—是自动化的首要价值。</li>
</ul>
<h3 id="自动化的应用案例"><a href="#自动化的应用案例" class="headerlink" title="自动化的应用案例"></a>自动化的应用案例</h3><ul>
<li>广泛使用的工具有Puppet、Chef、cfengine，甚至 Perl都提供了自动化完成特定任务的方法，主要区别在于对帮助进行自动化的组件的抽象层次不同。</li>
</ul>
<h3 id="可靠性是最基本的功能"><a href="#可靠性是最基本的功能" class="headerlink" title="可靠性是最基本的功能"></a>可靠性是最基本的功能</h3><ul>
<li>民航[20]或工业应用中—经常会指出高效的自动化的缺点[21]：随着时间的推移，操作员与系统的有用的、直接接触会逐渐减少，因为自动化会覆盖越来越多的日常活动。不可避免的，当自动化系统出现问题时，操作员将无法成功地操作该系统。</li>
</ul>
<h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><ul>
<li>团队应该在开发流程开始时就留出一定资源进行发布工程工作。尽早采用最佳实践和最佳流程可以降低成本，以免未来重新改动这些系统。</li>
</ul>
<h3 id="个人总结-4"><a href="#个人总结-4" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>自动化很重要，但也要避免自动化工具出问题时，人工无法处理</li>
</ol>
<hr>
<h2 id="第9章-简单化"><a href="#第9章-简单化" class="headerlink" title="第9章 简单化"></a>第9章 简单化</h2><ul>
<li><p>可靠性只有靠对最大程度的简化不断追求而得到。</p>
</li>
<li><p>软件系统本质上是动态的和不稳定的。[25]只有真空中的软件系统才是永远稳定的。如果我们不再修改代码，就不会引入新的Bug。如果底层硬件或类库永远不变，这些组件也就不会引入Bug。如果冻结当前用户群，我们将永远不必扩展系统。事实上，一个对SRE管理系统的方法不错的总结是：“我们的工作最终是在系统的灵活性和稳定性上维持平衡。”</p>
</li>
</ul>
<h3 id="乏味是一种美德"><a href="#乏味是一种美德" class="headerlink" title="乏味是一种美德"></a>乏味是一种美德</h3><ul>
<li>必要复杂度是一个给定的情况所固有的复杂度，不能从该问题的定义中移除，而意外复杂度则是不固定的，可以通过工程上的努力来解决。</li>
<li>例如，编写一个Web服务器需要处理快速提供Web页面的必要复杂度。但是，如果我们用Java编写该服务器，试图减少GC的影响就可能会引入意外复杂度。</li>
</ul>
<h3 id="我绝对不放弃我的代码"><a href="#我绝对不放弃我的代码" class="headerlink" title="我绝对不放弃我的代码"></a>我绝对不放弃我的代码</h3><ul>
<li>那些由于功能开关没有启用而没有被执行的代码，就像一个定时炸弹一样等待爆炸，正如Knight Capital的痛苦经历</li>
<li>审查代码以确保它确实符合商业目标，定期删除无用代码，并且在各级测试中增加代码膨胀检测。</li>
</ul>
<h3 id="“负代码行”作为一个指标"><a href="#“负代码行”作为一个指标" class="headerlink" title="“负代码行”作为一个指标"></a>“负代码行”作为一个指标</h3><ul>
<li>我曾经做过的一些最令人满意的编码工作就是删除了数千行已经没用的代码。</li>
</ul>
<h3 id="最小-API"><a href="#最小-API" class="headerlink" title="最小 API"></a>最小 API</h3><ul>
<li><p>法国诗人 Antoine de Saint Exupery 曾写道，“不是在不能添加更多的时候，而是没有什么可以去掉的时候，才能达到完美。”<br>（参见文献[Sai39]）这个原则同样适用于软件的设计和构建。API是这个规则应该遵循的一个清晰的例子。</p>
</li>
<li><p>书写一个明确的、最小的API 是管理软件系统管理简单性必要的部分。我们向API消费者提供的方法和参数越少，这些API就越容易理解，我们就能用更多的精力去尽可能地完善这些方法。同时，一个反复出现的主题是：有意识地不解决某些问题可以让我们能够更专注核心问题，使得我们已有的解决方案更好。在软件工程上，少就是多！一个很小的，很简单的API通常也是一个对问题深刻理解的标志。</p>
</li>
</ul>
<h3 id="个人总结-5"><a href="#个人总结-5" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>我们的工作最终是在系统的灵活性和稳定性上维持平衡</li>
<li>必要复杂度是业务固有的，而意外复杂度则是不固定的，可以通过工程上的努力来解决</li>
<li>“不是在不能添加更多的时候，而是没有什么可以去掉的时候，才能达到完美。”</li>
</ol>
<hr>
<h1 id="第Ⅲ部分-具体实践"><a href="#第Ⅲ部分-具体实践" class="headerlink" title="第Ⅲ部分 具体实践"></a>第Ⅲ部分 具体实践</h1><ul>
<li>正确的解决方案不一定是当场把问题一次性修复好，而可以靠降低系统准确度、关闭一些不重要的功能，或者将用户流量导向其他没有问题的任务实例等手段暂时缓解问题。解决方案的细节肯定是和每个服务和团队相关的。但是如何有效地应对紧急问题的方法论是每个团队都适用的。</li>
</ul>
<h2 id="第10章-基于时间序列数据进行有效报警"><a href="#第10章-基于时间序列数据进行有效报警" class="headerlink" title="第10章 基于时间序列数据进行有效报警"></a>第10章 基于时间序列数据进行有效报警</h2><ul>
<li>一个大型系统不应该要求运维人员持续关注其中使用的无数个小组件，而是应该自动汇总所有的信息，自动抛弃其中的异常情况。监控系统应该主要从高级服务质量目标层面进行报警，但是也应该保持足够的粒度，可以追踪到某个具体组件。</li>
</ul>
<h3 id="Borgmon的起源"><a href="#Borgmon的起源" class="headerlink" title="Borgmon的起源"></a>Borgmon的起源</h3><ul>
<li>Prometheus 都是开源软件中与Borgmon 基于时间序列数据报警理念类似的系统。</li>
<li>Prometheus[3]与Borgmon十分类似，尤其是当你对比其中的规则计算语法时。变量收集和规则计算的理念在所有这些项目中都很类似。希望借助这些工具，读者可以自行试验、部署本章内描述的一些想法。</li>
</ul>
<h3 id="黑盒监控"><a href="#黑盒监控" class="headerlink" title="黑盒监控"></a>黑盒监控</h3><ul>
<li>白盒监控只能看到已经接收到的请求，并不能看到由于DNS故障导致没有发送成功的请求，或者是由于软件服务器崩溃而没有返回的错误</li>
<li>探针程序使用应用级别的自动请求探测目标是否成功返回。</li>
</ul>
<h3 id="配置文件的维护"><a href="#配置文件的维护" class="headerlink" title="配置文件的维护"></a>配置文件的维护</h3><ul>
<li>Borgmon提供一种类似于宏的模板机制，允许用户创造出一些可重用的规则库，进一步减小了配置文件中的重复程度，降低配置文件出错的可能性。</li>
</ul>
<h3 id="个人总结-6"><a href="#个人总结-6" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>Prometheus</li>
<li>黑盒监控（类似APM）</li>
<li>保证监控系统的维护成本与服务的部署规模呈非线性相关增长是非常关键的。</li>
</ol>
<hr>
<ul>
<li><p>SRE团队和纯运维团队十分不一样的地方在于，SRE团队非常强调用工程化手段来应对运维问题。而这些运维问题，当达到一定规模时，也确实只有采用软件工程化手段才能解决。</p>
</li>
<li><p>我们为SRE花在纯运维事务上的时间设立了50%的上限。SRE至少要花50%的时间进行工程项目研发，以便能够研发出更好的自动化和服务优化手段来更好地服务整个业务。</p>
</li>
</ul>
<h3 id="安全感"><a href="#安全感" class="headerlink" title="安全感"></a>安全感</h3><ul>
<li><p>现代理论研究指出，在面临挑战时，一个人会主动或非主动（潜意识）地选择下列两种处理方法之一（参见文献[Kah11]）：● 依赖直觉，自动化、快速行动。● 理性、专注、有意识地进行认知类活动。</p>
</li>
<li><p>当处理复杂系统问题时，第二种行事方式是更好的，可能会产生更好的处理结果，以及计划更周全的执行过程。为了确保on-call工程师可以保持在第二种处理方式范围内，我们必须要减轻on-call所带来的压力感。</p>
</li>
<li><p>在应急事故处理过程中，凭直觉操作和快速反应（例如服务出现问题就先重启服务器）看起来都是很有用的方法，但是这些方法都有自己的缺点。直觉很可能是错误的，而且直觉一般都不是基于明确的数据支持的。因此，在处理问题的过程中，on-call工程师很有可能由于凭直觉去解释问题产生的原因而浪费宝贵的时间。快速反应主要是由习惯而产生的，习惯性的快速反应的动作后果一般都没有经过详细考虑，这可能会将灾难扩大。在应急事件处理过程中，最理想的方法论是这样的：在有足够数据支撑的时候按步骤解决问题，同时不停地审视和验证目前所有的假设。</p>
</li>
<li><p>让on-call SRE知道他们可以寻求外部帮助，对减轻on-call压力也很有帮助。最重要的资源有：● 清晰的问题升级路线。● 清晰定义的应急事件处理步骤。● 无指责，对事不对人的文化氛围（参见文献[Loo10]和[All12]）</p>
</li>
<li><p>最后，在应急事件处理结束时，仔细评估哪些地方有问题，哪些地方做得好是非常关键的。而且应该采取措施避免再次发生同样的问题。SRE团队必须在大型应急事件发生之后书写事后报告，详细记录所有事件发生的时间线。这些事后报告都是对事不对人的，为日后系统性地分析问题产生的原因提供了宝贵数据。犯错误是不可避免的，软件系统应该提供足够的自动化工具和检查来减少人为犯错误的可能性（参见文献[Loo10]）。</p>
</li>
</ul>
<h3 id="避免运维压力过大"><a href="#避免运维压力过大" class="headerlink" title="避免运维压力过大"></a>避免运维压力过大</h3><ul>
<li><p>控制on-call工程师收到的针对同一起事故的报警总数也很重要。有的时候，一个异常情况可能会触发多条报警，所以合理地分组汇总报警信息是很重要的。</p>
</li>
<li><p>奸诈的敌人—运维压力不够虽然给一个非常安静的系统on-call值班是很幸福的事情，但是当一个系统太稳定，或者SRE on-call的周期太长会发生什么呢？SRE团队运维压力不够也是一个不良现象。长时间不操作生产环境会导致自信心问题，包括自信心太强以及自信心不够。这些现象只有在下一次发生问题时，才会显现出来。为了避免这种问题，应该控制SRE团队的大小，保证每个工程师每个季度至少参与oncall一次，最好两次。这样可以保证团队成员有足够的生产环境操作经验。“命运之轮”（见第28章）也是一种有助提高技能和共享知识的团队活动。同时，Google每年举办一次持续数天的全公司灾难恢复演习（DiRT），针对理论性和实际性的灾难进行演练。</p>
</li>
</ul>
<h3 id="个人总结-7"><a href="#个人总结-7" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>理性，逐步验证解决</li>
<li>清晰定义的应急事件处理步骤和升级流程</li>
<li>定期演练避免一旦突发时生疏</li>
</ol>
<hr>
<h2 id="第12章-有效的故障排查手段"><a href="#第12章-有效的故障排查手段" class="headerlink" title="第12章 有效的故障排查手段"></a>第12章 有效的故障排查手段</h2><ul>
<li><p>值得警惕的是，理解一个系统应该如何工作并不能使人成为专家。只能靠调查系统为何不能正常工作才行。</p>
</li>
<li><p>新手们常常不能有效地进行故障排查，是因为这个过程理想情况下同时需要两个条件。</p>
<ul>
<li>1.对通用的故障排查过程的理解（不依靠任何特定系统）。2.对发生故障的系统的足够了解。</li>
</ul>
</li>
</ul>
<h3 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h3><ul>
<li>我们不断提出一个造成系统问题的假设，进而针对这些假设进行测试和排除。</li>
</ul>
<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><ul>
<li><p>有效的故障报告应该写清预期是什么，实际的结果是什么，以及如何重现</p>
</li>
<li><p>合理判定一个问题的严重程度需要良好的工程师判断力，同时，也需要一定程度的冷静。</p>
</li>
<li><p>在大型问题中，你的第一反应可能是立即开始故障排查过程，试图尽快找到问题根源。这是错误的！不要这样做。正确的做法应该是：尽最大可能让系统恢复服务。</p>
</li>
<li><p>这可能需要一些应急措施，比如，将用户流量从问题集群导向其他还在正常工作的集群，或者将流量彻底抛弃以避免连锁过载问题，或者关闭系统的某些功能以降低负载。缓解系统问题应该是你的第一要务。在寻找问题根源的时候，不能使用系统的用户并没有得到任何帮助。当然，快速定位问题时仍应该及时保存问题现场，比如服务日志等，以便后续进行问题根源分析时使用。</p>
</li>
<li><p>这种方法也同样适用于计算机系统：如果一个Bug有可能导致不可恢复的数据损坏，停止整个系统要比让系统继续运行更好。对新SRE来说，这个想法是反直觉，令人不安的。对以前曾经有过产品研发背景的人来说更有点难以接受</p>
</li>
<li><p>在日志中支持多级记录是很重要的，尤其是可以在线动态调整日志级别。</p>
</li>
</ul>
<h3 id="最后一个修改"><a href="#最后一个修改" class="headerlink" title="最后一个修改"></a>最后一个修改</h3><ul>
<li><p>计算机系统有惯性存在：我们发现，一个正常工作的计算机系统会维持工作，直到某种外力因素出现，例如一个配置文件的修改，用户流量的改变等。检查最近对系统的修改可能对查找问题根源很有帮助。</p>
</li>
<li><p>某项测试可能产生有误导性的结果。例如：防火墙规则可能只允许某些特定IP访问，所以在你的工作机上ping 数据库可能会失败，而实际从应用服务器上ping数据库可能是成功的。</p>
</li>
<li><p>将你的想法明确地记录下来，包括你执行了哪些测试，以及结果是什么。</p>
</li>
<li><p>尤其是当你处理更加复杂的问题时，良好的文档可以让你记住曾经发生过什么，可避免重复执行。</p>
</li>
</ul>
<h3 id="神奇的负面结果"><a href="#神奇的负面结果" class="headerlink" title="神奇的负面结果"></a>神奇的负面结果</h3><ul>
<li><p>我们在设计实验的时候应该将可能的负面结果考虑在内，因为一个可靠的、应用广泛的负面结果对其他人更有帮助。</p>
</li>
<li><p>公布负面结果有助于提升整个行业的数据驱动风气。</p>
</li>
<li><p>公布结果。如果你对一项测试的结果感兴趣，那么很有可能其他人也感兴趣。当你公布结果的时候，其他人不需要再重新设计和运行一套类似试验。</p>
</li>
<li><p>更多的试验压根没有公布数据，因为很多人错误地认为负面结果意味着没有价值。</p>
</li>
</ul>
<h3 id="使故障排查更简单"><a href="#使故障排查更简单" class="headerlink" title="使故障排查更简单"></a>使故障排查更简单</h3><ul>
<li>使故障排查更简单有很多方法可以简化和加速故障排查过程。可能最基本的是：● 增加可观察性。在实现之初就给每个组件增加白盒监控指标和结构化日志。● 利用成熟的、观察性好的组件接口设计系统。</li>
</ul>
<h3 id="个人总结-8"><a href="#个人总结-8" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>理解一个系统应该如何工作并不能使人成为专家。只能靠调查系统为何不能正常工作才行。</li>
<li>有效的故障报告应该写清预期是什么，实际的结果是什么，以及如何重现</li>
<li>先让系统恢复服务，再排查问题，尽量保存现场相关数据或日志等。</li>
<li>发生问题时，留意“最后一个修改”</li>
<li>排查问题后文档记录，避免以后重复执行</li>
<li>实验的负面结果也有价值</li>
</ol>
<hr>
<h2 id="第13章-紧急事件响应"><a href="#第13章-紧急事件响应" class="headerlink" title="第13章 紧急事件响应"></a>第13章 紧急事件响应</h2><ul>
<li>东西早晚要坏的，这就是生活。</li>
<li>将紧急事件的处理过程变成一个学习机会。</li>
</ul>
<h3 id="当系统出现问题时怎么办"><a href="#当系统出现问题时怎么办" class="headerlink" title="当系统出现问题时怎么办"></a>当系统出现问题时怎么办</h3><ul>
<li>当系统出现问题时怎么办首先，别惊慌失措！这不是世界末日，你也并不是一个人在战斗！作为一个专业人士，你已经接受过如何正确处理这样的情况的训练。通常来说，我们处理的问题一般不涉及真实的物理危险，只是计算机系统出现了问题。最差的情况下，也只是半个互联网都停止运转了（Google网络规模已经是全球排名前三）。所以请深吸一口气，慢慢来。</li>
</ul>
<h3 id="测试导致的紧急事故"><a href="#测试导致的紧急事故" class="headerlink" title="测试导致的紧急事故"></a>测试导致的紧急事故</h3><ul>
<li><p>这次测试带来的严重后果促使开发者对代码类库中的问题进行了一次彻底的修复，同时制定了一个周期性测试机制来保证这类严重问题不再重现。</p>
</li>
<li><p>由于我们没有在测试环境中测试回滚机制，没有发现这些机制其实是无效的，导致了事故总时长被延长了。我们现在要求在大型测试中一定先测试回滚机制。</p>
</li>
</ul>
<h3 id="变更部署带来的紧急事故"><a href="#变更部署带来的紧急事故" class="headerlink" title="变更部署带来的紧急事故"></a>变更部署带来的紧急事故</h3><ul>
<li><p>在这些带外通信系统之外，Google还有命令行工具和其他的访问方式确保我们能够在其他条件无法访问的时候进行更新和变更回滚。这些工具和访问方式在这次事故中起到了重大作用，但是工程师应该更加频繁地测试，以便更为熟悉它们。</p>
</li>
<li><p>具有讽刺意味的是，我们本来计划在下个季度提高部署测试流程和自动化的优先级。这次事故的发生直接将他们的优先级提高了，同时强调不管风险看起来有多小，也要经过严格完整的部署测试。</p>
</li>
</ul>
<h3 id="流程导致的严重事故"><a href="#流程导致的严重事故" class="headerlink" title="流程导致的严重事故"></a>流程导致的严重事故</h3><ul>
<li>我们在机器管理自动化上投入了大量的时间和精力，以使我们能很轻松地在整个集群里运行、停止和重新配置大量任务。但是当意外来临时，自动化的效率有时可能是很可怕的。</li>
</ul>
<h3 id="所有的问题都有解决方案"><a href="#所有的问题都有解决方案" class="headerlink" title="所有的问题都有解决方案"></a>所有的问题都有解决方案</h3><ul>
<li><p>时间和经验一再证明，系统不但一定会出问题，而且会以没有人能够想到的方式出问题。Google学到的最关键的一课是，所有的问题都有对应的解决方案，虽然对一个面对着疯狂报警的工程师来说，它可能不是那么显而易见。如果你想不到解决办法，那么就在更大的范围内寻求帮助。找到更多团队成员，寻求更多的帮助，做你需要做的一切事情，但是要快。最高的优先级永远是将手头问题迅速解决。很多时候，触发这个事故的人对事故了解得最清楚，一定要充分利用这一点。</p>
</li>
<li><p>非常重要的是，一旦紧急事件过去之后，别忘了留出一些时间书写事后报告。</p>
</li>
</ul>
<h3 id="向过去学习，而不是重复它"><a href="#向过去学习，而不是重复它" class="headerlink" title="向过去学习，而不是重复它"></a>向过去学习，而不是重复它</h3><ul>
<li><p>向过去学习，而不是重复它为事故保留记录没有什么比过去的事故记录是更好的学习资料了。历史就是学习其他人曾经犯的错误。在记录中，请一定要诚实，一定要事无巨细。尤其重要的是，提出关键的问题。时刻寻找如何能在战术及战略上避免这项事故的发生。公布和维护事后报告，确保全公司的每个人都能从中学到你所学到的知识。在事故结束后，确保自己和其他人切实完成事故中总结的待办事项。这样能够避免未来再次发生以同样的因素触发的同样的事故。一旦开始仔细学习过去的事故，我们就能更好地避免未来的事故。</p>
</li>
<li><p>鼓励主动测试面对失败，理论和实践是两个完全不同的领域。直到你的系统真的失败的那一刻，你并不真的了解它，以及依赖它的系统，或者它的用户会如何应对。不要预设任何假设，也不要依赖任何没有经过测试的假设。你是希望这个系统在星期六凌晨两点钟，公司大部分同事都还在参加黑森林中的团建时出现故障，还是希望和最可靠和最聪明的同事在一起仔细监控着它们上周详细评审过的测试时出现故障呢？</p>
</li>
</ul>
<h3 id="一次流程管理良好的事故"><a href="#一次流程管理良好的事故" class="headerlink" title="一次流程管理良好的事故"></a>一次流程管理良好的事故</h3><ul>
<li>Josephine上线之后，发现Robin也自愿加入进来。Sabrina 提醒Robin和Josephine，他们应该优先处理任何Mary交给他们的工作，同时他们必须告知Mary他们进行的任何操作。Robin和Josephine 通过阅读实时事故状况文档，很快熟悉了目前的情况。到下午5点时，Sabrina开始寻找接下来负责处理事故的替代人，因为她和她的同事们快要到下班时间了。她更新了事故状况文档。在5点45分时，她召开了一个简短的电话会议，让所有人都清楚目前的情况。在6点时，他们与他们的姐妹团队（另外一个办公室同团队的人）进行了职责交接。Mary第二天早上回到公司时，发现她身处大西洋另一端的同事已经定位了具体问题，缓解了问题，同时将事故做了了结，已经开始写事后总结了。问题解决了！她冲了点咖啡，开始规划一些结构性改变，使得这类问题在未来不会再重现。</li>
</ul>
<h3 id="什么时候对外宣布事故"><a href="#什么时候对外宣布事故" class="headerlink" title="什么时候对外宣布事故"></a>什么时候对外宣布事故</h3><ul>
<li><p>先宣布事故发生，随后找到一个简单解决方案，然后宣布事故结束，要比在问题已经持续几个小时之后才想起流程管理更好。应当针对事故设立一个明确的宣布条件。Google团队依靠下面几个宽松的标准——如果下面任何一条满足条件，这次事故应该被及时宣布。● 是否需要引入第二个团队来帮助处理问题？● 这次事故是否正在影响最终用户？● 在集中分析一小时后，这个问题是否依然没有得到解决？</p>
</li>
<li><p>如果平时不经常使用，事故流程管理的可靠性萎缩得很快。所以怎么使工程师不忘记他们的流程管理技能呢？难道一定要制造更多事故吗？幸运的是，事故流程管理框架常常也适用于其他的跨时区、或者跨团队的常规运维变更实施。如果我们经常使用流程管理框架处理生产变更请求，那么在事故来临时，就可以很好地利用流程管理框架管理它。如果你的组织经常进行灾难恢复演习（你应该这样做！参见文献[Kir12]），事故流程管理应该包含在其中。Google经常针对之前发生的灾难进行角色扮演式演习，比如演习另外一个地区的团队处理过的问题，以更好地熟悉事故流程管理体系。</p>
</li>
</ul>
<h3 id="小结-！！！"><a href="#小结-！！！" class="headerlink" title="小结 ！！！"></a>小结 ！！！</h3><ul>
<li>我们发现，通过事前准备一个事故流程管理策略，并确保平稳实施，以及经常测试，我们能够降低事故的平均恢复时间（MTTR），同时减轻处理紧急事故的人的工作压力。任何对服务可靠性关注的组织团队都会从类似策略上获得帮助。事故流程管理最佳实践划分优先级：控制影响范围，恢复服务，同时为根源调查保存现场。事前准备：事先和所有事故处理参与者一起准备一套流程。信任：充分相信每个事故处理参与者，分配职责后让他们自主行动。反思：在事故处理过程中注意自己的情绪和精神状态。如果发现自己开始惊慌失措或者感到压力难以承受，应该寻求更多的帮助。考虑替代方案：周期性地重新审视目前的情况，重新评估目前的工作是否应该继续执行，还是需要执行其他更重要或者更紧急的事情。练习：平时不断地使用这项流程，直到习惯成自然。换位思考：上次你是事故总控负责人吗？下次可以换一个职责试试。鼓励每个团队成员熟悉流程中的其他角色。</li>
</ul>
<h3 id="个人总结-9"><a href="#个人总结-9" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>东西早晚要坏的，这就是生活。</li>
<li>将紧急事件的处理过程变成一个学习机会。</li>
<li>在大型测试中一定先测试回滚机制。</li>
<li>时间和经验一再证明，系统不但一定会出问题，而且会以没有人能够想到的方式出问题。所有的问题都有对应的解决方案。</li>
<li>向过去学习，而不是重复它（事后报告）</li>
<li>事前准备一个事故流程管理策略</li>
</ol>
<hr>
<h2 id="第15章-事后总结：从失败中学习"><a href="#第15章-事后总结：从失败中学习" class="headerlink" title="第15章 事后总结：从失败中学习"></a>第15章 事后总结：从失败中学习</h2><ul>
<li>一篇事后总结是一次事故的书面记录，包括该事故造成的影响，为缓解该事故采取的措施，事故的根本原因，以及防止未来问题重现的后续任务。</li>
</ul>
<h3 id="Google的事后总结哲学"><a href="#Google的事后总结哲学" class="headerlink" title="Google的事后总结哲学"></a>Google的事后总结哲学</h3><ul>
<li><p>书写事后总结的主要目的是为了保证该事故被记录下来，理清所有的根源性问题，同时最关键的是，确保实施有效的措施使得未来重现的几率和影响得到降低，甚至避免重现。</p>
</li>
<li><p>书写事后总结不是一种惩罚措施，而是整个公司的一次学习机会。但是书写事后总结的过程确实需要消耗团队的一定时间和精力，所以我们在选择上很严格。每个团队都有一些内部灵活性，但是基本的事后总结条件为：● 用户可见的宕机时间或者服务质量降级程度达到一定标准。● 任何类型的数据丢失。● on-call 工程师需要人工介入的事故（包括回滚、切换用户流量等）。● 问题解决耗时超过一定限制。● 监控问题（预示着问题是由人工发现的，而非报警系统）。</p>
</li>
<li><p>在SRE的文化中，最重要的就是事后总结“对事不对人”。一篇事后总结必须重点关注如何定位造成这次事件的根本问题，而不是指责某个人或某团队的错误或者不恰当的举动。一篇对事不对人的事后总结假设所有参与事件处理的人都是善意的，他们在自己当时拥有的信息下做了正确的举动。如果因为某些“错误的”举动就公开指责或者羞辱某个人或团队，那么人们就会自然地逃避事后总结。</p>
</li>
<li><p>我们不能“修好”某个人，但是可以通过改善系统和流程从而更好地协助他在设计和维护大型复杂系统时，做出更多“正确”的判断。</p>
</li>
<li><p>当一次事故发生时，我们不能把事后总结当成例行公事。我们的工程师将事后总结看作一个修复问题，一个使Google变得更可靠的机会。一篇“对事不对人”的事后总结不应该简单地指责或者抱怨某个团队，而应该确实提出服务如何能够获得进步。</p>
</li>
<li><p>下面是两个例子。指责“我们需要重写整个复杂后端系统。在过去三个季度中，它每周都在出问题。我们对一点一点修复它的问题已经烦透了！真的，如果我再收到一个报警，那我就自己重写了。”对事不对人“通过重写整个后端系统可能可以避免这些烦人的报警信息继续发生，目前版本的维护手册非常冗长，学习成本很高。相信通过重写，可以减少报警信息，未来的oncall工程师会感谢我们的。”</p>
</li>
<li><p>最佳实践：避免指责，提供建设性意见。</p>
</li>
<li><p>对事不对人的事后总结有的时候比较难写，因为事后总结的格式清晰地表明了触发事故的原因。从事后总结中排除指责的因素可以使人们在向上级汇报问题的时候更有自信。同时我们也不应该因为某个团队和个人经常写事后总结而对他们产生怀疑。一个充满相互指责风气的环境很容易让人将事故和问题掩盖起来，从而对整个组织酿成更大的灾难。</p>
</li>
</ul>
<h3 id="协作和知识共享"><a href="#协作和知识共享" class="headerlink" title="协作和知识共享"></a>协作和知识共享</h3><ul>
<li><p>最佳实践：所有的事后总结都需要评审</p>
</li>
<li><p>一旦所有的事故参与者都对文档和其中的代办事项表示了肯定，这篇事后总结会被添加到该团队或者整个组织的文档汇总中。</p>
</li>
<li><p>透明化的共享机制保证了每个人都可以很容易地找到和学习以前的事故。</p>
</li>
</ul>
<h3 id="建立事后总结文化"><a href="#建立事后总结文化" class="headerlink" title="建立事后总结文化"></a>建立事后总结文化</h3><ul>
<li><p>最佳实践：公开奖励做正确事的人</p>
</li>
<li><p>最佳实践：收集关于事后总结有效性的反馈</p>
</li>
</ul>
<h3 id="个人总结-10"><a href="#个人总结-10" class="headerlink" title="个人总结"></a>个人总结</h3><ul>
<li>最佳实践：避免指责，提供建设性意见。</li>
<li>一篇“对事不对人”的事后总结不应该简单地指责或者抱怨某个团队，而应该确实提出服务如何能够获得进步。</li>
<li>一个充满相互指责风气的环境很容易让人将事故和问题掩盖起来，从而对整个组织酿成更大的灾难。</li>
</ul>
<hr>
<h2 id="第16章-跟踪故障"><a href="#第16章-跟踪故障" class="headerlink" title="第16章 跟踪故障"></a>第16章 跟踪故障</h2><ul>
<li><p>提高可靠性的唯一可靠的方法论是建立一个基线（baseline），同时不断跟踪改变。</p>
</li>
<li><p>通过找到基础设施中造成故障最多的一部分，可以更好地知道如果提高该部分的稳定性或性能会带来多大帮助。</p>
</li>
<li><p>甚至有的时候，我们需要人为制造一些宕机时间，以免给内部用户造成某种假象（通常指某些服务设计的架构已经决定发生故障会耗时很久才能解决，但是经常由于运气因素而造成非常稳定的假象。某些团队选择定期制造人为宕机时间，以避免用户过于依赖该服务）。</p>
</li>
</ul>
<h3 id="个人总结-11"><a href="#个人总结-11" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>定时宕机，避免把依赖当作理所当然。</li>
</ol>
<hr>
<h2 id="第17章-测试可靠性"><a href="#第17章-测试可靠性" class="headerlink" title="第17章 测试可靠性"></a>第17章 测试可靠性</h2><ul>
<li><p>如果你还没有亲自试过某件东西，那么就假设它是坏的。</p>
</li>
<li><p>测试的数量直接取决于所服务系统的可靠性要求。随着代码的测试覆盖度上升，每次改动的不确定性和降低系统可靠度的可能性都降低了。足够的代码测试覆盖度可以让我们对系统做出更多的改动，而不会使系统可靠度下降到可接受水平之下</p>
</li>
<li><p>测试和平均修复时间的关系系统通过某项测试或者一系列测试并不一定能证明系统是稳定的，但是失败的测试通常证明了系统不可靠。</p>
</li>
</ul>
<h3 id="软件测试的类型"><a href="#软件测试的类型" class="headerlink" title="软件测试的类型"></a>软件测试的类型</h3><ul>
<li><p>软件测试基本分为两大类：传统测试和生产测试。传统测试在软件开发过程中很常见，主要用来在开发过程中离线评估软件的正确性。生产测试在生产Web服务器上进行，用来评估一个已经部署的软件系统工作是否正常。</p>
</li>
<li><p>单元测试单元测试（unit test）是最小、最简单的软件测试形式。这些测试用来评估某一个独立的软件单元，比如一个类，或者一个函数的正确性。这些测试不考虑包含该软件单元的整体系统的正确性。单元测试同时也是一种规范，用来保证某个函数或者模块完全符合系统对其的行为要求。单元测试经常被用来引入测试驱动开发的概念。集成测试通过独立的单元测试的软件组件被组装成大的系统组件。工程师通过在这个组件中运行一个集成测试（integration test）来检验该组件的功能的正确性。依赖注入（dependency injection），利用类似Dagger[53]这样的工具，我们可以创建出复杂依赖的mock（测试中替代真实逻辑的伪组件），用以方便地测试某个系统组件。一个常见的例子是通过依赖注入来用轻便的mock替换一个有状态的数据库，同时保持一模一样的行为特征。</p>
</li>
<li><p>系统测试系统测试（system test）是一个在未部署的系统上运行的大型测试。某个组件的所有模块（Module）都会被装载到系统中（例如通过集成测试的软件服务器）。接下来工程师可以端到端地测试系统功能。系统测试包括以下几种类型。冒烟测试（smoke test）工程师在冒烟测试中可检测非常简单但是非常重要的系统行为。这是最简单的一种系统测试形式。冒烟测试有时也被称为理性测试，如果该测试不通过，那么其他更昂贵的测试可以不用运行了。性能测试（performance test）一旦冒烟测试通过，系统基本的正确性已经得到了保障。下一步通常是通过某个系统测试的变形来保证整个系统的性能自始至终保持在可接受范围内。因为系统的响应时间和资源要求可能在开发过程中大量改变，该系统必须接受某些测试以确保它不会在没人知道的情况下逐渐变慢（在发布到最终用户之前）。例如，一个程序可能随着改变开始需要32GB内存，而以前只需要8GB。或者该程序的响应时间由10ms变成了50ms，随后变成了100ms。性能测试可以保证随着时间推移系统性能不会下降，或者资源要求不会升高。回归测试（regression test）另外一种系统测试可保证之前的Bug不会重现。回归测试可以被理解为曾经发生过的，导致系统故障或产生错误信息的Bug列表。通过将这些Bug记录为系统测试或者集成测试，重构代码的工程师可以保证他们不会偶然间将他们曾经辛苦调查和修复的Bug又带回来。很重要的是，每个测试都有成本，时间成本和计算资源成本。在一个极限上，单元测试非常便宜，通常可以在毫秒级和很少的资源上（例如一个笔记本电脑上）完成。而在另一个极限上，将一个完整的软件服务器设立起来，同时包括它所有的依赖系统（或者是mock），然后运行相关的测试可能会需要很长时间—几分钟到几小时—一般还需要专属的运算资源。时刻关注这些测试的成本，是软件开发效率提升的重要因素，同时也鼓励程序员更有效地利用我们的测试资源。生产测试生产测试和一个已经部署在生产环境中的业务系统直接交互，而不是运行在密闭的测试环境中。这些测试和黑盒监控在很多地方十分类似（参见第6章），有的时候也被称为黑盒测试。生产测试对运行一个可靠的生产环境来说是必要的。</p>
</li>
</ul>
<h3 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h3><ul>
<li>测试是工程师提高可靠性投入回报比最高的一种手段。</li>
</ul>
<h3 id="个人总结-12"><a href="#个人总结-12" class="headerlink" title="个人总结"></a>个人总结</h3><ul>
<li>测试分类查资料总结</li>
</ul>
<h3 id="基于意图的容量规划"><a href="#基于意图的容量规划" class="headerlink" title="基于意图的容量规划"></a>基于意图的容量规划</h3><ul>
<li>向大型团队推广内部软件工具需要以下几点：● 持续的和完整的推广方案。● 用户的拥护。● 资深工程师和管理层的赞助，因为他们看到了项目的实用潜力。</li>
</ul>
<h3 id="使用DNS进行负载均衡"><a href="#使用DNS进行负载均衡" class="headerlink" title="使用DNS进行负载均衡"></a>使用DNS进行负载均衡</h3><ul>
<li>DNS负载均衡。最简单的方案是在DNS回复中提供多个A记录或者AAAA记录，由客户端任意选择一个IP地址使用</li>
</ul>
<h3 id="负载均衡：虚拟IP"><a href="#负载均衡：虚拟IP" class="headerlink" title="负载均衡：虚拟IP"></a>负载均衡：虚拟IP</h3><ul>
<li>虚拟IP地址（VIP）不是绑定在某一个特定的网络接口上的，它是由很多设备共享的。</li>
</ul>
<h3 id="识别异常任务：流速控制和跛脚鸭任务"><a href="#识别异常任务：流速控制和跛脚鸭任务" class="headerlink" title="识别异常任务：流速控制和跛脚鸭任务"></a>识别异常任务：流速控制和跛脚鸭任务</h3><ul>
<li><p>从一个客户端的视角来看，某个后端任务可能处于下列任一种状态中：健康后端任务初始化成功，正在处理请求。拒绝连接后端任务处于无响应状态。这可能是因为任务正在启动或者停止，或者是因为后端正处于一种异常状态（虽然很少有后端任务在非停止状态下停止监听端口）。</p>
</li>
<li><p>跛脚鸭状态后端任务正在监听端口，并且可以服务请求，但是已经明确要求客户端停止发送请求。</p>
</li>
<li><p>当某个请求进入跛脚鸭状态时，它会将这个状态广播给所有已经连接的客户端。但是那些没有建立连接的客户端呢？</p>
</li>
<li><p>在Google的RPC框架实现中，不活跃的客户端（没有建立TCP连接的客户端）也会定期发送UDP健康检查包。这就使跛脚鸭状态可以相对较快地传递给所有的客户端—通常在一到两个RTT周期内—无论它们处于什么状态下。</p>
</li>
<li><p>允许任务处于这种半正常的跛脚鸭状态的好处就是让无缝停止任务变得更容易，处于停止过程中的任务不会给正在处理的请求返回一个错误值。能够无影响地停止一个活跃的后端任务可以让处理代码推送、设备维护活动，和机器故障问题导致的任务重启变得对用户透明。这个停止过程通常按照以下步骤进行：1.任务编排系统发送一个SIGTERM信号给该任务。2.后端任务进入跛脚鸭状态，同时请求它的所有客户端发送请求给其他后端任务。这通过SIGTERM信号处理程序中调用RPC实现中的API完成。3.任何在后端进入跛脚鸭状态时正在进行的请求（或者在进入状态之后，但是其他客户端收到通知之前）仍会继续进行。4.随着请求回复被发送回客户端，该后端任务的活跃请求逐渐降低为0。5.在配置的时间过后，该后端程序要么自己干净地退出，要么任务编排系统主动杀掉它。该时间应该被设置为一个足够大的值，以便一般的请求可以有足够的时间完成。每个服务的该数值都不同，一般来说取决于客户端的复杂程度，10s到150s是一个不错的选择。这个策略使客户端可以在后端程序进行耗时较长的初始化过程中（这时后端程序还不能服务请求）就建立连接。如果后端程序等到服务可以接受请求的时候才建立链接，就增加了一些不必要的延迟。一旦后端程序可以提供服务了，它就会主动通知所有客户端。</p>
</li>
</ul>
<h3 id="利用划分子集限制连接池大小"><a href="#利用划分子集限制连接池大小" class="headerlink" title="利用划分子集限制连接池大小"></a>利用划分子集限制连接池大小</h3><ul>
<li>利用划分子集限制连接池大小在健康管理之外，负载均衡另外要考虑的一个因素就是子集划分：限制某个客户端任务需要连接的后端任务数量。我们的RPC系统中的每个客户端都会针对后端程序维持一个长连接发送请求。这些连接通常在客户端启动的时候就建立完成，并且保持活跃状态，不停地有请求通过它们，直到客户端终止。另外一个方案是针对每个请求建立和销毁后端连接，这样会带来极大的资源成本和造成延迟问题。在极端情况下，如果某个连接闲置时间非常长，我们的RPC实现可以自动将该连接转为“不活跃”状态，转为UDP模式连接，而非TCP模式。</li>
</ul>
<h3 id="QPS陷阱"><a href="#QPS陷阱" class="headerlink" title="QPS陷阱"></a>QPS陷阱</h3><ul>
<li>Google在多年的经验积累中得出：按照QPS来规划服务容量，或者是按照某种静态属性（认为其能指代处理所消耗的资源：例如某个请求所需要读取的键值数量）一般是错误的选择。就算这个指标在某一个时间段内看起来工作还算良好，早晚也会发生变化。有些变动是逐渐发生的，有些则是非常突然的（例如某个软件的新版本突然使得某些请求消耗的资源大幅减少）。这种不断变动的目标，使得设计和实现良好的负载均衡策略使用起来非常困难。更好的解决方案是直接以可用资源来衡量可用容量。</li>
</ul>
<h3 id="客户端侧的节流机制"><a href="#客户端侧的节流机制" class="headerlink" title="客户端侧的节流机制"></a>客户端侧的节流机制</h3><ul>
<li><p>拒绝一个执行简单内存查询的请求可能跟实际执行该请求消耗内存差不多（因为这里主要的消耗是在应用层协议解析中，结果的产生部分很简单）。就算在某些情况下，拒绝请求可以节省大量资源，发送这些拒绝回复仍然会消耗一定数量的资源。</p>
</li>
<li><p>当某个客户端检测到最近的请求错误中的一大部分都是由于“配额不足”错误导致时，该客户端开始自行限制请求速度，限制它自己生成请求的数量。超过这个请求数量限制的请求直接在本地回复失败，而不会真正发到网络层。</p>
</li>
<li><p>我们使用一种称为自适应节流的技术来实现客户端节流。具体地说，每个客户端记录过去两分钟内的以下信息：请求数量（requests）应用层代码发出的所有请求的数量总计（指运行于自适应节流系统之上的应用代码）。请求接受数量（accepts）后端任务接受的请求数量。</p>
</li>
</ul>
<h3 id="重要性"><a href="#重要性" class="headerlink" title="重要性"></a>重要性</h3><ul>
<li><p>重要性重要性（criticality）是另外一个在全局配额和限制机制中比较有用的信息。某个发往后端的请求都会被标记为以下4类中的一种，这说明了请求的重要性。最重要 CRITICAL_PLUS为最重要的请求预留的类型，拒绝这些请求会造成非常严重的用户可见的问题。重要 CRITICAL生产任务发出的默认请求类型。拒绝这些请求也会造成用户可见的问题，但是可能没有CRITICAL_PLUS那么严重。我们要求服务必须为所有的CRITICAL和CRTICAL_PLUS流量配置相应的资源。可丢弃的SHEDDABLE_PLUS这些流量可以容忍某种程度的不可用性。这是批量任务发出的请求的默认值。这些请求通常可以过几分钟，或者几小时之后重试。可丢弃的SHEDDABLE这些流量可能会经常遇到部分不可用情况，偶尔会完全不可用。</p>
</li>
<li><p>我们同时增强了RPC系统，可以自动传递重要性信息。如果后端接收到请求A，在处理过程中发出了请求B 和C给其他后端，请求B和C会使用与A相同的重要性属性。</p>
</li>
<li><p>在过去一段时间内，Google内部的许多系统都逐渐产生了一种与重要性类似的属性，但是通常不能跨服务兼容。通过标准化和在RPC系统中自动传递，我们现在可以在某些特定节点处统一设置重要性属性。这意味着，我们相信依赖的服务在过载情况下可以按正确的优先级来拒绝请求，不论它们处于整个处理栈中多深的位置。于是我们一般在离浏览器或者客户端最近的地方设置优先级—通常在HTTP前端服务器上。同时，我们可以在特殊情况下在处理栈的某处覆盖优先级设置。</p>
</li>
</ul>
<h3 id="资源利用率信号"><a href="#资源利用率信号" class="headerlink" title="资源利用率信号"></a>资源利用率信号</h3><ul>
<li><p>资源利用率信号我们的任务过载保护是基于资源利用率（utilization）实现的。</p>
</li>
<li><p>在多数情况下，资源利用率仅仅是指目前CPU的消耗程度（目前CPU使用量除以全部预留CPU数量）。但是在某些情况下，同时也会考虑内存的使用率。随着资源利用率的上升，我们开始根据请求的重要性来拒绝一些请求（高重要性的请求对应高阈值）。</p>
</li>
</ul>
<h3 id="处理过载错误"><a href="#处理过载错误" class="headerlink" title="处理过载错误"></a>处理过载错误</h3><ul>
<li>决定何时重试</li>
</ul>
<h3 id="连接造成的负载"><a href="#连接造成的负载" class="headerlink" title="连接造成的负载"></a>连接造成的负载</h3><ul>
<li><p>连接造成的负载连接造成的负载是最后一个值得一提的因素。有时候我们仅仅考虑后端处理接收的请求所造成的负载（这也是用QPS来建模负载的一个问题），然而却忽略了其他因素，比如维护一个大型连接池的CPU和内存成本，或者是连接快速变动的成本。这样的问题在小型系统中可以忽略不计，但是在大型RPC系统中很快就会造成问题。</p>
</li>
<li><p>我们的RPC协议需要不活跃的客户端定期执行健康检查。当某个连接空闲一段可配置的时间后，客户端放弃TCP连接，转为UDP健康检查。不幸的是，这种行为会对大量请求率很低的客户端造成问题：健康检查需要比实际处理请求更多的资源。</p>
</li>
<li><p>通过仔细调节连接参数（如，大幅降低健康检查频率）或者动态创建和销毁连接可以优化这些场景。</p>
</li>
</ul>
<h3 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h3><ul>
<li><p>利用不同的技术手段（确定性算法、加权轮询、客户端侧的节流、用户配额等）更平均地将负载分散到数据中心中。然而这些手段都依赖于在分布式下的状态传递机制。虽然大部分情况下都表现良好，但是在真实情况下，某些应用遇到了一些困难。所以，我们认为保护某个具体任务，防止过载是非常重要的。简单地说：一个后端任务被配置为服务一定程度的流量，不管多少额外流量被指向这个任务，它都应该保证服务质量。</p>
</li>
<li><p>一个常见的错误是认为过载后端应该拒绝和停止接受所有请求。然而，这个假设实际上是与可靠的负载均衡目标相违背的。我们实际上希望客户端可以尽可能地继续接受请求，然后在有可用资源时才处理。某个设计良好的后端程序，基于可靠的负载均衡策略的支持，应该仅仅接受它能处理的请求，而优雅地拒绝其他请求。</p>
</li>
</ul>
<h3 id="个人总结-13"><a href="#个人总结-13" class="headerlink" title="个人总结"></a>个人总结</h3><ul>
<li>RPC框架设计的重要参考 TODO</li>
<li>如何优雅地重试:<a href="https://mp.weixin.qq.com/s/6IkTnUbBlHjM3GM_bT35tA">https://mp.weixin.qq.com/s/6IkTnUbBlHjM3GM_bT35tA</a> 这个实现类似<table>
<thead>
<tr>
<th>策略</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>重试熔断</td>
<td>请求失败 &#x2F; 成功 &gt; 0.1 时停止重试</td>
</tr>
<tr>
<td>链路上传错误标志</td>
<td>下层重试失败后上传错误标志，上层不再重试</td>
</tr>
<tr>
<td>链路下传重试标志</td>
<td>重试请求特殊标记，下层对重试请求不会重试</td>
</tr>
<tr>
<td>DDL</td>
<td>当剩余时间不够时不再发起重试请求</td>
</tr>
<tr>
<td>框架熔断</td>
<td>微服务框架本身熔断、过载保护等机制也会影响重试效果</td>
</tr>
</tbody></table>
</li>
</ul>
<p>	</p>
<hr>
<h2 id="第22章-处理连锁故障"><a href="#第22章-处理连锁故障" class="headerlink" title="第22章 处理连锁故障"></a>第22章 处理连锁故障</h2><ul>
<li><p>如果请求没有成功，以指数型延迟重试。</p>
</li>
<li><p>连锁故障是由于正反馈循环（positive feedback）导致的不断扩大规模的故障。[72]连锁故障可能由于整个系统的一小部分出现故障而引发，进而导致系统其他部分也出现故障。例如，某个服务的一个实例由于过载出现故障，导致其他实例负载升高，从而导致这些实例像多米诺骨牌一样一个一个全部出现故障。</p>
</li>
</ul>
<h3 id="连锁故障产生的原因和如何从设计上避免"><a href="#连锁故障产生的原因和如何从设计上避免" class="headerlink" title="连锁故障产生的原因和如何从设计上避免"></a>连锁故障产生的原因和如何从设计上避免</h3><ul>
<li><p>RPC超时服务器过载时，对客户端RPC的回复会变慢，最终会超过客户端所设置的超时时间。这会导致服务器对请求实际进行的处理都被浪费了，而客户端可能会重试RPC，造成更严重的过载。</p>
</li>
<li><p>CPU缓存效率下降CPU使用得越多，任务被分配到多个CPU核心上的几率越大，从而导致CPU核心本地缓存的失效，进而降低CPU处理的效率。</p>
</li>
<li><p>缓存命中率下降可用内存的减少可能会导致应用层缓存的命中率降低，导致向后端发送更多的RPC，可能会导致后端任务过载。</p>
</li>
<li><p>线程线程不足可能会导致错误或者导致健康检查失败。如果服务器为此增加更多线程，这些线程可能会占用更多内存。在极端情况下，线程不足可能会导致进程ID数不足（Linux的进程ID数是有限的）。文件描述符文件描述符（file descriptor）不足可能会导致无法建立网络连接，进而导致健康检查失败。</p>
</li>
<li><p>假设如下场景：1.某Java前端服务器GC参数没有被调优。2.在高负载（但是在期待范围内）情况下，前端由于GC问题导致CPU不足。3.CPU不足导致请求处理变慢。4.同时处理的请求增多导致内存使用上升。5.内存压力上升，同时由于固定内存分配比例的原因，用于缓存的内存数量减少。6.缓存数量降低意味着缓存中键值数量下降，从而导致命中率下降。7.缓存命中率下降导致更多的请求被发往后端进行处理。8.后端服务器CPU或者线程不足。9.CPU不足导致健康检查失败，从而触发了连锁故障。在上述这个复杂情景下，发生故障时可能没有时间仔细分析因果关系。尤其是在前端和后端由不同团队运维时，判断后端崩溃是由于前端缓存命中率下降可能非常困难。</p>
</li>
<li><p>会自动避免产生错误的软件服务器的负载均衡策略会将这个问题加剧—某几个后端任务产生了错误，会导致负载均衡器不再向它们发送请求，进而使得其余软件服务器的负载上升，从而再次触发滚雪球效应。</p>
</li>
</ul>
<h3 id="防止软件服务器过载"><a href="#防止软件服务器过载" class="headerlink" title="防止软件服务器过载"></a>防止软件服务器过载</h3><ul>
<li><p>防止软件服务器过载下面描述了避免过载的几种策略，大致以优先级排序。使用负载压力测试得出服务器的极限，同时测试过载情况下的失败模式</p>
</li>
<li><p>提供降级结果给用户返回低质量的，但是更容易计算的结果。</p>
</li>
<li><p>在过载情况下主动拒绝请求软件服务器应该保护自己不进入过载崩溃状态。</p>
</li>
</ul>
<h3 id="上层系统应该主动拒绝请求"><a href="#上层系统应该主动拒绝请求" class="headerlink" title="上层系统应该主动拒绝请求"></a>上层系统应该主动拒绝请求</h3><ul>
<li><p>在反向代理层，通过针对请求的某种特性进行数量限制（如IP地址），来缓解和避免拒绝服务攻击，避免攻击性客户端的影响。● 在负载均衡器层，在服务进入全局过载时主动丢弃请求。</p>
</li>
<li><p>进行容量规划好的容量规划可以降低连锁反应发生的可能性。容量规划应该伴随着性能测试进行，以确定可能导致服务失败的负载程度。</p>
</li>
<li><p>进行容量规划只能减少触发连锁反应的可能性，但是并不能完全避免。当一个计划内或者计划外的事件导致大部分集群容量同时下线时，连锁反应是不可避免的。负载均衡问题、网络分区事件，或者突发性流量增长，都会创造意料之外的负载问题。有些系统可以根据需要动态增加容量，这可能防止过载发生，但是适当地进行容量规划还是必要的。</p>
</li>
<li><p>在这个理想化的情景下，只有在请求速率超过单个请求的处理速率时，请求才会进入队列，这种情况会导致线程池和队列的同时饱和。</p>
</li>
<li><p>对一个流量基本稳定的服务来说，队列长度比线程池大小更小会更好（如 50% 或更小）。当服务处理速度无法跟上请求到达速率时，尽早拒绝请求会更好。</p>
</li>
<li><p>流量抛弃和优雅降级流量抛弃（load shedding）是指在软件服务器临近过载时，主动抛弃一定量的负载。</p>
</li>
<li><p>一种简单的流量抛弃实现方式是根据CPU使用量、内存使用量及队列长度等进行节流。</p>
</li>
<li><p>简化了一些细节，[75]但是这里很好地展现了重试是如何摧毁一个系统的。注意临时性的过载升高，或者使用量的缓慢增加都有可能造成这种情况。</p>
</li>
<li><p>一定要使用随机化的、指数型递增的重试周期。</p>
</li>
<li><p>如果重试不是随机分布在重试窗口里的，那么系统出现的一个小故障（某个网络问题）就可能导致重试请求同时出现，这些请求可能会逐渐放大</p>
</li>
<li><p>限制每个请求的重试次数。不要将请求无限重试。● 考虑使用一个全局重试预算。例如，每个进程每分钟只允许重试60次，如果重试预算耗尽，那么直接将这个请求标记为失败，而不真正发送它。这个策略可以在全局范围内限制住重试造成的影响，容量规划失败可能只是会造成某些请求被丢弃，而不会造成全球性的连锁故障。</p>
</li>
<li><p>从多个视角重新审视该服务，决定是否需要在某个级别上进行重试。这里尤其要避免同时在多个级别上重试导致的放大效应：高层的一个请求可能会造成各层重试次数的乘积数量的请求。如果服务器由于过载不能提供服务，后端、前端、JavaScript层各发送3次重试（总计4次请求），那么一个用户的动作可能会造成对数据库的64 次请求（43）。在数据库由于过载返回错误时，这种重试只会加重问题。</p>
</li>
<li><p>使用明确的返回代码，同时详细考虑每个错误模式应该如何处理。例如，将可重试错误和不可重试错误分开。</p>
</li>
<li><p>设置一个截止时间通常是明智的。不设置截止时间，或者设置一个非常长的截止时间通常会导致某些短暂的、已经消失的问题继续消耗服务器资源，直到重启。</p>
</li>
<li><p>截止时间设置得太长可能会导致框架中的高层级部分由于低层级的问题而持续消耗资源。截止时间设置得太短可能会导致某些比较重型的请求持续失败。恰当的截止时间设置，需要在多个限制条件中选择一个平衡点。</p>
</li>
<li><p>截止时间传递与其在发送RPC给后端服务器时自拟一个截止时间，不如让软件服务器采用截止时间传递和取消传递的策略。</p>
</li>
<li><p>可使用截止时间传递机制，截止时间在整个服务栈的高层设置（如，前端服务器）。由初始请求触发的整个RPC树会设置同样的绝对截止时间。</p>
</li>
<li><p>同时，我们可能还会将传递出去的截止时间减少一点（如几百毫秒），以便将网络传输时间和客户端收到回复之后的处理时间考虑在内。</p>
</li>
<li><p>RPC取消的传递可以避免某些泄露情况，如果某个初始RPC设置了一个很长的截止时间，但是底层之间的RPC只有短暂的截止时间，超时失败了。使用简单的截止时间传递可能会导致初始RPC虽然无法继续处理，却继续消耗服务器资源直到超时。</p>
</li>
<li><p>请求延迟的双峰分布（Bimodal）</p>
</li>
<li><p>使用100s的截止时间，5%的请求会消耗5000个线程（50QPS * 100 seconds），但是前端服务器并没有这么多可用线程。忽略副作用，前端也仅能够处理19.6%的请求（1000可用线程 &#x2F;（5000+95）线程工作），这会造成 80.4%的错误率。因此，不仅 5% 的请求受到了影响（那些由于后端问题不可能成功的请求），实际上大部分的请求都受到了影响。</p>
</li>
<li><p>如果无法完成的请求能够尽早返回一个错误而不是等完整个截止时间，我们就可以避免这个问题。例如，如果一个后端服务器不可用，经常立刻返回一个错误值是最好的，而不是等待这个后端服务器变得可用。如果RPC层支持快速失败的选项，一定要启用它。</p>
</li>
<li><p>假设你的后端要处理来自不同客户端的性能和特征各异的请求，我们可以考虑限制一个客户端只能占用25% 的线程总数，以便在某个异常客户端大量产生负载的情况下提供一些公平性。</p>
</li>
</ul>
<h3 id="慢启动和冷缓存"><a href="#慢启动和冷缓存" class="headerlink" title="慢启动和冷缓存"></a>慢启动和冷缓存</h3><ul>
<li><p>慢启动和冷缓存进程在刚刚启动之后通常要比稳定状态下处理请求的速度慢一点。慢的原因可能是由下列一个或多个原因导致：必需的初始化过程在接收到第一个请求后，需要跟后端服务器建立连接。运行时性能优化，尤其是JavaJIT 编译过程，热点优化，以及类延迟加载机制。同样的，有些服务器会在缓存没有充满之前效率很低。</p>
</li>
<li><p>过量配备（overprovision）该服务。区分延迟类缓存和容量类缓存是很重要的：当使用延迟类缓存时，服务器可以在空缓存的情况下仍然处理预期的请求负载，但是使用容量类缓存时，该服务将不能够在空缓存下处理请求负载。</p>
</li>
</ul>
<h3 id="保持调用栈永远向下"><a href="#保持调用栈永远向下" class="headerlink" title="保持调用栈永远向下"></a>保持调用栈永远向下</h3><ul>
<li><p>假设一个用户有一个主后端和一个预先选择好的另外集群中的一个热备后端，主后端在底层出现错误或者延迟上升的情况下将请求代理给热备后端。如果整个系统都处于过载状态，那么从主到副的这种代理可能会增多，会给系统带来更多的负载，因为请求通常要被解析两次，还需要主后端消耗资源等待副后端任务。</p>
</li>
<li><p>在用户的请求路径中最好能够避免使用同层通信—也就是避免通信路径中出现环。</p>
</li>
<li><p>应该由客户端来进行这种通信。例如，如果一个前端需要和后端通信，但是猜错了后端任务，后端不会代理请求给正确的后端，而是通过返回错误使得前端在正确的后端任务上重试它的请求。</p>
</li>
</ul>
<h3 id="连锁故障的触发条件"><a href="#连锁故障的触发条件" class="headerlink" title="连锁故障的触发条件"></a>连锁故障的触发条件</h3><ul>
<li><p>根据请求数量和可用容量来动态调节任务的同时更新数量可能是个好办法。</p>
</li>
<li><p>在发生连锁故障时，检查最近的改变以及回滚通常是明智的，尤其在这些改变会影响容量或者更改请求特点的情况下。</p>
</li>
<li><p>自然增长在很多情况下，连锁故障不是由于某个特定的服务改变导致的，而是由于使用量的天然上升，却没有进行对应的容量调整导致的。</p>
</li>
</ul>
<h3 id="连锁故障的测试"><a href="#连锁故障的测试" class="headerlink" title="连锁故障的测试"></a>连锁故障的测试</h3><ul>
<li>设计良好的组件应该可以拒绝一小部分请求而继续存活。</li>
</ul>
<h3 id="解决连锁故障的立即步骤"><a href="#解决连锁故障的立即步骤" class="headerlink" title="解决连锁故障的立即步骤"></a>解决连锁故障的立即步骤</h3><ul>
<li>莎士比亚搜索服务的连锁故障某个关于莎士比亚作品的纪录片在日本上映了，同时特别指明了莎士比亚搜索服务是进行进一步研究的最佳工具。随着这次广播，亚洲数据中心的流量激增，超过了服务容量。服务容量的问题伴随着当时正在进行的大型更新而变得更严重了。幸运的是，一些安全防护措施帮助缓解了可能的故障。生产环境准备评审（production readiness review）流程指出了一些问题，开发团队已经解决。例如，开发者为服务加入了优雅降级功能。当容量不够时，服务不再返回照片，或者不再返回解释故事发生位置的小地图。取决于RPC的目的，超时的RPC要么不再重试（例如，之前提到的图片），要么采用随机指数型延迟进行重试。即使有这些保护措施的存在，任务还是一个接一个地失败了，然后被Borg系统重启，这导致正常工作的任务数量持续减少。由于这个原因，服务监控页面上的某些图表变成了红色，并且SRE收到了紧急警报。为了解决这个问题，SRE临时向亚洲数据中心增加了一些服务容量，调整了莎士比亚搜索任务的任务数量。通过这种操作，成功恢复了亚洲数据中心的莎士比亚搜索服务。接下来，SRE书写了一篇事后总结，详细说明了触发问题的事件，哪些做得好，哪些可以做得更好，和一系列待办事项来避免这个情景重现。例如，在服务过载的情况下，GSLB负载均衡器可以将一些流量导入邻近的数据中心。同时，SRE团队启用了自动伸缩机制，于是任务的数量可以自动跟着流量增长，这样他们就不用再操心这类问题了。</li>
</ul>
<h3 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h3><ul>
<li>小结当一个系统过载时，某些东西总是要被牺牲掉。一旦一个服务越过了临界点，服务一些用户可见错误，或者低质量结果要比尝试继续服务所有请求要好。理解这些临界点所在，以及超过临界点系统的行为模式，是所有想避免连锁故障的运维人员所必需的。如果不加小心，某些原本为了降低服务背景错误率或者优化稳定状态的改变反而会让服务更容易出现事故。在请求失败的时候重试、负载自动转移、自动杀掉不健康的服务器、增加缓存以提高性能或者降低延迟：这些手段原本都是为了优化正常情况下的服务性能，但是也可能会提高大规模的服务故障的几率。一定要小心评估这些改变，否则灾难就会接踵而至。</li>
</ul>
<hr>
<h2 id="第22章-处理连锁故障-1"><a href="#第22章-处理连锁故障-1" class="headerlink" title="第22章 处理连锁故障"></a>第22章 处理连锁故障</h2><ul>
<li><p>如果请求没有成功，以指数型延迟重试。</p>
</li>
<li><p>连锁故障是由于正反馈循环（positive feedback）导致的不断扩大规模的故障。[72]连锁故障可能由于整个系统的一小部分出现故障而引发，进而导致系统其他部分也出现故障。例如，某个服务的一个实例由于过载出现故障，导致其他实例负载升高，从而导致这些实例像多米诺骨牌一样一个一个全部出现故障。</p>
</li>
</ul>
<h3 id="连锁故障产生的原因和如何从设计上避免-1"><a href="#连锁故障产生的原因和如何从设计上避免-1" class="headerlink" title="连锁故障产生的原因和如何从设计上避免"></a>连锁故障产生的原因和如何从设计上避免</h3><ul>
<li><p>RPC超时服务器过载时，对客户端RPC的回复会变慢，最终会超过客户端所设置的超时时间。这会导致服务器对请求实际进行的处理都被浪费了，而客户端可能会重试RPC，造成更严重的过载。</p>
</li>
<li><p>CPU缓存效率下降CPU使用得越多，任务被分配到多个CPU核心上的几率越大，从而导致CPU核心本地缓存的失效，进而降低CPU处理的效率。</p>
</li>
<li><p>缓存命中率下降可用内存的减少可能会导致应用层缓存的命中率降低，导致向后端发送更多的RPC，可能会导致后端任务过载。</p>
</li>
<li><p>线程线程不足可能会导致错误或者导致健康检查失败。如果服务器为此增加更多线程，这些线程可能会占用更多内存。在极端情况下，线程不足可能会导致进程ID数不足（Linux的进程ID数是有限的）。文件描述符文件描述符（file descriptor）不足可能会导致无法建立网络连接，进而导致健康检查失败。</p>
</li>
<li><p>假设如下场景：1.某Java前端服务器GC参数没有被调优。2.在高负载（但是在期待范围内）情况下，前端由于GC问题导致CPU不足。3.CPU不足导致请求处理变慢。4.同时处理的请求增多导致内存使用上升。5.内存压力上升，同时由于固定内存分配比例的原因，用于缓存的内存数量减少。6.缓存数量降低意味着缓存中键值数量下降，从而导致命中率下降。7.缓存命中率下降导致更多的请求被发往后端进行处理。8.后端服务器CPU或者线程不足。9.CPU不足导致健康检查失败，从而触发了连锁故障。在上述这个复杂情景下，发生故障时可能没有时间仔细分析因果关系。尤其是在前端和后端由不同团队运维时，判断后端崩溃是由于前端缓存命中率下降可能非常困难。</p>
</li>
<li><p>会自动避免产生错误的软件服务器的负载均衡策略会将这个问题加剧—某几个后端任务产生了错误，会导致负载均衡器不再向它们发送请求，进而使得其余软件服务器的负载上升，从而再次触发滚雪球效应。</p>
</li>
</ul>
<h3 id="防止软件服务器过载-1"><a href="#防止软件服务器过载-1" class="headerlink" title="防止软件服务器过载"></a>防止软件服务器过载</h3><ul>
<li><p>防止软件服务器过载下面描述了避免过载的几种策略，大致以优先级排序。使用负载压力测试得出服务器的极限，同时测试过载情况下的失败模式。</p>
</li>
<li><p>提供降级结果给用户返回低质量的，但是更容易计算的结果。</p>
</li>
<li><p>在过载情况下主动拒绝请求软件服务器应该保护自己不进入过载崩溃状态。</p>
</li>
</ul>
<h3 id="上层系统应该主动拒绝请求-1"><a href="#上层系统应该主动拒绝请求-1" class="headerlink" title="上层系统应该主动拒绝请求"></a>上层系统应该主动拒绝请求</h3><ul>
<li><p>在反向代理层，通过针对请求的某种特性进行数量限制（如IP地址），来缓解和避免拒绝服务攻击，避免攻击性客户端的影响。● 在负载均衡器层，在服务进入全局过载时主动丢弃请求。</p>
</li>
<li><p>进行容量规划好的容量规划可以降低连锁反应发生的可能性。容量规划应该伴随着性能测试进行，以确定可能导致服务失败的负载程度。</p>
</li>
<li><p>进行容量规划只能减少触发连锁反应的可能性，但是并不能完全避免。当一个计划内或者计划外的事件导致大部分集群容量同时下线时，连锁反应是不可避免的。负载均衡问题、网络分区事件，或者突发性流量增长，都会创造意料之外的负载问题。有些系统可以根据需要动态增加容量，这可能防止过载发生，但是适当地进行容量规划还是必要的。</p>
</li>
<li><p>在这个理想化的情景下，只有在请求速率超过单个请求的处理速率时，请求才会进入队列，这种情况会导致线程池和队列的同时饱和。</p>
</li>
<li><p>对一个流量基本稳定的服务来说，队列长度比线程池大小更小会更好（如 50% 或更小）。当服务处理速度无法跟上请求到达速率时，尽早拒绝请求会更好。</p>
</li>
<li><p>流量抛弃和优雅降级流量抛弃（load shedding）是指在软件服务器临近过载时，主动抛弃一定量的负载。</p>
</li>
<li><p>一种简单的流量抛弃实现方式是根据CPU使用量、内存使用量及队列长度等进行节流。</p>
</li>
<li><p>简化了一些细节，[75]但是这里很好地展现了重试是如何摧毁一个系统的。注意临时性的过载升高，或者使用量的缓慢增加都有可能造成这种情况。</p>
</li>
<li><p>一定要使用随机化的、指数型递增的重试周期。</p>
</li>
<li><p>如果重试不是随机分布在重试窗口里的，那么系统出现的一个小故障（某个网络问题）就可能导致重试请求同时出现，这些请求可能会逐渐放大</p>
</li>
<li><p>限制每个请求的重试次数。不要将请求无限重试。● 考虑使用一个全局重试预算。例如，每个进程每分钟只允许重试60次，如果重试预算耗尽，那么直接将这个请求标记为失败，而不真正发送它。这个策略可以在全局范围内限制住重试造成的影响，容量规划失败可能只是会造成某些请求被丢弃，而不会造成全球性的连锁故障。</p>
</li>
<li><p>从多个视角重新审视该服务，决定是否需要在某个级别上进行重试。这里尤其要避免同时在多个级别上重试导致的放大效应：高层的一个请求可能会造成各层重试次数的乘积数量的请求。如果服务器由于过载不能提供服务，后端、前端、JavaScript层各发送3次重试（总计4次请求），那么一个用户的动作可能会造成对数据库的64 次请求（43）。在数据库由于过载返回错误时，这种重试只会加重问题。</p>
</li>
<li><p>使用明确的返回代码，同时详细考虑每个错误模式应该如何处理。例如，将可重试错误和不可重试错误分开。</p>
</li>
<li><p>设置一个截止时间通常是明智的。不设置截止时间，或者设置一个非常长的截止时间通常会导致某些短暂的、已经消失的问题继续消耗服务器资源，直到重启。</p>
</li>
<li><p>截止时间设置得太长可能会导致框架中的高层级部分由于低层级的问题而持续消耗资源。截止时间设置得太短可能会导致某些比较重型的请求持续失败。恰当的截止时间设置，需要在多个限制条件中选择一个平衡点。</p>
</li>
<li><p>截止时间传递与其在发送RPC给后端服务器时自拟一个截止时间，不如让软件服务器采用截止时间传递和取消传递的策略。</p>
</li>
<li><p>可使用截止时间传递机制，截止时间在整个服务栈的高层设置（如，前端服务器）。由初始请求触发的整个RPC树会设置同样的绝对截止时间。</p>
</li>
<li><p>同时，我们可能还会将传递出去的截止时间减少一点（如几百毫秒），以便将网络传输时间和客户端收到回复之后的处理时间考虑在内。</p>
</li>
<li><p>RPC取消的传递可以避免某些泄露情况，如果某个初始RPC设置了一个很长的截止时间，但是底层之间的RPC只有短暂的截止时间，超时失败了。使用简单的截止时间传递可能会导致初始RPC虽然无法继续处理，却继续消耗服务器资源直到超时。</p>
</li>
<li><p>请求延迟的双峰分布（Bimodal）</p>
</li>
<li><p>使用100s的截止时间，5%的请求会消耗5000个线程（50QPS * 100 seconds），但是前端服务器并没有这么多可用线程。忽略副作用，前端也仅能够处理19.6%的请求（1000可用线程 &#x2F;（5000+95）线程工作），这会造成 80.4%的错误率。因此，不仅 5% 的请求受到了影响（那些由于后端问题不可能成功的请求），实际上大部分的请求都受到了影响。</p>
</li>
<li><p>如果无法完成的请求能够尽早返回一个错误而不是等完整个截止时间，我们就可以避免这个问题。例如，如果一个后端服务器不可用，经常立刻返回一个错误值是最好的，而不是等待这个后端服务器变得可用。如果RPC层支持快速失败的选项，一定要启用它。</p>
</li>
<li><p>假设你的后端要处理来自不同客户端的性能和特征各异的请求，我们可以考虑限制一个客户端只能占用25% 的线程总数，以便在某个异常客户端大量产生负载的情况下提供一些公平性。</p>
</li>
</ul>
<h3 id="慢启动和冷缓存-1"><a href="#慢启动和冷缓存-1" class="headerlink" title="慢启动和冷缓存"></a>慢启动和冷缓存</h3><ul>
<li><p>慢启动和冷缓存进程在刚刚启动之后通常要比稳定状态下处理请求的速度慢一点。慢的原因可能是由下列一个或多个原因导致：必需的初始化过程在接收到第一个请求后，需要跟后端服务器建立连接。运行时性能优化，尤其是JavaJIT 编译过程，热点优化，以及类延迟加载机制。同样的，有些服务器会在缓存没有充满之前效率很低。</p>
</li>
<li><p>过量配备（overprovision）该服务。区分延迟类缓存和容量类缓存是很重要的：当使用延迟类缓存时，服务器可以在空缓存的情况下仍然处理预期的请求负载，但是使用容量类缓存时，该服务将不能够在空缓存下处理请求负载。</p>
</li>
</ul>
<h3 id="保持调用栈永远向下-1"><a href="#保持调用栈永远向下-1" class="headerlink" title="保持调用栈永远向下"></a>保持调用栈永远向下</h3><ul>
<li><p>假设一个用户有一个主后端和一个预先选择好的另外集群中的一个热备后端，主后端在底层出现错误或者延迟上升的情况下将请求代理给热备后端。如果整个系统都处于过载状态，那么从主到副的这种代理可能会增多，会给系统带来更多的负载，因为请求通常要被解析两次，还需要主后端消耗资源等待副后端任务。</p>
</li>
<li><p>在用户的请求路径中最好能够避免使用同层通信—也就是避免通信路径中出现环。</p>
</li>
<li><p>应该由客户端来进行这种通信。例如，如果一个前端需要和后端通信，但是猜错了后端任务，后端不会代理请求给正确的后端，而是通过返回错误使得前端在正确的后端任务上重试它的请求。</p>
</li>
</ul>
<h3 id="连锁故障的触发条件-1"><a href="#连锁故障的触发条件-1" class="headerlink" title="连锁故障的触发条件"></a>连锁故障的触发条件</h3><ul>
<li><p>根据请求数量和可用容量来动态调节任务的同时更新数量可能是个好办法。</p>
</li>
<li><p>在发生连锁故障时，检查最近的改变以及回滚通常是明智的，尤其在这些改变会影响容量或者更改请求特点的情况下。</p>
</li>
<li><p>自然增长在很多情况下，连锁故障不是由于某个特定的服务改变导致的，而是由于使用量的天然上升，却没有进行对应的容量调整导致的。</p>
</li>
</ul>
<h3 id="连锁故障的测试-1"><a href="#连锁故障的测试-1" class="headerlink" title="连锁故障的测试"></a>连锁故障的测试</h3><ul>
<li>设计良好的组件应该可以拒绝一小部分请求而继续存活。</li>
</ul>
<h3 id="小结-6"><a href="#小结-6" class="headerlink" title="小结"></a>小结</h3><ul>
<li>小结当一个系统过载时，某些东西总是要被牺牲掉。一旦一个服务越过了临界点，服务一些用户可见错误，或者低质量结果要比尝试继续服务所有请求要好。理解这些临界点所在，以及超过临界点系统的行为模式，是所有想避免连锁故障的运维人员所必需的。如果不加小心，某些原本为了降低服务背景错误率或者优化稳定状态的改变反而会让服务更容易出现事故。在请求失败的时候重试、负载自动转移、自动杀掉不健康的服务器、增加缓存以提高性能或者降低延迟：这些手段原本都是为了优化正常情况下的服务性能，但是也可能会提高大规模的服务故障的几率。一定要小心评估这些改变，否则灾难就会接踵而至。</li>
</ul>
<h3 id="个人总结-14"><a href="#个人总结-14" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>使用负载压力测试得出服务器的极限以及过载降级策略</li>
<li>一定要使用随机化的、指数型递增的重试周期。</li>
<li>使用明确的返回代码，同时详细考虑每个错误模式应该如何处理。例如，将可重试错误和不可重试错误分开。</li>
<li>设置一个截止时间通常是明智的。RPC之间传递。</li>
<li>限制一个客户端对线程总数占有比例，以便在某个异常客户端大量产生负载的情况下提供一些公平性。</li>
<li>慢启动和冷缓存；区分延迟类缓存和容量类缓存。</li>
<li>保持调用栈永远向下（减少转发次数和后端资源消耗）。</li>
<li>设计良好的组件应该可以拒绝一小部分请求而继续存活。</li>
</ol>
<hr>
<h2 id="第23章-管理关键状态：利用分布式共识来提高可靠性"><a href="#第23章-管理关键状态：利用分布式共识来提高可靠性" class="headerlink" title="第23章 管理关键状态：利用分布式共识来提高可靠性"></a>第23章 管理关键状态：利用分布式共识来提高可靠性</h2><ul>
<li><p>在构建可靠的、高可用的系统过程时，我们发现分布式共识系统适合用来维护某个强一致的系统状态</p>
</li>
<li><p>当你需要实现领头人选举（leader election）、关键性共享状态或分布式锁等时，我们建议采用某种正式证明过的、详尽测试过的分布式共识系统来实现。如果不严肃对待这个问题很有可能会导致事故，在更糟的情况下，将造成某种非常难以修复的数据一致性问题，这可能会大大加长系统事故的处理时间。</p>
</li>
<li><p>网络分区问题迟早会发生（光缆被切断，数据包由于拥塞造成丢失或延迟升高，硬件故障，网络组件配置错误等），理解如何构建分布式共识实际上就是理解某个服务应用如何实现强一致性和高可用。由于商业的压力，很多服务都需要很高的可用性，这些应用程序通常都需要对数据访问的强一致性。</p>
</li>
<li><p>最终一致可能会带来意想不到的问题（参见文献[Lu15]），尤其是当时钟漂移（在分布式系统中，这是不可避免的），或者网络分区（参见文献[Kin15]）发生的时候。</p>
</li>
<li><p>Jeff Shute（参见文献[Shu13]）曾经说过，“我们发现开发者通常花费了大量的时间构建一个极为复杂和容易出错的机制来应对最终一致性下可能过时的数据。我们认为对开发者来说这是一种无法接受的负担，数据一致性的问题应该在数据库层解决。”</p>
</li>
</ul>
<h3 id="使用共识系统的动力：分布式系统协调失败"><a href="#使用共识系统的动力：分布式系统协调失败" class="headerlink" title="使用共识系统的动力：分布式系统协调失败"></a>使用共识系统的动力：分布式系统协调失败</h3><ul>
<li><p>在网络分区情况下—造成问题不一定是由完全分区导致的，而是：● 网络非常慢。● 某些消息可以通过，但是某些消息被丢弃了。● 单方面的节流措施。</p>
</li>
<li><p>如果网络质量真的很差，分布式共识系统也无法正确选举出主实例时，作为工程师可能也没有什么好办法来做出正确决策。</p>
</li>
</ul>
<h3 id="分布式共识是如何工作的"><a href="#分布式共识是如何工作的" class="headerlink" title="分布式共识是如何工作的"></a>分布式共识是如何工作的</h3><ul>
<li><p>拜占庭式问题指的是当某个进程由于程序Bug或者恶意行为发送不正确的消息的问题，这种问题相对来说处理成本更高，同时也更少见。</p>
</li>
<li><p>严格来讲，在有限时间内解决异步式分布式共识问题是不可能的。正如Dijkstra 的获奖文章—FLP impossibility result（参见文献[Fis85]）写的那样，在不稳定的网络条件下，没有任何一种异步式分布式共识算法可以保证一定能够达成共识。在实际操作中，我们通过保证给系统提供足够的健康的副本，以及良好的网络连接状态来保障分布式共识算法在大多数情况下是可以在有限时间内达成共识的。同时整个系统还需要加入随机指数型延迟。</p>
</li>
<li><p>这样，我们可以保障重试不会造成连锁反应，以及本章后面会提到的角斗士（dueling proposers）问题。</p>
</li>
<li><p>这个协议在一个有利环境下能够保障安全性，同时提供足够的冗余度。</p>
</li>
<li><p>最初的分布式共识问题的解决方案是Lamport的Paxos 协议（参见文献[Lam98]），但是也有其他的协议能够解决这个问题，包括 Raft（参见文献[Ong14]）、Zab（参见文献[Jun11]），以及 Mencius（参见文献[Mao08]）。Paxos本身也有很多变种尝试提升性能（参见文献[Zoo14]）。这些变种常常只是在某一个小细节上不同，例如给某个进程一个特殊的领头人角色以简化协议实现等。</p>
</li>
</ul>
<h3 id="分布式共识的系统架构模式"><a href="#分布式共识的系统架构模式" class="headerlink" title="分布式共识的系统架构模式"></a>分布式共识的系统架构模式</h3><ul>
<li><p>可靠的复制状态机一个复制状态机（replicated state machine,RSM）是一个能在多个进程中用同样顺序执行同样的一组操作的系统。RSM 是一个有用的分布式系统基础组件，可以用来构建数据和配置存储，执行锁机制和领头人选举（接下来会详细描述）。</p>
</li>
<li><p>在RSM系统上进行的操作是通过共识算法来全局排序的。</p>
</li>
<li><p>时间戳在分布式系统中问题非常大，因为在多个物理机器上保证时间同步是不可能的。Spanner（参见文献[Cor12]）通过针对最差情况下的不确定性建模，同时在必要时减慢处理速度来解决这个问题。</p>
</li>
<li><p>分布式系统的领头人选举是跟分布式共识等价的问题。复制多份服务并使用一个唯一的领头人（leader）来进行某种类型的工作是很常见的设计。唯一的领头人是一种保证粗粒度互斥性的方法。</p>
</li>
</ul>
<h3 id="分布式共识系统的性能问题"><a href="#分布式共识系统的性能问题" class="headerlink" title="分布式共识系统的性能问题"></a>分布式共识系统的性能问题</h3><ul>
<li><p>世界上并没有某个性能“最优”的分布式共识和状态机复制算法，因为算法性能通常取决于与系统负载有关的多个因子，以及系统性能的目标和系统的部署情况。</p>
</li>
<li><p>复合式Paxos：消息流过程详解复合式Paxos（Multi-Paxos）协议采用了一个强势领头人（strong leader）进程的概念：除非目前没有选举出任何的领头人进程，或者发生了某种错误，在正常情况下，提议者只需要对满足法定人数的进程发送一次消息就可以保障系统达成共识。这种强势领头人在很多共识协议中都适用，在系统需要传递大量消息的时候非常合适。</p>
</li>
<li><p>很多共识系统使用TCP&#x2F;IP作为通信协议。TCP&#x2F;IP是面向连接的，同时针对消息的先进先出（FIFO）顺序提供了强保障。但是在发送任何数据之前，都需要先建立新的TCP&#x2F;IP连接，也就是一次网络往返需要进行三次握手协议。TCP&#x2F;IP慢启动机制也限制了连接的初始带宽。常见的TCP&#x2F;IP窗口大小在4～15KB之间。</p>
</li>
<li><p>TCP&#x2F;IP的慢启动问题对共识组中的进程来说可能不是问题：因为这些进程会互相建立一个连接而且保持这些连接，因为通信将会很频繁。但是，对拥有非常多的客户端的系统来说，可能不能做到让每个客户端都和共识组所有进程都保持一个活动连接。因为TCP&#x2F;IP需要消耗一定资源，包括文件描述符，以及对应的KeepAlive数据流量。对高度分片、拥有几千个副本的数据存储系统，以及更大规模的客户端来说，这种成本是无法接受的。一个解决方案是使用地域性的代理池，如图23-9所示。该代理池的进程与共识组建立持久的TCP&#x2F;IP进程，以降低客户端的开销。同时代理池也是包装分片逻辑和负载均衡逻辑，以及共识系统的服务发现逻辑的好地方。</p>
</li>
<li><p>快速Paxos协议：性能优化快速Paxos协议（Fast Paxos，参见文献[Lam06]）是Paxos协议的一个变种，意在优化Paxos算法在广域网络中的性能。使用该协议的每个客户端可以直接向组内的接收者们发送Propose消息，而不需要像经典Paxos和复合Paxos那样通过一个领头人进程发送。</p>
</li>
<li><p>稳定的领头人机制上文已经描述过，复合Paxos是如何通过选举一个稳定的领头人进程来提高性能的。Zab（参见文献[Jun11]）和Raft（参见文献[Ong14]）协议是其他两个例子，它们也通过选举稳定的领头人进程来提高性能。这种方案可以进一步进行读操作优化，因为领头人始终拥有最新信息，但是也存在以下几个问题：● 所有的改变状态的操作都必须经由该领头人，这个要求使得距离领头人进程较远的客户端必须要增加额外的网络延迟。● 领头人进程的外发网络带宽是系统性能的瓶颈（参见文献[Mao08]），因为该领头人的Accept消息包含了每个提议的所有数据，而其他进程发送的消息仅仅包含了交易数字，而没有真正的数据。● 如果领头人进程恰好处于一台有性能问题的机器上，整个系统的吞吐量都会受到影响。几乎在所有关注性能的分布式共识系统设计中，都采用了单个稳定领头人进程机制，或者是某种领头人轮换机制—预先分配给每个副本一个独立的分布式算法编号（通常是对交易编号取模）。使用轮换机制的算法包括Mencius（参见文献[Mao08]）和Egalitarian Paxos（参见文献[Mor12a0]）。</p>
</li>
<li><p>复合Paxos的信息流的过程在本章前面“复合式Paxos：消息流过程详解”一节中描述过了，但是并没有展示在什么情况下协议要求必须在磁盘中记录状态改变。在进程做任何一个承诺之前都必须进行磁盘写操作。在复合Paxos性能的关键点—协议的第二部分中，这些操作点处于接收者针对某个提议发送Accepted消息之前，以及提议者发送Accept消息之前—因为这条Accept消息其实是一个隐含的Accepted消息</p>
</li>
<li><p>这就意味着在单个共识操作的延迟中，有以下几个操作：● 提议者的一次硬盘写入操作。● 并行消息发送给接收者。● 每个接收者的磁盘写操作（并行）。● 回复消息的传递。</p>
</li>
<li><p>分布式共识算法经常用来实现一个复制状态机。RSM需要保留一份交易日志，以便用于灾难恢复（正如其他数据存储那样）。共识算法的日志可以和RSM的交易日志合为一个。将这两个日志合并可以避免不停地向磁盘上的两个不同位置交替写入（参见文献[Bol11]），也就降低了磁盘寻址操作消耗的时间。这些磁盘于是可以每秒处理更多操作，该系统也可以每秒处理更多操作。</p>
</li>
<li><p>在数据存储系统中，磁盘在维护日志之外还有其他用处：数据通常也是存放于磁盘中的。日志的写操作必须直接刷写到硬盘，但是数据的改变通常可以写入内存缓存中，稍后再写入磁盘，可以进行重新排序以便更有效地写入（参见文献[Bol11]）。</p>
</li>
</ul>
<h3 id="分布式共识系统的部署"><a href="#分布式共识系统的部署" class="headerlink" title="分布式共识系统的部署"></a>分布式共识系统的部署</h3><ul>
<li><p>系统设计者部署共识系统时，最重要的决策在于选择副本的数量和对应的部署位置。</p>
</li>
<li><p>副本的数量一般来说，共识系统都要采用“大多数”的法定过程。也就是说，一组2f+1副本组成的共识组可以同时承受f个副本失败而继续运行（如果需要容忍拜占庭式失败，也就是要能够承受副本返回错误结果的情况，则需要3f+1个副本来承受f个副本失败（参看文献[Cas99]））。针对非拜占庭式失败的情况，最小的副本数量是3—如果仅仅部署两个副本，则不能承受任何一个副本失败）。3个副本可以承受1个副本失败。大部分系统的不可用时间都是由计划内维护造成的</p>
</li>
<li><p>3个副本使该系统可以在1个副本维护时继续工作（这里假设其余两个副本可以承受系统负载）。如果某个非计划内的失败情况在常规维护时发生了，那么共识系统就会不可用。而共识系统的不可用通常是不可接受的，于是在这种情况下，我们需要5个副本同时运行，于是可以允许系统在两个副本不可用的情况下继续运行。如果5个副本中有4个能正常运行，则不需要进行任何人工干预操作，但是如果仅仅只有3个能正常运行，那么我们需要立刻增加一个或者两个额外的副本。</p>
</li>
<li><p>如果共识系统中大部分的副本已经无法访问，以至于无法完成一次法定进程，那么该系统理论上来说已经进入了一个无法恢复的状态。因为至少有一个副本的持久化日志无法访问。在这个状态下，有可能某个操作仅仅只在无法访问的副本上执行了。这时，系统管理员可以强行改变小组成员列表，将新的副本添加到小组中，使用其他可用成员的信息来填充。但是数据丢失的可能性永远存在—这种情况应该全力避免。在灾难处理过程中，系统管理员需要决定是否需要进行这种强制性的重新配置，或者仅仅是等待那些机器恢复可用。当决策做出后，对系统日志的处理（以及对应的监控）就变得非常重要。</p>
</li>
<li><p>针对任何系统的副本数量的考虑都是基于以下几个因素中的一个进行妥协：● 对可靠性的要求● 计划内维护操作的频率● 危险性● 性能● 成本最后的决策每个系统都会不同：每个系统都有不同的可用性服务水平目标；某些组织会更频繁地进行维护性操作；而某些组织使用的硬件成本、质量和可靠性都有所不同。</p>
</li>
<li><p>一个故障域（failure domain）是指系统中可能由于一个故障而同时不可用的一组组件。常见的故障域包括：● 物理机器。● 数据中心中用同一个供电设施的一个机柜。● 数据中心中的数个机柜，使用同一个网络设备连接。● 受单个光纤影响的一个数据中心。● 处于同一个地理区域的一组数据中心，可能被同一个自然灾害所影响。</p>
</li>
<li><p>一般来说，随着副本之间的距离增加，副本之间的网络往返时间也会增加，但是系统能够承受的失败程度也会增加。对多数共识系统来说，网络往返时间的增加会导致操作延迟的增加。</p>
</li>
<li><p>对延迟的敏感性和对灾难的承受程度，每个系统很不一样。在某些共识系统架构下并不需要特别高的吞吐量，或者特别低的延迟：例如，某个共识系统如果只是为了提供成员信息和领头人选举，服务一般不会负载很高，如果共识操作时间仅仅是领头人租约的一小部分时，性能并不是关键点。批处理居多的系统也很少会被延迟所影响：可以通过批处理数量的增加来提高吞吐量。</p>
</li>
<li><p>当处理关键数据时，即使已经有了可靠的共识系统部署在不同的故障域范围内，我们也必须经常将数据备份在其他地方。因为有两个故障域是我们永远无法逃避的：软件本身和系统管理员的人为错误。软件系统中的Bug可能会在罕见情况下浮现造成数据丢失，而错误的系统配置也可能会造成类似情况。而人工操作可能会执行错误的命令，从而造成数据损坏。</p>
</li>
<li><p>当决定副本位置的时候，记得最关键的因素是客户端可见性能：理想情况下，客户端和共识系统之间的RTT应该是最小化的。在广域网络中，无领头人的协议，例如 Mencius和 Egalitarian Paxos可能有一定的性能优势，尤其是当应用程序设计为可以对任意副本进行读操作而不需要进行共识操作时。</p>
</li>
<li><p>向一个采取“大多数”法定仲裁过程系统中增加新的副本可能会降低系统的可用性，如图23-10所示。对ZooKeeper和Chubby来说，一个常见的部署使用5个副本，一个法定仲裁过程需要3个副本参与。整个系统可以在两个副本，也就是40% 不可用的情况下仍然正常工作。当使用6个副本时，仲裁过程需要4个副本：也就是超过33% 的副本不可用就会导致系统无法工作。</p>
</li>
<li><p>为了将系统流量分布得更为均匀，系统设计者可以考虑采用5个副本，将其中2个副本放置于美国中心地带，1个放置于东海岸，另外两个放置于欧洲。这样分布可基本保证共识过程在北美洲的副本上完成，而不需要等待欧洲的回复。而从欧洲起始的共识过程可以仅仅跟美国东海岸的副本完成。东海岸的副本就像两个可能的仲裁组的关键轴，将两个组连接在了一起。</p>
</li>
</ul>
<h3 id="个人总结-15"><a href="#个人总结-15" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>复合式Paxos、快速Paxos协议</li>
<li>一个常见的部署使用5个副本，一个法定仲裁过程需要3个副本参与。</li>
<li>分布式共识协议学习参考 TODO</li>
</ol>
<hr>
<h3 id="数据完整性的强需求"><a href="#数据完整性的强需求" class="headerlink" title="数据完整性的强需求"></a>数据完整性的强需求</h3><ul>
<li><p>数据完整性意味着用户可以维持对云服务的访问，用户对数据的访问能力是最重要的，所以这种访问能力的完整性非常重要。</p>
</li>
<li><p>大多数云计算应用都是优化以下5项的某种组合：在线时间、延迟、规模、创新速度和隐私。</p>
</li>
<li><p>为了避免应用程序的数据出现问题，影响到最终用户，一个带外系统、专门负责检查和平衡各种数据存储的系统就很有必要了。</p>
</li>
<li><p>一般来说，公司会采用某种备份策略来“预防”数据丢失。然而，真正应该被关注的重点其实是数据恢复，这是区分备份与存档的重要区别。就像一句流行语说的那样：没有人真的想要备份数据，他们只想恢复数据。</p>
</li>
<li><p>备份与存档最重要的区别就是，备份是可以直接被应用程序重新加载的。因此备份和存档的使用场景非常不同。</p>
</li>
<li><p>存档的目的是将数据长时间安全保存，以满足审核、取证和合规要求。在这些情况下的数据恢复通常不需要满足服务的在线率要求。例如，我们可能需要将财务交易数据保存七年时间。为了达到这个目标，我们可以每个月将累积的审核日志迁移到离线的、异地的长期存档存储系统上。读取和恢复这样的信息可能需要一周时间，在长达一个月的财务审核过程中，这是可以接受的。相对存档，当灾难来临的时候，数据必须从真实的备份中快速恢复，最好能维持服务在线率的要求。否则的话，受影响的用户将由于数据问题无法使用应用程序，直到数据恢复过程完成。</p>
</li>
<li><p>尤其考虑到大多数最新产生的数据直到安全备份结束之前都存在丢失的风险，这就意味着备份（而不是存档）应该至少每天进行一次，或者每小时，甚至更短时间内进行一次。备份应该同时使用完整备份、增量备份，或者甚至是流式持续备份手段。因此，当选择备份策略时，一定要考虑针对某个问题需要的恢复时间，以及可以丢失多少最新数据。</p>
</li>
</ul>
<h3 id="保障数据完整性和可用性：Google-SRE的目标"><a href="#保障数据完整性和可用性：Google-SRE的目标" class="headerlink" title="保障数据完整性和可用性：Google SRE的目标"></a>保障数据完整性和可用性：Google SRE的目标</h3><ul>
<li><p>数据完整性是手段，数据可用性是目标数据完整性指的是在其生命周期中，数据的准确性和一致性。从数据被记录的那一刻开始，一直到数据被访问的时候，数据应该保持正确，不会以某种未预知的方式改变。</p>
</li>
<li><p>从用户的角度来看，仅仅保障数据完整性，而没有保障数据的可用性是没有意义的。</p>
</li>
<li><p>交付一个恢复系统，而非备份系统针对系统进行备份是一个长期被忽视、被拖延的系统管理任务。任何人都不会将备份作为一个高优先级任务进行—备份需要长期消耗时间和资源，却不能带来任何现在可见的好处。由于这个原因，在备份策略具体实施中如果出现了某些被忽视的细节问题，大家一般都能理解。甚至有的人说，就像其他针对低可能性的危险的保护措施那样，这样的态度是必然发生的。这里的核心问题其实是，我们没有意识到备份措施防护的问题虽然是不太可能发生的，但却是会造成严重问题的。当该服务的数据不可用时，备份系统对整个服务、整个产品，甚至整个公司来说，都是生死攸关的。</p>
</li>
<li><p>相对于关注没人愿意做的备份任务来说，我们应该通过关注更重要的（但并不是更简单的）恢复任务来鼓励用户进行备份。备份其实就像纳税一样，是一个服务需要持久付出的代价，来保障其数据的可用性。我们不应该强调应该纳多少税，而是应该强调这些税会用来提供什么服务：数据可用性的保障。因此，我们不会强迫团队进行“备份”，而是要求：● 各团队需要为不同的失败场景定义一系列数据可用性SLO。● 各团队需要定期进行演练，以确保他们有能力满足这些SLO。</p>
</li>
</ul>
<h3 id="造成数据丢失的事故类型"><a href="#造成数据丢失的事故类型" class="headerlink" title="造成数据丢失的事故类型"></a>造成数据丢失的事故类型</h3><ul>
<li><p>根源问题某种无法恢复的用户数据丢失是由以下几个因素造成的：用户行为、管理员的错误、应用程序的Bug、基础设施中的问题、硬件故障和部署区的大型事故。</p>
</li>
<li><p>Google根据一次针对19次数据恢复过程的研究得出，最常见的用户可见数据丢失场景是由于数据删除和软件Bug造成的引用完整性问题。</p>
</li>
<li><p>在设计数据完整性保障机制时，必须要认识到复制机制和冗余并不意味着可恢复性。</p>
</li>
</ul>
<h3 id="扩展性问题：全量、增量以及相互竞争的备份和恢复机制"><a href="#扩展性问题：全量、增量以及相互竞争的备份和恢复机制" class="headerlink" title="扩展性问题：全量、增量以及相互竞争的备份和恢复机制"></a>扩展性问题：全量、增量以及相互竞争的备份和恢复机制</h3><ul>
<li>当别人问你“是否有备份”的时候，一个经典的错误回答是“我们有比备份更好的机制—复制机制！”复制机制很重要，包括提高数据的本地性（locality），保护某个部署点单点事故等。但是有很多数据丢失场景是复制机制无法保护的。一个自动同步多个副本的数据存储多半会在你发现问题之前，将损坏的数据记录以及错误的删除动作更新到多个副本上。</li>
</ul>
<h3 id="Google-SRE保障数据完整性的手段"><a href="#Google-SRE保障数据完整性的手段" class="headerlink" title="Google SRE保障数据完整性的手段"></a>Google SRE保障数据完整性的手段</h3><ul>
<li><p>24种数据完整性的事故组合</p>
</li>
<li><p>由于数据丢失类型很多（如上文所述），没有任何一种银弹可以同时保护所有事故类型，我们需要分级进行。分级防护会引入多个层级，随着层级增加，所保护的数据丢失场景也更为罕见。</p>
</li>
<li><p>软删除机制可以大幅度减少支持人员的压力。软删除意味着被删除的数据立刻被标记为已删除，这样除了管理后台代码之外其他代码不可见。</p>
</li>
<li><p>软删除还意味着一旦数据被标记为已删除，在某段时间以后会真的被删除。这个时间的长度，尤其是在有很多短期数据的情况下，取决于某个组织的政策和相关的法律条文、可用的存储空间和存储成本，以及产品的价格和市场定位等。常见的软删除时间是15、30、45或者60天。在Google的经验中，大部分账号劫持和数据完整性问题都会在60天内汇报或者检测到。因此，为软删除保存超过60天的需求可能没有那么强烈。</p>
</li>
<li><p>应用中实现一个回收站机制，作为用户错误的主要防护手段。</p>
</li>
<li><p>就算不考虑成本问题，频繁地进行全量备份也是非常昂贵的。最主要的是，这会给线上服务用户的数据存储造成很大的计算压力，以至于影响服务的扩展性和性能。为了缓解这种压力，我们需要在非峰值时间段进行全量备份，同时在繁忙时间段进行增量备份。</p>
</li>
<li><p>没有任何办法可以100% 确定数据是正确的：虽然我们相信存储系统的实现，但是还是要校验！使这个问题变得更复杂的是，为了从低级数据损坏或者删除场景中恢复数据，我们必须从不同恢复点的不同备份中恢复不同子集的数据。同时，我们还要考虑到在一个不断变化的环境中，代码和数据结构的变化对老的备份数据的影响。</p>
</li>
<li><p>安排一些开发者来开发一套数据校验流水线可能会在短期内降低业务功能开发的速度。然而，在数据校验方面投入的工程资源可以在更长时间内保障其他业务开发可以进行得更快。因为工程师们可以放心数据损坏的Bug没那么容易流入生产环境。和在项目早期引入单元测试效果类似，数据校验流水线可以在整个软件开发过程中起到加速作用。</p>
</li>
<li><p>举一个具体的例子：Gmail拥有一系列数据校验器，每一个校验器都曾经在生产环境中检测到真实的数据完整性问题。Gmail开发者由于知道每个新引入的数据一致性问题都可以在24小时之内被检测到而感到非常安心。这些数据校验器的存在，结合单元测试及回归测试的文化使得Gmail开发者有足够的勇气每周多次修改Gmail生产存储系统的实现。</p>
</li>
<li><p>带外数据校验比较难以正确实现。当校验规则太严格的时候，一个简单的合理的修改就会触发校验逻辑而失败。这样一来，工程师就会抛弃数据校验逻辑。如果规则不够严格，那么就可能漏过一些用户可见的数据问题。为了在两者之间取得恰当的平衡，我们应该仅仅校验那些对用户来说具有毁灭性的数据问题。</p>
</li>
<li><p>大规模部署带外检测器可能成本较高。Gmail计算资源的很大一部分都被用来支持每日数据检测的运行。使这个问题变得更严重的是，校验器本身可能会造成软件服务器缓存命中率的下降，这就会造成用户可见响应速度的下降。为了避免这种问题，Gmail提供了一系列针对校验器的限速机制，同时定期重构这些校验器，以降低磁盘压力。</p>
</li>
<li><p>我们可以保证每天运行的校验器持续寻找毁灭性的问题，而其他更严格的校验器可以以更低频率运行，以便满足延迟和成本的要求。</p>
</li>
<li><p>大部分高速进行的小型开发团队都负担不起设计、构建和维护这样的系统所需的资源。就算强迫他们进行，最后的结果也经常是不可靠、不全面的，以及浪费性、一次性的方案，很快就会被抛弃。因此，最好的办法是单独组织一个中央基础设施组为多个产品和工作组提供一套数据校验框架。该基础设施组负责维护带外数据校验框架，而产品开发组负责维护对应的业务逻辑，以便和他们不断发展的产品保持一致。</p>
</li>
<li><p>数据恢复流程中任何一个环节都有可能出问题，只有建立一个完善的端到端测试才能让人晚上放心睡觉。即使最近刚刚成功进行过一次数据恢复，下次执行时某些步骤仍然可能出问题。</p>
</li>
<li><p>只有真正进行恢复操作之后，才能确定到底能否恢复最新数据。</p>
</li>
<li><p>失败是不可避免的，不去主动寻找这些数据恢复失败的场景等于玩火自焚。只有通过进行测试来主动寻找这些弱点，才能够提前修复，关键时刻才不至于追悔莫及！</p>
</li>
</ul>
<h3 id="SRE的基本理念在数据完整性上的应用"><a href="#SRE的基本理念在数据完整性上的应用" class="headerlink" title="SRE的基本理念在数据完整性上的应用"></a>SRE的基本理念在数据完整性上的应用</h3><ul>
<li>信任但要验证我们依赖的任何API都不可能一直完美工作。不管测试有多么复杂，工程质量有多么高，API都一定会存在某些问题。应该通过使用带外数据检测器来检查数据最关键、最核心的部分，哪怕API语义中说明了这些问题不存在。要记住，完美的理论不代表实现也是完美的。</li>
</ul>
<h3 id="个人总结-16"><a href="#个人总结-16" class="headerlink" title="个人总结"></a>个人总结</h3><ul>
<li>备份与存档最重要的区别就是，备份是可以直接被应用程序重新加载的。</li>
<li>通过使用带外数据检测器来检查数据最关键、最核心的部分。</li>
</ul>
<hr>
<h3 id="不完美的机器"><a href="#不完美的机器" class="headerlink" title="不完美的机器"></a>不完美的机器</h3><ul>
<li><p>不完美的机器从某种意义上讲，人类可以被称为不完美的机器。人会感觉无聊，人的处理器（指思维方式）工作原理不清楚，用户界面（指沟通方式）也不太友好，效率也不高。在工作安排中，能够认识到人的这些缺陷，取长补短是最好的。</p>
</li>
<li><p>分心指数工程师能够被分心的方法太多了。例如，某个名字是Fred的SRE 星期一正常上班，他今天不是on-call，也不负责处理中断性事务。很明显，他希望能够进行他自己的项目工作。倒一杯咖啡，带上“不要打扰”的耳机，开始干活，一切正常，对吗？但是，下列任何一件事情都可能随时发生：● Fred的团队使用随机工单分配系统，某个需要今天处理的工单被分配给了他。● Fred的同事目前负责on-call，收到了一个紧急警报。发出警报的组件Fred最熟悉，所以这个同事过来咨询意见。● 某个用户将某个工单的优先级提高了，这个工单是上周Fred轮值on-call的时候就在处理的。● 某个已经持续了三四周的发布到Fred的时候突然出现了问题，Fred需要停下手中的事情检查发布的状态，回滚这个发布等。● 某个用户过来咨询一个问题，因为Fred为人和善。● 等等。最后结果是</p>
</li>
<li><p>虽然Fred有一整天的时间分配给项目工作，他还是很容易被分心。他可以通过关闭E-mail、关掉IM，或者其他手段来减少一定的干扰。但是某些干扰是政策造成的，以及一些无法避免的责任造成的。我们可以说某种程度的干扰是不可避免的，也是有意为之的。这是正确的：每个人都有甩不掉的Bug，同事之间也会有关系的产生与职责的分配。然而，作为团队来说，是有一些管理方式能使更多的员工不受干扰的。</p>
</li>
<li><p>极化时间为了限制干扰数量，我们应该减少上下文切换（指工作类型、环境等的改变）。某些中断性任务是无法避免的。然而，将工程师当成是可以随时中断、上下文切换没有成本是不正确的。给每次上下文切换加上成本的考虑。在项目工作中，一次20分钟的中断性任务需要进行两次上下文切换，而这种切换会造成数个小时的生产力的丧失。为了避免这种经常性的生产力丧失，我们应该延长每种工作模式的时间，一天甚至半天都可以。这种策略与“挤时间”（参见文献[Gra09]）策略工作得很好。</p>
</li>
<li><p>极化时间意味着当每个人来上班时，他们应该清晰地知道自己今天是否只是做项目工作，还是只是做中断性工作。这意味着他们可以更长时间地专注于手上的工作，不会不停地被那些他们本不应该负责的事情所打扰。</p>
</li>
<li><p>一般性建议不论哪种中断性任务，如果中断性任务的量对一个人来说太高，那么应该增加一个人负责。这个概念很显然适用于工单，但是也适用于紧急警报。on-call工程师可以将紧急警报降级为工单，也可以找副on-call来共同处理。</p>
</li>
<li><p>主on-call工程师应该专注于on-call工作。如果目前紧急警报较少，那么一些可以随时放下的工单，或者其他中断性事务应该由on-call人员处理。当某个工程师on-call一周时，这一周他应该完全排除在项目进度之外。如果某个项目非常重要，不能等待一周，那么这个人就不应该参与on-call。管理层应该介入，安排其他人替代on-call。管理层不应该期望员工在on-call的同时还能在项目上有所进展（或者其他高上下文切换成本的活动）。</p>
</li>
<li><p>另外：总有一些清理工作要做，工单数量可能是0，但是总会有需要更新的文档，需要整理的配置文件等。未来的on-call工程师可以从这些活动中受益。他们就不会再来打扰你了！</p>
</li>
<li><p>工单如果目前你是随机分配工单给团队成员，请立刻停止。这样做对团队的时间非常不尊重，和让成员尽可能不被打扰的目标背道而驰。工单处理应该由全职人员负责，同时保证占用合理的时间。如果团队目前的工单主oncall和副on-call都处理不完，那么需要重新架构整个工单的处理流程，保障任何时间都有两个全职员工处理工单。不要将复杂分散到整个团队中去。人不是机器，这样做只会干扰员工，降低他们的工作效率。</p>
</li>
<li><p>持续性的运维工作尽可能地让整个团队共同负责这件事。例如变更发布、配置文件修改等，如果这项工作有非常清晰的流程定义，那么就没有任何理由让任何一个人专门负责这件事情。定义一个发布管理者的角色来由on-call和其他中断性任务处理者来承担。同时应该进行正式化交接过程—这有一定成本，但是却保障了接下来的人不受打扰。负责中断性事务，或者不负责有的时候，某个中断性任务只有某个目前不在值班的成员能够妥善处理。虽然理想情况下，这种情况不应该发生，但是还是偶尔会发生，我们应该尽一切努力避免这种情况。</p>
</li>
</ul>
<h3 id="个人总结-17"><a href="#个人总结-17" class="headerlink" title="个人总结"></a>个人总结</h3><ol>
<li>极化时间，减少干扰；整理必要的文档。</li>
<li>不要将复杂分散到整个团队中去。人不是机器，这样做只会干扰员工，降低他们的工作效率。</li>
</ol>
<hr>
<h2 id="第30章-通过嵌入SRE的方式帮助团队从运维过载中恢复"><a href="#第30章-通过嵌入SRE的方式帮助团队从运维过载中恢复" class="headerlink" title="第30章 通过嵌入SRE的方式帮助团队从运维过载中恢复"></a>第30章 通过嵌入SRE的方式帮助团队从运维过载中恢复</h2><ul>
<li><p>Google的SRE团队的标准政策要求团队在项目研发和被动式工作之间均匀分配时间。在实际工作中，这种平衡可能会被每天工单数量的不断增加而被打乱，甚至持续数月之久。长时间承担非常繁重的Ops类型的工作是非常危险的，团队成员可能会劳累过度，不能在项目工作上取得任何进展。当一个团队被迫花费过多时间解决工单的时候，他们就会减少花在改进服务上的时间，服务的可扩展性和可靠性肯定会随之变差。解决这个问题的一种方式是给处于过载状态的团队临时调入一个SRE。调入该团队后，该SRE应该关注于改善这个团队的行事方式，而不是简单地帮助团队清理积压的工单。通过观察团队的日常工作，提出改善性意见，该SRE可以帮助团队用全新的视角来审视自己的日常工作。这往往是团队本身的成员做不到的。注意，当采用这个方法的时候，只需要调入一名SRE就够了。同时调入两名SRE不一定会产生更好的结果。对那些防御性比较强的团队来说，可能会激发问题的发生。</p>
</li>
<li><p>当你开始构建自己的第一个SRE团队时，采用本章中介绍的方法可以帮助避免团队走入歧途，退化成那种只专注于工单处理的传统运维团队。</p>
</li>
<li><p>在决定采用这种嵌入SRE的方式之前，你应该花一些时间来回顾一下Ben Treynor Sloss的介绍中提到的SRE理念和实践经验，同时应该看一下本书的第6章。</p>
</li>
</ul>
<h3 id="第一阶段：了解服务，了解上下文"><a href="#第一阶段：了解服务，了解上下文" class="headerlink" title="第一阶段：了解服务，了解上下文"></a>第一阶段：了解服务，了解上下文</h3><ul>
<li><p>第一阶段：了解服务，了解上下文在嵌入团队的过程中，你的主要工作是清楚地表达团队目前的流程和工作习惯对于该服务的可扩展性有利或者有弊的原因。你应该提醒该团队，日益增加的工单不应需要更多的SRE来处理。SRE模型的目标是仅仅在系统复杂度上升的时候才增加新人。你应该尝试引导团队建立健康的工作习惯，这样能够减少花费在工单上的时间。这与指出该服务目前还可以自动化或者进一步简化同样重要。</p>
</li>
<li><p>SRE团队陷入Ops模式的原因是过分关注如何快速解决紧急事件而不是如何减少紧急事件的数量。</p>
</li>
</ul>
<h3 id="第二阶段：分享背景知识"><a href="#第二阶段：分享背景知识" class="headerlink" title="第二阶段：分享背景知识"></a>第二阶段：分享背景知识</h3><ul>
<li><p>第二阶段：分享背景知识在了解团队内部动态和找到痛点之后，你应该通过建立一些最佳实践来为改善状况做准备。例如，建立书写事后总结的机制，辨别琐事的来源，确定每个琐事的最佳解决方案等。书写一个好的事后总结作为示范</p>
</li>
<li><p>你应该将团队遇到的紧急事件分为琐事的和非琐事的。最后，将这个列表交给团队并且清晰地解释哪些紧急事件应该被自动化，而其他的紧急事件则是运维服务必须承担的工作。</p>
</li>
</ul>
<h3 id="第三阶段：主导改变"><a href="#第三阶段：主导改变" class="headerlink" title="第三阶段：主导改变"></a>第三阶段：主导改变</h3><ul>
<li><p>第三阶段：主导改变保持团队健康是一个持续的过程。正因为此，这不是你可以通过个人英雄主义来解决的问题。为了确保团队在未来可以进行自我调节，我们需要帮助他们建立一个良好的SRE心理模型。</p>
</li>
<li><p>对某项决策进行充分解释的例子：●“我反对最新版本的原因不是因为测试结果有问题，而是因为我们对发布所制定的错误预算已经耗尽了。”● “发布需要能够安全回退，因为我们的SLO非常高。要想达到SLO的要求，平均恢复时间必须非常短，这样在回退之前进行深入的现场调查是不现实的。”对于某项决策不充分的解释的例子：●“我不认为每一个服务器自己生成自身的路由配置是安全的，因为我不信。”这一决策可能是正确的，但是分析论证上是很薄弱的（也没有详细解释）。团队无法知道你心中所想，所以他们很可能模拟你这种不良行为。相反，尝试“［……］不安全，因为在该代码中的一个错误会导致其他服务同时受到影响，同时额外的代码也可能带来减慢回滚的速度的问题。”●“自动化机制在遇到部署不一致的情况时应该放弃进行。”</p>
</li>
<li><p>和之前的例子一样，这一决策可能是正确的，但是是不充分的。相反，尝试“[……]因为我们这里的一个简化假设是全部的改变都通过自动化进行，这种情况的发生说明了有什么东西违反了这一规则。如果这种情况经常发生，我们应该找到和消除造成这种变化的根源。”</p>
</li>
<li><p>提出引导性问题应该提出引导性问题，而非指责性的问题。当你和SRE团队交流时，试着用一种可以鼓励别人思考基本理念的方式来提出问题。</p>
</li>
<li><p>引导性问题的例子：● “我看到任务失败的警报经常发生，但是on-call工程师通常什么都不做。这样会对SLO有什么影响？”● “这个上线过程看起来非常复杂。你知道为什么创建一个新的服务实例需要这么多的配置文件的更新吗？”引导性问题的反例：●“这些旧的、停滞的发布是什么情况？”●“为什么某个组件要做这么多的事情？”</p>
</li>
</ul>
<h3 id="小结-7"><a href="#小结-7" class="headerlink" title="小结"></a>小结</h3><ul>
<li>你的最后一个任务是书写一份报告。报告中应该重申你的观点、例子和逻辑推理过程。同时，该报告应该向团队提供一些待办事项，来保证他们会实践你所传授的东西。你应该将报告组织成一份检查报告[12]，解释成功路上的每一个重要的决策。大部分的工作现在已经完成了。虽然你的嵌入式工作正式结束，但仍然应该参与设计评审和代码评审。在未来几个月中持续关注这个团队，确保他们正在慢慢提高自己的容量规划能力、紧急事件处理能力和部署发布过程。</li>
</ul>
<hr>
<h2 id="第31章-SRE与其他团队的沟通与协作"><a href="#第31章-SRE与其他团队的沟通与协作" class="headerlink" title="第31章 SRE与其他团队的沟通与协作"></a>第31章 SRE与其他团队的沟通与协作</h2><h3 id="沟通：生产会议"><a href="#沟通：生产会议" class="headerlink" title="沟通：生产会议"></a>沟通：生产会议</h3><ul>
<li>在两个SRE团队视频会议时，如果一个团队比另外一个大很多，我们建议从较小的团队一边选择主席。更大的一方会自然而然地安静下来，一些不平衡的团队规模所造成的不良影响（这些会由于视频会议的延迟而变得更糟）将得到改善。[14]我们不知道这是否有任何科学依据，但它确实有效。</li>
</ul>
<h3 id="SRE的内部协作"><a href="#SRE的内部协作" class="headerlink" title="SRE的内部协作"></a>SRE的内部协作</h3><ul>
<li><p>不管这些角色定义得是否清晰，基本来说，技术负责人是负责团队技术方向的，可以以多种方式进行领导。他可以通过仔细评审每个人的代码，组织进行季度工作汇报，或者是在团队中推进共识的建立来引领团队方向等方式来领导团队。</p>
</li>
<li><p>在Google内部，技术负责人和SRE经理的工作几乎一样，因为我们的SRE经理也具有高度的技术能力。但SRE经理在这之外还有两个特殊责任：绩效管理，以及其他一切其他人不能处理的事情。好的技术负责人、SRE经理以及项目经理组成了一个完整的管理团队，可以很好地组织项目进行讨论设计文档，必要的时候甚至亲自书写代码。</p>
</li>
<li><p>建议只有在不得已的情况下才应该跨地域开发项目，但是这同时也会带来一定的好处。跨地域工作需要更多的沟通，工作完成得也更慢；但是好处是—如果你能协调好的话—则会有更高的产能。单地项目其实也可能会导致其他人不知道你正在做什么，所以这两种做法其实都有一定成本。</p>
</li>
</ul>
<hr>
<h2 id="第33章-其他行业的实践经验"><a href="#第33章-其他行业的实践经验" class="headerlink" title="第33章 其他行业的实践经验"></a>第33章 其他行业的实践经验</h2><ul>
<li>在本章中，我们会讨论到许多SRE的核心指导思想。为了简化与其他行业最佳实践的比较，我们将这些理念分为4大类：● 灾难预案与演习● 书写事后总结的文化● 自动化与降低日常运维负载● 结构化的、理智的决策</li>
</ul>
<hr>
<h3 id="附录A-系统可用性"><a href="#附录A-系统可用性" class="headerlink" title="附录A 系统可用性"></a>附录A 系统可用性</h3><h3 id="附录B-生产环境运维过程中的最佳实践"><a href="#附录B-生产环境运维过程中的最佳实践" class="headerlink" title="附录B 生产环境运维过程中的最佳实践"></a>附录B 生产环境运维过程中的最佳实践</h3><h3 id="附录C-事故状态文档示范"><a href="#附录C-事故状态文档示范" class="headerlink" title="附录C 事故状态文档示范"></a>附录C 事故状态文档示范</h3><h3 id="附录D-事后总结示范"><a href="#附录D-事后总结示范" class="headerlink" title="附录D 事后总结示范"></a>附录D 事后总结示范</h3><h3 id="附录E-发布协调检查列表"><a href="#附录E-发布协调检查列表" class="headerlink" title="附录E 发布协调检查列表"></a>附录E 发布协调检查列表</h3><hr>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><pre>

看见有人不赞同，其实这些问题你们没有遇见过，产品着急上线，出现了一个极低概率的case，修复成本很高。上线后的回报很大，而这个case带来的损失很小，这个时候肯定带着bug上线啊。很多时候产品上线发现商业模式跑不通，这个bug就不用修了，或者迭代过程中才用了另外的实现方式避免了这个问题。错误预算都不一定能用上。
——评论

阿里的要求：可灰度、可监控、可回滚，大厂的思路基本都是一致的。
——评论

产品在不同的发展阶段，可用性目标应该是动态变化的，快速发展期的可用性往往低于成熟稳定期，以保证新功能的发布、试错等顺利进行。——评论

打天下和守天下，需要不同的节奏，优先级不同，方案和指标也不同。——评论

量化风险成本，建立一致性目标，风险共担，减少非必要的沟通扯皮成本，比较好的双赢模式。
对照着看传统运维和开发的独立承担指标就属于零和博弈了，只有政治斗争能化解。——评论

</pre>

<ul>
<li><a href="https://mp.weixin.qq.com/s/LITm9MuQ8bs8XRg9QyPeLQ">一文帮你理解 Google SRE 体系</a></li>
<li><a href="https://mp.weixin.qq.com/s/GqhKuJ8yzZuLdRzS_MSCcw">我对 SRE 的理解</a></li>
<li><a href="https://mp.weixin.qq.com/s/nD3qFgmNkBfiLA8r7wapfA">云原生背景运维转型之 SRE 实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/NQPhLgw2TrbYz3qO8c5czQ">SRE的主要职责是什么？</a></li>
</ul>
]]></content>
      <tags>
        <tag>IT-BOOK</tag>
        <tag>SRE</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes学习笔记</title>
    <url>/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/</url>
    <content><![CDATA[<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/Kubernetes%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%840.png"><br><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/Kubernetes%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%841.jpg"><br><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/Kubernetes%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%842.png"><br><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/Kubernetes%E5%8F%8A%E5%AE%B9%E5%99%A8%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F.png"><br><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/Kubernetes%E5%8F%8A%E5%AE%B9%E5%99%A8%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F2.png"></p>
<ul>
<li>图来源：<a href="https://www.cnblogs.com/wwchihiro/p/9261607.html">k8s-整体概述和架构</a></li>
</ul>
<h2 id="关键名词"><a href="#关键名词" class="headerlink" title="关键名词"></a>关键名词</h2><ul>
<li>CNCF（Cloud Native Computing Foundation，云原生计算基金会）</li>
</ul>
<h2 id="关键总结"><a href="#关键总结" class="headerlink" title="关键总结"></a>关键总结</h2><ol>
<li>自动化</li>
<li>Docker是其目前支持的底层容器技术之一</li>
<li>服务弹性扩容机制应对突发流量</li>
<li>Kubernetes视为云计算时代的操作系统</li>
<li>k8s解决进程（服务）部署、容器编排的问题，service mesh解决进程（服务）通信的问题</li>
</ol>
<h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><h3 id="Kubernetes-API-Server"><a href="#Kubernetes-API-Server" class="headerlink" title="Kubernetes API Server"></a>Kubernetes API Server</h3><ul>
<li>Kubernetes API Server的核心功能是提供Kubernetes各类资源对象（如Pod、RC、Service等）的增、删、改、查及Watch等HTTP Rest接口，成为集群内各个功能模块之间数据交互和通信的中心枢纽，是整个系统的数据总线和数据中心。除此之外，它还有以下一些功能特性。<ol>
<li>是集群管理的API入口。</li>
<li>是资源配额控制的入口。</li>
<li>提供了完备的集群安全机制。</li>
</ol>
</li>
<li>可以通过命令行工具kubectl来与Kubernetes API Server交互，它们之间的接口是RESTful API；另一种方式是通过编程方式调用Kubernetes API Server。</li>
<li>Kubernetes API Server本身也是一个Service，它的名称就是kubernetes，并且它的Cluster IP地址是Cluster IP地址池里的第1个地址。</li>
<li>由于API Server是Kubernetes集群数据的唯一访问入口，因此安全性与高性能就成为API Server设计和实现的两大核心目标。通过采用HTTPS安全传输通道与CA签名数字证书强制双向认证的方式，API Server的安全性得以保障。此外，为了更细粒度地控制用户或应用对Kubernetes资源对象的访问权限，Kubernetes启用了RBAC访问控制策略。</li>
<li>API层：主要以REST方式提供各种API接口，除了有Kubernetes资源对象的CRUD和Watch等主要API，还有健康检查、UI、日志、性能指标等运维监控相关的API。</li>
<li>etcd数据库：用于持久化存储Kubernetes资源对象的KV数据库。</li>
<li>借助etcd提供的Watch API接口，API Server可以监听（Watch）在etcd上发生的数据操作事件，比如Pod创建事件、更新事件、删除事件等，在这些事件发生后，etcd会及时通知API Server。</li>
<li>为了让Kubernetes中的其他组件在不访问底层etcd数据库的情况下，也能及时获取资源对象的变化事件，API Server模仿etcd的Watch API接口提供了自己的Watch接口，这样一来，这些组件就能近乎实时地获取它们感兴趣的任意资源对象的相关事件通知了。</li>
<li>Kubernetes API Server最主要的REST接口是资源对象的增、删、改、查接口，除此之外，它还提供了一类很特殊的REST接口——Kubernetes Proxy API接口，这类接口的作用是代理REST请求，即Kubernetes API Server把收到的REST请求转发到某个Node上的kubelet守护进程的REST端口，由该kubelet进程负责响应。</li>
<li>Kubernetes Proxy API里关于Node的相关接口、关于Pod的相关接口</li>
<li>在Kubernetes集群之外访问某个Pod容器的服务（HTTP服务）时，可以用Proxy API实现，这种场景多用于管理目的，比如逐一排查Service的Pod副本，检查哪些Pod的服务存在异常。Proxy API也有Service的Proxy接口，其接口定义与Pod的接口定义基本一样：&#x2F;api&#x2F;v1&#x2F;proxy&#x2F;namespaces&#x2F;{namespace}&#x2F;services&#x2F;{name}。</li>
</ul>
<h3 id="Controller-Manager"><a href="#Controller-Manager" class="headerlink" title="Controller Manager"></a>Controller Manager</h3><ul>
<li>Kubernetes集群中，每个Controller都是这样的一个“操作系统”，它们通过API Server提供的（List-Watch）接口实时监控集群中特定资源的状态变化，当发生各种故障导致某资源对象的状态发生变化时，Controller会尝试将其状态调整为期望的状态。</li>
<li>Controller Manager是Kubernetes中各种操作系统的管理者，是集群内部的管理控制中心，也是Kubernetes自动化功能的核心。</li>
</ul>
<h3 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h3><ul>
<li>kubelet进程在启动时通过API Server注册自身的节点信息，并定时向API Server汇报状态信息，API Server在接收到这些信息后，会将这些信息更新到etcd中。在etcd中存储的节点信息包括节点健康状况、节点资源、节点名称、节点地址信息、操作系统版本、Docker版本、kubelet版本等。</li>
<li>在Kubernetes集群中，在每个Node（又称Minion）上都会启动一个kubelet服务进程。该进程用于处理Master下发到本节点的任务，管理Pod及Pod中的容器。每个kubelet进程都会在API Server上注册节点自身的信息，定期向Master汇报节点资源的使用情况，并通过cAdvisor监控容器和节点资源。</li>
</ul>
<h3 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h3><ul>
<li>每个Node上的kube-proxy进程获取每个Service的Endpoints，实现了Service的负载均衡功能。</li>
<li>Service只是一个概念，而真正将Service的作用落实的是它背后的kube-proxy服务进程</li>
<li>在Kubernetes集群的每个Node上都会运行一个kube-proxy服务进程，我们可以把这个进程看作Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</li>
<li>Service的Cluster IP与NodePort等概念是kube-proxy服务通过iptables的NAT转换实现的，kube-proxy在运行过程中动态创建与Service相关的iptables规则，这些规则实现了将访问服务（Cluster IP或NodePort）的请求负载分发到后端Pod的功能。由于iptables机制针对的是本地的kube-proxy端口，所以在每个Node上都要运行kube-proxy组件，这样一来，在Kubernetes集群内部，我们可以在任意Node上发起对Service的访问请求。综上所述，由于kube-proxy的作用，在Service的调用过程中客户端无须关心后端有几个Pod，中间过程的通信、负载均衡及故障恢复都是透明的。</li>
<li>kube-proxy进程转发Service流量方式<ol>
<li>userspace（用户空间代理）模式。（是一个真实的TCP&#x2F;UDP代理，类似HA Proxy，负责从Service到Pod的访问流量的转发。当某个Pod以Cluster IP方式访问某个Service的时候，这个流量会被Pod所在本机的iptables转发到本机的kube-proxy进程，然后由kube-proxy建立起到后端Pod的TCP&#x2F;UDP连接，随后将请求转发到某个后端Pod上，并在这个过程中实现负载均衡功能。）</li>
<li>iptables模式。Kubernetes从1.2版本开始，将iptables作为kube-proxy的默认模式。iptables模式下的kube-proxy不再起到Proxy的作用，其核心功能：通过API Server的Watch接口实时跟踪Service与Endpoint的变更信息，并更新对应的iptables规则，Client的请求流量则通过iptables的NAT机制“直接路由”到目标Pod。根据Kubernetes的网络模型，一个Node上的Pod与其他Node上的Pod应该能够直接建立双向的TCP&#x2F;IP通信通道，所以如果直接修改iptables规则，则也可以实现kube-proxy的功能，只不过后者更加高端，因为是全自动模式的。与第1代的userspace模式相比，iptables模式完全工作在内核态，不用再经过用户态的kube-proxy中转，因而性能更强。</li>
<li>IPVS模式。iptables模式虽然实现起来简单，但存在无法避免的缺陷：在集群中的Service和Pod大量增加以后，iptables中的规则会急速膨胀，导致性能显著下降，在某些极端情况下甚至会出现规则丢失的情况，并且这种故障难以重现与排查，于是Kubernetes从1.8版本开始引入第3代的IPVS（IP Virtual Server）模式，如图5.16所示。IPVS在Kubernetes 1.11中升级为GA稳定版。<br>iptables与IPVS虽然都是基于Netfilter实现的，但因为定位不同，二者有着本质的差别：iptables是为防火墙而设计的；IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张，因此被kube-proxy采纳为第三代模式。在IPVS模式下，kube-proxy又做了重要的升级，即使用iptables的扩展ipset，而不是直接调用iptables来生成规则链。ipset则引入了带索引的数据结构，因此当规则很多时，也可以很高效地查找和匹配。</li>
</ol>
</li>
</ul>
<h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><ul>
<li>Kubernetes Scheduler在整个系统中承担了“承上启下”的重要功能，“承上”是指它负责接收Controller Manager创建的新Pod，为其安排一个落脚的“家”——目标Node；“启下”是指安置工作完成后，目标Node上的kubelet服务进程接管后继工作，负责Pod生命周期中的“下半生”。</li>
<li>在整个调度过程中涉及三个对象，分别是待调度Pod列表、可用Node列表，以及调度算法和策略。</li>
</ul>
<h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><h3 id="kubectl"><a href="#kubectl" class="headerlink" title="kubectl"></a>kubectl</h3><ol>
<li>创建RC： <code>kubectl create -f mysql-rc.yaml</code>;  <code>kubectl get rc</code></li>
<li>创建Service：<code>kubectl create -f mysql-svc.yaml</code>; <code>kubectl get svc</code></li>
<li>查看在集群中有多少个Node：<code>kubectl get nodes</code></li>
<li>查看某个Node的详细信息：<code>kubectl describe node</code> </li>
<li>修改RC的副本数量，来实现Pod的动态缩放（Scaling）：<code>kubectl scale rc redis-slave --replicas=3</code></li>
<li>创建Deployment：<code>kubectl create -f tomcat-deployment.yaml</code></li>
<li>查看Deployment的信息： <code>kubectl get deployments</code></li>
<li>查看对应的Replica Set：  <code>kubectl get rs</code></li>
<li>查看创建的Pod：<code>kubectl get pods</code></li>
<li>查看Deployment的更新过程：<code>kubectl rollout status</code></li>
<li>检查Deployment部署的历史记录：<code>kubectl rollout history</code></li>
</ol>
<h2 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h2><ul>
<li>Kubernetes里的3种IP，这3种IP分别如下<ul>
<li>Node IP：Node的IP地址。</li>
<li>Pod IP：Pod的IP地址。</li>
<li>Cluster IP：Service的IP地址。</li>
</ul>
</li>
<li>node IP是Kubernetes集群中每个节点的物理网卡的IP地址，是一个真实存在的物理网络。，所有属于这个网络的服务器都能通过这个网络直接通信，不管其中是否有部分节点不属于这个Kubernetes集群。这也表明在Kubernetes集群之外的节点访问Kubernetes集群之内的某个节点或者TCP&#x2F;IP服务时，都必须通过Node IP通信。（未打通Pod IP网络的情况下）</li>
<li>Pod IP是每个Pod的IP地址，它是Docker Engine根据docker0网桥的IP地址段进行分配的，通常是一个虚拟的二层网络。Kubernetes要求位于不同Node上的Pod都能够彼此直接通信，所以Kubernetes里一个Pod里的容器访问另外一个Pod里的容器时，就是通过Pod IP所在的虚拟二层网络进行通信的，而真实的TCP&#x2F;IP流量是通过Node IP所在的物理网卡流出的。</li>
<li>Service的Cluster IP，它也是一种虚拟的IP，但更像一个“伪造”的IP网络，原因有以下几点。<ul>
<li>Cluster IP仅仅作用于Kubernetes Service这个对象，并由Kubernetes管理和分配IP地址（来源于Cluster IP地址池）。</li>
<li>Cluster IP无法被Ping，因为没有一个“实体网络对象”来响应。</li>
<li>Cluster IP只能结合Service Port组成一个具体的通信端口，单独的Cluster IP不具备TCP&#x2F;IP通信的基础，并且它们属于Kubernetes集群这样一个封闭的空间，集群外的节点如果要访问这个通信端口，则需要做一些额外的工作。</li>
<li>在Kubernetes集群内，Node IP网、Pod IP网与Cluster IP网之间的通信，采用的是Kubernetes自己设计的一种编程方式的特殊路由规则，与我们熟知的IP路由有很大的不同。</li>
<li>Service的Cluster IP属于Kubernetes集群内部的地址，无法在集群外部直接使用这个地址。</li>
</ul>
</li>
</ul>
<h3 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h3><ul>
<li>把所有的配置项都当作key-value字符串，当然value可以来自某个文本文件，比如配置项password&#x3D;123456、user&#x3D;root、host&#x3D;192.168.8.4用于表示连接FTP服务器的配置参数。这些配置项可以作为Map表中的一个项，整个Map的数据可以被持久化存储在Kubernetes的Etcd数据库中，然后提供API以方便Kubernetes相关组件或客户应用CRUD操作这些数据，上述专门用来保存配置参数的Map就是Kubernetes ConfigMap资源对象。</li>
<li>Kubernetes提供了一种内建机制，将存储在etcd中的ConfigMap通过Volume映射的方式变成目标Pod内的配置文件，不管目标Pod被调度到哪台服务器上，都会完成自动映射。进一步地，如果ConfigMap中的key-value数据被修改，则映射到Pod中的“配置文件”也会随之自动更新。于是，Kubernetes ConfigMap就成了分布式系统中最为简单（使用方法简单，但背后实现比较复杂）且对应用无侵入的配置中心。</li>
<li>ConfigMap供容器使用的典型用法如下。<ol>
<li>生成为容器内的环境变量。</li>
<li>设置容器启动命令的启动参数（需设置为环境变量）。</li>
<li>以Volume的形式挂载为容器内部的文件或目录。</li>
</ol>
</li>
<li>不使用YAML文件，直接通过kubectl create configmap也可以创建ConfigMap，可以使用参数–from-file或–from-literal指定内容，并且可以在一行命令中指定多个参数。</li>
<li>容器应用对ConfigMap的使用有以下两种方法。<ol>
<li>通过环境变量获取ConfigMap中的内容。</li>
<li>通过Volume挂载的方式将ConfigMap中的内容挂载为容器内部的文件或目录。</li>
</ol>
</li>
<li>Kubernetes从1.6版本开始，引入了一个新的字段envFrom，实现了在Pod环境中将ConfigMap（也可用于Secret资源对象）中所有定义的key&#x3D;value自动生成为环境变量。</li>
</ul>
<h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><ul>
<li>负责整个集群的管理和控制</li>
<li>在Master上运行着以下关键进程<ul>
<li>Kubernetes API Server（kube-apiserver）</li>
<li>Kubernetes Controller Manager（kube-controller-manager）</li>
<li>Kubernetes Scheduler（kube-scheduler）</li>
</ul>
</li>
</ul>
<h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><ul>
<li>Pod运行在一个被称为节点（Node）的环境中，这个节点既可以是物理机，也可以是私有云或者公有云中的一个虚拟机，通常在一个节点上运行几百个Pod。</li>
<li>Node除了Master，Kubernetes集群中的其他机器被称为Node。与Master一样，Node可以是一台物理主机，也可以是一台虚拟机。</li>
<li>每个Node上都运行着以下关键进程<ul>
<li>kubelet</li>
<li>kube-proxy</li>
<li>Docker Engine（docker）</li>
</ul>
</li>
<li>Node可以在运行期间动态增加到Kubernetes集群中，在默认情况下kubelet会向Master注册自己，这也是Kubernetes推荐的Node管理方式。</li>
</ul>
<h3 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h3><ul>
<li>由一组容器组成</li>
<li>每个Pod都有一个特殊的被称为“根容器”的Pause容器</li>
<li>Kubernetes为每个Pod都分配了唯一的IP地址，称之为Pod IP，一个Pod里的多个容器共享Pod IP地址。</li>
<li>Kubernetes要求底层网络支持集群内任意两个Pod之间的TCP&#x2F;IP直接通信，一个Pod里的容器与另外主机上的Pod容器能够直接通信。</li>
<li>Pod其实有两种类型：普通的Pod及静态Pod（Static Pod）。</li>
<li>Pod的IP加上这里的容器端口（containerPort），组成了一个新的概念——Endpoint，它代表此Pod里的一个服务进程的对外通信地址。（一个Pod也存在具有多个Endpoint的情况）</li>
<li>在Kubernetes里，一个计算资源进行配额限定时需要设定以下两个参数。<ul>
<li>Requests：该资源的最小申请量，系统必须满足要求。</li>
<li>Limits：该资源最大允许使用的量，不能被突破，当容器试图使用超过这个量的资源时，可能会被Kubernetes“杀掉”并重启。通常，我们会把Requests设置为一个较小的数值，符合容器平时的工作负载情况下的资源需求，而把Limit设置为峰值负载情况下资源占用的最大量。</li>
</ul>
</li>
<li>Pod的管理对象，除了RC和Deployment，还包括ReplicaSet、DaemonSet、StatefulSet、Job等，分别用于不同的应用场景中。</li>
<li>Pod定义详解YAML格式的Pod定义文件的完整内容</li>
<li>静态Pod是由kubelet进行管理的仅存在于特定Node上的Pod<ul>
<li>创建静态Pod有两种方式：配置文件方式和HTTP方式。</li>
</ul>
</li>
<li>在容器内获取Pod信息（Downward API）<ul>
<li>Downward API有什么价值呢？</li>
<li>在某些集群中，集群中的每个节点都需要将自身的标识（ID）及进程绑定的IP地址等信息事先写入配置文件中，进程在启动时会读取这些信息，然后将这些信息发布到某个类似服务注册中心的地方，以实现集群节点的自动发现功能。</li>
</ul>
</li>
<li>Pod的重启策略（RestartPolicy）包括Always、OnFailure和Never，默认值为Always。<ul>
<li>kubelet重启失效容器的时间间隔以sync-frequency乘以2n来计算，例如1、2、4、8倍等，最长延时5min，并且在成功重启后的10min后重置该时间。</li>
<li>Pod的重启策略与控制方式息息相关，当前可用于管理Pod的控制器包括ReplicationController、Job、DaemonSet及直接通过kubelet管理（静态Pod）。每种控制器对Pod的重启策略要求如下。◎ RC和DaemonSet：必须设置为Always，需要保证该容器持续运行。◎ Job：OnFailure或Never，确保容器执行完成后不再重启。◎ kubelet：在Pod失效时自动重启它，不论将RestartPolicy设置为什么值，也不会对Pod进行健康检查。</li>
</ul>
</li>
<li>Pod健康检查和服务可用性检查<ul>
<li>Kubernetes对Pod的健康状态可以通过两类探针来检查： LivenessProbe和ReadinessProbe，kubelet定期执行这两类探针来诊断容器的健康状况。</li>
<li>LivenessProbe探针：用于判断容器是否存活（Running状态）；ReadinessProbe探针：用于判断容器服务是否可用（Ready状态）</li>
<li>LivenessProbe和ReadinessProbe均可配置以下三种实现方式。<ol>
<li>ExecAction：在容器内部执行一个命令，如果该命令的返回码为0，则表明容器健康。</li>
<li>TCPSocketAction：通过容器的IP地址和端口号执行TCP检查，如果能够建立TCP连接，则表明容器健康。</li>
<li>HTTPGetAction：通过容器的IP地址、端口号及路径调用HTTP Get方法，如果响应的状态码大于等于200且小于400，则认为容器健康。</li>
</ol>
</li>
<li>Kubernetes的ReadinessProbe机制可能无法满足某些复杂应用对容器内服务可用状态的判断，所以Kubernetes从1.11版本开始，引入Pod Ready++特性对Readiness探测机制进行扩展，在1.14版本时达到GA稳定版，称其为Pod Readiness Gates。通过Pod Readiness Gates机制，用户可以将自定义的ReadinessProbe探测方式设置在Pod上，辅助Kubernetes设置Pod何时达到服务可用状态（Ready）。</li>
</ul>
</li>
<li>init container（初始化容器）与应用容器在本质上是一样的，但它们是仅运行一次就结束的任务，并且必须在成功执行完成后，系统才能继续执行下一个容器</li>
</ul>
<h4 id="Pod的核心：pause容器"><a href="#Pod的核心：pause容器" class="headerlink" title="Pod的核心：pause容器"></a>Pod的核心：pause容器</h4><ul>
<li>Kubernetes的Pod抽象基于Linux的namespace和cgroups，为容器提供了隔离的环境。从网络的角度看，同一个Pod中的不同容器犹如运行在同一个主机上，可以通过localhost进行通信。</li>
<li>Docker容器非常适合部署单个软件单元。但是当你想要一起运行多个软件时，尤其是在一个容器里管理多个进程时，这种模式会变得有点麻烦。Kubernetes非常不建议“富容器”这种方式，认为将这些应用程序部署在部分隔离并且部分共享资源的容器组中更为有用。为此，Kubernetes为这种使用场景提供了一个称为Pod的抽象。</li>
<li>原则上，任何人都可以配置Docker来控制容器组之间的共享级别——只需创建一个父容器，并创建与父容器共享资源的新容器，然后管理这些容器的生命周期。在Kubernetes中，pause容器被当作Pod中所有容器的“父容器”，并为每个业务容器提供以下功能：·在Pod中，它作为共享Linux namespace（Network、UTS等）的基础；·启用PID namespace共享，它为每个Pod提供1号进程，并收集Pod内的僵尸进程。</li>
<li>这个pause容器运行一个非常简单的进程，它不执行任何功能，一启动就永远把自己阻塞住了（见pause（）系统调用）。正如你看到的，它当然不会只知道“睡觉”。它执行另一个重要的功能——即它扮演PID 1的角色，并在子进程成为“孤儿进程”的时候，通过调用wait（）收割这些僵尸子进程。这样就不用担心我们的Pod的PID namespace里会堆满僵尸进程了。这也是为什么Kubernetes不随便找个容器（例如Nginx）作为父容器，让用户容器加入的原因。</li>
</ul>
<h3 id="Pod的调度"><a href="#Pod的调度" class="headerlink" title="Pod的调度"></a>Pod的调度</h3><ul>
<li>在Kubernetes平台上，我们很少会直接创建一个Pod，在大多数情况下会通过RC、Deployment、DaemonSet、Job等控制器完成对一组Pod副本的创建、调度及全生命周期的自动控制任务。</li>
<li>RC也出现了新的继任者——Deployment，用于更加自动地完成Pod副本的部署、版本更新、回滚等功能。RC的继任者其实并不是Deployment，而是ReplicaSet，因为ReplicaSet进一步增强了RC标签选择器的灵活性。</li>
<li>与RC不同，ReplicaSet被设计成能控制多个不同标签的Pod副本。一种常见的应用场景是，应用MyApp目前发布了v1与v2两个版本，用户希望MyApp的Pod副本数保持为3个，可以同时包含v1和v2版本的Pod，就可以用ReplicaSet来实现这种控制</li>
<li>Kubernetes的滚动升级就是巧妙运用ReplicaSet的这个特性来实现的，同时，Deployment也是通过ReplicaSet来实现Pod副本自动控制功能的。我们不应该直接使用底层的ReplicaSet来控制Pod副本，而应该使用管理ReplicaSet的Deployment对象来控制副本，这是来自官方的建议。</li>
<li>在真实的生产环境中的确也存在一种需求：希望某种Pod的副本全部在指定的一个或者一些节点上运行，比如希望将MySQL数据库调度到一个具有SSD磁盘的目标节点上，此时Pod模板中的NodeSelector属性就开始发挥作用了。</li>
<li>如果NodeSelector选择的Label不存在或者不符合条件，比如这些目标节点此时宕机或者资源不足，该怎么办？如果要选择多种合适的目标节点，比如SSD磁盘的节点或者超高速硬盘的节点，该怎么办？Kubernates引入了NodeAffinity（节点亲和性设置）来解决该需求。</li>
<li>与单独的Pod实例不同，由RC、ReplicaSet、Deployment、DaemonSet等控制器创建的Pod副本实例都是归属于这些控制器的，这就产生了一个问题：控制器被删除后，归属于控制器的Pod副本该何去何从？在Kubernates 1.9之前，在RC等对象被删除后，它们所创建的Pod副本都不会被删除；在Kubernates 1.9以后，这些Pod副本会被一并删除。如果不希望这样做，则可以通过kubectl命令的–cascade&#x3D;false参数来取消这一默认特性。</li>
<li>Deployment或RC：全自动调度：Deployment或RC的主要功能之一就是自动部署一个容器应用的多份副本，以及持续监控副本的数量，在集群内始终维持用户指定的副本数量。</li>
<li>除了使用系统自动调度算法完成一组Pod的部署，Kubernetes也提供了多种丰富的调度策略，用户只需在Pod的定义中使用NodeSelector、NodeAffinity、PodAffinity、Pod驱逐等更加细粒度的调度策略设置，就能完成对Pod的精准调度。</li>
<li>亲和性调度功能包括节点亲和性（NodeAffinity）和Pod亲和性（PodAffinity）两个维度的设置。NodeAffinity意为Node亲和性的调度策略，是用于替换NodeSelector的全新调度策略。亲和性的操作符也包括In、NotIn、Exists、DoesNotExist、Gt、Lt。</li>
</ul>
<h3 id="Pod的扩缩容"><a href="#Pod的扩缩容" class="headerlink" title="Pod的扩缩容"></a>Pod的扩缩容</h3><ul>
<li>Kubernetes对Pod的扩缩容操作提供了手动和自动两种模式，手动模式通过执行kubectl scale命令或通过RESTful API对一个Deployment&#x2F;RC进行Pod副本数量的设置，即可一键完成。自动模式则需要用户根据某个性能指标或者自定义业务指标，并指定Pod副本数量的范围，系统将自动在这个范围内根据性能指标的变化进行调整。</li>
<li>自动扩缩容机制：HPA控制器基于Master的kube-controller-manager服务启动参数–horizontal-pod-autoscaler-sync-period定义的探测周期（默认值为15s），周期性地监测目标Pod的资源性能指标，并与HPA资源对象中的扩缩容条件进行对比，在满足条件时对Pod副本数量进行调整。</li>
<li>Kubernetes从1.11版本开始，弃用基于Heapster组件完成Pod的CPU使用率采集的机制，全面转向基于Metrics Server完成数据采集。从1.10版本开始，Kubernetes引入了对外部系统指标的支持。</li>
</ul>
<h3 id="Label"><a href="#Label" class="headerlink" title="Label"></a>Label</h3><ul>
<li>一个Label是一个key&#x3D;value的键值对，其中key与value由用户自己指定。Label可以被附加到各种资源对象上，例如Node、Pod、Service、RC等，一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上。Label通常在资源对象定义时确定，也可以在对象创建后动态添加或者删除。</li>
<li>过Label Selector（标签选择器）查询和筛选拥有某些Label的资源对象</li>
<li>有两种Label Selector表达式：基于等式的（Equality-based）和基于集合的（Set-based）</li>
<li>使用Label可以给对象创建多组标签，Label和Label Selector共同构成了Kubernetes系统中核心的应用模型，使得被管理对象能够被精细地分组管理，同时实现了整个集群的高可用性。</li>
</ul>
<h3 id="Annotation"><a href="#Annotation" class="headerlink" title="Annotation"></a>Annotation</h3><ul>
<li>Annotation（注解）与Label类似，也使用key&#x2F;value键值对的形式进行定义。不同的是Label具有严格的命名规则，它定义的是Kubernetes对象的元数据（Metadata），并且用于Label Selector。Annotation则是用户任意定义的附加信息，以便于外部工具查找。在很多时候，Kubernetes的模块自身会通过Annotation标记资源对象的一些特殊信息。通常来说，用Annotation来记录的信息如下。◎ build信息、release信息、Docker镜像信息等，例如时间戳、release id号、PR号、镜像Hash值、Docker Registry地址等。◎ 日志库、监控库、分析库等资源库的地址信息。◎ 程序调试工具信息，例如工具名称、版本号等。◎ 团队的联系信息，例如电话号码、负责人名称、网址等。</li>
</ul>
<h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><ul>
<li>Service是分布式集群架构的核心，一个Service对象拥有如下关键特征。</li>
<li>拥有一个虚拟IP（Cluster IP、Service IP或VIP）和端口号。</li>
<li>通过Label关联Pod和Service。</li>
<li>并不是每个Pod和它里面运行的容器都能被映射到一个Service上，只有提供服务（无论是对内还是对外）的那组Pod才会被映射为一个服务。</li>
<li>通常，Cluster IP是在Service创建后由Kubernetes系统自动分配的，其他Pod无法预先知道某个Service的Cluster IP地址，因此需要一个服务发现机制来找到这个服务。</li>
<li>Kubernetes的Service定义了一个服务的访问入口地址，前端的应用（Pod）通过这个入口地址访问其背后的一组由Pod副本组成的集群实例，Service与其后端Pod副本集群之间则是通过Label Selector来实现无缝对接的。RC的作用实际上是保证Service的服务能力和服务质量始终符合预期标准。</li>
<li>运行在每个Node上的kube-proxy进程其实就是一个智能的软件负载均衡器，负责把对Service的请求转发到后端的某个Pod实例上，并在内部实现服务的负载均衡与会话保持机制。</li>
<li>Service没有共用一个负载均衡器的IP地址，每个Service都被分配了一个全局唯一的虚拟IP地址，这个虚拟IP被称为Cluster IP。这样一来，每个服务就变成了具备唯一IP地址的通信节点，服务调用就变成了最基础的TCP网络通信问题。</li>
<li>Pod的Endpoint地址会随着Pod的销毁和重新创建而发生改变，因为新Pod的IP地址与之前旧Pod的不同。而Service一旦被创建，Kubernetes就会自动为它分配一个可用的Cluster IP，而且在Service的整个生命周期内，它的Cluster IP不会发生改变。</li>
<li>Kubernetes提供了Headless Service，即不为Service设置ClusterIP（入口IP地址），仅通过Label Selector将后端的Pod列表返回给调用的客户端。</li>
<li>Service只是一个概念，而真正将Service的作用落实的是它背后的kube-proxy服务进程</li>
</ul>
<h4 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h4><ul>
<li>每个Kubernetes中的Service都有唯一的Cluster IP及唯一的名称。</li>
<li>如何通过Service的名称找到对应的Cluster IP。Kubernetes通过Add-On增值包引入了DNS系统，把服务名作为DNS域名，这样程序就可以直接使用服务名来建立通信连接了。目前，Kubernetes上的大部分应用都已经采用了DNS这种新兴的服务发现机制。</li>
<li>Service具有稳定的IP地址（区别于容器不固定的IP地址）和端口，并会在一组匹配的后端Pod之间提供负载均衡，匹配的条件就是Service的Label Selector与Pod的Labels相匹配。</li>
<li>Kubernetes的Service代表的是Kubernetes后端服务的入口，它主要包含服务的访问IP（虚IP）和端口，因此工作在L4。既然Service只存储服务入口信息，那如何关联后端Pod呢？前文已经提到Service通过Label Selector选择与之匹配的Pod。那么被Service选中的Pod，当它们运行且能对外提供服务后，Kubernetes的Endpoints Controller会生成一个新的Endpoints对象，记录Pod的IP和端口，这就解决了前文提到的后端实例健康检查问题。</li>
<li>Kubernetes会从集群的可用服务IP池中为每个新创建的服务分配一个稳定的集群内访问IP地址，称为Cluster IP。Kubernetes还会通过添加DNS条目为Cluster IP分配主机名。Cluster IP和主机名在集群内是独一无二的，并且在服务的整个生命周期内不会更改。只有将服务从集群中删除，Kubernetes才会释放Cluster IP和主机名。用户可以使用服务的Cluster IP或主机名访问正常运行的Pod。</li>
<li>Kubernetes使用Kube-proxy组件管理各服务与之后端Pod的连接，该组件在每个节点上运行。</li>
<li>Kube-proxy是一个基于出站流量的负载平衡控制器，它监控Kubernetes API Service并持续将服务IP（包括Cluster IP等）映射到运行状况良好的Pod，落实到主机上就是iptables&#x2F;IPVS等路由规则。访问服务的IP会被这些路由规则直接DNAT到Pod IP，然后走底层容器网络送到对应的Pod。</li>
<li>服务分配的Cluster IP是一个虚拟IP，刚接触Kubernetes Service的人经常犯的错误是试图ping这个IP，然后发现它没有任何响应。实际上，这个虚拟IP只有和它的port一起使用才有作用，直接访问该IP或者想访问该IP的其他端口都是徒劳。</li>
<li>Kubernetes Service能够支持TCP、UDP和SCTP三种协议，默认是TCP协议。</li>
<li>当Service的后端Pod准备就绪后，Kubernetes会生成一个新的Endpoints对象，而且这个Endpoints对象和Service同名。</li>
<li>Service的三个port先来看一个最简单的Service定义：Service的几个port的概念很容易混淆，它们分别是port、targetPort和NodePort。port表示Service暴露的服务端口，也是客户端访问用的端口，例如Cluster IP:port是提供给集群内部客户访问Service的入口。需要注意的是，port不仅是Cluster IP上暴露的端口，还可以是external IP和Load Balancer IP。Service的port并不监听在节点IP上，即无法通过节点IP:port的方式访问Service。NodePort是Kubernetes提供给集群外部访问Service入口的一种方式（另一种方式是Load Balancer），所以可以通过Node IP:nodePort的方式提供集群外访问Service的入口。需要注意的是，我们这里说的集群外指的是Pod网段外，例如Kubernetes节点或因特网。targetPort很好理解，它是应用程序实际监听Pod内流量的端口，从port和NodePort上到来的数据，最终经过Kube-proxy流入后端Pod的targetPort进入容器。在配置服务时，可以选择定义port和targetPort的值重新映射其监听端口，这也被称为Service的端口重映射。Kube-proxy通过在节点上iptables规则管理此端口的重新映射过程。</li>
<li>Kubernetes Service有几种类型：Cluster IP、Load Balancer和NodePort。</li>
<li>其中，Cluster IP是默认类型，自动分配集群内部可以访问的虚IP——Cluster IP。</li>
<li>Cluster IP的主要作用是方便集群内Pod到Pod之间的调用。</li>
<li>Cluster IP主要在每个node节点使用iptables，将发向Cluster IP对应端口的数据转发到后端Pod中</li>
<li>NodePort的实现机制是Kube-proxy会创建一个iptables规则，所有访问本地NodePort的网络包都会被直接转发至后端Port。</li>
<li>NodePort的问题集中体现在性能和可对宿主机端口占用方面。一旦服务多起来，NodePort在每个节点上开启的端口会变得非常庞大且难以维护</li>
<li>最早的时候，Kubernetes采用了Docker曾经使用过的方法——环境变量。Kubelet创建每个Pod时，会把系统当前所有服务的IP和端口信息都通过环境变量的方式注入容器。这样Pod中的应用可以通过读取环境变量获取所需服务的地址信息。</li>
<li>但这种方式的缺点也很明显：·容易环境变量洪泛，Docker启动参数过长会影响性能，甚至直接导致容器启动失败；·Pod想要访问的任何Service必须在Pod自己被创建之前创建，否则这些环境变量就不会被注入。更理想的方案是，应用能够直接使用服务的名字，不需要关心它实际的IP地址，中间的转换能够自动完成。名字和IP之间的转换即DNS，DNS的方式并没有以上两个限制。在Kubernetes中使用域名服务，即假设Service（my-svc）在namespace（my-ns）中，暴露名为http的TCP端口，那么在Kubernetes的DNS服务器中会生成两种记录，分别是A记录：域名（my-svc.my-ns）到Cluster IP的映射和SRV记录。</li>
<li>所谓的无头（headless）Service即没有selector的Service。Servcie抽象了该如何访问Kubernetes Pod，也能够抽象其他类型的backend</li>
</ul>
<h4 id="Kubernetes-Service的工作原理"><a href="#Kubernetes-Service的工作原理" class="headerlink" title="Kubernetes Service的工作原理"></a>Kubernetes Service的工作原理</h4><ul>
<li>主要涉及的Kubernetes组件有Controller Manager（包括Service Controller和Endpoints Controller）和Kube-proxy</li>
<li>IPVS是LVS的负载均衡模块，亦基于netfilter，但比iptables性能更高，具备更好的可扩展性。</li>
<li>IPVS支持三种负载均衡模式：Direct Routing（简称DR）、Tunneling（也称ipip模式）和NAT（也称Masq模式）。</li>
<li>Kube-proxy实现的是分布式负载均衡，而非集中式负载均衡。何谓分布式负载均衡器呢？就是每个节点都充当一个负载均衡器，每个节点上都会被配置一模一样的转发规则。上文提到，受制于iptables的实现，iptables模式的转发策略底层实现其实就是随机法，即将请求随机地分配到各个后端Pod（可能在不同节点上）。由概率统计理论得知，随着客户端调用服务端次数的增加，其实际效果越来越接近评价分配，也就是轮询（rr）的结果。缺点也比较明显，就是没有考虑机器的性能问题。根据木桶原理，Service的性能瓶颈会受性能最差的节点影响。那么，支持多种Load Balancer算法的IPVS模式呢？例如，lc（最小连接数）策略能否奏效？受制于Kube-proxy的分布式负载均衡架构，恐怕很难。同一个后端Pod可能有不同的Kube-proxy把请求转发给它，因此任何一个Kube-proxy都无法准确估计其后端Pod的连接数，故最小连接数这种转发策略无法派上用场。不过，可以尝试IPVS模式的sed（最短时延）转发策略。</li>
</ul>
<h4 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a>Ingress</h4><ul>
<li>Ingress Controller将Ingress入口地址和后端Pod地址的映射关系（规则）实时刷新到Load Balancer的配置文件中，再让负载均衡器重载（reload）该规则，便可实现服务的负载均衡和自动发现。</li>
<li>Kubernetes为什么要发明Ingress这个概念呢？笔者认为，其中一个重要的原因便是服务动态发现和负载均衡。在微服务的开发模式下，外部网络要通过域名、UR路径、负载均衡等转发到后端私有网络中，微服务之所以称为微，是因为它是动态变化的，它会经常被增加、删除或更新。传统的反向代理对服务动态变化的支持不是很方便，也就是服务变更后，不是很容易马上改变配置和热加载。Nginx Ingress Controller的出现就是为了解决这个问题，它可以时刻监听服务注册或服务编排API，随时感知后端服务变化，自动重新更改配置并重新热加载，期间服务不会暂停或停止，这对用户来说是无感知的。</li>
<li>因为微服务架构及Kubernetes等编排工具最近几年才开始逐渐流行，所以一开始的反向代理服务器（例如Nginx和HA Proxy）并未提供对微服务的支持，才会出现Nginx Ingress Controller这种中间层做Kubernetes和负载均衡器（例如Nginx）之间的适配器（adapter）。Nginx Ingress Controller的存在就是为了与Kubernetes交互，同时刷新Nginx配置，还能重载Nginx。而号称云原生边界路由的Traefik设计得更彻底，首先它是个反向代理，其次原生提供了对Kubernetes的支持，也就是说，Traefik本身就能跟Kubernetes打交道，感知Kubernetes集群服务的更新。Traefik是原生支持Kubernetes Ingress的，因此用户在使用Traefik时无须再开发一套Nginx Ingress Controller，受到了广大运维人员的好评。相比Nginx和HA Proxy这类老古董，Traefik设计思想比较先进，有点“Envoy+Istio”降维打击Nginx的意思。</li>
</ul>
<h3 id="RC（Replication-Controller）"><a href="#RC（Replication-Controller）" class="headerlink" title="RC（Replication Controller）"></a>RC（Replication Controller）</h3><ul>
<li>为需要扩容的Service关联的Pod创建一个RC（定义Pod副本数量，Label等）</li>
<li>RC是Kubernetes系统中的核心概念之一，简单来说，它其实定义了一个期望的场景，即声明某种Pod的副本数量在任意时刻都符合某个预期值。</li>
<li>RC的定义包括如下几个部分。<ul>
<li>Pod期待的副本数量。</li>
<li>用于筛选目标Pod的Label Selector。</li>
<li>当Pod的副本数量小于预期数量时，用于创建新Pod的Pod模板（template）。</li>
</ul>
</li>
<li>定义了一个RC并将其提交到Kubernetes集群中后，Master上的Controller Manager组件就得到通知，定期巡检系统中当前存活的目标Pod，并确保目标Pod实例的数量刚好等于此RC的期望值。</li>
<li>最佳的系统升级方式是旧版本的Pod每停止一个，就同时创建一个新版本的Pod，在整个升级过程中此消彼长，而运行中的Pod数量始终是10个，几分钟以后，当所有的Pod都已经是新版本时，系统升级完成。通过RC机制，Kubernetes很容易就实现了这种高级实用的特性，被称为“滚动升级”（Rolling Update）</li>
<li>总结一下Replication Controller的职责，如下所述。<ol>
<li>确保在当前集群中有且仅有N个Pod实例，N是在RC中定义的Pod副本数量。</li>
<li>通过调整RC的spec.replicas属性值来实现系统扩容或者缩容。</li>
<li>通过改变RC中的Pod模板（主要是镜像版本）来实现系统的滚动升级。</li>
</ol>
</li>
</ul>
<h4 id="Replica-Set"><a href="#Replica-Set" class="headerlink" title="Replica Set"></a>Replica Set</h4><ul>
<li><p>Replication Controller由于与Kubernetes代码中的模块Replication Controller同名，同时“Replication Controller”无法准确表达它的本意，所以在Kubernetes 1.2中，升级为另外一个新概念——Replica Set，官方解释其为“下一代的RC”。Replica Set与RC当前的唯一区别是，Replica Sets支持基于集合的Label selector（Set-based selector），而RC只支持基于等式的Label Selector（equality-based selector），这使得Replica Set的功能更强。</p>
</li>
<li><p>kubectl命令行工具适用于RC的绝大部分命令同样适用于Replica Set。此外，我们当前很少单独使用Replica Set，它主要被Deployment这个更高层的资源对象所使用，从而形成一整套Pod创建、删除、更新的编排机制。我们在使用Deployment时，无须关心它是如何创建和维护Replica Set的，这一切都是自动发生的。</p>
</li>
<li><p>Replica Set与Deployment这两个重要的资源对象逐步替代了之前RC的作用，是Kubernetes 1.3里Pod自动扩容（伸缩）这个告警功能实现的基础</p>
</li>
<li><p>总结一下RC（Replica Set）的一些特性与作用。</p>
<ul>
<li>在大多数情况下，我们通过定义一个RC实现Pod的创建及副本数量的自动控制。</li>
<li>在RC里包括完整的Pod定义模板。</li>
<li>RC通过Label Selector机制实现对Pod副本的自动控制。</li>
<li>通过改变RC里的Pod副本数量，可以实现Pod的扩容或缩容。</li>
<li>通过改变RC里Pod模板中的镜像版本，可以实现Pod的滚动升级。</li>
</ul>
</li>
</ul>
<h3 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h3><ul>
<li>Deployment是Kubernetes在1.2版本中引入的新概念，用于更好地解决Pod的编排问题。为此，Deployment在内部使用了Replica Set来实现目的，无论从Deployment的作用与目的、YAML定义，还是从它的具体命令行操作来看，我们都可以把它看作RC的一次升级，两者的相似度超过90%。Deployment相对于RC的一个最大升级是我们可以随时知道当前Pod“部署”的进度。</li>
<li>Deployment的典型使用场景有以下几个。<ul>
<li>创建一个Deployment对象来生成对应的Replica Set并完成Pod副本的创建。</li>
<li>检查Deployment的状态来看部署动作是否完成（Pod副本数量是否达到预期的值）。</li>
<li>更新Deployment以创建新的Pod（比如镜像升级）。</li>
<li>如果当前Deployment不稳定，则回滚到一个早先的Deployment版本。</li>
<li>暂停Deployment以便于一次性修改多个PodTemplateSpec的配置项，之后再恢复Deployment，进行新的发布。</li>
<li>扩展Deployment以应对高负载。</li>
<li>查看Deployment的状态，以此作为发布是否成功的指标。</li>
<li>清理不再需要的旧版本ReplicaSets。除了API声明与Kind类型等有所区别，Deployment的定义与Replica Set的定义很类似。</li>
</ul>
</li>
<li>Pod的升级和回滚：如果Pod是通过Deployment创建的，则用户可以在运行时修改Deployment的Pod定义（spec.template）或镜像名称，并应用到Deployment对象上，系统即可完成Deployment的自动更新操作。如果在更新过程中发生了错误，则还可以通过回滚操作恢复Pod的版本。<ul>
<li>通过kubectl set image命令为Deployment设置新的镜像名称</li>
<li>使用kubectl rollout status命令查看Deployment的更新过程</li>
<li>用kubectl rollout history命令检查这个Deployment部署的历史记录</li>
<li>撤销本次发布并回滚到上一个部署版本：  kubectl rollout undo deployment&#x2F;nginx-deployment</li>
<li>使用–to-revision参数指定回滚到的部署版本号：kubectl rollout undo deployment&#x2F;nginx-deployment –to-revision&#x3D;2</li>
<li>运行kubectl rolling-update命令完成Pod的滚动升级</li>
<li>如果在更新过程中发现配置有误，则用户可以中断更新操作，并通过执行kubectl rolling- update –rollback完成Pod版本的回滚</li>
</ul>
</li>
</ul>
<h3 id="RC、Deployment、ReplicaSet"><a href="#RC、Deployment、ReplicaSet" class="headerlink" title="RC、Deployment、ReplicaSet"></a>RC、Deployment、ReplicaSet</h3><h3 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h3><ul>
<li>StatefulSet从本质上来说，可以看作Deployment&#x2F;RC的一个特殊变种，它有如下特性。	<ul>
<li>StatefulSet里的每个Pod都有稳定、唯一的网络标识，可以用来发现集群内的其他成员。假设StatefulSet的名称为kafka，那么第1个Pod叫kafka-0，第2个叫kafka-1，以此类推。</li>
<li>StatefulSet控制的Pod副本的启停顺序是受控的，操作第n个Pod时，前n-1个Pod已经是运行且准备好的状态。</li>
<li>StatefulSet里的Pod采用稳定的持久化存储卷，通过PV或PVC来实现，删除Pod时默认不会删除与StatefulSet相关的存储卷（为了保证数据的安全）。</li>
</ul>
</li>
<li>StatefulSet除了要与PV卷捆绑使用以存储Pod的状态数据，还要与Headless Service配合使用，即在每个StatefulSet定义中都要声明它属于哪个Headless Service。Headless Service与普通Service的关键区别在于，它没有Cluster IP，如果解析Headless Service的DNS域名，则返回的是该Service对应的全部Pod的Endpoint列表。</li>
<li>StatefulSet的更新策略Kubernetes从1.6版本开始，针对StatefulSet的更新策略逐渐向Deployment和DaemonSet的更新策略看齐，也将实现RollingUpdate、Paritioned和OnDelete这几种策略，以保证StatefulSet中各Pod有序地、逐个地更新，并且能够保留更新历史，也能回滚到某个历史版本。</li>
<li>使用StatefulSet搭建MongoDB集群<ul>
<li>在创建StatefulSet之前，需要确保在Kubernetes集群中管理员已经创建好共享存储，并能够与StorageClass对接，以实现动态存储供应的模式。</li>
<li>创建StatefulSet为了完成MongoDB集群的搭建，需要创建如下三个资源对象。<ul>
<li>一个StorageClass，用于StatefulSet自动为各个应用Pod申请PVC。</li>
<li>一个Headless Service，用于维护MongoDB集群的状态。</li>
<li>一个StatefulSet。</li>
</ul>
</li>
<li>MongoDB集群的扩容：假设在系统运行过程中，3个mongo实例不足以满足业务的要求，这时就需要对mongo集群进行扩容。仅需要通过对StatefulSet进行scale操作，就能实现在mongo集群中自动添加新的mongo节点。使用kubectl scale命令将StatefulSet设置为4个实例：        # kubectl scale –replicas&#x3D;4 statefulset mongo，同时，系统也为mongo-3分配了一个新的PVC用于保存数据</li>
<li>自动故障恢复（MongoDB集群的高可用）：Kubernetes使用StatefulSet来搭建有状态的应用集群（MongoDB、MySQL等），同部署无状态的应用一样简便。Kubernetes能够保证StatefulSet中各应用实例在创建和运行的过程中，都具有固定的身份标识和独立的后端存储；还支持在运行时对集群规模进行扩容、保障集群的高可用等非常重要的功能。</li>
</ul>
</li>
</ul>
<h3 id="HPA"><a href="#HPA" class="headerlink" title="HPA"></a>HPA</h3><ul>
<li>Horizontal Pod Autoscaling（Pod横向自动扩容，HPA）。HPA与之前的RC、Deployment一样，也属于一种Kubernetes资源对象。。</li>
<li>HPA有以下两种方式作为Pod负载的度量指标。<ul>
<li>CPUUtilizationPercentage。</li>
<li>应用程序自定义的度量指标，比如服务在每秒内的相应请求数（TPS或QPS）。</li>
</ul>
</li>
</ul>
<h3 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h3><ul>
<li>Job所控制的Pod副本是短暂运行的，可以将其视为一组Docker容器，其中的每个Docker容器都仅仅运行一次。当Job控制的所有Pod副本都运行结束时，对应的Job也就结束了。Job在实现方式上与RC等副本控制器不同，Job生成的Pod副本是不能自动重启的，对应Pod副本的RestartPoliy都被设置为Never。因此，当对应的Pod副本都执行完成时，相应的Job也就完成了控制使命，即Job生成的Pod在Kubernetes中是短暂存在的。Kubernetes在1.5版本之后又提供了类似crontab的定时任务——CronJob，解决了某些批处理任务需要定时反复执行的问题。</li>
<li>Job所控制的Pod副本的工作模式能够多实例并行计算，以TensorFlow框架为例，可以将一个机器学习的计算任务分布到10台机器上，在每台机器上都运行一个worker执行计算任务，这很适合通过Job生成10个Pod副本同时启动运算。</li>
</ul>
<h3 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h3><ul>
<li>在每个Node上调度并且仅仅创建一个Pod副本。这种调度通常用于系统监控相关的Pod，比如主机上的日志采集、主机性能采集等进程需要被部署到集群中的每个节点，并且只能部署一个副本，这就是DaemonSet这种特殊Pod副本控制器所解决的问题。</li>
<li>这种用法适合有这种需求的应用。◎ 在每个Node上都运行一个GlusterFS存储或者Ceph存储的Daemon进程。◎ 在每个Node上都运行一个日志采集程序，例如Fluentd或者Logstach。◎ 在每个Node上都运行一个性能监控程序，采集该Node的运行性能数据，例如Prometheus Node Exporter、collectd、New Relic agent或者Ganglia gmond等。</li>
<li>目前DaemonSet的升级策略包括两种：OnDelete和RollingUpdate。</li>
</ul>
<h3 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h3><ul>
<li>Volume（存储卷）是Pod中能够被多个容器访问的共享目录。Kubernetes的Volume概念、用途和目的与Docker的Volume比较类似，但两者不能等价。首先，Kubernetes中的Volume被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下；其次，Kubernetes中的Volume与Pod的生命周期相同，但与容器的生命周期不相关，当容器终止或者重启时，Volume中的数据也不会丢失。最后，Kubernetes支持多种类型的Volume，例如GlusterFS、Ceph等先进的分布式文件系统。</li>
<li>Volume的使用也比较简单，在大多数情况下，我们先在Pod上声明一个Volume，然后在容器里引用该Volume并挂载（Mount）到容器里的某个目录上。</li>
<li>Kubernetes的Volume还扩展出了一种非常有实用价值的功能，即容器配置文件集中化定义与管理，这是通过ConfigMap这种新的资源对象来实现的。</li>
<li>Volume是被定义在Pod上的，属于计算资源的一部分，而实际上，网络存储是相对独立于计算资源而存在的一种实体资源。</li>
<li>同一个Pod中的多个容器能够共享Pod级别的存储卷Volume。</li>
<li>PV可以被理解成Kubernetes集群中的某个网络存储对应的一块存储，它与Volume类似，但有以下区别。<ul>
<li>PV只能是网络存储，不属于任何Node，但可以在每个Node上访问。</li>
<li>PV并不是被定义在Pod上的，而是独立于Pod之外定义的。</li>
<li>PV目前支持的类型包括：gcePersistentDis。</li>
</ul>
</li>
</ul>
<h3 id="PV、PVC、StorageClass"><a href="#PV、PVC、StorageClass" class="headerlink" title="PV、PVC、StorageClass"></a>PV、PVC、StorageClass</h3><ul>
<li><a href="https://cloud.tencent.com/developer/article/1755618">k8s之PV、PVC、StorageClass详解</a></li>
<li>PV是对底层网络共享存储的抽象，将共享存储定义为一种“资源”，比如Node也是容器应用可以消费的资源。PV由管理员创建和配置，与共享存储的具体实现直接相关。</li>
<li>PVC则是用户对存储资源的一个“申请”，就像Pod消费Node资源一样，PVC能够消费PV资源。PVC可以申请特定的存储空间和访问模式。（PVC 的全称是：PersistentVolumeClaim（持久化卷声明），PVC 是用户存储的一种声明）</li>
<li>StorageClass，用于标记存储资源的特性和性能，管理员可以将存储资源定义为某种类别，正如存储设备对于自身的配置描述（Profile）。根据StorageClass的描述可以直观的得知各种存储资源的特性，就可以根据应用对存储资源的需求去申请存储资源了。存储卷可以按需创建。</li>
<li>数据的容灾由具体安装部署的服务自行实现，k8s只负责资源的分配。</li>
</ul>
<h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><ul>
<li>Namespace在很多情况下用于实现多租户的资源隔离。Namespace通过将集群内部的资源对象“分配”到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能被分别管理。</li>
<li>Kubernetes集群在启动后会创建一个名为default的Namespace，通过kubectl可以查看： <code>kubectl get namespaces</code></li>
<li>如果不特别指明Namespace，则用户创建的Pod、RC、Service都将被系统创建到这个默认的名为default的Namespace中。</li>
<li>一旦创建了Namespace，我们在创建资源对象时就可以指定这个资源对象属于哪个Namespace。</li>
<li>当给每个租户创建一个Namespace来实现多租户的资源隔离时，还能结合Kubernetes的资源配额管理，限定不同租户能占用的资源，例如CPU使用量、内存使用量等</li>
</ul>
<h3 id="CRI"><a href="#CRI" class="headerlink" title="CRI"></a>CRI</h3><ul>
<li>CRI（容器运行时接口）详解</li>
<li>归根结底，Kubernetes Node（kubelet）的主要功能就是启动和停止容器的组件，我们称之为容器运行时（Container Runtime），其中最知名的就是Docker了。为了更具扩展性，Kubernetes从1.5版本开始就加入了容器运行时插件API，即Container Runtime Interface，简称CRI。</li>
<li>kubelet使用gRPC框架通过UNIX Socket与容器运行时（或CRI代理）进行通信</li>
<li>Protocol Buffers API包含两个gRPC服务：ImageService和RuntimeService。</li>
<li>kubelet的职责在于通过RPC管理容器的生命周期，实现容器生命周期的钩子，存活和健康监测，以及执行Pod的重启策略等。</li>
<li>要尝试新的Kubelet-CRI-Docker集成，只需为kubelet启动参数加上–enable-cri&#x3D;true开关来启动CRI。这个选项从Kubernetes 1.6开始已经作为kubelet的默认选项了</li>
</ul>
<h4 id="CRI介绍"><a href="#CRI介绍" class="headerlink" title="CRI介绍"></a>CRI介绍</h4><ul>
<li><a href="https://www.infoq.cn/article/EAH8zM3VH8MgwOt5Hokc">从零开始入门 K8s：理解容器运行时接口 CRI</a></li>
<li>在 CRI 出现之前（也就是 Kubernetes v1.5 之前），Docker 作为第一个容器运行时，Kubelet 通过内嵌的 dockershim 操作 Docker API 来操作容器，进而达到一个面向终态的效果。在这之后，又出现了一种新的容器运行时 - rkt，它也想要成为 Kubernetes 支持的一个容器运行时，当时它也合到了 Kubelet 的代码之中。这两个容器运行时的加入使得 Kubernetes 的代码越来越复杂、难以维护。之后 hyber.sh 加入社区，也想成为第三个容器运行时。</li>
<li>此时就有人站出来说，我们能不能对容器运行时的操作抽象出一个接口，将 Kubelet 代码与具体的容器运行时的实现代码解耦开，只要实现了这样一套接口，就能接入到 Kubernetes 的体系中，这就是我们后来见到的 Container Runtime Interface (CRI)。</li>
</ul>
<h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul>
<li>所有以非API Server方式创建的Pod都叫作Static Pod</li>
<li>在新的Kubernetes监控体系中，Metrics Server用于提供Core Metrics（核心指标），包括Node和Pod的CPU和内存使用数据。其他Custom Metrics（自定义指标）则由第三方组件（如Prometheus）采集和存储。</li>
</ul>
<hr>
<h2 id="网络部分"><a href="#网络部分" class="headerlink" title="网络部分"></a>网络部分</h2><ul>
<li>Docker时代，需要将容器的端口映射到宿主机端口，以便在外部访问。<ul>
<li>k8s: type&#x3D;NodePort和nodePort&#x3D;30001的两个属性表明此Service开启了NodePort方式的外网访问模式。</li>
</ul>
</li>
<li>Kubernetes集群的网络配置在多个Node组成的Kubernetes集群内，跨主机的容器间网络互通是Kubernetes集群能够正常工作的前提条件。</li>
<li>Kubernetes本身并不会对跨主机的容器网络进行设置，这需要额外的工具来实现。除了谷歌公有云GCE平台提供的网络设置，一些开源的工具包括Flannel、Open vSwitch、Weave、Calico等都能够实现跨主机的容器间网络互通。随着CNI网络模型的逐渐成熟，Kubernetes将优先使用CNI网络插件打通跨主机的容器网络。</li>
<li>Kubernetes网络模型设计的一个基础原则是：每个Pod都拥有一个独立的IP地址，并假定所有Pod都在一个可以直接连通的、扁平的网络空间中。所以不管它们是否运行在同一个Node（宿主机）中，都要求它们可以直接通过对方的IP进行访问。设计这个原则的原因是，用户不需要额外考虑如何建立Pod之间的连接，也不需要考虑如何将容器端口映射到主机端口等问题。</li>
<li>Kubernetes的网络依赖于Docker，Docker的网络又离不开Linux操作系统内核特性的支持</li>
</ul>
<h3 id="IP-per-Pod模型"><a href="#IP-per-Pod模型" class="headerlink" title="IP-per-Pod模型"></a>IP-per-Pod模型</h3><ul>
<li>将IP地址和端口在Pod内部和外部都保持一致，也就不需要使用NAT来进行地址转换了</li>
<li>IP-per-Pod模式和Docker原生的通过动态端口映射方式实现的多节点访问模式有什么区别呢？主要区别是后者的动态端口映射会引入端口管理的复杂性，而且访问者看到的IP地址和端口与服务提供者实际绑定的不同（因为NAT的缘故，它们都被映射成新的地址或端口了），这也会引起应用配置的复杂化。</li>
<li>同时，标准的DNS等名字解析服务也不适用了，甚至服务注册和发现机制都将迎来挑战，因为在端口映射情况下，服务自身很难知道自己对外暴露的真实的服务IP和端口，外部应用也无法通过服务所在容器的私有IP地址和端口来访问服务。总的来说，IP-per-Pod模型是一个简单的兼容性较好的模型。从该模型的网络的端口分配、域名解析、服务发现、负载均衡、应用配置和迁移等角度来看，Pod都能够被看作一台独立的虚拟机或物理机。</li>
<li>按照这个网络抽象原则，Kubernetes对网络有什么前提和要求呢？Kubernetes对集群网络有如下要求。<ol>
<li>所有容器都可以在不用NAT的方式下同别的容器通信。</li>
<li>所有节点都可以在不用NAT的方式下同所有容器通信，反之亦然。</li>
<li>容器的地址和别人看到的地址是同一个地址。</li>
</ol>
</li>
</ul>
<h3 id="Docker网络基础"><a href="#Docker网络基础" class="headerlink" title="Docker网络基础"></a>Docker网络基础</h3><ul>
<li>网络命名空间（Network Namespace）、Veth设备对、网桥、Iptables和路由。</li>
<li>标准的Docker支持以下4类网络模式<ol>
<li>host模式：使用–net&#x3D;host指定。</li>
<li>container模式：使用–net&#x3D;container:NAME_or_ID指定。(同一个Pod内的容器)</li>
<li>none模式：使用–net&#x3D;none指定。</li>
<li>bridge模式：使用–net&#x3D;bridge指定，为默认设置。</li>
</ol>
</li>
<li>Docker的网络局限从Docker对Linux网络协议栈的操作可以看到，Docker一开始没有考虑到多主机互联的网络解决方案。</li>
<li>之后，Docker开启了一个宏伟的虚拟化网络解决方案——Libnetwork，这个概念图没有了IP，也没有了路由，已经颠覆了我们的网络常识，对于不怎么懂网络的大多数人来说，它的确很有诱惑力，未来是否会对虚拟化网络的模型产生深远冲击，我们还不得而知，但它仅仅是Docker官方当前的一次“尝试”。</li>
<li>Docker容器端口映射原理都是在本地的iptable的nat表中添加相应的规则，将访问本机IP地址:hostport的网包进行一次DNAT，转换成容器IP:containerport。</li>
<li>怎么从容器内访问外网呢？一般情况下需要两个因素：ip_forward和SNAT&#x2F;MASQUERADE。<br>在默认情况下，容器可以访问外部网络的连接，因为容器的默认网络接口为docker0网桥上的接口，即主机上的本地接口。其原理是通过Linux系统的转发功能实现的（把主机当交换机）。至于SNAT&#x2F;MASQUERADE，Docker会自动在iptables的POSTROUTING链上创建形如下面的规则：即从容器网段出来访问外网的包，都要做一次MASQUERADE，即出去的包都用主机的IP地址替换源地址。</li>
</ul>
<h4 id="Network-Namespace"><a href="#Network-Namespace" class="headerlink" title="Network Namespace"></a>Network Namespace</h4><ul>
<li><p>network namespace的增删改查功能已经集成到Linux的ip工具的netns子命令中</p>
</li>
<li><p>为了支持网络协议栈的多个实例，Linux在网络栈中引入了网络命名空间，这些独立的协议栈被隔离到不同的命名空间中。处于不同命名空间中的网络栈是完全隔离的，彼此之间无法通信，就好像两个“平行宇宙”。通过对网络资源的隔离，就能在一个宿主机上虚拟多个不同的网络环境。Docker正是利用了网络的命名空间特性，实现了不同容器之间的网络隔离。</p>
</li>
<li><p>在Linux的网络命名空间中可以有自己独立的路由表及独立的iptables设置来提供包转发、NAT及IP包过滤等功能。为了隔离出独立的协议栈，需要纳入命名空间的元素有进程、套接字、网络设备等。进程创建的套接字必须属于某个命名空间，套接字的操作也必须在命名空间中进行。同样，网络设备也必须属于某个命名空间。因为网络设备属于公共资源，所以可以通过修改属性实现在命名空间之间移动。当然，是否允许移动与设备的特征有关。</p>
</li>
<li><p>Linux的网络协议栈是十分复杂的，为了支持独立的协议栈，相关的这些全局变量都必须被修改为协议栈私有。最好的办法就是让这些全局变量成为一个Net Namespace变量的成员，然后为协议栈的函数调用加入一个Namespace参数。这就是Linux实现网络命名空间的核心。同时，为了保证对已经开发的应用程序及内核代码的兼容性，内核代码隐式地使用了命名空间中的变量。程序如果没有对命名空间有特殊需求，就不需要编写额外的代码，网络命名空间对应用程序而言是透明的。</p>
</li>
</ul>
<h4 id="tun-x2F-tap"><a href="#tun-x2F-tap" class="headerlink" title="tun&#x2F;tap"></a>tun&#x2F;tap</h4><ul>
<li><p>它是一组通用的虚拟驱动程序包，里面包含了两个设备，分别是用于网络数据包处理的虚拟网卡驱动，以及用于内核空间与用户空间交互的字符设备（Character Devices，这里具体指&#x2F;dev&#x2F;net&#x2F;tun）驱动。</p>
</li>
<li><p>tun和tap是两个相对独立的虚拟网络设备，其中tap模拟了以太网设备，操作二层数据包（以太帧），tun则模拟了网络层设备，操作三层数据包（IP报文）。</p>
</li>
<li><p>使用tun&#x2F;tap设备的目的是实现把来自协议栈的数据包先交由某个打开了&#x2F;dev&#x2F;net&#x2F;tun字符设备的用户进程处理后，再把数据包重新发回到链路中。你可以通俗地将它理解为这块虚拟化网卡驱动一端连接着网络协议栈，另一端连接着用户态程序，而普通的网卡驱动则是一端连接则网络协议栈，另一端连接着物理网卡。只要协议栈中的数据包能被用户态程序截获并加工处理，程序员就有足够的舞台空间去玩出各种花样，譬如数据压缩、流量加密、透明代理等功能都能够以此为基础来实现，比如典型的VPN应用程序。</p>
</li>
<li><p>使用tun&#x2F;tap设备传输数据需要经过两次协议栈，不可避免地会有一定的性能损耗，如果条件允许，容器对容器的直接通信并不会把tun&#x2F;tap作为首选方案，一般是基于稍后介绍的veth来实现的。但是tun&#x2F;tap没有veth那样要求设备成对出现、数据要原样传输的限制，数据包到用户态程序后，程序员就有完全掌控的权力，要进行哪些修改，要发送到什么地方，都可以编写代码去实现，因此tun&#x2F;tap方案比起veth方案有更广泛的适用范围。</p>
</li>
<li><p>tun&#x2F;tap设备到底是什么？从Linux文件系统的角度看，它是用户可以用文件句柄操作的字符设备；从网络虚拟化角度看，它是虚拟网卡，一端连着网络协议栈，另一端连着用户态程序。</p>
</li>
<li><p>tun表示虚拟的是点对点设备，tap表示虚拟的是以太网设备</p>
</li>
<li><p>tun&#x2F;tap设备可以将TCP&#x2F;IP协议栈处理好的网络包发送给任何一个使用tun&#x2F;tap驱动的进程，由进程重新处理后发到物理链路中。tun&#x2F;tap设备就像是埋在用户程序空间的一个钩子，我们可以很方便地将对网络包的处理程序挂在这个钩子上，OpenVPN、Vtun、flannel都是基于它实现隧道包封装的。</p>
</li>
<li><p>从网络协议栈的角度看，tun&#x2F;tap设备这类虚拟网卡与物理网卡并无区别。只是对tun&#x2F;tap设备而言，它与物理网卡的不同表现在它的数据源不是物理链路，而是来自用户态！这也是tun&#x2F;tap设备的最大价值所在</p>
</li>
<li><p>flannel的UDP模式的技术要点就是tun&#x2F;tap设备。</p>
</li>
<li><p>tun&#x2F;tap设备其实就是利用Linux的设备文件实现内核态和用户态的数据交互，而访问设备文件则会调用设备驱动相应的例程，要知道设备驱动也是内核态和用户态的一个接口。</p>
</li>
<li><p>普通的物理网卡通过网线收发数据包，而tun设备通过一个设备文件（&#x2F;dev&#x2F;tunX）收发数据包。所有对这个文件的写操作会通过tun设备转换成一个数据包传送给内核网络协议栈。当内核发送一个包给tun设备时，用户态的进程通过读取这个文件可以拿到包的内容。当然，用户态的程序也可以通过写这个文件向tun设备发送数据。tap设备与tun设备的工作原理完全相同，区别在于：·tun设备的&#x2F;dev&#x2F;tunX文件收发的是IP包，因此只能工作在L3，无法与物理网卡做桥接，但可以通过三层交换（例如ip_forward）与物理网卡连通；·tap设备的&#x2F;dev&#x2F;tapX文件收发的是链路层数据包，可以与物理网卡做桥接。</p>
</li>
<li><p>tun&#x2F;tap设备的用处是将协议栈中的部分数据包转发给用户空间的应用程序，给用户空间的程序一个处理数据包的机会。常见的tun&#x2F;tap设备使用场景有数据压缩、加密等，最常见的是VPN，包括tunnel及应用层的IPSec等。我们将使用tun设备搭建一个基于UDP的VPN</p>
</li>
</ul>
<h4 id="veth-pair（Veth设备对）"><a href="#veth-pair（Veth设备对）" class="headerlink" title="veth pair（Veth设备对）"></a>veth pair（Veth设备对）</h4><ul>
<li>veth全称是(Virtual Ethernet)虚拟以太网，其原理类似linux管道，在一个veth设备写入网络包，其对端的veth设备可以读取到对应的网络包。</li>
<li>veth实际上不是一个设备，而是一对设备，因而也常被称作veth pair。要使用veth，必须在两个独立的网络名称空间中进行才有意义，因为veth pair是一端连着协议栈，另一端彼此相连的，在veth设备的其中一端输入数据，这些数据就会从设备的另外一端原样不变地流出。</li>
<li>引入Veth设备对是为了在不同的网络命名空间之间通信，利用它可以直接将两个网络命名空间连接起来。</li>
<li>创建Veth设备对：       <code> ip link add veth0 type veth peer name veth1</code></li>
<li>veth pair的缺点<ul>
<li>veth pair相当于网线连接两个网口，打个比喻，我们平时使用电脑插路由器网线，在你电脑的网口和路由器的lan口就是veth pair。</li>
<li>其不足也在这里，只能连接两个network namespace，如果要多个network namespace进行通信，会非常复杂，你会建立一系列的veth pair，整个关系网是点对点的，也就是任意两个network namespace都需要veth pair来通信。</li>
<li>这个问题的解决办法需要依赖linux网桥(bridge)，利用网桥来将多个veth设备连接起来。</li>
</ul>
</li>
<li>由于两个容器之间采用veth通信不需要反复多次经过网络协议栈，这让veth比起tap&#x2F;tun具有更好的性能，也让veth pair的实现变的十分简单。</li>
</ul>
<h4 id="bridge（网桥）"><a href="#bridge（网桥）" class="headerlink" title="bridge（网桥）"></a>bridge（网桥）</h4><ul>
<li><p>网桥是一个二层的虚拟网络设备，把若干个网络接口“连接”起来，以使得网络接口之间的报文能够互相转发。网桥能够解析收发的报文，读取目标MAC地址的信息，和自己记录的MAC表结合，来决策报文的转发目标网络接口。为了实现这些功能，网桥会学习源MAC地址（二层网桥转发的依据就是MAC地址）。在转发报文时，网桥只需要向特定的网口进行转发，来避免不必要的网络交互。如果它遇到一个自己从未学习到的地址，就无法知道这个报文应该向哪个网络接口转发，就将报文广播给所有的网络接口（报文来源的网络接口除外）。在实际的网络中，网络拓扑不可能永久不变。设备如果被移动到另一个端口上，却没有发送任何数据，网桥设备就无法感知到这个变化，网桥还是向原来的端口转发数据包，在这种情况下数据就会丢失。所以网桥还要对学习到的MAC地址表加上超时时间（默认为5min）。如果网桥收到了对应端口MAC地址回发的包，则重置超时时间，否则过了超时时间后，就认为设备已经不在那个端口上了，它就会重新广播发送。</p>
</li>
<li><p>在Linux的内部网络栈里实现的网桥设备，作用和上面的描述相同。过去Linux主机一般都只有一个网卡，现在多网卡的机器越来越多，而且有很多虚拟的设备存在，所以Linux的网桥提供了在这些设备之间互相转发数据的二层设备。Linux内核支持网口的桥接（目前只支持以太网接口）。但是与单纯的交换机不同，交换机只是一个二层设备，对于接收到的报文，要么转发，要么丢弃。运行着Linux内核的机器本身就是一台主机，有可能是网络报文的目的地，其收到的报文除了转发和丢弃，还可能被送到网络协议栈的上层（网络层），从而被自己（这台主机本身的协议栈）消化，所以我们既可以把网桥看作一个二层设备，也可以把它看作一个三层设备。</p>
</li>
<li><p>容器先创建veth设备对（veth0、veth1），再把veth1连到同一个bridge。</p>
</li>
<li><p>配置例子：</p>
<pre>
网桥br0：分配IP地址192.168.31.1；
容器：三个网络名称空间（容器），分别编号为1、2、3，均使用veth pair接入网桥，且有如下配置：
在容器一端的网卡名为veth0，在网桥一端网卡名为veth1、veth2、veth3；
三个容器中的veth0网卡分配IP地址：192.168.1.10、192.168.1.11、192.168.1.12；
三个容器中的veth0网卡设置网关为网桥，即192.168.31.1；
网桥中的veth1、veth2、veth3无IP地址；
物理网卡eth0：分配的IP地址14.123.254.86；
外部网络：外部网络中有一台服务器，地址为122.246.6.183
</pre>
</li>
<li><p>混杂模式（Promiscuous mode），简称Promisc mode，俗称“监听模式”</p>
<ul>
<li>混杂模式是指一个网卡会把它接收的所有网络流量都交给CPU，而不是只把它想转交的部分交给CPU。</li>
<li>在IEEE 802定的网络规范中，每个网络帧都有一个目的MAC地址。在非混杂模式下，网卡只会接收目的MAC地址是它自己的单播帧，以及多播及广播帧；在混杂模式下，网卡会接收经过它的所有帧</li>
<li>将网络设备加入Linux bridge后，会自动进入混杂模式。</li>
</ul>
</li>
</ul>
<h4 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h4><ul>
<li>在Linux网络协议栈中有一组回调函数挂接点，通过这些挂接点挂接的钩子函数可以在Linux网络栈处理数据包的过程中对数据包进行一些操作，例如过滤、修改、丢弃等。整个挂接点技术叫作Netfilter和iptables。</li>
<li>Netfilter负责在内核中执行各种挂接的规则，运行在内核模式中；而iptables是在用户模式下运行的进程，负责协助和维护内核中Netfilter的各种规则表。二者互相配合来实现整个Linux网络协议栈中灵活的数据包处理机制。</li>
</ul>
<h4 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h4><ul>
<li>路由功能由IP层维护的一张路由表来实现。当主机收到数据报文时，它用此表来决策接下来应该做什么操作。当从网络侧接收到数据报文时，IP层首先会检查报文的IP地址是否与主机自身的地址相同。如果数据报文中的IP地址是主机自身的地址，那么报文将被发送到传输层相应的协议中。如果报文中的IP地址不是主机自身的地址，并且主机配置了路由功能，那么报文将被转发，否则，报文将被丢弃。</li>
<li>Linux的路由表至少包括两个表（当启用策略路由时，还会有其他表）：一个是LOCAL，另一个是MAIN。在LOCAL表中会包含所有的本地设备地址。LOCAL路由表是在配置网络设备地址时自动创建的。LOCAL表用于供Linux协议栈识别本地地址，以及进行本地各个不同网络接口之间的数据转发。可以通过下面的命令查看LOCAL表的内容：<code> ip route show table local type local</code></li>
<li>MAIN表用于各类网络IP地址的转发。它的建立既可以使用静态配置生成，也可以使用动态路由发现协议生成。动态路由发现协议一般使用组播功能来通过发送路由发现数据，动态地交换和获取网络的路由信息，并更新到路由表中。路由表的查看我们可以使用ip route list命令查看当前的路由表：<code> ip route list</code></li>
<li>Netstat -rn 是另一个查看路由表的工具：<br>在它显示的信息中，如果标志是U，则说明是可达路由；如果标志是G，则说明这个网络接口连接的是网关，否则说明这个接口直连主机。</li>
</ul>
<h4 id="Linux隧道：ipip"><a href="#Linux隧道：ipip" class="headerlink" title="Linux隧道：ipip"></a>Linux隧道：ipip</h4><ul>
<li>tun设备也叫作点对点设备，之所以叫这个名字，是因为tun经常被用来做隧道通信（tunnel）。</li>
<li>Linux原生支持下列5种L3隧道：<ul>
<li>ipip：即IPv4 in IPv4，在IPv4报文的基础上封装一个IPv4报文；</li>
<li>GRE：即通用路由封装（Generic Routing Encapsulation），定义了在任意一种网络层协议上封装其他任意一种网络层协议的机制，适用于IPv4和IPv6；</li>
<li>sit：和ipip类似，不同的是sit用IPv4报文封装IPv6报文，即IPv6 over IPv4；</li>
<li>ISATAP：即站内自动隧道寻址协议（Intra-Site Automatic Tunnel Addressing Protocol），与sit类似，也用于IPv6的隧道封装；</li>
<li>VTI：即虚拟隧道接口（Virtual Tunnel Interface），是思科提出的一种IPSec隧道技术。下面我们以ipip为例，介绍Linux隧道通信的基本原理。：</li>
</ul>
</li>
<li>Linux L3隧道底层实现原理都基于tun设备。我们熟知的各种VPN软件，其底层实现都离不开这5种隧道协议。其他隧道实现方式与ipip隧道的大同小异。</li>
</ul>
<h4 id="VXLAN"><a href="#VXLAN" class="headerlink" title="VXLAN"></a>VXLAN</h4><ul>
<li>目前比较常见的封装报文的技术有VxLAN和隧道（gre、ipip等），其中vxlan是通过udp协议进行封装的，隧道方式是通过ip层封装的。</li>
<li>VXLAN（Virtual eXtensible LAN，虚拟可扩展的局域网），是一种虚拟化隧道通信技术。它是一种overlay（覆盖网络）技术，通过三层的网络搭建虚拟的二层网络。</li>
<li>简单来讲，VXLAN是在底层物理网络（underlay）之上使用隧道技术，依托UDP层构建的overlay的逻辑网络，使逻辑网络与物理网络解耦，实现灵活的组网需求。</li>
<li>它不仅能适配虚拟机环境，还能用于容器环境。由此可见，VXLAN这类隧道网络的一个特点是对原有的网络架构影响小，不需要对原网络做任何改动，就可在原网络的基础上架设一层新的网络。</li>
<li>不同于其他隧道协议，VXLAN是一个一对多的网络，并不仅是一对一的隧道协议。一个VXLAN设备能通过像网桥一样的学习方式学习到其他对端的IP地址，也可以直接配置静态转发表。</li>
<li>VLAN技术的缺陷是VLAN Header预留的长度只有12 bit，故最多只能支持2的12次方（4096）子网的划分，无法满足云计算场景下主机数量日益增长的需求。VXLAN能突破VLAN的最多4096个子网的数量限制，以满足大规模云计算数据中心的需求。</li>
<li>VXLAN的报文就是MAC in UDP，即在三层网络的基础上构建一个虚拟的二层网络。为什么这么说呢？VXLAN的封包格式显示原来的二层以太网帧（包含MAC头部、IP头部和传输层头部的报文），被放在VXLAN包头里进行封装，再套到标准的UDP头部（UDP头部、IP头部和MAC头部），用来在底层网络上传输报文。</li>
<li>总的来说，VXLAN报文的转发过程就是：原始报文经过VTEP，被Linux内核添加上VXLAN包头及外层的UDP头部，再发送出去，对端VTEP接收到VXLAN报文后拆除外层UDP头部，并根据VXLAN头部的VNI把原始报文发送到目的服务器。</li>
<li>传统的局域网是怎么构建的(非虚拟lan)，要构成一个局域网，需要一台路由器设备作为网关和其他接入该路由器的设备，这时候lan是这样定义的：接在同一台路由器上（物理）且具有相同网络号（逻辑）的设备在同一个局域网下。那么vxlan可以使得局域网的构建可以打破物理上的限制，构建逻辑上的lan——评论</li>
</ul>
<h4 id="Macvlan"><a href="#Macvlan" class="headerlink" title="Macvlan"></a>Macvlan</h4><ul>
<li>通常，我们在自定义Docker与外部网络通信的网络时会用到NAT，还有Linux bridge、Open vSwitch、Macvlan几种选择，相比之下，Macvlan拥有更好的性能。</li>
<li>在Macvlan出现之前，我们可以通过网卡别名（例如eth0:1）的方式为一块以太网卡添加多个IP地址，却不能为其添加多个MAC地址。原因是以太网卡是以MAC地址为唯一识别的，而网卡别名并没有改变这些网卡的MAC地址。Macvlan接口可以看作是物理以太网接口的虚拟子接口。Macvlan允许用户在主机的一个网络接口上配置多个虚拟的网络接口，每个Macvlan接口都有自己的区别于父接口的MAC地址，并且可以像普通网络接口一样分配IP地址。因此，使用Macvlan技术带来的效果是一块物理网卡上可以绑定多个IP地址，每个IP地址都有自己的MAC地址。</li>
<li>使用Macvlan的虚拟机或者容器网络与主机在同一个网段，即同一个广播域中。</li>
<li>Macvlan支持5种模式，分别是bridge、VEPA、Private、Passthru和Source模式。</li>
<li>在Macvlan虚拟网络世界中，物理网卡（父接口）相当于一个交换机，对于进出其子Macvlan网卡的数据包，物理网卡只转发数据包而不处理数据包，于是也就造成了使用本机Macvlan网卡的IP无法和物理网卡的IP通信。总结，Macvlan只为虚拟机或容器提供访问外部物理网络的连接。</li>
<li>Macvlan是将虚拟机或容器通过二层连接到物理网络的一个不错的方案，但它也有一些局限性，例如：·因为每个虚拟网卡都要有自己的MAC地址，所以Macvlan需要大量的MAC地址，而Linux主机连接的交换机可能会限制一个物理端口的MAC地址数量上限，而且许多物理网卡的MAC地址数量也有限制，超过这个限制就会影响到系统的性能；·IEEE 802.11标准（即无线网络）不喜欢同一个客户端上有多个MAC地址，这意味着你的Macvlan子接口没法在无线网卡上通信。我们可以通过复杂的办法突破以上这些限制，但还有一种更简单的办法。那就是使用IPvlan。</li>
</ul>
<h4 id="IPvlan"><a href="#IPvlan" class="headerlink" title="IPvlan"></a>IPvlan</h4><ul>
<li>Macvlan和IPvlan虚拟网络模型提供的功能看起来差不多，那么，什么时候需要用到IPvlan呢？要回答这个问题，先来看看Macvlan先天存在的不足：·无法支持大量的MAC地址；·无法工作在无线网络环境中。</li>
<li>与Macvlan类似，IPvlan也是从一个主机接口虚拟出多个虚拟网络接口。区别在于IPvlan所有的虚拟接口都有相同的MAC地址，而IP地址却各不相同。因为所有的IPvlan虚拟接口共享MAC地址，所以特别需要注意DHCP使用的场景。DHCP分配IP地址的时候一般会用MAC地址作为机器的标识。因此，在使用Macvlan的情况下，客户端动态获取IP的时候需要配置唯一的Client ID，并且DHCP服务器也要使用该字段作为机器标识，而不是使用MAC地址。</li>
<li>外部网络默认情况下是不知道IPvlan虚拟出来的网络的，如果不在外部路由器上配置好对应的路由规则，那么IPvlan的网络是不能被外部直接访问的。</li>
<li>我们将IPvlan称为Macvlan的“救护员”是因为IPvlan除了能够完美解决以上问题，还允许用户基于IPvlan搭建比较复杂的网络拓扑，不再基于Macvlan的简单的二层网络，而是能够与BGP（Boader Gateway Protocol，边界网关协议）等协议扩展我们的网络边界。</li>
</ul>
<h4 id="Docker的四大网络模式"><a href="#Docker的四大网络模式" class="headerlink" title="Docker的四大网络模式"></a>Docker的四大网络模式</h4><ul>
<li>从网络的角度看容器，就是network namespace+容器的组网方案。利用network namespace，可以为Docker容器创建隔离的网络环境。容器具有完全独立的网络栈，与宿主机隔离。用户也可以让Docker容器共享主机或者其他容器的network namespace。</li>
<li>容器的网络方案可以分为三大部分：<ol>
<li>单机的容器间通信；</li>
<li>跨主机的容器间通信；</li>
<li>容器与主机间通信。</li>
</ol>
</li>
<li>Docker有以下4种网络模式：<ol>
<li>bridge模式，通过–network&#x3D;bridge指定；(Docker容器的默认组网模式)<ul>
<li>连接在docker0上的所有容器的默认网关均为docker0，即访问非本机容器网段要经过docker0网关转发，而同主机上的容器（同网段）之间通过广播通信。</li>
<li>bridge模式为Docker容器创建独立的网络栈，保证容器内的进程使用独立的网络环境，使容器和容器、容器和宿主机之间能实现网络隔离。</li>
</ul>
</li>
<li>host模式，通过–network&#x3D;host指定；<ul>
<li>连接到host网络的容器共享Docker host的网络栈，容器的网络配置与host完全一样。host模式下容器将不会获得独立的network namespace，而是和宿主机共用一个network namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。</li>
<li>host模式下的容器可以看到宿主机的所有网卡信息，甚至可以直接使用宿主机IP地址和主机名与外界通信，无须额外进行NAT，也无须通过Linux bridge进行转发或者进行数据包的封装。</li>
<li>当然，host模式有利有弊，优点是没有性能损耗且配置方便，缺点也很明显，例如：·容器没有隔离、独立的网络栈：容器因与宿主机共用网络栈而争抢网络资源，并且容器崩溃也可能使主机崩溃，导致网络的隔离性不好；</li>
<li>端口资源冲突：宿主机上已经使用的端口就不能再用了。</li>
</ul>
</li>
<li>container模式，通过–network&#x3D;container:NAME_or_ID指定，即joiner容器；<ul>
<li>创建容器时使用–network&#x3D;container:NAME_or_ID模式，在创建新的容器时指定容器的网络和一个已经存在的容器共享一个network namespace，但是并不为Docker容器进行任何网络配置，这个Docker容器没有网卡、IP、路由等信息，需要手动为Docker容器添加网卡、配置IP等。需要注意的是，container模式指定新创建的容器和已经存在的任意一个容器共享一个network namespace，但不能和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过lo网卡设备通信。</li>
<li>Kubernetes的Pod网络采用的就是Docker的container模式网络，我们将在后面的章节详细介绍。</li>
</ul>
</li>
<li>none模式，通过–network&#x3D;none指定。</li>
</ol>
</li>
<li>连接在docker0上的所有容器的默认网关均为docker0，即访问非本机容器网段要经过docker0网关转发，而同主机上的容器（同网段）之间通过广播通信。<ul>
<li>none模式下的容器只有lo回环网络，没有其他网卡</li>
<li>none模式网络可以在容器创建时通过–network&#x3D;none指定。这种类型的网络没有办法联网，属于完全封闭的网络。唯一的用途是客户有充分的自由度做后续的配置。这种模式下的Docker容器拥有自己的network namespace，但是并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息，需要我们自己为Docker容器添加网卡、配置IP等。</li>
</ul>
</li>
</ul>
<h3 id="容器组网的挑战"><a href="#容器组网的挑战" class="headerlink" title="容器组网的挑战"></a>容器组网的挑战</h3><ul>
<li><p>容器网络的挑战：“以隔离的方式部署容器，在提供隔离自己容器内数据所需功能的同时，保持有效的连接性”，提炼两个关键词便是“隔离”和“连接”。</p>
</li>
<li><p>容器网络最大的挑战在跨容器通信层面，具体有以下几点：</p>
<ol>
<li>虚拟机拥有较强的隔离机制，虚拟网卡与硬件网卡在使用上没有什么区别。由于容器基于网络隔离能力较弱的network namespace，容器网络的设计首要考虑隔离性和安全性；</li>
<li>出于安全考虑，很多情况下容器会被部署在虚拟机内部，这种嵌套部署对应一个新的组网模型；</li>
<li>原生Docker容器不解决跨主机通信问题，而大规模的容器部署势必涉及不同主机上的网络通信；</li>
<li>容器相较虚拟机生命周期更短，重启更加频繁，重启后IP地址将发生变化，需要进行高效的网络地址管理，因此静态的IP地址分配或DHCP（耗费数秒才能生效）将不起作用；</li>
<li>在创建虚拟机的时候，IP地址的分配是一种静态方式。但是在容器上面，IP地址的分配通常是动态的。在创建容器时，通常我们不知道它的IP是什么，只有真正运行后才能知道；</li>
<li>容器相较虚拟机发生迁移的频率更高，且原生的Docker容器不支持热迁移，迁移后的容器面临IP地址漂移，而且经常出现不在同一网段的情况，对应的网络策略的刷新要及时跟上；</li>
<li>容器的部署数量远大于虚拟机，如果为每个容器分配一个主机网络的IP地址，则可能会导致不够分配；</li>
<li>大规模跨机部署带来多主机间的ARP洪泛，造成大量的资源浪费；</li>
<li>大部分的容器网络方案都会使用iptables和NAT，NAT的存在会造成通信两端看不到彼此的真实IP地址，并且iptable和NAT的结合使用限制了可扩展性和性能，这让使用容器的主要优势之一荡然无存；</li>
<li>大规模部署使用veth设备会影响网络性能，最严重时甚至会比裸机降低50%；</li>
<li>过多的MAC地址。当MAC地址超过限制时，主机中的物理网络接口卡虽然可以切换到混杂模式，但会导致性能下降，而且顶级机架（ToR）交换机可支持的MAC地址数量也有上限。</li>
</ol>
</li>
<li><p>针对以上挑战，有一些针对性的解决方案。例如，可以使用Macvlan和IPvlan替代veth，以降低处理veth网络的性能开销。当使用IPvlan驱动时，IPvlan工作在L3，而L3网络不会受到洪泛影响，因此只有主机的物理网卡MAC地址可见，容器MAC地址不会暴露在网络中，从而解决数据中心可见MAC地址过多给ToR交换机带来的影响。容器网络对NAT的依赖及NAT自身的局限性，而避免NAT的基本思想是将容器和虚拟机、主机同等对待。我们可以直接将容器连接到主机的网络接口来实现这一点，即容器与主机共享本地局域网（LAN）的资源，通过DHCP服务器或静态地址分配的方式给容器分配LAN的IP地址。这样一来，所有L4的容器网络端口完全暴露，虽然这种直接的暴露比管理映射端口更好，但保证安全状态需要网络策略的加持。直接连接到物理接口，即把容器的veth&#x2F;Macvlan网卡与连通互联网的物理网卡桥接。不过，这种方法需要修改物理接口，即移除IP地址并将其分配到桥接接口上。</p>
</li>
<li><p>消除NAT的第二种方法是把主机变成全面的路由器，甚至是使用BGP的路由器。主机会将前缀路由到主机中的容器，每个容器会使用全球唯一的IP地址。尽管在IPv4地址空间已经耗尽的今天，给每个容器提供一个完全可路由的IPv4地址有些不太实际，但IPv6将使这种主机作为路由器的容器组网技术变得可能，事实上很多公有云都已经支持IPv6。以上这些都只是针对某个具体问题的，而非整体的端到端的方案，例如IP地址管理、跨主机通信、消除NAT、安全策略等。Docker最初并没有提供必要的此类能力，在开始的很长一段时间内，只支持使用Linux bridge+iptables的单机网络部署方式，这种方式下容器的可见性只存在于主机内部，这严重地限制了容器集群的规模及可用性！</p>
</li>
<li><p>Docker目前拥有两种网络解决方案</p>
<ul>
<li>一种是原生方式，即Docker官方支持且无须配置的开箱即用。</li>
<li>允许第三方网络管理工具以插件方式替代Docker中内置的网络功能，接口标准便是CNM。</li>
<li>所以docker + calico + k8s 使用的是CNM还是CNI？？TODO</li>
</ul>
</li>
<li><p>对相对成熟的第三方容器解决方案进行分类，则大致可以分为隧道方案和路由方案。</p>
</li>
<li><p>当前主流的容器网络虚拟化技术有Linux bridge、Macvlan、IPvlan、Open vSwitch、flannel、Weave、Calico等。而容器网络最基础的一环是为容器分配IP地址，主流的方案有本地存储+固定网段的host-local，DHCP，分布式存储+IPAM的flannel和SDN的Weave等。任何一个主流的容器组网方案无非就是网络虚拟机+IP地址分配，即Linux bridge、Macvlan、IPvlan、Open vSwitch、flannel、Weave、Calico等虚拟化技术和host-local、DHCP、flannel、Weave任取两样的排列组合。</p>
</li>
<li><p>calico方案是使用哪种IP地址分配方案？？？k8s pod ip是k8s分配的，使用calico只需要规划好node ip的分配。</p>
</li>
<li><p>overlay网络</p>
<ul>
<li>隧道网络也称为overlay网络，有时也被直译为覆盖网络。</li>
<li>overlay网络最大的优点是适用于几乎所有网络基础架构，它唯一的要求是主机之间的IP连接。但overlay网络的问题是随着节点规模的增长，复杂度也会随之增加，而且用到了封包，因此出了网络问题定位起来比较麻烦。</li>
<li>典型的基于overlay的网络插件有：<ul>
<li>Weave：源自Weaveworks，包括Weave Net、Weave Scope和Weave Flux。Weave Net是一种用于构建和部署Docker容器的网络工具；</li>
<li>Open vSwitch（OVS）：基于VXLAN和GRE协议，但是性能方面损失比较严重；</li>
<li>flannel：源自CoreOS，支持自研的UDP封包及Linux内核的VXLAN协议。</li>
</ul>
</li>
<li>Weave和flannel用到的封包技术特点类似，不过使用的是VXLAN。另外，Weave的思路是共享IP而非绑定。在传输层先找到目的地址，然后把包发到对端，节点之间互相通过协议共享信息。使用UDP进行封包的时候性能损失在50%以上，使用VXLAN也会有20%～30%的损耗。</li>
</ul>
</li>
<li><p>路由方案</p>
<ul>
<li>路由方案回过头来想一下，我们为什么要封包？其实它是改包，主要解决的问题是同一个问题，即在容器网络里，主机间不知道对方的目的地址，没有办法把IP包投递到正确的地方。传统的三层网络是用路由来互相访问的，不需要封包。至于路由规则怎么维护？传统的网络解决方案是利用BGP部署一个分布式的路由集群。　传统BGP分布式路由集群方案通过路由来实现，比较典型的网络插件有：</li>
<li>Calico：源自Tigera，基于BGP的路由方案，支持很细致的ACL控制，对混合云亲和度比较高；	</li>
<li>Macvlan：从逻辑和Kernel层来看，是隔离性和性能最优的方案，基于二层隔离，需要二层路由器支持，大多数云服务商不支持，因此混合云上比较难以实现；</li>
<li>Metaswitch：容器内部配一个路由指向自己宿主机的地址，这是一个纯三层的网络不存在封包，因此性能接近原生网络。路由方案的另一个优点是出了问题也很容易排查。路由方案往往需要用户了解底层网络基础结构，因此使用和运维门槛较高。</li>
<li>Calico是一个纯三层网络方案。不同主机上的每个容器内部都配一个路由，指向自己所在的IP地址；每台服务器变成路由器，配置自己的路由规则，通过网卡直接到达目标容器，整个过程没有封包。</li>
<li>那么，路由交换是不是很难呢？用传统的BGP技术就可以实现。这个协议在大规模应用下是一个很好的场景，而且BGP有一个自治域的概念。在这个场景下会有一个问题，路由之间的信息交换实际上基于TCP，每两个之间都有一个TCP连接，规模大了维护这些连接的开销会非常高。</li>
<li>Calico的设计灵感源自通过将整个互联网的可扩展IP网络原则压缩到数据中心级别。Calico在每一个计算节点，利用Linux Kernel实现高效的vRouter来负责数据转发，而每个vRouter通过BGP把自己节点上的工作负载的路由信息向整个Calico网络传播。小规模部署可以直接互联，大规模下可通过指定的BGP Route Reflector完成。保证最终所有的容器之间的数据流量都是通过IP路由的方式完成互联的。</li>
</ul>
</li>
</ul>
<h4 id="容器网络组网类型"><a href="#容器网络组网类型" class="headerlink" title="容器网络组网类型"></a>容器网络组网类型</h4><ul>
<li>关于容器网络对overlay和underlay的分类，常见的非主机网络（host network）的容器组网类型有L2 overlay、L3 overlay、L2 underlay和L3 underlay。</li>
</ul>
<ol>
<li><p>overlay网络</p>
<ul>
<li>overlay网络是在传统网络上虚拟出一个虚拟网络，承载的底层网络不再需要做任何适配。在容器的世界里，物理网络只承载主机网络通信，虚拟网络只承载容器网络通信。overlay网络的任何协议都要求在发送方对报文进行包头封装，接收方剥离包头。</li>
</ul>
<ol>
<li>L2 overlay<ul>
<li>传统的二层网络的范围有限，L2 overlay网络是构建在底层物理网络上的L2网络，相较于传统的L2网络，L2 overlay网络是个“大二层”的概念，其中“大”的含义是可以跨越多个数据中心（即容器可以跨L3 underlay进行L2通信），而“二层”指的是通信双方在同一个逻辑的网段内，例如172.17.1.2&#x2F;16和172.17.2.3&#x2F;16。VXLAN就是L2 overlay网络的典型实现，其通过在UDP包中封装原始L2报文，实现了容器的跨主机通信。L2 overlay网络容器可在任意宿主机间迁移而不改变其IP地址的特性，使得构建在大二层overlay网络上的容器在动态迁移时具有很高的灵活性。</li>
</ul>
</li>
<li>L3 overlay<ul>
<li>L3 overlay组网类似L2 overlay，但会在节点上增加一个网关。每个节点上的容器都在同一个子网内，可以直接进行二层通信。跨节点的容器间通信只能走L3，都会经过网关转发，性能相比于L2 overlay较弱。牺牲的性能获得了更高的灵活性，跨节点通信的容器可以存在于不同的网段中，例如192.168.1.0&#x2F;24和172.17.16.0&#x2F;24。flannel的UDP模式采用的就是L3 overlay模型。L3 overlay网络容器在主机间迁移时可能需要改变其IP地址。</li>
</ul>
</li>
</ol>
</li>
<li><p>underlay网络</p>
<ul>
<li>underlay网络一般理解为底层网络，传统的网络组网就是underlay类型，区别于上文提到的overlay网络。</li>
</ul>
<ol>
<li>L2 underlay<ul>
<li>L2 underlay网络就是链路层（L2）互通的底层网络。IPvlan L2模式和Macvlan属于L2 underlay类型的网络。</li>
</ul>
</li>
<li>L3 underlay<ul>
<li>在L3 underlay组网中，可以选择IPvlan的L3模式，该模式下IPvlan有点像路由器的功能，它在各个虚拟网络和主机网络之间进行不同网络报文的路由转发工作。只要父接口相同，即使虚拟机&#x2F;容器不在同一个网络，也可以互相ping通对方，因为IPvlan会在中间做报文的转发工作。IPvlan的L3模式，flannel的host-gw模式和Calico的BGP组网方式都是L3 underlay类型的网络。</li>
</ul>
</li>
</ol>
</li>
</ol>
<h3 id="Kubernetes网络"><a href="#Kubernetes网络" class="headerlink" title="Kubernetes网络"></a>Kubernetes网络</h3><ul>
<li><p>Kubernetes网络包括网络模型、CNI、Service、Ingress、DNS等。在Kubernetes的网络模型中，每台服务器上的容器有自己独立的IP段，各个服务器之间的容器可以根据目标容器的IP地址进行访问。</p>
</li>
<li><p>为了实现这一目标，重点解决以下两点：</p>
<ul>
<li>各台服务器上的容器IP段不能重叠，所以需要有某种IP段分配机制，为各台服务器分配独立的IP段；</li>
<li>从某个Pod发出的流量到达其所在服务器时，服务器网络层应当具备根据目标IP地址，将流量转发到该IP所属IP段对应的目标服务器的能力。总结起来，实现Kubernetes的容器网络重点需要关注两方面：IP地址分配和路由。</li>
</ul>
</li>
<li><p>Kubernetes网络策略</p>
<ul>
<li>与Kubernetes Ingress API类似，Kubernetes只提供了Network Policy的API定义，不负责具体实现。</li>
<li>通常，Policy Controller是由Kubernetes网络插件提供的。支持Network Policy的网络插件有Calico、Cilium、Weave Net、Kube-router、Romana等。需要注意的是，flannel不在这个名单中。</li>
</ul>
</li>
</ul>
<h4 id="IP地址分配"><a href="#IP地址分配" class="headerlink" title="IP地址分配"></a>IP地址分配</h4><ul>
<li>Kubernetes使用各种IP范围为节点、Pod和服务分配IP地址。</li>
<li>系统会从集群的VPC网络为每个节点分配一个IP地址。该节点IP用于提供从控制组件（如Kube-proxy和Kubelet）到Kubernetes Master的连接；</li>
<li>系统会为每个Pod分配一个地址块内的IP地址。用户可以选择在创建集群时通过–pod-cidr指定此范围；</li>
<li>系统会从集群的VPC网络为每项服务分配一个IP地址（称为ClusterIP）。<br>大部分情况下，该VPC与节点IP地址不在同一个网段，而且用户可以选择在创建集群时自定义VPC网络。</li>
</ul>
<h4 id="Pod出站流量"><a href="#Pod出站流量" class="headerlink" title="Pod出站流量"></a>Pod出站流量</h4><ul>
<li>Kubernetes处理Pod的出站流量的方式主要分为以下三种：</li>
<li>Pod到Pod<ul>
<li>在Kubernetes集群中，每个Pod都有自己的IP地址，运行在Pod内的应用都可以使用标准的端口号，不用重新映射到不同的随机端口号。所有的Pod之间都可以保持三层网络的连通性，比如可以相互ping对方，相互发送TCP&#x2F;UDP&#x2F;SCTP数据包。CNI就是用来实现这些网络功能的标准接口。</li>
</ul>
</li>
<li>Pod到Service<ul>
<li>Pod的生命周期很短暂，但客户需要的是可靠的服务，因此Kubernetes引入了新的资源对象Service，其实它就是Pod前面的4层负载均衡器。Service总共有4种类型，其中最常用的类型是ClusterIP，这种类型的Service会自动分配一个仅集群内部可以访问的虚拟IP。Kubernetes通过Kube-proxy组件实现这些功能，每台计算节点上都运行一个Kubeproxy进程，通过复杂的iptables&#x2F;IPVS规则在Pod和Service之间进行各种过滤和NAT。</li>
</ul>
</li>
<li>Pod到集群外<ul>
<li>从Pod内部到集群外部的流量，Kubernetes会通过SNAT来处理。SNAT做的工作就是将数据包的源从Pod内部的IP:Port替换为宿主机的IP:Port。当数据包返回时，再将目的地址从宿主机的IP:Port替换为Pod内部的IP:Port，然后发送给Pod。当然，中间的整个过程对Pod来说是完全透明的，它们对地址转换不会有任何感知。</li>
</ul>
</li>
</ul>
<h4 id="Kubernetes网络架构综述"><a href="#Kubernetes网络架构综述" class="headerlink" title="Kubernetes网络架构综述"></a>Kubernetes网络架构综述</h4><ul>
<li>谈到Kubernetes的网络模型，就不能不提它著名的“单Pod单IP”模型，即每个Pod都有一个独立的IP，Pod内所有容器共享network namespace（同一个网络协议栈和IP）。</li>
<li>“单Pod单IP”网络模型为我们勾勒了一个Kubernetes扁平网络的蓝图，在这个网络世界里：容器是一等公民，容器之间直接通信，不需要额外的NAT，因此不存在源地址被伪装的情况；Node与容器网络直连，同样不需要额外的NAT。扁平化网络的优点在于：没有NAT带来的性能损耗，而且可追溯源地址，为后面的网络策略做铺垫，降低网络排错的难度等。</li>
<li>总体而言，集群内访问Pod，会经过Service；集群外访问Pod，经过的是Ingress。Service和Ingress是Kubernetes专门为服务发现而抽象出来的相关概念。</li>
<li>Kubernetes Ingress提供了负载平衡器的典型特性：HTTP路由、黏性会话、SSL终止、SSL直通、TCP和UDP负载平衡等</li>
<li>与CRI之于Kubernetes的runtime类似，Kubernetes使用CNI作为Pod网络配置的标准接口。需要注意的是，CNI并不支持Docker网络，也就是说，docker0网桥会被大部分CNI插件“视而不见”。</li>
<li>当然也有例外，Weave就是一个会处理docker0的CNI插件。</li>
</ul>
<p><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/Kubernetes%E7%BD%91%E7%BB%9C%E6%80%BB%E4%BD%93%E6%9E%B6%E6%9E%84.jpg"></p>
<ul>
<li>图中描绘了当用户在Kubernetes里创建了一个Pod后，CRI和CNI协同创建Pod所属容器，并为它们初始化网络协议栈的全过程。具体过程如下：<ol>
<li>当用户在Kubernetes的Master里创建了一个Pod后，Kubelet观察到新Pod的创建，于是首先调用CRI（后面的runtime实现，比如dockershim、containerd等）创建Pod内的若干个容器。</li>
<li>在这些容器里，第一个被创建的pause容器是比较特殊的，这是Kubernetes系统“赠送”的容器，也称pause容器。里面运行着一个功能十分简单的C程序，具体逻辑是一启动就把自己永远阻塞在那里。一个永远阻塞而且没有实际业务逻辑的pause容器到底有什么用呢？用处很大。我们知道容器的隔离功能利用的是Linux内核的namespace机制，而只要是一个进程，不管这个进程是否处于运行状态（挂起亦可），它都能“占”用着一个namespace。因此，每个Pod内的第一个系统容器pause的作用就是占用一个Linux的network namespace。</li>
<li>Pod内其他用户容器通过加入这个network namespace的方式共享同一个network namespace。用户容器和pause容器之间的关系有点类似于寄居蟹和海螺。因此，Container runtime创建Pod内的用户容器时，调用的都是同一个命令：docker run–net&#x3D;none。意思是只创建一个network namespace，不初始化网络协议栈。如果这个时候通过nsenter方式进入容器，会看到里面只有一个本地回环设备lo。</li>
<li>容器的eth0是怎么创建出来的呢？答案是CNI。CNI主要负责容器的网络设备初始化工作。Kubelet目前支持两个网络驱动，分别是Kubenet和CNI。Kubenet是一个历史产物，即将废弃，因此本节不过多介绍。CNI有多个实现，官方自带的插件就有p2p、bridge等，这些插件负责初始化pause容器的网络设备，也就是给pause容器内的eth0分配IP等，到时候，Pod内其他容器就使用这个IP与其他容器或节点进行通信。Kubernetes主机内容器的默认组网方案是bridge。flannel、Calico这些第三方插件解决容器之间的跨机通信问题，典型的跨机通信解决方案有bridge和overlay等。</li>
</ol>
</li>
</ul>
<h4 id="Kubernetes主机内组网模型"><a href="#Kubernetes主机内组网模型" class="headerlink" title="Kubernetes主机内组网模型"></a>Kubernetes主机内组网模型</h4><ul>
<li>Kubernetes经典的主机内组网模型是veth pair+bridge的方式。</li>
<li>当Kubernetes调度Pod在某个节点上运行时，它会在该节点的Linux内核中为Pod创建network namespace，供Pod内所有运行的容器使用。从容器的角度看，Pod是具有一个网络接口的物理机器，Pod中的所有容器都会看到此网络接口。因此，每个容器通过localhost就能访问同一个Pod内的其他容器。</li>
<li>Kubernetes使用veth pair将容器与主机的网络协议栈连接起来，从而使数据包可以进出Pod。容器放在主机根network namespace中veth pair的一端连接到Linux网桥，可让同一节点上的各Pod之间相互通信。</li>
</ul>
<p><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/Kubernetes_bridge%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.jpg"></p>
<ul>
<li>如果Kubernetes集群发生节点升级、修改Pod声明式配置、更新容器镜像或节点不可用，那么Kubernetes就会删除并重新创建Pod。在大部分情况下，Pod创建会导致容器IP发生变化。也有一些CNI插件提供Pod固定IP的解决方案，例如Weave、Calico等。</li>
</ul>
<p><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/CNI_Bridge.png"></p>
<ul>
<li>使用新建的bridge网桥（CNI bridge）代替docker0网桥（docker0也可以继续保留，常规容器还是用docker0，而需要互通的容器可以借助于这个工具给docker容器新建虚拟网卡并绑定IP桥接到bridge）</li>
<li>bridge和主机eth0之间是也是利用veth pair这个技术。</li>
</ul>
<h4 id="Kubernetes跨节点组网模型"><a href="#Kubernetes跨节点组网模型" class="headerlink" title="Kubernetes跨节点组网模型"></a>Kubernetes跨节点组网模型</h4><ul>
<li>Kubernetes典型的跨机通信解决方案有bridge、overlay等。</li>
<li>bridge网络本身不解决容器的跨机通信问题，需要显式地书写主机路由表，映射目标容器网段和主机IP的关系，集群内如果有N个主机，需要N-1条路由表项。</li>
<li>至于overlay网络，它是构建在物理网络之上的一个虚拟网络，其中VXLAN是主流的overlay标准。VXLAN就是用UDP包头封装二层帧，即所谓的MAC in UDP。和bridge网络类似，Pod同样接在Linux网桥上，目的地址落在本机Pod网段的网络包同样发给Linux网桥cni0。不同的是，目的Pod在其他节点上的路由表规则。</li>
<li>bridge和overlay是Kubernetes最早采用的跨机通信方案，但随着集成Weave和Calico等越来越多的CNI插件，Kubernetes也支持虚拟路由等方式。</li>
</ul>
<h4 id="Pod的hosts文件"><a href="#Pod的hosts文件" class="headerlink" title="Pod的hosts文件"></a>Pod的hosts文件</h4><ul>
<li>与宿主机一样，容器也有&#x2F;etc&#x2F;hosts文件，用来记录容器的hostname和IP地址的映射关系。通过向Pod的&#x2F;etc&#x2F;hosts文件中添加条目，可以在Pod级别覆盖对hostname的解析。</li>
<li>一个Pod内如果有多个容器，修改任意一个容器的hostname都会影响其他容器，因为Pod共享UTS namespace。</li>
</ul>
<h4 id="打通CNI与Kubernetes：Kubernetes网络驱动"><a href="#打通CNI与Kubernetes：Kubernetes网络驱动" class="headerlink" title="打通CNI与Kubernetes：Kubernetes网络驱动"></a>打通CNI与Kubernetes：Kubernetes网络驱动</h4><ul>
<li>Kubernetes支持两种网络驱动，分别是Kubenet和CNI，其中：<br>·CNI plugins：遵守appc&#x2F;CNI规范，允许自由接入多个符合CNI标准的网络插件；<br>·Kubenet plugins：基于cbr0的一个单机容器网络方案，同时使用CNI的bridge和host-local插件实现一些功能。</li>
<li>CNI是容器网络的标准化，试图通过JSON描述一个容器网络配置。CNI是Kubernetes与底层网络插件之间的一个抽象层，为Kubernetes屏蔽了底层网络实现的复杂度，同时解耦了Kubernetes的具体网络插件实现。</li>
<li>CNI主要有两类接口：分别是在创建容器时调用的配置网络接口：[插图]和删除容器时调用的清理网络接口</li>
<li>不论是配置网络接口还是清理网络接口，都有两个入参，分别是网络配置和runtime配置。网络配置很好理解，runtime配置则主要是容器运行时传入的网络namespace信息。</li>
<li>可以简单理解就是cni就是一个开发网络插件的规范，这个规范规定了这个插件要实现的子命令(add delete)。所以如果你自己开发了一个k8网络同时实现了针对自己网络的cni插件，就是一个可执行命令，那么你的网络方案就可以被kubernetes使用。——评论</li>
</ul>
<h4 id="Kubernetes网络策略"><a href="#Kubernetes网络策略" class="headerlink" title="Kubernetes网络策略"></a>Kubernetes网络策略</h4><ul>
<li>网络策略就是基于Pod源IP（所以Kubernetes网络不能随随便便做SNAT）的访问控制列表，限制的是Pod之间的访问。通过定义网络策略，用户可以根据标签、IP范围和端口号的任意组合限制Pod的入站&#x2F;出站流量。网络策略作为Pod网络隔离的一层抽象，用白名单实现了一个访问控制列表（ACL），从Label Selector、namespace selector、端口、CIDR这4个维度限制Pod的流量进出。</li>
<li>Egress表示出站流量，即Pod作为客户端访问外部服务，Pod地址作为源地址。策略可以定义目的地址和目的端口，可以根据ports和to定义规则。ports字段用来指定目的端口和协议。to（目的地址）分为IP地址段、Pod selector和Kubernetes namespace selector；</li>
<li>Ingress表示入站流量，Pod地址和服务作为服务端（目的地址），提供外部访问。与Egress类似，策略可以定义源地址和端口，可以根据ports和from定义规则。ports字段同样用来指定目的端口和协议。from（源地址）分为IP地址段、Pod selector和Kubernetes namespace selector</li>
</ul>
<h4 id="Kubernetes网络故障定位指南"><a href="#Kubernetes网络故障定位指南" class="headerlink" title="Kubernetes网络故障定位指南"></a>Kubernetes网络故障定位指南</h4><ul>
<li><p>Kubernetes网络利用Linux内核Netfilter模块设置低级别的集群IP负载均衡，除了iptables和IPVS（前面已经详细解析过，这里不再赘述），还需要用到两个关键的模块：IP转发（IP forward）和桥接。</p>
</li>
<li><p>IP转发是一种内核态设置，允许将一个接口的流量转发到另一个接口，该配置是Linux内核将流量从容器路由到外部所必需的。</p>
</li>
<li><p>如果一个容器请求外部的服务，由于容器IP是不可路由的，则远程服务器不知道应该把响应发到哪里。但事实上，只要每个主机对容器到外部的连接做一次SNAT或是Masquerade就能实现。</p>
</li>
<li><p>我们的Docker主机能够和数据中心的其他机器通信，它们有可路由的IP。当一个容器尝试访问一个外部服务时，运行容器的主机将网络包中的容器IP用它本身的IP替换，即Masquerade（SNAT的一种）。对于外部服务，看起来像是和主机建立了连接。当响应返回到主机的时候，它进行一个逆转换（把网络包中的主机IP替换成容器IP）。对于容器，这个操作完全是透明的，它不知道发生了这样的一个转换。Kubernetes NodePort的实现默认就开启了Kube-proxy的–masq-all&#x3D;true选项。</p>
</li>
<li><p>SNAT导致Linux内核丢包的原因在于其conntrack的实现。SNAT代码在POSTROUTING链上被调用两次。</p>
</li>
<li><p>解决方法需要在masquerade规则中设置flag NF_NAT_RANGE_PROTO_RANDOM_FULLY。</p>
</li>
<li><p>通过使用打了补丁的flannel和Kube-proxy，能够显著降低conntrack表的插入错误，使整个集群中的丢包错误的数目从每几秒一次下降到每几个小时一次。需要注意的是，iptabels的–ramdom-fully选项只能缓解集群SNAT带来的这个问题，而并不能根治。因此，并不推荐在生产环境使用NodePort。</p>
</li>
<li><p>pod 访问集群外的pod和访问集群外的服务ip转化过程区别，是否NAT？TODO</p>
<ul>
<li>pod 访问集群外的pod不需要NAT，访问集群外的服务取决于是否打通网络和如何配置。</li>
</ul>
</li>
</ul>
<h4 id="Kubernetes-DNS架构演进之路"><a href="#Kubernetes-DNS架构演进之路" class="headerlink" title="Kubernetes DNS架构演进之路"></a>Kubernetes DNS架构演进之路</h4><ul>
<li>Kubernetes DNS服务目前有两个实现，分别是Kube-dns和CoreDNS。</li>
<li>无论是Kube-dns还是CoreDNS，基本原理都是利用watch Kubernetes的Service和Pod，生成DNS记录，然后通过重新配置Kubelet的DNS选项让新启动的Pod使用Kube-dns或CoreDNS提供的Kubernetes集群内域名解析服务。</li>
</ul>
<h4 id="Kubernetes网络插件生态"><a href="#Kubernetes网络插件生态" class="headerlink" title="Kubernetes网络插件生态"></a>Kubernetes网络插件生态</h4><ul>
<li>Docker自己的网络方案比较简单，就是每个宿主机上会跑一个非常纯粹的Linux bridge，这个bridge可以认为是一个二层的交换机，但它的能力有限，只能做一些简单的学习和转发。出网桥的流量会经过iptables，经过NAT，最后通过路由转发在宿主之间进行通信。当真正用Docker原生的网络模型部署一个比较复杂的业务时，会遇到诸如：容器重启之后IP就变了；每台宿主机会分配固定的网段，因此同一个容器迁到不同宿主机时，除了IP发生变化，网段也会变化，随之而来的网络策略都需要调整等问题。另外，NAT的存在会造成两端在通信时看到对方的地址是不真实的，而且NAT本身也有性能损耗。这些问题都对Docker自身网络方案的应用造成了障碍。</li>
<li>一些最常见的术语包括：<ul>
<li>第2层网络：OSI（Open Systems Interconnections，开放系统互连）网络模型的“数据链路”层。第2层网络会处理网络上两个相邻节点之间的帧传递。第2层网络的一个典型示例是以太网。</li>
<li>第3层网络：OSI网络模型的“网络”层。第3层网络的主要关注点，是在第2层连接之上的主机之间路由数据包。IPv4、IPv6和ICMP是第3层网络协议的示例。</li>
<li>VXLAN：即虚拟可扩展的LAN。首先，VXLAN用于通过在UDP数据包中封装第2层以太网帧帮助实现大型云部署。VXLAN虚拟化与VLAN类似，但提供更大的灵活性和功能（VLAN仅限于4096个网络ID）。VXLAN是一种overlay协议，可在现有网络之上运行。</li>
<li>overlay网络：是建立在现有网络之上的虚拟逻辑网络。overlay网络通常用于在现有网络之上提供有用的抽象，并分离和保护不同的逻辑网络。</li>
<li>封装：是指在附加层中封装网络数据包以提供其他上下文和信息的过程。</li>
<li>在overlay网络中，封装被用于从虚拟网络转换到底层地址空间，从而能路由到不同的位置（数据包可以被解封装，并继续到其目的地）。</li>
<li>网状网络：是指每个节点连接到许多其他节点以协作路由，并实现更大连接的网络。</li>
<li>网状网络（mesh network）允许通过多个路径进行路由，从而提供更可靠的网络。网状网格的缺点是每个附加节点都会增加大量开销。</li>
<li>BGP：代表“边界网关协议”，用于管理边缘路由器之间数据包的路由方式。BGP通过考虑可用路径、路由规则和特定网络策略等因素，将数据包从一个网络发送到另一个网络。BGP有时被用作容器网络的路由机制，但不会用在overlay网络中。</li>
</ul>
</li>
</ul>
<h4 id="CNI标准的胜出：从此江湖没有CNM"><a href="#CNI标准的胜出：从此江湖没有CNM" class="headerlink" title="CNI标准的胜出：从此江湖没有CNM"></a>CNI标准的胜出：从此江湖没有CNM</h4><ul>
<li><p>CNI即容器网络接口（Container Network Interface）。Kubernetes采用CNI而非CNM（容器网络模型），这背后有很长的一段故事，核心的原因就是CNI对开发者的约束更少，更开放，不依赖于Docker工具，而CNM对Docker有非常强的依赖，无法作为通用的容器网络标准。在CNI标准中，网络插件是独立的可执行文件，被上层的容器管理平台调用。网络插件只有两件事情要做：把容器加入网络或把容器从网络中删除。调用插件的配置通过两种方式传递：环境变量和标准输入。</p>
</li>
<li><p>CNI很简单，只需要：</p>
<ul>
<li>   1个配置文件，配置文件描述插件的版本、名称、描述等基本信息；</li>
<li>1个可执行文件，可执行文件就是CNI插件本身会在容器需要建立网络和需要销毁容器时被调用；</li>
<li>读取6个环境变量，获得需要执行的操作、目标网络Namespace、容器的网卡必要信息；</li>
<li>接受1个命令行参数，同样用于获得需要执行的操作、目标网络Namespace、容器的网卡必要信息；</li>
<li>实现2个操作（ADD&#x2F;DEL）。</li>
</ul>
</li>
<li><p>Kubernetes使用CNI网络插件的工作流程</p>
<ul>
<li>Kubernetes调用CRI创建pause容器，生成对应的network namespace；</li>
<li>调用网络driver（因为配置的是CNI，所以会调用CNI的相关代码）；</li>
<li>CNI driver根据配置调用具体的CNI插件；</li>
<li>CNI插件给pause容器配置正确的网络，Pod中的其他容器都是用pause容器的网络栈。</li>
</ul>
</li>
<li><p>CNI的初衷是创建一个框架，用于在配置或销毁容器时动态配置适当的网络配置和资源。CNI规范概括了用于配制网络的插件接口，这个接口可以让容器运行时与插件进行协调。CNI插件负责为每个容器分配IP地址，为容器接口配置和管理IP地址，以及多主机连接相关的功能。容器运行时（runtime）会调用网络插件，从而在容器启动时分配IP地址并配置网络，并在删除容器时再次调用它以清理这些资源。容器运行时决定了容器应该加入哪个网络及它需要调用哪个插件。然后，插件会将网络接口添加到容器网络命名空间中（例如，作为一个veth pair的一端）。接着，它会在主机上进行相关配置（例如，将veth的其他部分连接到网桥上）。最后，CNI会通过调用单独的IPAM（IP地址管理）插件分配IP地址并设置路由。在Kubernetes中，Kubelet可以在适当的时间调用它找到的插件，为通过Kubelet启动的Pod进行自动的网络配置。</p>
</li>
<li><p>CNI的最大价值在于提供了一致的容器网络操作界面，不论是什么网络插件都使用一致的API，提高了网络配置的自动化程度和一致性的体验。</p>
</li>
<li><p>Kubernetes是一个支持多容器的运行环境，而Docker只是其中一个容器而已。每一个运行环境都会配置网络环境，所以当人们问“Kubernetes会支持CNM吗？”时，他们真正的意思是“Kubernetes是否在Docker运行时下支持CNM？”。当然，我们希望同一个网络插件支持所有的运行环境，但这并不是一个绝对目标。</p>
</li>
<li><p>Kubernetes认为CNI更适合快速开发和迭代。早期的实验尝试证明，Kubernetes可以利用CNI插件替代几乎所有Kubelet中硬编码的网络逻辑。</p>
</li>
<li><p>考虑到Kubernetes和Docker项目的独立性等种种原因，促使Kubernetes选择CNI作为网络模型。这将带来诸如：docker inspect命令显示不了Pod的IP地址，直接被Docker启动的容器可能无法和被Kubernetes启动的容器通信等问题。</p>
</li>
<li><p>但Kubernetes必须做一个权衡：选择CNI，使Kubernetes网络配置更简单、灵活并且不需要额外的配置（例如，配置Docker使用Kubernetes或其他网络插件的网桥）。</p>
</li>
</ul>
<h3 id="SDN"><a href="#SDN" class="headerlink" title="SDN"></a>SDN</h3><ul>
<li><p>软件定义网络（Software Defined Network，SDN）</p>
</li>
<li><p>有了虚拟化网络设备后，下一步就是要使用这些设备组成网络，容器分布在不同的物理主机上，每一台物理主机都有物理网络相互联通，然而这种网络的物理拓扑结构是相对固定的，很难跟上云原生时代的分布式系统的逻辑拓扑结构变动频率，譬如服务的扩缩、断路、限流，等等，都可能要求网络跟随做出相应的变化。正因如此，软件定义网络（Software Defined Network，SDN）的需求在云计算和分布式时代变得前所未有地迫切。</p>
</li>
<li><p>SDN的核心思路是在物理的网络之上再构造一层虚拟化的网络，将控制平面和数据平面分离开来，实现流量的灵活控制，为核心网络及应用的创新提供良好的平台。SDN里位于下层的物理网络被称为Underlay，它着重解决网络的连通性与可管理性，位于上层的逻辑网络被称为Overlay，它着重为应用提供与软件需求相符的传输服务和网络拓扑。</p>
</li>
<li><p>VLAN的全称是“虚拟局域网”（Virtual Local Area Network）</p>
</li>
<li><p>VXLAN，这是三层虚拟化网络（Network Virtualization over Layer 3，NVO3）的标准技术规范之一，是一种典型的Overlay网络。</p>
</li>
<li><p>副本网卡：MACVLAN</p>
</li>
</ul>
<h3 id="Kubernetes的网络实现"><a href="#Kubernetes的网络实现" class="headerlink" title="Kubernetes的网络实现"></a>Kubernetes的网络实现</h3><ul>
<li>Kubernetes网络的设计主要致力于解决以下问题。<ol>
<li>容器到容器之间的直接通信。</li>
<li>抽象的Pod到Pod之间的通信。</li>
<li>Pod到Service之间的通信。</li>
<li>集群外部与内部组件之间的通信。</li>
</ol>
</li>
</ul>
<h4 id="容器到容器之间的直接通信"><a href="#容器到容器之间的直接通信" class="headerlink" title="容器到容器之间的直接通信"></a>容器到容器之间的直接通信</h4><ul>
<li>同一个Pod内的容器（Pod内的容器是不会跨宿主机的）共享同一个网络命名空间，共享同一个Linux协议栈。所以对于网络的各类操作，就和它们在同一台机器上一样，它们甚至可以用localhost地址访问彼此的端口。</li>
</ul>
<h4 id="Pod到Pod之间的通信"><a href="#Pod到Pod之间的通信" class="headerlink" title="Pod到Pod之间的通信"></a>Pod到Pod之间的通信</h4><ul>
<li>每一个Pod都有一个真实的全局IP地址，同一个Node内的不同Pod之间可以直接采用对方Pod的IP地址通信，而且不需要采用其他发现机制，例如DNS、Consul或者etcd。Pod容器既有可能在同一个Node上运行，也有可能在不同的Node上运行，所以通信也分为两类：同一个Node内Pod之间的通信和不同Node上Pod之间的通信。</li>
<li>同一个Node内Pod之间的通信<ul>
<li>同一个Node内两个Pod之间的关系可以看出，Pod1和Pod2都是通过Veth连接到同一个docker0网桥上的，它们的IP地址IP1、IP2都是从docker0的网段上动态获取的，它们和网桥本身的IP3是同一个网段的。另外，在Pod1、Pod2的Linux协议栈上，默认路由都是docker0的地址，也就是说所有非本地地址的网络数据，都会被默认发送到docker0网桥上，由docker0网桥直接中转。综上所述，由于它们都关联在同一个docker0网桥上，地址段相同，所以它们之间是能直接通信的。</li>
</ul>
</li>
<li>不同Node上Pod之间的通信<ul>
<li>Pod的地址是与docker0在同一个网段的，我们知道docker0网段与宿主机网卡是两个完全不同的IP网段，并且不同Node之间的通信只能通过宿主机的物理网卡进行，因此要想实现不同Node上Pod容器之间的通信，就必须想办法通过主机的这个IP地址进行寻址和通信。</li>
<li>另一方面，这些动态分配且藏在docker0之后的所谓“私有”IP地址也是可以找到的。Kubernetes会记录所有正在运行的Pod的IP分配信息，并将这些信息保存在etcd中（作为Service的Endpoint）。这些私有IP信息对于Pod到Pod的通信也是十分重要的，因为我们的网络模型要求Pod到Pod使用私有IP进行通信。所以首先要知道这些IP是什么。</li>
<li>之前提到，Kubernetes的网络对Pod的地址是平面的和直达的，所以这些Pod的IP规划也很重要，不能有冲突。只要没有冲突，我们就可以想办法在整个Kubernetes的集群中找到它。</li>
<li>支持不同Node上Pod之间的通信，就要满足两个条件：<ol>
<li>在整个Kubernetes集群中对Pod的IP分配进行规划，不能有冲突；</li>
<li>找到一种办法，将Pod的IP和所在Node的IP关联起来，通过这个关联让Pod可以互相访问。</li>
</ol>
</li>
<li>根据条件1的要求，我们需要在部署Kubernetes时对docker0的IP地址进行规划，保证每个Node上的docker0地址都没有冲突。我们可以在规划后手工配置到每个Node上，或者做一个分配规则，由安装的程序自己去分配占用。例如，Kubernetes的网络增强开源软件Flannel就能够管理资源池的分配。</li>
<li>根据条件2的要求，Pod中的数据在发出时，需要有一个机制能够知道对方Pod的IP地址挂在哪个具体的Node上。也就是说先要找到Node对应宿主机的IP地址，将数据发送到这个宿主机的网卡，然后在宿主机上将相应的数据转发到具体的docker0上。一旦数据到达宿主机Node，则那个Node内部的docker0便知道如何将数据发送到Pod。</li>
<li>在实际的私有云环境中，除了需要部署Kubernetes和Docker，还需要额外的网络配置，甚至通过一些软件来实现Kubernetes对网络的要求。做到这些后，Pod和Pod之间才能无差别地进行透明通信。为了达到这个目的，开源界有不少应用增强了Kubernetes、Docker的网络，几个常用的组件及其组网原理。</li>
</ul>
</li>
</ul>
<h4 id="Pod和Service网络实战"><a href="#Pod和Service网络实战" class="headerlink" title="Pod和Service网络实战"></a>Pod和Service网络实战</h4><ul>
<li>Kubernetes的网络模型要求每个Node上的容器都可以相互访问。默认的Docker网络模型提供了一个IP地址段是172.17.0.0&#x2F;16的docker0网桥。每个容器都会在这个子网内获得IP地址，并且将docker0网桥的IP地址（172.17.42.1）作为其默认网关。需要注意的是，Docker宿主机外面的网络不需要知道任何关于这个172.17.0.0&#x2F;16的信息或者知道如何连接到其内部，因为Docker的宿主机针对容器发出的数据，在物理网卡地址后面都做了IP伪装MASQUERADE（隐含NAT）。也就是说，在网络上看到的任何容器数据流都来源于那台Docker节点的物理IP地址。这里所说的网络都指连接这些主机的物理网络。这个模型便于使用，但是并不完美，需要依赖端口映射的机制。在Kubernetes的网络模型中，每台主机上的docker0网桥都是可以被路由到的。也就是说，在部署了一个Pod时，在同一个集群内，各主机都可以访问其他主机上的Pod IP，并不需要在主机上做端口映射。综上所述，我们可以在网络层将Kubernetes的节点看作一个路由器。如果将实验环境改画成一个网络图，那么它看起来如图7.12所示。</li>
<li>每一个新部署的容器都将使用这个Node（docker0的网桥IP）作为它的默认网关。而这些Node（类似路由器）都有其他docker0的路由信息，这样它们就能够相互连通了。</li>
<li>首先，一个Pod内的所有容器都需要共用同一个IP地址，这就意味着一定要使用网络的容器映射模式（container模式）。然而，为什么不能只启动第1个Pod中的容器，而将第2个Pod中的容器关联到第1个容器呢？我们认为Kubernetes是从两方面来考虑这个问题的：首先，如果在Pod内有多个容器的话，则可能很难连接这些容器；其次，后面的容器还要依赖第1个被关联的容器，如果第2个容器关联到第1个容器，且第1个容器死掉的话，第2个容器也将死掉。启动一个基础容器（pause容器），然后将Pod内的所有容器都连接到它上面会更容易一些。</li>
<li>Kubernetes的kube-proxy作为一个全功能的代理服务器管理了两个独立的TCP连接：一个是从容器到kube-proxy：另一个是从kube-proxy到负载均衡的目标Pod。总结：跨node的pod到pod请求，经过自身node的kube-proxy（因为要通过etcd定位目标pod属于到哪个node），不经过目标node的kube-proxy，因为连接是直接通过目标node的eth0的（是否NAT方式，看k8s具体使用的组网实现）。<br><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/%E8%B7%A8Node%E7%9A%84Pod%E9%80%9A%E4%BF%A1.jpg"></li>
</ul>
<h3 id="容器网络模型"><a href="#容器网络模型" class="headerlink" title="容器网络模型"></a>容器网络模型</h3><ul>
<li>随着容器技术在企业生产系统中的逐步落地，用户对容器云的网络特性要求也越来越高。跨主机容器间的网络互通已经成为基本要求，更高的要求包括容器固定IP地址、一个容器多个IP地址、多个子网隔离、ACL控制策略、与SDN集成等。目前主流的容器网络模型主要有Docker公司提出的Container Network Model（CNM）模型和CoreOS公司提出的Container Network Interface（CNI）模型。</li>
<li>CNM模型：CNM模型主要通过Network Sandbox、Endpoint和Network这3个组件进行实现</li>
<li>CNI 模型：CNI提供了一种应用容器的插件化网络解决方案，定义对容器网络进行操作和配置的规范，通过插件的形式对CNI接口进行实现。CNI是由rkt Networking Proposal发展而来的，试图提供一种普适的容器网络解决方案。CNI仅关注在创建容器时分配网络资源，和在销毁容器时删除网络资源，这使得CNI规范非常轻巧、易于实现，得到了广泛的支持。<ul>
<li>在CNI模型中只涉及两个概念：容器和网络。<ol>
<li>容器（Container）：是拥有独立Linux网络命名空间的环境，例如使用Docker或rkt创建的容器。关键之处是容器需要拥有自己的Linux网络命名空间，这是加入网络的必要条件。</li>
<li>网络（Network）：表示可以互连的一组实体，这些实体拥有各自独立、唯一的IP地址，可以是容器、物理机或者其他网络设备（比如路由器）等。对容器网络的设置和操作都通过插件（Plugin）进行具体实现，CNI插件包括两种类型：CNI Plugin和IPAM（IP Address Management）Plugin。CNI Plugin负责为容器配置网络资源，IPAM Plugin负责对容器的IP地址进行分配和管理。IPAM Plugin作为CNI Plugin的一部分，与CNI Plugin一起工作。</li>
</ol>
</li>
</ul>
</li>
<li>CNI和CNM并非是完全不可调和的两个模型，二者是可以进行转化的。</li>
<li>CNM阵营支持CNM标准的网络插件有：<ul>
<li>Docker Swarm overlay；Macvlan&amp;IP network drivers；Calico；Contiv。</li>
<li>Docker Libnetwork的优势就是Docker原生与Docker容器生命周期结合紧密，缺点是与Docker耦合度过高。</li>
</ul>
</li>
<li>CNI阵营支持CNI标准的网络插件：<ul>
<li>Weave；Macvlan；flannel；Calico；Contiv；Mesos CNI。</li>
<li>CNI的优势是兼容其他容器技术（例如rkt）及上层编排系统（Kubernetes&amp;Mesos），而且社区活跃势头迅猛，再加上Kubernetes主推，迅速成为容器网络的事实标准。</li>
</ul>
</li>
</ul>
<h3 id="Kubernetes网络策略-1"><a href="#Kubernetes网络策略-1" class="headerlink" title="Kubernetes网络策略"></a>Kubernetes网络策略</h3><ul>
<li>Network Policy的主要功能是对Pod间的网络通信进行限制和准入控制，设置方式为将Pod的Label作为查询条件，设置允许访问或禁止访问的客户端Pod列。策略控制器由第三方网络组件提供，目前Calico、Cilium、Kube-router、Romana、Weave Net等开源项目均支持网络策略的实现。</li>
<li>Network Policy的工作原理如图7.19所示，policy controller需要实现一个API Listener，监听用户设置的NetworkPolicy定义，并将网络访问规则通过各Node的Agent进行实际设置（Agent则需要通过CNI网络插件实现）。</li>
<li>egress：定义目标Pod允许访问的“出站”白名单规则，目标Pod仅允许访问满足to条件的服务端IP范围和ports定义的端口号。</li>
<li>Namespace级别还可以设置一些默认的全局网络策略，以方便管理员对整个Namespace进行统一的网络策略设置。</li>
</ul>
<h3 id="开源的网络组件"><a href="#开源的网络组件" class="headerlink" title="开源的网络组件"></a>开源的网络组件</h3><ul>
<li>Kubernetes的网络模型假定了所有Pod都在一个可以直接连通的扁平网络空间中。这在GCE里面是现成的网络模型，Kubernetes假定这个网络已经存在。而在私有云里搭建Kubernetes集群，就不能假定这种网络已经存在了。我们需要自己实现这个网络假设，将不同节点上的Docker容器之间的互相访问先打通，然后运行Kubernetes。目前已经有多个开源组件支持容器网络模型。有几个常见的网络组件及其安装配置方法，包括Flannel、Open vSwitch、直接路由和Calico等。</li>
</ul>
<h4 id="Flannel"><a href="#Flannel" class="headerlink" title="Flannel"></a>Flannel</h4><ul>
<li><p>Flannel之所以可以搭建Kubernetes依赖的底层网络，是因为它能实现以下两点。</p>
<ol>
<li>它能协助Kubernetes，给每一个Node上的Docker容器都分配互相不冲突的IP地址。</li>
<li>它能在这些IP地址之间建立一个覆盖网络（Overlay Network），通过这个覆盖网络，将数据包原封不动地传递到目标容器内。</li>
</ol>
</li>
<li><p>Flannel之间的底层通信协议的可选技术包括UDP、VxLan、AWS VPC等多种方式。通过源flanneld封包、目标flanneld解包，最终docker0收到的就是原始的数据，对容器应用来说是透明的，感觉不到中间Flannel的存在。</p>
</li>
<li><p>根据不同的封包方式，flannel提供了UDP和VXLAN两种传输方法。</p>
</li>
<li><p>事实上，flannel的Gateway模式的性能甚至要比Calico好。然而，由于flannel只能修改各个主机的路由表，一旦主机之间隔了其他路由设备，比如三层路由器，这个包就会在路由设备上被丢掉。这样一来，Host-Gateway的模式就只能用于二层直接可达的网络，由于广播风暴的问题，这种网络通常是比较小规模的。</p>
</li>
<li><p>flannel的底层实现实质上是一种overlay网络（除了Host-Gateway模式），即把某一协议的数据包封装在另一种网络协议中进行路由转发。</p>
</li>
<li><p>总的来说，flannel是大多数用户的不错选择。从管理角度来看，它提供了一个简单的网络模型，用户只需要一些基础知识，就可以设置适合大多数用例的环境。与其他方案相比，flannel相对容易安装和配置，许多常见的Kubernetes集群部署工具和许多Kubernetes发行版都可以默认安装flannel。</p>
</li>
<li><p>Open vSwitch是一个开源的虚拟交换机软件，有点儿像Linux中的bridge，但是功能要复杂得多。Open vSwitch的网桥可以直接建立多种通信通道（隧道）</p>
</li>
<li><p>无论是OVS还是Flannel，通过覆盖网络提供的Pod到Pod通信都会引入一些额外的通信开销，如果是对网络依赖特别重的应用，则需要评估对业务的影响。</p>
</li>
</ul>
<h4 id="Calico"><a href="#Calico" class="headerlink" title="Calico"></a>Calico</h4><ul>
<li><p>Calico是一个基于BGP的纯三层的网络方案，与OpenStack、Kubernetes、AWS、GCE等云平台都能够良好地集成。Calico在每个计算节点都利用Linux Kernel实现了一个高效的vRouter来负责数据转发。每个vRouter都通过BGP1协议把在本节点上运行的容器的路由信息向整个Calico网络广播，并自动设置到达其他节点的路由转发规则。Calico保证所有容器之间的数据流量都是通过IP路由的方式完成互联互通的。Calico节点组网时可以直接利用数据中心的网络结构（L2或者L3），不需要额外的NAT、隧道或者Overlay Network，没有额外的封包解包，能够节约CPU运算，提高网络效率，如图7.24所示。 Calico不使用额外的封包解包Calico在小规模集群中可以直接互联，在大规模集群中可以通过额外的BGP route reflector来完成。</p>
</li>
<li><p>此外，Calico基于iptables还提供了丰富的网络策略，实现了Kubernetes的Network Policy策略，提供容器间网络可达性限制的功能。</p>
</li>
<li><p>Calico的主要组件如下。</p>
<ol>
<li>Felix：Calico Agent，运行在每个Node上，负责为容器设置网络资源（IP地址、路由规则、iptables规则等），保证跨主机容器网络互通。</li>
<li>etcd：Calico使用的后端存储。</li>
<li>BGP Client：负责把Felix在各Node上设置的路由信息通过BGP协议广播到Calico网络。</li>
<li>Route Reflector：通过一个或者多个BGP Route Reflector来完成大规模集群的分级路由分发。</li>
<li>CalicoCtl：Calico命令行管理工具。</li>
</ol>
</li>
<li><p>IP Pool可以使用两种模式：BGP或IPIP。</p>
</li>
<li><p>Calico的设计比较新颖，flannel的host-gw模式之所以不能跨二层网络，是因为它只能修改主机的路由，Calico把改路由表的做法换成了标准的BGP路由协议。相当于在每个节点上模拟出一个额外的路由器，由于采用的是标准协议，Calico模拟路由器的路由表信息可以被传播到网络的其他路由设备中，这样就实现了在三层网络上的高速跨节点网络。</p>
</li>
<li><p>现实中的网络并不总是支持BGP路由，因此Calico也设计了一种ipip模式，使用overlay的方式传输数据。ipip的包头非常小，而且是内置在内核中的，因此它的速度理论上要比VXLAN快，但是安全性更差。</p>
</li>
<li><p>虽然flannel被公认为是最简单的选择，但Calico以其性能、灵活性闻名于Kubernetes生态系统。Calico的功能更全面，正如Calico的slogan提到的：为容器和虚拟机工作负载提供一个安全的网络连接。</p>
</li>
<li><p>Calico以其丰富的网络功能著称，不仅提供容器的网络解决方案，还可以用在虚拟机网络上。除了网络连接，网络策略是Calico最受追捧的功能之一。使用Calico的策略语言，可以实现对容器、虚拟机工作负载和裸机主机各节点之间网络通信进行细粒度和动态的安全规则控制。Calico基于iptables实现了Kubernetes的网络策略，通过在各个节点上应用ACL（访问控制列表）提供工作负载的多租户隔离、安全组及其他可达性限制等功能。此外，Calico还可以与服务网格Istio集成，以便在服务网格层和网络基础架构层中解释和实施集群内工作负载的网络策略。</p>
</li>
<li><p>Calico还支持容器漂移。因为Calico配置的三层网络使用BGP路由协议在主机之间路由数据包。BGP路由机制可以本地引导数据包，这意味着无须overlay网络中额外的封包解包操作。由于免去了额外包头（大部分情况下依赖宿主机IP地址）封装数据包，容器在不同主机之间迁移没有网络的限制。</p>
</li>
<li><p>Calico在每一个计算节点利用Linux内核的一些能力实现了一个高效的vRouter负责数据转发，而每个vRouter通过BGP把自己运行的工作负载的路由信息向整个Calico网络传播。</p>
</li>
<li><p>BGP Route Reflector（BIRD）简单的BGP可能成为较大规模部署的性能瓶颈，因为它要求每个BGP客户端连接到网状拓扑中的每一个其他BGP客户端。随着集群规模的增大，一些设备的路由表甚至会被撑满。</p>
</li>
<li><p>因此，在较大规模的部署中，Calico建议使用BGP Route Reflector（路由器反射器）。互联网中通常使用BGP Route Reflector充当BGP客户端连接的中心点，从而避免与互联网中的每个BGP客户端进行通信。Calico使用BGP Route Reflector是为了减少给定一个BGP客户端与集群其他BGP客户端的连接。用户也可以同时部署多个BGP Route Reflector服务实现高可用。Route Reflector仅仅是协助管理BGP网络，并没有工作负载的数据包经过它们。</p>
</li>
<li><p>然而在需要使用overlay网络的环境中，Calico也提供了IP-in-IP（简称ipip）的隧道技术</p>
</li>
<li><p>为Pod分配固定IP很多传统的应用程序，在上容器云时都会有使用固定IP地址的需求。虽然这种要求并不符合Kubernetes对网络的基本假定，但Calico IPAM却支持为Pod分配固定IP。</p>
</li>
<li><p>为什么Calico网络选择BGP</p>
<ul>
<li>我们都知道Calico使用了BGP，那么为什么Calico要选择BGP呢？为什么选择BGP而不是一个IGP协议（如OSPF或者IS-IS）？</li>
<li>要弄清楚原因，我们需要先明确目前BGP和IGP是如何在一个大规模网络中工作的。任何网络，尤其是大型网络，都需要处理两个不同的路由问题：<ol>
<li>发现网络中路由器之间的拓扑结构。</li>
<li>发现网络中正在工作的节点，以及可到达该网络的外部连接。</li>
</ol>
</li>
<li>网络中的端点（Endpoint）没有运行路由协议的能力，而路由器（Router）可以。同一个网络内的两个网络之间通过路由器连接。IGP需要执行大量复杂计算，才能让每台设备在同一时刻都能得到对所处网络拓扑的相同认知。这其实就限制了IGP所能运行的规模。在一个IGP的单一视图内应该只包含几十个（极端情况下可能是小几百个）路由器，以满足这些规模和性能的需求。虽然存在一些可以突破规模限制的技术［比如在OSPF中使用area（区域）或者在IS-IS中使用Level（层），两者都可以认为是将网络切割成若干个单一视图］，但这些技术也带来了其他架构上的限制（超出本书范畴这里不再展开）。IGP也被限制在它们所能通告的最大Endpoints数量上，这个数量浮动范围比较大，但是上限也就在几千到1万多。当IGP中的路由数量超过5000或6000条时，许多大型网络的管理人员都会感到紧张。那么BGP呢？截至2015年1月，在公共互联网上宣告的路由超过526000条，一些网络中甚至拥有超过100万的节点。为了解决大规模网络中的路由可扩展性问题，BGP被开发出来。BGP可以在一个网络中扩容到几百台路由器的规模，而如果使用BGP Route Reflection这一数量更是可以到达数万台。如果需要的话，BGP可以宣告数百万条路由信息，并通过非常灵活的策略加以管理。因此，我们就能理解为什么Calico使用BGP宣告网络端点的路由了。一言以蔽之，就是提高路由规则的可扩展性以满足大规模组网的需求。在Calico设计的网络中，可能会出现几万台路由器，以及潜在的几百万条路由信息或者Endpoints，这种数量级是与IGP的设计不匹配的，但是BGP可以，特别是当我们使用BGP Route Reflection扩展路由器数量的时候。Calico的核心设计思想是：使用通用的互联网工具和技术实现大规模网络互连结构。产生这种设计思想的主要原因是互联网行业在运营真正大型网络上已经积累了几十年的经验，使用的工具和技术（例如BGP）也已经过长时间的磨炼，如果把这些工作全部丢进垃圾桶，重新造轮子就不够明智了。对于那些数据终端规模已经接近互联网规模的公有云环境，一个云上可用区就可以轻松承载数千到数万个服务器，并运行着几万甚至小几十万个虚拟机（在Calico中称为Endpoints）。如果这些虚拟机中再运行容器，则Endpoints的数量可能还会增加一个或两个数量级。因此，从规模角度，我们应该尽量复用互联网运营商的成功经验。总结Calico网络使用BGP的原因有：（1）BGP是一种简单的路由协议。（2）拥有当前行业的最佳实践。（3）唯一能够支撑Calico网络规模的协议。</li>
</ul>
</li>
<li><p>Calico是一个比较有意思的虚拟网络解决方案，完全利用路由规则实现动态组网，通过BGP通告路由。由于Calico利用宿主机协议栈的三层确保容器之间跨主机的连通性，报文的流向完全通过路由规则控制，没有overlay，没有NAT，直接经过宿主机协议栈处理，因此我们称Calico是一个纯三层的组网方案，转发效率也较高。Calico的核心设计思想就是Router，它把每个操作系统的协议栈看成一个路由器，然后把所有的容器看成连在这个路由器上的网络终端，在路由器之间运行标准的BGP，并让节点自己学习这个网络拓扑该如何转发。然而，当网络端点数量足够大时，自我学习和发现拓扑的收敛过程非常耗费资源和时间。Calico的缺点是网络规模会受到BGP网络规模的限制。Calico路由的数目与容器数目相同，极易超过三层交换、路由器或节点的处理能力，从而限制了整个网络的扩张，因此Calico网络的瓶颈在于路由信息的容量。Calico会在每个节点上设置大量的iptables规则和路由规则，这将带来极大的运维和故障排障难度。Calico的原理决定了它不可能支持VPC，容器只能从Calico设置的网段中获取IP。Calico目前的实现没有流量控制的功能，会出现少数容器抢占节点多数带宽的情况。当然，我们可以结合CNI的bandwidth插件实现流量整形。Calico的应用场景主要在IDC内部，Calico官方推荐将其部署在大二层网络上，这样所有路由器之间是互通的。所谓大二层就是没有任何三层的网关，所有的机器、宿主机、物理机在二层是可达的。大二层主要的问题是弹性伸缩的问题。频繁开关机的时候，容器启停虽然不影响交换机，但容易产生广播风暴。事实上，在很多有经验的网络工程师眼里，大二层存在单一故障问题，也就是说，任何一个都会有一定的硬件风险让整个大二层瘫痪。因此，实际场景经常会把集群划分成多个网段，对外是三层网络的结构。如图5-18所示，从架构上看，Calico在每个节点上会运行两个主要的程序，一个是Felix，另一个是BIRD。Felix会监听etcd的事件并负责配置节点上容器的网络协议栈和主机上的iptables规则及路由表项。BIRD会从内核里获取IP的路由发生了变化的信息，并告知Route Reflector。Route Reflector是一个路由程序，它会通过标准BGP的路由协议扩散到其他宿主机上，让集群的其他容器都知道这个IP。　Calico网络拓扑参考资料：<a href="https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2017/04/11/calico-usage.html">https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2017/04/11/calico-usage.html</a>.</p>
</li>
<li><p>Calico 不足：</p>
<ul>
<li>BGP 支持问题：需要网路设备支持 BGP 协议，否则需要追加 IPIP 隧道；</li>
<li>规划 2 层直连：需要节点做良好的规划实现 2 层网络直接互联；</li>
<li>大规模配置复杂：网络规划，手动部署 Route Reflector，增加 API 代理。</li>
</ul>
</li>
</ul>
<h4 id="Weave"><a href="#Weave" class="headerlink" title="Weave"></a>Weave</h4><ul>
<li>支持数据加密的网络插件Weave是CNCF的官方子项目，是其第一个也是目前唯一一个容器网络插件项目。用一个词评价Weave，就是“功能齐全”，有网络通信、有安全策略、有域名服务、有加密通信还有监控。Weave的工作模式与flannel相似，它最早只提供了UDP（称为sleeve模式）的网络模式，后来又加上了fastpath方式（基于VXLAN和OVS），不过Weave消除了flannel中用来存储网络地址的额外组件etcd，自己集成了高可用的数据存储功能。</li>
<li>Weave控制面在实现上与Calico类似，数据面在1.2版本前使用userspace实现，即通过UDP封装实现L2 overlay。Weave在1.2版本后，结合了Linux内核的Open vSwitch datapata（odp）和VXLAN，在网络性能上有较大的提升。由于odp和VXLAN与内核相关模块结合较为紧密，因此在实际使用过程中可能会遇到一些和内核相关的问题</li>
</ul>
<h4 id="Cilium"><a href="#Cilium" class="headerlink" title="Cilium"></a>Cilium</h4><ul>
<li>为微服务网络连接安全而生什么是Cilium？Cilium是“纤毛”的意思，它十分细小又无处不在。Cilium官方的定位是：API-aware Networking and Security plugin，helping Linux Secure Microservices.Cilium是一个具备API感知的网络和安全的开源软件，该软件用于透明地保护使用Linux容器管理平台（如Docker和Kubernetes）部署的应用程序服务之间的网络连接。</li>
<li>为什么使用Cilium在回答为什么使用Cilium这个问题之前，我们先来探讨为什么从单机时代便广泛应用的iptables在微服务时代显得有些力不从心？<ol>
<li>iptables在微服务时代的限制作为通用操作系统的一个组件，iptables专注于为Linux管理员提供系统安全性管理的“瑞士军刀”，即基于静态环境的IP和端口配置网络转发、过滤等规则。然而，随着iptables在大规模、高度动态的微服务环境中投入使用，原始设计目标与现代基础设施需求之间的不匹配愈发明显。前文在对Kube-proxy转发模式讨论时就提到了基于iptables服务负载均衡的严重性能瓶颈。除了性能和规模，由于容器的创建和销毁非常频繁，基于IP做身份关联的故障排除和安全审计等功能很难实现。现代数据中心应用程序的开发已经转向面向服务的体系结构（SOA），即我们常说的微服务。基于微服务的应用程序被拆分为一个个独立的小型服务，这些服务使用HTTP、gRPC和Kafka等轻量级协议，通过API相互通信。但是，现有的Linux网络安全机制（例如iptables）仅在网络和传输层（即IP地址和端口）上运行，并且缺乏对微服务层的可见性（visibility）。微服务架构下的应用程序，尤其是通过容器部署的是高度动态变化的。在向高度动态的微服务架构的转变过程中，确实给微服务之间的连接安全性提出了挑战和机遇。具体表现为：传统的Linux网络安全方法（例如iptables）过滤IP地址和TCP&#x2F;UDP端口，但容器高度不稳定的生命周期导致这些方法难以与应用程序并排扩展。因为负载均衡和访问控制列表要不断更新，系统可能要维护成千上万条规则，这给运维带来了较大负担。出于更精细的安全考虑，协议端口不能再用于区分应用流量，因为同一端口可能承载跨服务的各种消息。另一个挑战是提供准确的可见性，因为传统系统使用IP地址作为主要识别工具，而IP在微服务架构中的寿命可能才几秒。归根结底，通用的基于IP&#x2F;端口的防火墙方式在微服务架构中的网络和安全面临一系列限制。因此我们不禁发问：如果在微服务时代从头开始设计内核Linux网络和安全方法会是什么样子？</li>
<li>BPF：让Linux感知微服务幸运的是，我们拥有BPF（Berkeley Packet Filter）。一句话总结BPF就是：BPF是Linux内核中的一个高性能沙箱虚拟机，它将内核变成了可编程的。作为一种Linux内核的黑科技，BPF可以在不影响安全性或性能的情况下扩展Linux内核，提供了内核的数据包过滤机制。跟netfilter和tc等一样，BPF是一个框架，用于在内核中的各个挂钩点运行自定义逻辑，这其中就包括Linux网络协议栈中的多处挂载点。这也是那些基于BPF实现的profiling和tracing（例如tcpdump）工具的工作原理。BPF给用户提供两种SOCKET选项：SO_ATTACH_FILTER和SO_ATTACH_BPF，允许用户在sokcet上添加自定义的filter，只有满足该filter指定条件的数据包才会上发到用户空间。SO_ATTACH_FILTER插入的是cBPF（classic Berkeley Packet Filter，即经典BPF，我们说的BPF值就是cBPF）代码，SO_ATTACH_BPF插入的是eBPF（extended Berkeley Packet Filter，即扩展BPF）代码。从Linux 3.15开始，eBPF被引入内核，eBPF扩充了cBPF的功能，丰富了指令集但保留了对cBPF的兼容。例如，tcpdump还是用的cBPF，但cBPF字节码被加载到内核后会被内核自动转换为eBPF字节码。注：若不特殊说明，本书不区分cBPF和eBPF，统一用BPF指代。BPF的工作原理是在内核提供了一个虚拟机，用户态将过滤规则以虚拟机指令的形式传递到内核，由内核根据这些指令来过滤网络数据包。BPF逻辑被编写为简单的“BPF程序”，它们在运行前先要通过验证，以确保它们在任何情况下都不会导致运行它的内核崩溃。验证之后，这些程序被一个JIT（just in time）编译器编译成CPU相关的代码（例如X86）在内核态运行，这意味着它们以与编译到内核中的代码相同的速度运行。最重要的是，任何网络报文都没法绕过BPF在内核态的限制。要理解BPF的作用，首先要意识到Linux内核本质上是事件驱动的！写数据到磁盘，读写socket，请求定时器等，这些过程都是系统调用，都是事件驱动的。世界上最大的单体应用，有着1000万行代码量的Linux无时无刻不在处理各种事件。BPF给我们提供了在事件发生时运行指定的BPF程序的能力。例如，我们可以在以下事件发生时运行我们的BPF程序：·应用发起read&#x2F;write&#x2F;connect等系统调用；·TCP发生重传；·网络包达到网卡。BPF在过去几年中发展迅速，Netflix、Facebook和Google等在Linux上做了大量投资的公司，都在积极探索使用BPF作为内核的可扩展性机制，把Linux打造成一个可感知微服务的操作系统。为什么这么说呢？BPF能够使Linux内核感知到API层。当内核能够理解两个应用程序通信过程中调用了哪些API时，它便能够为API调用提供安全保障，并以此构建一个基于身份认证的机制。因此，不同于以前简单的IP+Port过滤网络包的方式，有了BPF加持的Linux内核可以理解什么是一个微服务，微服务的标签有哪些，这个微服务的安全性是怎么样的。</li>
<li>Cilium：把BPF带到Kubernetes首先，Cilium是一个CNI插件，它提供网络连通性、服务负载均衡等功能，但主打的功能还是安全。例如，Cilium实现了Kubernetes的网络策略API，还提供了基于身份认证的微服务安全机制。从一开始，Cilium就是为大规模、高度动态的容器环境而设计的。Cilium在3&#x2F;4层运行，除了提供传统的网络和安全服务，还有一些L7的负载均衡和流量过滤功能。区别于传统系统中的IP地址识别，Cilium原生地了解服务&#x2F;容器&#x2F;Pod标识，并解析HTTP、gRPC和Kafka等协议，提供比传统防火墙更简单、更强大的可见性和安全性。BPF的高效灵活是Cilium的基础。Cilium支持在各种集成点（例如，网络IO、应用程序套接字和跟踪点）中将BPF字节码动态插入Linux内核，为工作负载（包括进程和容器）提供透明的网络连接保护、负载均衡、安全和可观测性支持。最关键的是，BPF的使用使得Cilium能够以高度可扩展的方式实现以上功能，尤其能够应对大规模的微服务场景。Cilium基于BPF，但为用户隐藏了BPF的复杂性，提供了与通用编排框架（例如Kubernetes等）Mesos的集成。Cilium的工作原理如图5-26所示。[插图]图5-26　Cilium的工作原理BPF的强大功能可实现高效的内核数据转发，为常见的微服务用例提供巨大的性能优势，例如Cilium就可以作为Kubernetes服务负载均衡（iptables或IPVS）和Istio本地代理（Envoy）的可选项。</li>
<li>Cilium功能一览具体来说，Cilium实现了以下功能。1）容器的网络连接Cilium的网络模型较简单，即一个三层网络空间为所有服务端点提供链接，并通过策略层实现安全控制。Cilium支持以下跨节点网络模型。·overlay：基于封装的虚拟网络产生所有主机。目前，已支持基于VXLAN和Geneve等封包协议；·直接路由：使用Linux主机内置或云提供商的路由表，通过底层网络路由应用程序容器的IP地址。从架构上看，Cilium将安全与网络寻址进行解耦，极大简化了网络模型，也提高了扩展性，降低了排错难度。2）基于策略的网络安全Cilium同时提供基于数据包和API的网络安全与认证，为传统部署和微服务架构提供安全的网络连接。Cilium的网络策略分为以下几大类。·基于身份：在每个包内，Cilium将负载和身份信息打包在一起（而不是依靠源IP地址），提供高可扩展安全性；·基于IP&#x2F;CIDR：如果基于身份的方式不适用，那么可以采用基于IP&#x2F;CIDR安全的方式控制安全访问。Cilium建议在安全策略中尽量采用抽象方式，避免写入具体IP地址。例如，使用Kubernetes的Service（通过label selector选择后端Pod）名；·基于API：HTTP&#x2F;REST、gRPC和Kafka通过暴露IP和端口对外提供服务，其安全机制明显不足。基于API的网络策略允许使用更细粒度的安全限制，例如REST方法等。下文会详细展开介绍Cilium的安全机制，这里不再赘述。3）分布式可扩展负载均衡BPF提供高性能L3&#x2F;L4的服务转发与负载均衡，转发策略有rr、wrr、源hash等。基于散列表实现的BPF提供O（1）时间复杂度的路由性能（这一点与IPVS很像），也就是说，Cilium可以替换Kube-proxy实现Kubernetes Service机制。这样所有Kubernetes集群IP服务会自动在BPF中得到高效地实现，而且性能不会随着服务数量的增加而下降。4）可视化与网络策略类似，Cilium也同时在网络包和API调用两个层面实现了可视化。所有可视化信息，不仅是IP地址和端口号，还包括丰富的工作流元数据，例如容器和Pod标签、服务名等。这样一来，Cilium就能提供基于标签、安全身份和事件类型的过滤和可视化。Cilium的可视化基于BPF高性能循环缓冲区（perf ring buffer），可以追踪每秒百万级的应用事件。除此之外，还利用BPF可编程性的高效通道允许数据可视化同时降低额外负担。最后，Cilium的所有可视化都对外提供API，可以嵌入现有系统中。5）监控Cilium周期性地监控集群连接状态，包括节点之间延迟、节点失效和底层网络问题等，并且可以将Cilium整合到Prometheus监控系统中。</li>
</ol>
</li>
<li>总的来说，Cilium使用BPF作为底层引擎，创建了一个精确优化的网络堆栈，用于在Kubernetes等平台上运行API驱动的微服务。下文将重点讨论使用Cilium带来的两个主要好处：·不只简单关注数据包、IP地址和端口，而是将服务标识和API协议（例如HTTP、gRPC和Kafka）视为平台中的一等公民；·针对在微服务环境中越来越常见的规模、动态和部署模式（例如服务网格代理）优化Linux网络转发、可见性和过滤。</li>
<li>然而在同一主机上，将数据从一个Linux套接字复制到另一个Linux套接字可以做到非常高效。因此，一个直观的想法是如果服务和sidecar运行在同一台宿主机上，那么我们可以直接在两个socket之间复制数据，这将带来极大的性能提升（3～4倍）。这也是Cilium和BPF使Linux内核可感知微服务的一个例子。</li>
<li>简而言之，如果采用Service Mesh这种架构，那么使用Cilium+Sockmap应该是减少CPU&#x2F;内存使用和降低延迟的一种简单方法。</li>
<li>在云原生带来的微服务浪潮下，尽管几乎所有关于如何设计和运行应用程序的内容都在变化，但像iptables（基于内核的netfilter）这样的内核功能仍然是Kubernetes、Mesos、Docker等现代微服务环境中网络路由、包过滤、安全性和记录网络数据的最常用工具。然而，在高度动态和复杂的微服务世界中，仅仅通过IP地址和端口的传统镜头来思考网络和安全性会导致实现效率非常低，只能实现过程可见性和过滤，并且通常非常复杂且难以排查。由于BPF是Linux内部强大的新内核可扩展性机制，使我们有机会在微服务时代重新思考Linux网络和安全堆栈并解决这些问题。Cilium通过将安全性与寻址分离，不仅可以在高度动态的环境中应用安全策略，还提供了除传统的L3&#x2F;L4网络隔离外的应用层安全限制。Cilium将不再基于传统的“IP+Port”的方式做网络策略，而是基于“身份”，这将带来可见性和安全性，使用起来也更简单，而且功能上更加强大（支持对单个RPC调用的细粒度控制）。参考资料：<a href="http://cilium.readthedocs.io/en/stable/bpf/">http://Cilium.readthedocs.io/en/stable/bpf/</a>.</li>
</ul>
<h4 id="CNI-Genie"><a href="#CNI-Genie" class="headerlink" title="CNI-Genie"></a>CNI-Genie</h4><ul>
<li>一个直观的想法是能不能在同一个容器集群中集成多个网络插件，博采众长？下面介绍一个由华为开源的多网络插件：CNI-Genie。CNI-Genie是一个集成引导插件，本身无具体功能，由引用的插件完成网络功能，支持flannel、Calico、Weave Net、Canal、Romana等CNI插件，还支持SR-IOV、DPDK等。值得一提的是，CNI-Genie本身也是一个符合CNI标准的容器网络插件。</li>
<li>CNI-Genie本质上就是Kubernetes和底层多个CNI插件之间的适配器（adapter）。</li>
<li>CNI-Genie使用户能够在同一个集群中运行多个CNI，并有助于为每个容器创建多个接口。事实上，多网络平面是CNI-Genie的一个重要功能。需要注意的是，使用CNI-Genie所集成的网络插件才是容器多网络平面和多网卡（IP地址）的真正提供者。</li>
</ul>
<h3 id="提供给Kubernetes集群外访问"><a href="#提供给Kubernetes集群外访问" class="headerlink" title="提供给Kubernetes集群外访问"></a>提供给Kubernetes集群外访问</h3><ol>
<li>采用NodePort是解决上述问题的最直接、有效的常见做法。（将Service的端口号映射到物理机）<ul>
<li>NodePort的实现方式是在Kubernetes集群里的每个Node上都为需要外部访问的Service开启一个对应的TCP监听端口，外部系统只要用任意一个Node的IP地址+具体的NodePort端口号即可访问此服务</li>
<li>在任意Node上运行netstat命令，就可以看到有NodePort端口被监听：   <code> netstat -tlp | grep 31002</code></li>
<li>NodePort没有完全解决外部访问Service的所有问题，比如负载均衡问题。</li>
</ul>
</li>
<li>将容器应用的端口号映射到物理机。<ul>
<li>设置容器级别的hostPort，将容器应用的端口号映射到物理机上。</li>
<li>通过设置Pod级别的hostNetwork&#x3D;true，该Pod中所有容器的端口号都将被直接映射到物理机上。</li>
</ul>
</li>
<li>DNS服务搭建<ul>
<li>在集群内需要能够通过服务名对服务进行访问，这就需要一个集群范围内的DNS服务来完成从服务名到ClusterIP的解析。</li>
</ul>
</li>
<li>Ingress：HTTP 7层路由机制<ul>
<li>在Kubernetes中，Ingress Controller将以Pod的形式运行，监控API Server的&#x2F;ingress接口后端的backend services，如果Service发生变化，则Ingress Controller应自动更新其转发规则。</li>
</ul>
</li>
</ol>
<h3 id="容器-vs-虚拟机"><a href="#容器-vs-虚拟机" class="headerlink" title="容器 vs 虚拟机"></a>容器 vs 虚拟机</h3><ul>
<li>容器是进程级别的隔离技术，因此相比虚拟机有启动快、占用资源少、体积小等优点。</li>
<li>容器与虚拟机对比传统的虚拟机需要模拟整台机器，包括硬件（因此，虚拟机方案需要硬件的支持，例如VT-X），每台虚拟机都需要有自己的操作系统。虚拟机一旦被开启，预分配给它的资源将全部被占用。每台虚拟机包括应用程序、必要的依赖库，以及一个完整的用户操作系统。容器和宿主机共享操作系统，而且可以实现资源的动态分配。容器包含应用程序和所依赖的软件包，并且不同容器之间共享内核，这与虚拟机相比大大节省了额外的资源占用。在宿主机操作系统中，不同容器在用户空间以隔离的方式运行着各自的进程。虚拟机和容器最大的区别在于没有Guest OS（客户虚拟机）这一层。</li>
<li>虚拟机和容器都是在硬件和操作系统以上的，虚拟机有Hypervisor层，Hypervisor即虚拟化管理软件，是整个虚拟机的核心所在。它为虚拟机提供了虚拟的运行平台，管理虚拟机的操作系统运行。每台虚拟机都有自己的操作系统及系统库。容器没有Hypervisor这一层，也没有Hypervisor带来性能的损耗，每个容器和宿主机共享硬件资源及操作系统。</li>
<li>Docker容器有Docker Engine这一层。其实Docker Engine远远比Hypervisor轻量，它只负责对Linux内核namespace API的封装和调用，真正的内核虚拟化技术是由Linux提供的。容器的轻量带来的一个好处是资源占用远小于虚拟机。同样的硬件环境，可以运行容器的数量远大于虚拟机，这对提供系统资源利用率非常有用。每台虚拟机都有一个完整的Guest OS，Guest OS能为应用提供一个更加隔离和安全的环境，不会因为应用程序的漏洞给宿主机造成任何威胁。</li>
<li>从虚拟化层面来看，传统虚拟化技术是对硬件资源的虚拟，容器技术则是对进程的虚拟，从而提供更轻量级的虚拟化，实现进程和资源的隔离。从架构来看，容器比虚拟机少了Hypervisor层和Guest OS层，使用Docker Engine进行资源分配调度并调用Linux内核namespace API进行隔离，所有应用共用主机操作系统。因此在体量上，Docker较虚拟机更轻量级，在性能上优于虚拟化，接近裸机性能。</li>
</ul>
<h3 id="NAT"><a href="#NAT" class="headerlink" title="NAT"></a>NAT</h3><ul>
<li>SNAT: Source Network Address Translation，是修改网络包源ip地址的。</li>
<li>DNAT: Destination Network Address Translation,是修改网络包目的ip地址的。</li>
</ul>
<h3 id="Istio"><a href="#Istio" class="headerlink" title="Istio"></a>Istio</h3><h4 id="Service-Mesh"><a href="#Service-Mesh" class="headerlink" title="Service Mesh"></a>Service Mesh</h4><ul>
<li>在Kubernetes逐渐普及的时代，Service Mesh技术已完全取代了使用软件库实现网络运维的方式。严格来说，Service Mesh并不在Kubernetes的核心范围之内。但是，在Kubernetes的帮助下，应用上云后，还面临着服务治理的难题。现在，大多数云原生的应用都是微服务架构，微服务的注册。服务之间的相互调用关系，服务异常后的熔断、降级，调用链的跟踪、分析等一系列现实问题摆在各机构面前。Service Mesh就是解决这类微服务发现和治理问题的一个概念。</li>
<li>在我看来，Service Mesh之于微服务架构就像TCP之于Web应用。<br>Istio提供了真正可供操作、非侵入式的方案，相对于Spring Cloud、Dubbo这些SDK方式让人有种耳目一新的感觉。</li>
<li>只有在服务数量和服务间调用的复杂度上升到一定程度后，Service Mesh才会真正派上用场。</li>
<li>所谓sidecar模式，翻译过来就是边车模式，是一种分布式和微服务架构的设计模式，目的是实现了控制和逻辑的分离与解耦。</li>
<li>软件设计中的sidecar模式通过给应用服务加装一个“边车”达到控制和逻辑分离的目的。该设计模式通过给应用程序加上一个“边车”的方式拓展应用程序现有的功能，例如日志记录、监控、流量控制、服务注册、服务发现、服务限流、服务熔断等在业务服务中不需要实现的控制面功能，可以交给“边车”，业务服务只需要专注于实现业务逻辑即可。</li>
<li>sidecar模式一般有两种实现方式：·通过SDK的形式，在开发时引入该软件包依赖，使其与业务服务集成起来。这种方法可以与应用密切集成，提高资源利用率并且提高应用性能，但也对代码有侵入，受到编程语言和软件开发人员水平的限制；·agent形式。服务所有的通信都是通过这个agent代理的，这个agent同服务一起部署，和服务一起有着相同的生命周期创建。这种方式对应用服务没有侵入性，不受编程语言和开发人员水平的限制，做到了控制与逻辑分开部署。但是会增加应用延迟，并且管理和部署的复杂度会增加。</li>
<li>Service Mesh作为sidecar运行时，对应用程序来说是透明的，所有应用程序间的流量都会通过sidecar，然后由sidecar转发给应用程序。换句话说，由于sidecar劫持了流量，所以对应用程序流量的控制都可以在sidecar中实现。</li>
<li>William Morgan在What’s a service mesh？And why do I need one文章中指出Service Mesh有以下几个特点：·应用程序间通信的中间层；·轻量级网络代理；·应用程序无感知；·解耦应用程序的重试&#x2F;超时、监控、追踪和服务发现。Service Mesh将底层那些难以控制的网络通信统一管理，诸如流量管控、丢包重试、访问控制等。而上层的应用层协议只须关心业务逻辑。Service Mesh是一个用于处理服务间通信的基础设施层，它负责为构建复杂的云原生应用传递可靠的网络请求。</li>
<li>Kube-proxy实现了流量在Kubernetes Service的负载均衡，但是没法对流量做细粒度的控制，例如灰度发布和蓝绿发布（按照百分比划分流量到不同的应用版本）等。Kubernetes社区提供的蓝绿发布案例其实是针对Deployment的，但不支持Service。</li>
<li>Istio Service Mesh把Kubernetes看作服务注册机构，通过控制平面生成数据平面的配置，数据平面的透明代理以sidecar容器的方式部署在每个应用服务的Pod中。之所以说是透明代理，是因为应用程序容器完全无感知代理的存在。区别在于Kube-proxy拦截的是进出Kubernetes节点的流量，而Istio sidecar拦截的是进出该Pod的流量。</li>
</ul>
<h4 id="Istio-1"><a href="#Istio-1" class="headerlink" title="Istio"></a>Istio</h4><ul>
<li>什么是Istio？官方给出的定义是：An open platform to connect，secure，control and control services.即一个提供微服务连接的、安全的、流量控制的和可观察性的开放平台。Istio分为两个平面：数据平面和控制平面。数据平面由一组sidecar的代理（Envoy）组成。这些代理调解和控制微服务之间的所有网络通信，并且与控制平面的Mixer通信，接受调度策略。控制平面通过管理和配置Envoy管理流量。此外，控制平面配置Mixers来实施路由策略并收集检测到的监控数据</li>
<li>在安装Istio核心组件之前，需要安装一个“服务注册器”，这个“服务注册器”既可以是Kubernetes，也可以是Nomad &amp; Consul。下面笔者以Kubernetes为例，讲解如何在Kubernetes集群中安装Istio控制平面。</li>
<li>Istio提供多种安装路径，具体取决于你环境中的Kubernetes平台。但不论平台如何，基本流程都是相同的，即：（1）确认Istio对Pod和服务的要求。（2）安装Kubernetes。（3）在Kubernetes上安装Istio。</li>
</ul>
<h4 id="Istio-sidecar透明注入"><a href="#Istio-sidecar透明注入" class="headerlink" title="Istio sidecar透明注入"></a>Istio sidecar透明注入</h4><ul>
<li>网格中的每个Pod都必伴随着一个Istio的sidecar一同运行。下文中将会介绍两种把sidecar注入Pod的方法：使用istioctl客户端工具进行注入，或者使用Istio sidecar injector自动完成注入过程，并且深入sidecar内部解析其工作原理。</li>
<li>需要注意的是，跟手工注入不同，自动注入过程是发生在Pod级别的，因此不会看到Deployment本身发生什么变化。但是可以使用kubectl describe观察单独的Pod，在其中能看到注入sidecar的相关信息。1. 验证sidecar注入部署sleep应用，检查是不是只产生了一个容器。</li>
</ul>
<h4 id="Istio-CNI插件"><a href="#Istio-CNI插件" class="headerlink" title="Istio CNI插件"></a>Istio CNI插件</h4><ul>
<li>Istio当前默认使用特权init容器istio-init将访问用户容器的流量转发到Envoy。istioinit的主要作用是运行脚本配置容器内的iptables规则。Istio CNI插件的主要设计目标是消除这个特权init container，使用Kubernetes CNI机制实现相同功能的替代方案，因此它是Kubernetes CNI的一个具体实现。</li>
</ul>
<h2 id="云原生架构"><a href="#云原生架构" class="headerlink" title="云原生架构"></a>云原生架构</h2><ul>
<li>根据云计算服务提供的内容，业界把云计算分成三层：基础架构即服务（IaaS）、平台即服务（PaaS）和软件即服务（SaaS）。根据云计算服务提供的来源和服务对象，云计算分为公有云和私有云。</li>
<li>在虚拟化计算和云计算服务蓬勃发展的阶段，人们也意识到了虚拟化技术的弊端。虚拟化技术虚拟出来的是一个完整操作系统，它的底层包括宿主机操作系统和虚拟化层，势必导致虚拟机的性能低于物理机的性能。此外，完整的操作系统所占用的存储空间较大，而且启动一个虚拟机，等同于启动一个完整操作系统。但是往往在虚拟服务器中可能仅仅是为了运行某一个软件而已。为此，LXC（Linux Container）技术和Docker技术开始出现。它摒弃了启动完整系统的弊端，在现有操作系统上对任务进行隔离，并实现资源按需分配。它允许多个容器共享一个操作系统内核，容器内存储的仅仅是与某个应用紧密相关的资源，其空间占用往往只有几十到几百MB。单独容器化如同虚拟PC一样会面临高可用性不足、管理低级等问题。为此，业界推出了容器编排技术。</li>
</ul>
<h3 id="什么是云原生"><a href="#什么是云原生" class="headerlink" title="什么是云原生"></a>什么是云原生</h3><ul>
<li>云原生（Cloud Native）概念是由Pivotal的Matt Stine在2013年首次提出的。这个概念得到了社区的不断完善，内容越来越丰富，目前已经包括了DevOps（Development和Operations的组合）、持续交付（Continuous Delivery，CD）、微服务（MicroServices）、敏捷基础设施（Agile Infrastructure）和十二要素（The Twelve-Factor App）等几大主题。这个概念不但包括根据业务能力对企业（高校）进行文化、组织架构的重组与建设，也包括方法论和原则，以及具体的操作工具。采用基于云原生的技术和管理方法，可以更好地从云中诞生业务，也可以把业务迁移到不同的云中，从而享受云的高效与持续服务的能力。</li>
<li>2015年云原生计算基金会（CNCF）成立，对云原生定义进行了修改，认为云原生需要包含应用容器化、面向微服务架构以及支持容器编排调度等方面的内容。</li>
<li>云三层模型与云原生架构的对比图所示，原先的IaaS层升级为敏捷基础设施，而PaaS和SaaS层则合并为微服务架构。敏捷基础设施和微服务都属于技术范畴的架构。在整个云原生架构中，也少不了自动化的持续交付和DevOps等管理措施。<br><img src="/2021/07/13/20210713-kubernetes-xue-xi-bi-ji/%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84.jpg"></li>
<li>在传统的应用系统开发过程中，软件开发商喜欢聚焦在业务系统，专注于系统如何开发、如何闭源成一个独立的整体系统。但是随着开源软件的盛行，全球合作背景下的分工细化，再加之GitHub的影响力越来越大，一个软件开发商很难在短时间内处理所有问题。软件开发商应该充分利用第三方开源或不开源的组件，自己仅仅实现必要的代码，再借助敏捷基础架构进行灵活多变的必要集成，从而节省大量人力、物力和时间，以便更加聚焦业务开发，同时又能利用整体协作快速部署业务。云原生的意义就在于此，按照云原生的理念进行顶层架构设计、实施、部署，即可实现快速迭代，投入生产使用。云原生主要包括两部分内容：云原生基础架构和云原生应用。</li>
</ul>
<h3 id="云原生基础架构"><a href="#云原生基础架构" class="headerlink" title="云原生基础架构"></a>云原生基础架构</h3><ul>
<li>Kubernetes也不能简单地称为云原生基础架构。Kubernetes的容器编排技术为云原生基础架构提供了必要的平台支撑功能。是否是云原生基础架构的关键在于是否使用自动化处理的方式。</li>
</ul>
<h3 id="云原生应用"><a href="#云原生应用" class="headerlink" title="云原生应用"></a>云原生应用</h3><ul>
<li><p>云原生应用程序的关键在于提供弹性、敏捷性、可操作性和可观察性。</p>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/zYikOS2XmBWFzlBdbKfAXQ">快速了解云原生架构</a></p>
</li>
<li><p>概念随着新的技术发展而演化。</p>
<ul>
<li>第一阶段：容器化封装 +自动化管理 + 面向微服务</li>
<li>第二阶段：DevOps、持续交付、微服务、容器</li>
<li>第三阶段：DevOps、持续交付、容器、服务网格、微服务、声明式API对云原生的解构</li>
</ul>
</li>
<li><p>云原生应用：docker 应用打包、发布、运行，Kubernetes 服务部署和集群管理，Istio 构建服务治理能力。</p>
</li>
</ul>
<hr>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol>
<li>Netfilter、BPF、SNAT</li>
<li>虚拟网络相关基础知识（Veth、Linux Bridge、Open vSwitch等）</li>
<li>VxLan、vlan、Open vSwitch、Macvlan、IPvlan等的分类、区别、关系</li>
<li>NVIDIA和AMD两个厂商的GPU、NUMA、Huge Page</li>
<li>现在是用veth还是IPvlan？</li>
<li>学习各种网络插件，比对和总结。</li>
<li>istio、Service Mesh</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>Kubernetes权威指南：从Docker到Kubernetes实践全接触（第4版）</li>
<li>Kubernetes网络权威指南：基础、原理与实践</li>
<li>云原生架构进阶实战</li>
<li><a href="https://zhuanlan.zhihu.com/p/185686233">docker网络之veth设备</a></li>
<li><a href="https://segmentfault.com/a/1190000009491002">Linux虚拟网络设备之bridge(桥)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/363293333">一文详细讲述—Linux网络虚拟化</a></li>
<li><a href="https://www.jianshu.com/p/ea77ece7158d">K8S 网络详解 3 CNI 与 CNM 网络模型</a></li>
<li><a href="https://blog.csdn.net/qq_36183935/article/details/90735049">Kubernetes利用CNI-bridge插件打通网络</a></li>
<li><a href="https://mp.weixin.qq.com/s/G1kNSmXLaAzAOQ-ja2pKVQ">60道重要的Kubernetes面试题</a></li>
<li><a href="https://mp.weixin.qq.com/s/yX0hgIOLuaKsAcrWfOfcUQ">一文带你理解云原生</a> – 很全面的总结！！！</li>
<li><a href="https://mp.weixin.qq.com/s/OXiqHvWJkmqz7FbclDd1jA">一文深入理解 Kubernetes</a></li>
</ul>
]]></content>
      <tags>
        <tag>IT-BOOK</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>也谈谈feed流的设计</title>
    <url>/2024/05/28/20240528-ye-tan-tan-feed-liu-de-she-ji/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>几年前也做过feed流相关的服务，虽然网上相关的文章很多，这里也做个人的简要记录和总结<br>方案并非原创，当时是参考其他业务团队的设计</p>
</blockquote>
</blockquote>
<ul>
<li>需求背景：做一个用户动态模块，可以发动态，可以关注别人动态，有推荐列表，有消息提醒（其实就是微博的基本功能）</li>
</ul>
<h1 id="实现逻辑流程"><a href="#实现逻辑流程" class="headerlink" title="实现逻辑流程"></a>实现逻辑流程</h1><ul>
<li><p>整个feed流设计都是强依赖Redis来实现的，以下列出key设计和对应的功能模块</p>
<ul>
<li>粉丝的feed流 - 【feed_list_$userId】<ul>
<li>member-$id_$userId_$type （score-addtime）</li>
</ul>
</li>
<li>粉丝的feed流为空标志 - 【【feed_list_empty_$userId】】- 防止每次请求都穿透到DB</li>
<li>用户的活跃粉丝列表 - 【active_fans_list_$userId】</li>
<li>用户的活跃属性 - 【active_user_status_${userId}】</li>
<li>动态详情 - 【cache.user.dynamic_${dynamicId}】 - MGet获取</li>
</ul>
</li>
<li><p>数据库分表设计</p>
<ul>
<li>用户动态表 - 按用户id分库</li>
<li>评论表 - 按动态id分库（根据业务，一般都是单个动态的所有评论）</li>
<li>点赞表 - 按用户id分库（根据业务，一般都是动态列表中展示当前用户的点赞状态）</li>
</ul>
</li>
<li><p>feed流使用sortset，score是addtime</p>
</li>
<li><p>推模式，通过维护用户的活跃粉丝列表（有数量限制），推到粉丝的feed流</p>
</li>
<li><p>拉模式，通过请求第一页或其他接口进行预加载，查询粉丝的关注人和对应动态（有数量限制），构建粉丝自己feed流</p>
</li>
</ul>
<h2 id="01-feed流-构建-整体流程"><a href="#01-feed流-构建-整体流程" class="headerlink" title="01.feed流 构建 整体流程"></a>01.feed流 构建 整体流程</h2><p><img src="/2024/05/28/20240528-ye-tan-tan-feed-liu-de-she-ji/01.feed%E6%B5%81%E6%9E%84%E5%BB%BA.drawio.png"></p>
<ul>
<li>用户发动态、删动态、关注和取关事件，都会对feed流有相应操作</li>
<li>通过发布事件的设计进行业务逻辑解耦</li>
</ul>
<h3 id="用户发动态（推模式）"><a href="#用户发动态（推模式）" class="headerlink" title="用户发动态（推模式）"></a>用户发动态（推模式）</h3><ol>
<li>用户发布动态（写入DB）</li>
<li>查询用户的活跃粉丝列表（Redis）</li>
<li>写入粉丝的Feed流（Redis）</li>
<li>写入消息表</li>
</ol>
<h3 id="粉丝拉关注列表（拉模式）（请求第一页或其他接口，预加载）"><a href="#粉丝拉关注列表（拉模式）（请求第一页或其他接口，预加载）" class="headerlink" title="粉丝拉关注列表（拉模式）（请求第一页或其他接口，预加载）"></a>粉丝拉关注列表（拉模式）（请求第一页或其他接口，预加载）</h3><ol>
<li>获取feed流（Redis）</li>
<li>获取关注用户列表（RPC）（限制2000个粉丝）</li>
<li>获取关注人的动态数据（DB）（限制没人100条动态）</li>
<li>写入个人的Feed流（Redis）</li>
<li>成为活跃用户（Redis）</li>
</ol>
<h2 id="02-动态消息交互"><a href="#02-动态消息交互" class="headerlink" title="02.动态消息交互"></a>02.动态消息交互</h2><p><img src="/2024/05/28/20240528-ye-tan-tan-feed-liu-de-she-ji/02.%E5%8A%A8%E6%80%81%E6%B6%88%E6%81%AF%E4%BA%A4%E4%BA%92.drawio.png"></p>
<ul>
<li>消息表 和 消息读取时间表（用于控制用户红点提示和读取消息列表的范围）</li>
<li>消息表保存7天定时清除</li>
</ul>
<h2 id="03-feed流预加载策略（pull模式）"><a href="#03-feed流预加载策略（pull模式）" class="headerlink" title="03.feed流预加载策略（pull模式）"></a>03.feed流预加载策略（pull模式）</h2><p><img src="/2024/05/28/20240528-ye-tan-tan-feed-liu-de-she-ji/03.feed%E6%B5%81%E9%A2%84%E5%8A%A0%E8%BD%BD%E7%AD%96%E7%95%A5%EF%BC%88pull%E6%A8%A1%E5%BC%8F%EF%BC%89.drawio.png"></p>
<ul>
<li>。。。。</li>
<li>将用户加入为活跃粉丝</li>
</ul>
<h2 id="04-动态新增、删除（push模式），活跃粉丝处理"><a href="#04-动态新增、删除（push模式），活跃粉丝处理" class="headerlink" title="04.动态新增、删除（push模式），活跃粉丝处理"></a>04.动态新增、删除（push模式），活跃粉丝处理</h2><p><img src="/2024/05/28/20240528-ye-tan-tan-feed-liu-de-she-ji/04.%E5%8A%A8%E6%80%81%E6%96%B0%E5%A2%9E%E3%80%81%E5%88%A0%E9%99%A4%EF%BC%88push%E6%A8%A1%E5%BC%8F%EF%BC%89%EF%BC%8C%E6%B4%BB%E8%B7%83%E7%B2%89%E4%B8%9D%E5%A4%84%E7%90%86.drawio.png"></p>
<ul>
<li>用户的活跃粉丝列表逻辑<ol>
<li>拉取过feed流或发布过动态等操作的用户，都会设置成有活跃粉丝属性的用户</li>
<li>RPC获取用户的粉丝列表，过滤掉非活跃用户，保存到用户的活跃粉丝列表</li>
<li>关注和取关事件，也更新活跃粉丝列表</li>
</ol>
</li>
</ul>
<h2 id="05-关注、取关-事件-对feed流的处理"><a href="#05-关注、取关-事件-对feed流的处理" class="headerlink" title="05.关注、取关 事件 对feed流的处理"></a>05.关注、取关 事件 对feed流的处理</h2><p><img src="/2024/05/28/20240528-ye-tan-tan-feed-liu-de-she-ji/05.%E5%85%B3%E6%B3%A8%E3%80%81%E5%8F%96%E5%85%B3%E4%BA%8B%E4%BB%B6%E5%AF%B9feed%E6%B5%81%E7%9A%84%E5%A4%84%E7%90%86.drawio.png"></p>
<h2 id="06-获取feed流"><a href="#06-获取feed流" class="headerlink" title="06.获取feed流"></a>06.获取feed流</h2><p><img src="/2024/05/28/20240528-ye-tan-tan-feed-liu-de-she-ji/06.%E8%8E%B7%E5%8F%96feed%E6%B5%81.drawio.png"></p>
<ul>
<li>有了前面的推拉模式，用户直接从redis获取feed流即可</li>
</ul>
<h2 id="07-动态类型版本设计"><a href="#07-动态类型版本设计" class="headerlink" title="07.动态类型版本设计"></a>07.动态类型版本设计</h2><p><img src="/2024/05/28/20240528-ye-tan-tan-feed-liu-de-she-ji/07.%E5%8A%A8%E6%80%81%E7%B1%BB%E5%9E%8B%E7%89%88%E6%9C%AC%E8%AE%BE%E8%AE%A1.drawio.png"></p>
<ul>
<li><p>随着动态类型的新增，客户端旧版本不支持新类型动态，需要过滤；</p>
</li>
<li><p>目前feed流是存在redis的，直接过滤可能会导致旧版本数据为空，可以通过多版本动态来区分</p>
</li>
<li><p>实现描述</p>
<ol>
<li>用户获取feed流，根据客户端的版本号等信息，判断出客户端支持的feed版本，并构建对应的feed流</li>
<li>用户发布动态，构建用户存在的活跃动态版本的feed流（为了用户的新旧版本都兼容）</li>
</ol>
</li>
</ul>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><ul>
<li>很久之前做的一次实验<ul>
<li>取消了微信黑名单，没看到之前的人的朋友圈。说明微信朋友圈也是feed持久化的方式实现</li>
<li>微博也是这样，之前关注过，取关后再恢复，内容也能恢复，说明feed表只是逻辑删（应该是存数据库表了）</li>
</ul>
</li>
<li>微博feed实现（猜测）<ol>
<li>为每个用户保存他所有关注的用户的feed表数据</li>
<li>假如取关，则重写关注能恢复数据（逻辑删除）</li>
<li>但如果之前没关注的用户，则他之前的动态不会出现在feed表中</li>
</ol>
</li>
</ul>
]]></content>
      <tags>
        <tag>feed流</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Saturn定时任务的客户端工具设计</title>
    <url>/2024/05/30/20240530-ji-yu-saturn-ding-shi-ren-wu-de-ke-hu-duan-gong-ju-she-ji/</url>
    <content><![CDATA[<ul>
<li>基于之前写的这篇<a href="https://kingson4wu.github.io/2023/07/03/20230703-tan-tan-ding-shi-ren-wu-de-yuan-li-he-ying-yong/">谈谈定时任务的原理和应用</a>继续聊。</li>
</ul>
<p><img src="/2024/05/30/20240530-ji-yu-saturn-ding-shi-ren-wu-de-ke-hu-duan-gong-ju-she-ji/saturn_uds.drawio.png"></p>
<ul>
<li><p>由于业务进程不是Java编写的，无法使用Saturn提供的Java定时任务，只能使用Shell定时任务</p>
</li>
<li><p>这里选择用UDS实现Shell进程和服务进程之间的通信，实现和使用Java定时任务一样的效果</p>
</li>
<li><p>在上次的实现中，只考虑了如何触发定时任务执行，并没有考虑如何停止</p>
</li>
</ul>
<h2 id="实现对执行中的任务进行停止"><a href="#实现对执行中的任务进行停止" class="headerlink" title="实现对执行中的任务进行停止"></a>实现对执行中的任务进行停止</h2><p><img src="/2024/05/30/20240530-ji-yu-saturn-ding-shi-ren-wu-de-ke-hu-duan-gong-ju-she-ji/saturn_signal.drawio.png">    </p>
<ul>
<li><p>通过测试可以知道，当在saturn控制台点击终止任务时，会对shell进程发出terminated信号</p>
</li>
<li><p>如何不是通过saturn控制台触发，直接终端执行shell命令时，操作Crtl+C时，会对Shell进程发出interrupt信号</p>
</li>
<li><p>基于上述研究，提供以下方式停止业务服务的运行中的定时任务</p>
<ol>
<li>通过saturn控制台点击终止任务，发terminated信号</li>
<li>通过操作Crtl+C，发interrupt信号</li>
<li>通过执行shell命令，指定任务名称和-stop选项，直接发出终止任务请求</li>
</ol>
</li>
<li><p>具体实现参考：<a href="https://github.com/Kingson4Wu/saturncli">saturncli</a></p>
</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul>
<li>经过测试，saturn的调度不会因为设置的频率太快导致并发运行，只会执行完一个任务再执行下一个</li>
</ul>
]]></content>
      <tags>
        <tag>Go</tag>
        <tag>定时任务</tag>
        <tag>Saturn</tag>
        <tag>UDS</tag>
        <tag>Signal</tag>
      </tags>
  </entry>
  <entry>
    <title>看似理科实则文科，看似文科实则理科</title>
    <url>/2024/07/17/20240717-kan-si-li-ke-shi-ze-wen-ke-kan-si-wen-ke-shi-ze-li-ke/</url>
    <content><![CDATA[<ul>
<li><p>前段时间在看Rust，所有权部分涉及到很多规则，让我重新反思了传统文科和理科的区别</p>
</li>
<li><p>学习一门编程语言，大家普遍会认为这是一门理科</p>
</li>
<li><p>但像Rust语言的所有权规则，让我想到了英语中的各种时态规则</p>
</li>
<li><p>大家基本会认为英语是文科</p>
</li>
<li><p>但我其实认为Rust中的规则和英语中的规则，其实没啥区别，都是逻辑规则，比较烧脑。</p>
</li>
<li><p>所以无论是学习文科还是学习理科，有些地方，都是需要良好的逻辑能力。</p>
</li>
<li><p>逻辑能力好的人，基本学习文科理科都不会有太大差异。都是聪明的人。</p>
</li>
<li><p>当然中理科中偏理的部分，文科中偏文的部分，这些可能有差异则另说。</p>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>高效会议的重要性</title>
    <url>/2024/07/18/20240718-gao-xiao-hui-yi-de-chong-yao-xing/</url>
    <content><![CDATA[<blockquote>
<p>生命是以时间为单位的，浪费别人的时间等于谋财害命；浪费自己的时间，等于慢性自杀。 - 鲁迅</p>
</blockquote>
<ul>
<li>平常在工作中，有些同事在没有提前发会议主题和相关资料前，突然就拉一群人一起开会，方便了自己，却浪费了别人的时间。</li>
<li>比如一些不专业的产品为了节省自己的时间，也不做充分的会前准备，拉一堆开发给自己做需求完善员，对别人的时间极其不尊重。</li>
</ul>
<h2 id="高效会议"><a href="#高效会议" class="headerlink" title="高效会议"></a>高效会议</h2><ol start="0">
<li>能线下小部分人沟通清楚的，不必拉齐人一起开会</li>
<li>会前发相关资料，让潜在参与者提前了解</li>
<li>看完资料，可以发相关疑问，有些内容可以提前单独沟通</li>
<li>真正开会前发会议主题和目标</li>
<li>会有要有会议纪要，结论，执行人等</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/Eew2WXHKskYR3VH35QTh4A">去TMD低效会议</a></li>
</ul>
<pre>
最近和几个大佬朋友聊天，大家不约而同的在吐槽公司开会效率低下的问题。



一提到开会，想必大家都会浮现各种场景，甚至有人可能要开始骂娘了吧？不断延长的会议时间，沉默的参会成员，语无伦次的会议组织者，不断跑偏的主题，一不小心一天就全在开会了。



what? 不仅一天全开会了，还没有任何有用的结论？



作为一个开会无数的互联网老鸟，针对高效开会，我有以下六点建议：



1.能不开会就不要开会



很多会其实根本没有开的必要，不少人平时不沟通，沟通全靠会议！



一旦开会出现几个人相互扯皮，你一句我一句的情况，基本可以断定这几个人平时就不怎么沟通，或者沟通有问题。



更为可怕的是，有些管理者，不开会就不知道自己要做什么！曾经我招过一个产品leader，热衷于组织各种会议，基本可以在会议室呆着不用出来的那种，但关键事情的推进都没落地。



具体注意点如下：

会议组织者还没完全想清楚之前，坚决不要开会

能定点沟通清楚的问题，坚决不要开会

能召集3，4个人花5分钟说清楚的事情，坚决不要开会



2.开小会，越小越好



会议人数尽量控制在7个人以内，人越多会议效率越低。有时候喊很多人开会，无非是出于显示你的权威或者逃避责任，潜台词是：反正大家都参加会议了，出了问题一起扛。



不知道大家注意过一个现象没有，不少微信群人少的时候，大家都很活跃，如果进来一些不说话的「潜水者」，大家也就慢慢都不说话了。



开会也是一个道理！如果有不太相关的人进来，他肯定会不怎么参与讨论，而其他人的思维活跃度都会受影响。



那么有人会问：如果会议就是需要很多人参与怎么办？可以将一个大的会议拆解成几个议题，分议题开小会。然后再把小会的决策者喊一起开会。



乔布斯就特别重视控制会议人数，在「疯狂的简洁」一书中记载了乔布斯一个小故事：「在一次和广告公司的例行会议上，乔布斯突然发现了一位名叫Lorrie的陌生的参会者，乔布斯指着Lorrie问到：“请问您是哪位？”，Lorrie解释自己需要听这个会议，但最后乔布斯还是礼貌的请Lorrie小姐离开了：“我不觉得你有必要参加这个会议，Lorrie小姐，谢谢。”」



我猜，Lorrie小姐估计也是暗爽的吧，毕竟她估计也是莫名其妙被拉到这个会议。



3.开会前做好充分准备



会议组织者需要把会议主题、会议背景、提前同步给所有参会人员，甚至需要提前进行答疑及相关沟通工作。



比如产品的技术评审会，不少产品经理可能没有提前发出原型做沟通。结果在会议上大家需要先理解原型，而不是上来直奔主题。



充分的准备工作，会让会议更加高效，大家坐下来开会的时候已经清楚所有信息，开门见山展开思辨，而不是一屋子人毫无准备甚至满头雾水。



4.能站着开，就别坐着开



比尔盖茨说过一句话，“当你能站着开会，就不要坐下来”。



会议室的椅子也不能用太舒服的那种，为什么？当人们坐在一个舒适且舒服的椅子上，大脑更多的时候是在放空状态，注意力无法被集中。



坐在那里舒舒服服的探讨，效率远低于站着快速解决。当站着开会，不再有人坐在办公椅上犯困想打瞌睡，不再有人玩手机看电脑。时间大大的减少，不再沉默寡言，而是速战速决。



每日的项目进度之类，特别适合10-20分钟的站会形式。站着开会，大家都不想浪费时间，自然就更能保证高节奏，高效率。



5.盯紧走神的人



开会的过程中，一般会不断有人走神。这点很考验会议组织者，如果发现有人走神，需要盯着他，看他眼睛。如果还不行，就需要提醒下拉回他的注意力。



开会应该是个激烈思辨的过程，走神是要被杜绝的。如果团队中发现开会经常走神的人，那要小心了。他要么是对业务不太了解，说不上话，要么是心灰意冷已经不想说话。「要引起重视了」



6.会后，有结论、有责任



开会过程要对关键结论做会议纪要，在会议结束后，尽早发出会议记录。会议记录可能会有遗漏和错误的地方，尽早将会议记录发给所有相关人，可以让其它参会者检查，提出问题或作出补充。



会议结束后，将任务指派给每一位责任人。这也往往是会议组织者的工作，不仅仅做出决定，更要负责落实决定的执行。如果这一步做不到位，那基本可以说这个会白开了。



最后总结几句：



开会是个大学问，千万不要小看提升的那点效率。10个人开会，浪费2小时，就相当于浪费了一个人一天的生命和一个人的工资。



工作的目标是为了创造价值，而不是摧毁价值。低效会议无疑是摧毁价值的重要帮凶！！！



浪费时间等于谋财害命，高效开会是每个会议组织者必须学会的技能。

</pre>

]]></content>
      <tags>
        <tag>职场</tag>
        <tag>会议</tag>
      </tags>
  </entry>
  <entry>
    <title>谈谈接口调用中的序列化协议</title>
    <url>/2024/07/24/20240724-tan-tan-jie-kou-diao-yong-zhong-de-xu-lie-hua-xie-yi/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>接口调用存在于内部服务之间，也存在于客户端和服务端之间<br>既然涉及接口调用，必然就涉及到数据的序列化</p>
</blockquote>
</blockquote>
<h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><ul>
<li>什么是 RPC？<ul>
<li>RPC是”远程过程调用”(Remote Procedure Call)的缩写。这是一种计算机通信协议,允许程序调用另一个地址空间(通常是在其它计算机上)的子程序或过程,而程序员就像调用本地程序一样,无需额外地为这个交互作用编程。</li>
</ul>
</li>
<li>其实 RPC 不仅可以存在于内部服务之间，前端和服务端之间的交互也可以用 RPC</li>
</ul>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><ul>
<li>一般情况下，我们习惯于使用 idl 文件定义数据格式（比如 thrift 或 Protocol Buffer），然后使用 RPC（比如 gPRC 等）用于服务之间的调用；而使用 JSON 和 HTTP 作为前端和服务端的交互方式</li>
<li>这里提一点，回看 RPC 的定义，即使使用 JSON 作为序列化协议，也可以使用 RPC 作为接口调用，具体要看 RPC 框架的实现。</li>
</ul>
<h2 id="使用-RPC-和-IDL文件-的好处"><a href="#使用-RPC-和-IDL文件-的好处" class="headerlink" title="使用 RPC 和 IDL文件 的好处"></a>使用 RPC 和 IDL文件 的好处</h2><ul>
<li>本文只关注序列化方面相关的好处</li>
<li>举个例子，接口调用简单使用 HTTP + JSON；如果后续加字段，而调用方使用不规范，复用接口调用的返回对象用于业务的其他逻辑，而字段名刚好相同，则会冲突从而可能导致逻辑异常，这种低级错误无论是客户端还是服务端都经常发生</li>
<li>理论上每个接口都应该有单独的接口响应类，这样才不会在后续加字段时产生语义冲突,虽然写起来麻烦，但这是最规范最严谨的做法，所以自动化代码工具很重要</li>
<li>其中一种解决方式：使用 IDL 文件定义数据格式，并且通过 RPC 框架限制调用的返回对象不被随意设置，从而解决这种低级又容易忽视的错误</li>
<li>对 RPC 框架的要求：<ol>
<li>限制返回对象不被修改</li>
<li>排查工具完善，支持将数据转成可阅读格式（比如使用Protobuf二进制传输，将很难排查）</li>
<li>适配多种语言的客户端 sdk（包括客户端）</li>
</ol>
</li>
</ul>
]]></content>
      <tags>
        <tag>RPC</tag>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title>简单记录我在几家公司的经历</title>
    <url>/2024/10/22/20241022-jian-dan-ji-lu-wo-zai-ji-jia-gong-si-de-jing-li/</url>
    <content><![CDATA[<ul>
<li><p>经历了一次大家普遍觉得“没考好”的高考后，我补录进入了广州一家末流的一本学校。出身于广东四五线城市的普通家庭，在高考前我并没有认真研究自己想要选择的专业。经过简单的网上搜索就业率后，我选择了网络工程这个专业。当时我并不认为这个专业与编程有什么关联，甚至可以说我对编程一无所知。</p>
</li>
<li><p>进入大学后，习惯于自学的我感到如同置身地狱（初中和高中时期我都是习惯自己看书、解题，几乎很少主动向老师请教）。现在回想起来，这种极端的习惯可能是我未能进一步提升，或走了一些弯路的原因。之所以称之为“地狱难度”，是因为我真的一无所知，只知道努力却无法抓住重点。在大学里，没有明确的方向，学习的内容繁多而杂乱。</p>
</li>
<li><p>另一方面，我也得为自己辩解一下。中国的大学（我没有见识过其他国家的情况）计算机专业的教育在一定程度上与社会脱节。缺乏引路人或足够的主动性和渴望，很难在未来的就业中具备足够的竞争力。当然，那时的网络没有现在这么发达，优质的教程较为匮乏。因此，我始终相信年轻人会越来越聪明，只要愿意学习，网络上有很多免费的优质资源，能够帮助我们少走很多弯路。毕竟，站在巨人的肩膀上学习，可以大大提高效率，节约时间。</p>
</li>
</ul>
<h2 id="毕业进入第一家公司-V"><a href="#毕业进入第一家公司-V" class="headerlink" title="毕业进入第一家公司 V"></a>毕业进入第一家公司 V</h2><blockquote>
<blockquote>
<p>时长：两年<br>社会经验尚浅，没有好好体会和感受就离开了。<br>个人成长：业务和技术启蒙，基本开发技术和业务流程的熟悉与掌握，大公司职场的适应。</p>
</blockquote>
</blockquote>
<ul>
<li><p>我首先要感谢三个人：飞哥、龙哥和强哥。</p>
</li>
<li><p>飞哥是我关系最好的同事，我们在工作中配合默契，工作之外也相处得非常融洽。他曾告诉我：“我不是来工作的，我是来交朋友的。”随着年龄的增长，我越来越认同，对于绝大多数人来说，人脉确实非常重要。</p>
</li>
<li><p>龙哥回想起来应该是我当时工作中的业务小组长。由于刚参加工作，我对这个角色并没有太多概念，我们平常就像普通同事那样相处。龙哥像大哥一样指导我解决工作中的问题，也会和我讨论业务和技术，推荐阅读技术书籍，鼓励我相信自己的学习能力，多读英文书，获取一手资料。工作之外，我们也常常开玩笑，偶尔一起出去吃下午茶。</p>
</li>
<li><p>强哥是我遇到的技术能力最强的同事，思维敏捷、动手能力出众。我现在的许多工作习惯都是向他学习的。强哥当时负责组内的基础建设，算是技术含量最高的小组。我后来主动去学习，并自然地加入了这个小组。虽然强哥有时显得严肃，但可能是对某些事情无法忍受。聪明的人有时会觉得与不太聪明的人共事很困难，因此难免会有些暴躁，现在我偶尔也能体会到这种感觉。与强哥的故事并未结束，后来我还跟着他一起创业了一段时间。</p>
</li>
<li><p>在这里，我交到了最多的朋友，大家都非常友好。</p>
</li>
</ul>
<h2 id="第二家公司-U"><a href="#第二家公司-U" class="headerlink" title="第二家公司 U"></a>第二家公司 U</h2><blockquote>
<blockquote>
<p>时长：一年三个月<br>技术基础较好的公司，但气氛却比较压抑，难以适应。<br>个人成长：学习能力和方法，技术基础原理的积累。</p>
</blockquote>
</blockquote>
<ul>
<li><p>在这里，我遇到了两个不错的同事，阿舜和阿君。总体来说，我与某些同事相处得较好，但总感觉有些同事特别冷漠，虽然不是故意的，似乎普遍存在社交恐惧，平常默默去食堂吃饭也不打招呼。可能是性格、职业属性、职场压力和公司文化等多方面原因，我个人的感受比较压抑。</p>
</li>
<li><p>作为国内前几的大公司，里面确实汇聚了很多人才和技术沉淀，光是在内网的论坛上就能学到不少知识。</p>
</li>
<li><p>此外，我在这家公司体验到了大公司内部创业的团队模式，以及组织架构调整和人员变动的经历。</p>
</li>
</ul>
<h2 id="第三家公司-D"><a href="#第三家公司-D" class="headerlink" title="第三家公司 D"></a>第三家公司 D</h2><blockquote>
<blockquote>
<p>时长：三个月<br>一家创业公司，最累但也是最开心的时光，同事相处融洽。<br>个人成长：技术管理者全局思考能力的培养，技术规划等经验。</p>
</blockquote>
</blockquote>
<ul>
<li><p>加入这家公司是前一家公司的强哥邀请的，他是团队的创始人之一，后来他也辞去了前公司的职务，全职加入。</p>
</li>
<li><p>团队规模较小，大约十三人，其中开发人员七个，没有专门的测试人员。虽然我只在这里待了三个月就宣布解散，但还是体验到了创业公司的开放与忙碌，当然也有混乱和无奈等。团队的技术人员经验虽然较浅，但各有优点和潜力。其中阿韬是我邀请到下家公司一起共事的。</p>
</li>
</ul>
<h2 id="第四家公司-K"><a href="#第四家公司-K" class="headerlink" title="第四家公司 K"></a>第四家公司 K</h2><blockquote>
<blockquote>
<p>时长：六年<br>收入最多，但在大公司光环下却是一个相对奇葩的小作坊。在这里，我的个人能力得到了充分发挥。<br>个人成长：各方面能力的积累与提升，职场经验和事务处理的积累。</p>
</blockquote>
</blockquote>
<ul>
<li><p>不确定是什么原因，前期技术和业务能力的积累、个人职业能力的成熟、对职场规则的理解，还是这里人才密度不足的影响。在这里，我的职业发展如鱼得水。在六年中经历了多次组织调整和三四次换领导，我也开始带领小规模的技术团队。在这段时间，我得到了同事们不同程度的认可，六年来每年的绩效都是优秀或以上。</p>
</li>
<li><p>我认为有几个因素促成了这一点：遇到优秀的领导、扎实的个人技术能力、良好的透明沟通等。最核心的窍门在于，在正确的职场价值观前提下，常常换位思考，这样基本能做出合理的选择。当然，有时在某些原则下可能会产生冲突和不愉快，或许有更好的处理方式，但我个人尚未掌握，某些方面也不想耗费额外时间，显得比较直接。另外，我的行事风格也在增加自己的“可替代性”。</p>
</li>
<li><p>在这里，我结识了许多关系良好的同事，毕竟待了很多年。其中，特别提到阿拳、阿杰和阿韬。</p>
</li>
<li><p>阿拳是我偶然发现的校友，比我小一届。有些人天然有种默契，眼神一对，自然而然就成了好朋友。他是一个喜欢技术挑战，渴望提升自己能力的人，但似乎在职场上的投入和专注不足，始终未能如愿。经历了换团队后，他也没有改观，最终离开了，加入了其他公司。现在看到他职业发展越来越好，生活也越来越丰富，我意识到，合适的环境和机遇对我们来说确实很重要。</p>
</li>
<li><p>阿杰是我刚加入公司时的同事，后来换团队后的领导。他与之前的领导不同，比较平易近人，尽量将公司的各种政策和职场潜规则向我们说明白。尽管身处职场，他总能从一个打工人的角度保持良心。大多数情况下，我们的相处就像朋友一样。</p>
</li>
<li><p>阿韬是前公司 D 的同事，他给我留下的印象最深刻的就是人际关系很好，从未见他与任何人发生冲突，平常开朗，喜欢群体活动。加入公司后，除了工作，我们私下相处的时间也最多，成为了我最好的朋友。在公司，他的评价一直很好，大家有心事都会找他倾诉，我常戏称他为“中央空调”。在这里，虽然技术能力是基础，但大多数情况下，沟通能力更为重要。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title>金钱业务数据库事务相关要点记录</title>
    <url>/2024/10/23/20241023-jin-qian-ye-wu-shu-ju-ku-shi-wu-xiang-guan-yao-dian-ji-lu/</url>
    <content><![CDATA[<h2 id="表结构"><a href="#表结构" class="headerlink" title="表结构"></a>表结构</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `user_balance` (</span><br><span class="line">`user_id` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;用户ID&#x27;</span>,</span><br><span class="line">`coin` <span class="type">bigint</span>(<span class="number">20</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;余额&#x27;</span>,</span><br><span class="line">`create_time` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line">`update_time` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;更新时间&#x27;</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (`user_id`),</span><br><span class="line">KEY `idx_updatetime` (`update_time`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 COMMENT<span class="operator">=</span><span class="string">&#x27;账户余额表&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `user_balance_log` (</span><br><span class="line">`log_id` <span class="type">bigint</span>(<span class="number">20</span>) unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT COMMENT <span class="string">&#x27;流水id&#x27;</span>,</span><br><span class="line">`order_id` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;业务订单ID&#x27;</span>,</span><br><span class="line">`user_id` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span> COMMENT <span class="string">&#x27;用户ID&#x27;</span>,</span><br><span class="line">`type` tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;1：加，2：减&#x27;</span>,</span><br><span class="line">`coin` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;变更金额&#x27;</span>,</span><br><span class="line">`coin_after` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;变更后的金额&#x27;</span>,</span><br><span class="line">`create_time` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (`log_id`),</span><br><span class="line">KEY `idx_createtime` (`create_time`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4 COMMENT<span class="operator">=</span><span class="string">&#x27;账户余额表流水表&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `user_balance`(`user_id`, `coin`, `create_time`, `update_time`) <span class="keyword">VALUES</span> (<span class="string">&#x27;kxw&#x27;</span>, <span class="number">20000000</span>, <span class="string">&#x27;2024-10-23 00:00:00&#x27;</span>, <span class="string">&#x27;2024-10-23 00:00:00&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">UPDATE</span> `user_balance` <span class="keyword">SET</span> `coin`<span class="operator">=</span> `coin` <span class="operator">-</span> <span class="number">1000</span> <span class="keyword">WHERE</span> `user_id` <span class="operator">=</span> <span class="string">&#x27;kxw&#x27;</span> <span class="keyword">AND</span> `coin` <span class="operator">&gt;=</span> <span class="number">1000</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="操作用户余额时注意"><a href="#操作用户余额时注意" class="headerlink" title="操作用户余额时注意"></a>操作用户余额时注意</h2><ol>
<li>可重复读（记录扣费后余额快照）(select <code>coin</code> 后记录到user_balance_log表的<code>coin_after</code>)</li>
<li>乐观锁（扣费冲突）（set <code>coin</code> - 1000 where <code>coin</code> &gt;&#x3D; 1000）</li>
<li>业务幂等（不同业务使用相应的订单表）</li>
<li>事务（用户余额表<code>user_balance</code>、日志流水表<code>user_balance_log</code>、业务订单表绑定）</li>
<li>canal 监听 binlog 识别业务异常 (对比 binlog监听的<code>user_balance</code>表<code>coin</code>变化量 和 <code>user_balance_log</code>的 <code>coin</code>记录总量 是否一致)</li>
</ol>
<h2 id="流水表只需要记录coin-after"><a href="#流水表只需要记录coin-after" class="headerlink" title="流水表只需要记录coin_after"></a>流水表只需要记录coin_after</h2><h3 id="事务过程"><a href="#事务过程" class="headerlink" title="事务过程"></a>事务过程</h3><table>
<thead>
<tr>
<th>事务1</th>
<th>事务2</th>
</tr>
</thead>
<tbody><tr>
<td>BEGIN;</td>
<td></td>
</tr>
<tr>
<td></td>
<td>BEGIN;</td>
</tr>
<tr>
<td>SELECT * FROM <code>user_balance</code> WHERE <code>user_id</code> &#x3D; ‘kxw’; (coin&#x3D;20000000)</td>
<td></td>
</tr>
<tr>
<td>UPDATE <code>user_balance</code> SET <code>coin</code>&#x3D; <code>coin</code> - 1000 WHERE <code>user_id</code> &#x3D; ‘kxw’ AND <code>coin</code> &gt;&#x3D; 1000;</td>
<td></td>
</tr>
<tr>
<td></td>
<td>SELECT * FROM <code>user_balance</code> WHERE <code>user_id</code> &#x3D; ‘kxw’; (coin&#x3D;20000000)</td>
</tr>
<tr>
<td></td>
<td>UPDATE <code>user_balance</code> SET <code>coin</code>&#x3D; <code>coin</code> - 1000 WHERE <code>user_id</code> &#x3D; ‘kxw’ AND <code>coin</code> &gt;&#x3D; 1000;</td>
</tr>
<tr>
<td>SELECT * FROM <code>user_balance</code> WHERE <code>user_id</code> &#x3D; ‘kxw’; (coin&#x3D;19999000)</td>
<td></td>
</tr>
<tr>
<td>COMMIT;</td>
<td></td>
</tr>
<tr>
<td></td>
<td>SELECT * FROM <code>user_balance</code> WHERE <code>user_id</code> &#x3D; ‘kxw’; (coin&#x3D;19998000)</td>
</tr>
<tr>
<td></td>
<td>COMMIT;</td>
</tr>
</tbody></table>
<ul>
<li>流水表只需要记录<code>coin_after</code>（变更后的余额）即可，因为变更前的余额，可能因为并发导致不准确，除非开启事务后，使用<code>select for update</code>来查询，而不是用普通的快照读</li>
</ul>
]]></content>
      <tags>
        <tag>金钱相关</tag>
      </tags>
  </entry>
  <entry>
    <title>《认知觉醒》-笔记</title>
    <url>/2024/10/25/20241025-ren-zhi-jue-xing-bi-ji/</url>
    <content><![CDATA[<p><img src="/2024/10/25/20241025-ren-zhi-jue-xing-bi-ji/%E8%AE%A4%E7%9F%A5%E8%A7%89%E9%86%92.jpg"></p>
<hr>
<ul>
<li>无论在大脑构造、潜意识、元认知、刻意练习等基本概念的解读上，还是在自控力、专注力、行动力、学习力、情绪力等具体能力的使用策略（包括早起、冥想、阅读、写作、运动等必备习惯的养成）上，都有相对独到的原理呈现和具体可行的方法提供。</li>
</ul>
<h3 id="每日反思"><a href="#每日反思" class="headerlink" title="每日反思"></a>每日反思</h3><ul>
<li>记录时间对我最大的意义，就是让自己能够觉知到时间的存在，让自己过得更加踏实。</li>
<li>每天只需花一点点时间，对当天最触动自己的事情或感悟进行复盘。</li>
<li>通过反思，我越来越多地觉知到生活中的很多细节，无须外界的帮助，就可以从小处不断完善自己。</li>
<li>如果你去练习反思，也必然会关注身体、情绪和思维三个层面，进而不断优化和改进自己。当然也会产生很多灵感、顿悟和创意，只要你去实践，就会有很多发现。</li>
<li>正视痛苦- 少数人会选择正视痛苦，反思错误，而大多数人选择逃避，沉浸在负面情绪中。</li>
<li>谨记：反思的最终目的是改变，而不是形式的完美，所以哪怕只有一句话，且这句话让自己发生了改变，那么反思的目的也就达到了。</li>
</ul>
<h2 id="第一章-大脑——一切问题的起源"><a href="#第一章-大脑——一切问题的起源" class="headerlink" title="第一章 大脑——一切问题的起源"></a>第一章 大脑——一切问题的起源</h2><ul>
<li><p>人类三重大脑</p>
<ul>
<li>本能脑（源于爬行动物，主管本能，对环境快速做出本能反应）</li>
<li>情绪脑（源于哺乳动物，主管情绪，在恶劣的环境中趋利避害，提升生存优势，比如恐惧情绪可以让他远离危险，兴奋情绪可以让他专注捕猎）</li>
<li>理智脑（源于灵长类动物，主管认知，理性地思考）</li>
</ul>
</li>
<li><p>“我怜悯恶人，我该死，应该受报应。”事实上，如果这位农夫懂得一些大脑知识，就不会犯如此低级的错误了。蛇这种冷血的爬行动物根本就没有发达的情绪脑，它不知感恩为何物，只会依靠本能行事，遇到危险要么战斗、要么逃跑；而愚昧的农夫竟然以为蛇和人类一样有善恶之心，会知恩图报，结果使自己命丧黄泉。！！！</p>
</li>
<li><p>令人欣慰的是，高级的理智脑是我们人类所独有的，它使我们富有远见、善于权衡，能立足未来获得延时满足</p>
</li>
<li><p>理智脑虽然高级，但比起本能脑和情绪脑，它的力量实在是太弱小了</p>
</li>
<li><p>本能脑早在婴儿时期就比较完善了，情绪脑则要等到青春期早期才趋于完善，而理智脑最晚，要等到成年早期才基本发育成熟。</p>
</li>
<li><p>所以在人生的前20年里，我们总是显得心智幼稚不成熟。</p>
</li>
<li><p>理智脑对大脑的控制能力很弱，所以我们在生活中做的大部分决策往往源于本能和情绪，而非理智。</p>
</li>
<li><p>为了生存，他们必须借助本能和情绪的力量对危险做出快速反应，对食物进行即时享受，对舒适产生强烈欲望，才不至于被吃掉、被饿死</p>
</li>
<li><p>为了生存，原始人还要尽量节省能量，像思考、锻炼这种耗能高的行为都会被视为对生存的威胁，会被本能脑排斥，而不用动脑的娱乐消遣行为则深受本能脑和情绪脑的欢迎</p>
</li>
<li><p>本能脑和情绪脑的基因一直被生存压力塑造着，所以它们的天性自然成了目光短浅、即时满足</p>
</li>
<li><p>我们当前遇到的几乎所有的成长问题都可以归结到目光短浅、即时满足的天性上，不过在现代社会，用避难趋易和急于求成来代指它们显然更加贴切。</p>
</li>
<li><p>成长就是克服天性的过程！！</p>
</li>
<li><p>而觉醒和成长就是让理智脑尽快变强，以克服天性</p>
</li>
<li><p>因为大脑和肌肉一样，遵循用进废退的原则。</p>
</li>
<li><p>理智脑不是直接干活的，干活是本能脑和情绪脑的事情，因为它们的“力气”大；上天赋予理智脑智慧，是让它驱动本能和情绪，而不是直接取代它们</p>
</li>
<li><p>学习知识，提升认知，运用策略</p>
</li>
<li><p>归结起来，焦虑的原因就两条：想同时做很多事，又想立即看到效果。王小波说：人的一切痛苦，本质上都是对自己无能的愤怒。焦虑的本质也契合这一观点：自己的欲望大于能力，又极度缺乏耐心。焦虑就是因为欲望与能力之间差距过大。</p>
</li>
<li><p>急于求成，想同时做很多事；避难趋易，想不怎么努力就立即看到效果。这才是焦虑真正的根源！焦虑是天性，是人类的默认设置。</p>
</li>
<li><p>我们没有必要自责或愧疚，也没有必要与天性较劲，而应想办法看清背后的机理并设法改变。</p>
</li>
<li><p>得耐心者得天下</p>
</li>
<li><p>缺乏耐心根本不是什么可耻的事，和自己的道德品质也全无关系，这仅仅是天生属性罢了，每个人都一样。</p>
</li>
<li><p>复利效应显示了价值积累的普遍规律：前期增长非常缓慢，但到达一个拐点后会飞速增长。这个“世界第八大奇迹”</p>
</li>
<li><p>我们需要冷静面对前期缓慢的增长并坚持到拐点。</p>
</li>
<li><p>复利曲线和舒适区边缘是一对好朋友，它们组合在一起可以让我们在宏观上看到保持耐心的力量，而且这种力量适用于每一个普通人。</p>
</li>
<li><p>即对于学习而言，学习之后的思考、思考之后的行动、行动之后的改变更重要，如果不盯住内层的改变量，那么在表层投入再多的学习量也会事倍功半；因此，从权重上看，改变量﹥行动量﹥思考量﹥学习量</p>
</li>
<li><p>单纯保持学习输入是简单的，而思考、行动和改变则相对困难。在缺乏觉知的情况下，我们会本能地避难趋易，不自觉地沉浸在表层的学习量中。</p>
</li>
<li><p>我们不会因自己进步缓慢而沮丧，也不会因别人成长迅速而焦虑</p>
</li>
<li><p>毕竟各自所处的阶段不同，只要持续创造价值，别人的今天就是自己的明天。</p>
</li>
<li><p>耐心不是毅力带来的结果，而是具有长远目光的结果。</p>
</li>
<li><p>对外部世界的规律的认知能使我们耐心倍增。</p>
</li>
<li><p>首先，面对天性，放下心理包袱，坦然接纳自己。当我们明白缺乏耐心是自己的天性时，就坦然接纳吧！从现在开始，对自己表现出的任何急躁、焦虑、不耐烦，都不要感到自责和愧疚</p>
</li>
<li><p>面对诱惑，学会延迟满足，变对抗为沟通。</p>
</li>
<li><p>该有的享受一点都不会少，只是不是现在享受，而是在完成重要的事情之后。”这是一个有效的策略，因为放弃享受，它们是不会同意的，但延迟享受，它们是能接受的。</p>
</li>
<li><p>最高级的方法是请本能脑和情绪脑出动来解决困难。</p>
</li>
<li><p>所以，想办法让本能脑和情绪脑感受到困难事物的乐趣并上瘾，才是理智脑的最高级的策略</p>
</li>
</ul>
<h2 id="第二章-潜意识——生命留给我们的彩蛋"><a href="#第二章-潜意识——生命留给我们的彩蛋" class="headerlink" title="第二章 潜意识——生命留给我们的彩蛋"></a>第二章 潜意识——生命留给我们的彩蛋</h2><ul>
<li><p>模糊：人生是一场消除模糊的比赛</p>
</li>
<li><p>为了更好地生存，进化之手巧妙地采用了意识分层的手段，它让潜意识负责生理系统，让意识负责社会系统，如此分工，意识便得到了解放，可以全力投入高级的社会活动。</p>
</li>
<li><p>这种模糊让人心生迷茫和恐惧，而迷茫和恐惧又使我们的认知、情绪和行动遭遇各种困扰，继而影响人生的走向。模糊，正是人生困扰之源。而人生也像是一场消除模糊的比赛，谁的模糊越严重，谁就越混沌；谁的模糊越轻微，谁就越清醒。</p>
</li>
<li><p>正如你知道了“元认知”，就知道了该如何反观自己；知道了“刻意练习”，就明白了如何精进自己；知道了“运动改造大脑”，就清楚了如何激发自己的运动热情</p>
</li>
<li><p>不幸的是，人类天生不喜欢学习和思考，因为这类事极其耗能。在漫长的进化过程中，生命的首要任务是生存，于是，基因自我设计的第一原则是节能，凡耗能高的事情都会被视为是对生存的威胁</p>
</li>
<li><p>学习知识的目的是“消除模糊”，而获取知识的方法也是“消除模糊”，目的和方法相统一</p>
</li>
<li><p>《思考力》一书的作者上田正仁提示：思考力的本质就是“丢弃所有已经消化的信息，让问题的核心浮出水面”；·《刻意练习》中的核心方法论是：不要重复练习已经会的，要不断寻找那些稍有难度的部分；·《原则》一书的作者瑞·达利欧罗列了工作和生活中的原则，用以清晰地指导自己行事；·《超越感觉》一书告诉我们，想拥有清晰的逻辑，就坚持一点：凡事不要凭模糊的感觉判断，要寻找清晰的证据。种种现象都在告诉我们一个事实</p>
</li>
<li><p>学霸”和普通同学之间的差异不仅体现在勤奋的程度上，还体现在努力的模式上：谁更愿意做高耗能的事——消除模糊，制造清晰。</p>
</li>
<li><p>受苦比解决问题来得容易，承受不幸比享受幸福来得简单。</p>
</li>
<li><p>因为解决问题需要动脑，享受幸福也需要动脑平衡各种微妙的关系，而承受痛苦则只需陷在那里不动。</p>
</li>
<li><p>真正的困难总比想象的要小很多。人们拖延、纠结、畏惧、害怕的根本原因往往不是事情本身有多难，而是内心的想法变得模糊。</p>
</li>
<li><p>如果我们再积极些，学会从一开始就主动正视它、拆解它、看清它，或许那种紧张就不困扰自己了，我们甚至能从容地“享受”比赛。</p>
</li>
<li><p>要想不受其困扰，唯一的办法就是正视它、看清它、拆解它、化解它，不给它进入潜意识的机会，不给它变模糊的机会；即使已经进入潜意识，也要想办法将它挖出来。</p>
</li>
<li><p>虽然直面情绪不会让痛苦马上消失，甚至短时间内还会加剧痛苦，但这会让你主导形势，至少不会被情绪无端恐吓。</p>
</li>
<li><p>行动力不足的真正原因是选择模糊。</p>
</li>
<li><p>选择模糊就是一种不确定性，而人类面对不确定性时会不自觉逃避</p>
</li>
<li><p>当我们没有足够清晰的指令或者目标时，就很容易选择享乐，放弃那些本该坚持但比较烧脑的选项。</p>
</li>
<li><p>在现代生活中，要想让自己更胜一筹，就必须学会花费更多的脑力和心力去思考如何拥有足够清晰的目标。我们要把目标和过程细化、具体化，在诸多可能性中建立一条单行通道，让自己始终处于“没得选”的状态。</p>
</li>
<li><p>在这条赛道上，领先的群体都有意无意地做着同一件事：消除认知、情绪和行动上的模糊。</p>
</li>
<li><p>先用感性能力帮助自己选择，再用理性能力帮助自己思考。</p>
</li>
<li><p>读书也是这样，如果单纯运用理性，我们通常会在看完整本书后花大量时间梳理作者的框架、思路，以此来表明自己读懂、读透了这本书；</p>
</li>
<li><p>一个人若是没有人生目标，纵然每天有吃、有喝、有书读、有班上，也会像一个迷失的人一样，内心没有喜悦、生活没有激情，甚至会厌恶自己，因为目标是存放我们热情和精力的地方。很多人为了找到自己的人生目标，费尽心思地分析什么事情最值得做，最后得到的答案往往是“变得很有钱”或“被别人崇拜”。这样的目标不能说有错，但往往不能长久，也无法给人真正的动力，因为这是理性思维权衡利弊和考量得失之后的结果，其动机往往来自“自我索取和外在评价”，时间一长，很容易使人迷失方向，使动力枯竭。</p>
</li>
<li><p>真正的觉醒者往往会有意无意地用感知力来代替思考力    </p>
</li>
<li><p>比如《美好人生运营指南》一书的作者一稼就提出了6条寻找人生使命的建议。·这个世界有很多事情可以做，你最想帮助哪些人？·什么事让你废寝忘食？·你在做什么事情的时候最让自己感动？·你最让人感动的时刻是什么？·如果没有任何经济压力，你会如何度过余生？·闲暇的时候，你关注最多的是哪方面的信息？</p>
</li>
<li><p>理智的分析和计算无法解出内心的真正需求，唯有感性的觉知和洞察才能让答案浮出水面。而且正确的答案往往都是利他的，因为真正长久的人生意义和幸福只能从他人的反馈中获得。</p>
</li>
<li><p>设想你即将离开世界，回首一生会为什么事情而后悔？·想一想你最喜欢的人物是谁？·你年轻的时候是怎么度过闲暇时光的？</p>
</li>
<li><p>对于你喜欢的人物，不管是虚构的还是真实的，只要让你深深地着迷，就可以从这些人物身上反射出内心理想的自己；</p>
</li>
<li><p>而年轻的时候没有家庭、工作负担，那时的追求更加遵从内心，不会受外界压力的干扰。</p>
</li>
<li><p>归纳起来，我们可以发现，理性思维虽然很高级，但在判断与选择方面可能并不具有优势，它那蹩脚的性能实在无法与灵敏快速的感性媲美。所以，先用感性选择，再用理性思考，或许是一个更好的策略，尤其是在做那些重大选择时。诚如洪兰教授的建议：小事听从你的脑，大事听从你的心。这话不无道理。</p>
</li>
<li><p>梦境。梦境是潜意识传递信息的一种方式，它可能是内心真实想法的展示，也可能是灵感的启发。</p>
</li>
<li><p>身体不会说话，却是最诚实的。无论生理还是心理上的不适，都会通过身体如实地反映出来，记得多关注这些反馈。</p>
</li>
</ul>
<h2 id="第三章-元认知——人类的终极能力"><a href="#第三章-元认知——人类的终极能力" class="headerlink" title="第三章 元认知——人类的终极能力"></a>第三章 元认知——人类的终极能力</h2><ul>
<li><p>早在15万年之前，人类就已经拥有这种能力，当然不是指人的身体真的飞到空中，而是指意识与本体分离，“飞”到更高处去反观自己。</p>
</li>
<li><p>你如果仔细观察过这个世界上优秀的人，就会发现他们几乎都是“飞”着前进的；</p>
</li>
<li><p>元认知能力就是我们习以为常、见怪不怪的反思能力。这种能力不仅为我们人类所独有，也是我们成为万物之灵[插图]的根源</p>
</li>
<li><p>当一个人能主动开启第三视角、开始持续反观自己的思维和行为时，就意味着他真正开始觉醒了，他有了快速成长的可能。</p>
</li>
<li><p>高级的元认知——时刻帮你从高处、深处、远处看待现在的自己，让自己保持清醒、不迷失，保持动力、不懈怠，保持平和、不冲动。</p>
</li>
<li><p>元认知能力总能让你站在高处俯瞰全局，不会让你一头扎进生活的细节，迷失其中。</p>
</li>
<li><p>未来视角总是当前行动的指南针</p>
</li>
<li><p>提高元认知能力的方法有很多，但最让人意想不到是下面这条——冥想。是的，冥想就是那种只要静坐在某处，然后放松身体，把注意力完全集中到呼吸和感受上的活动。</p>
</li>
<li><p>不难发现这些活动本质上都在做同一件事：监控自己的注意力，然后将其集中到自己需要关注的地方。</p>
</li>
<li><p>元认知正是人类认知能力的反馈回路，有了它，我们才可能进入快速进化的通道。</p>
</li>
<li><p>有的人能看到事物更多的意义，赋予目标强烈的价值，因此他们比其他人的专注力、执行力和意志力更强；有的人能觉察他人的想法，克制自己的言行，从而显得情商更高。他们真正的竞争力不在于学习能力，而在于强大的元认知能力。！！！</p>
</li>
<li><p>很多学习能力、运算能力超强的学霸，他们的理智脑虽然同样强大，但未必能过好自己的人生。</p>
</li>
<li><p>在“元时间”内我们要做什么呢？很简单，就做一件事：想清楚。如果不在这些选择的节点想清楚，我们就会陷入模糊状态，而模糊是潜意识的领地，它会使我们产生本能的反应——娱乐。所以，基本的应对策略便是：在选择的节点审视自己的第一反应，并产生清晰明确的主张。</p>
</li>
<li><p>虽然这样做会更累，但这正是锻炼元认知能力的最佳时机，就像是在举思想哑铃，让自己的理智脑变得更强大</p>
</li>
<li><p>元认知能力强的一个突出表现是：对模糊零容忍。换句话说，就是想尽一切办法让自己找出那个最重要的、唯一的选项，让自己在某一个时间段里只有一条路可以走。这道理很简单，既然权重都差不多，那么做哪件事都没有损失。犹豫不决，什么都想做又什么都做不好，才是最大的损失。</p>
</li>
<li><p>元认知能力强的人就是这样：无论是当下的注意力、当天的日程安排，还是长期的人生目标，他们都力求想清楚意义、进行自我审视和主动控制，而不是随波逐流。</p>
</li>
</ul>
<h2 id="第四章-专注力——情绪和智慧的交叉地带"><a href="#第四章-专注力——情绪和智慧的交叉地带" class="headerlink" title="第四章 专注力——情绪和智慧的交叉地带"></a>第四章 专注力——情绪和智慧的交叉地带</h2><ul>
<li><p>一是觉得当下太无聊，所以追求更有意思的事情；二是觉得当下太痛苦，于是追求更舒适的事情。因为身体受困于现实，只好让思想天马行空。</p>
</li>
<li><p>可见，分心走神的本质是逃避，所以，面对困难时，身心分离的人总会不自觉地退回舒适区，而身心合一的人则更容易跳出舒适区，直面困难。</p>
</li>
<li><p>身体感受永远是进入当下状态的最好媒介，而感受事物消失的过程更是一种很好的专注力训练。它提示我们，身心合一的要领不仅是专注于当下，更是享受当下，而这种享受必将使我们更从容，不慌张。</p>
</li>
<li><p>行者又问：“那何谓得道？”老和尚说：“得道前，砍柴时惦记着挑水，挑水时惦记着做饭；得道后，砍柴即砍柴，担水即担水，做饭即做饭。”</p>
</li>
<li><p>变聪明的秘诀就是：先保持极度专注，想不出答案时再将注意力转换到另一件与此毫不相干的事情上。即事前聚精会神，让意识极度投入；事后完全忘记，让意识彻底撒手。这样，灵感和答案就会大概率地出现。</p>
</li>
<li><p>很多例子都表明，科学发现或其他智力上的突破都是在当事人毫无期待、正在想别的事情的时候出现的。</p>
</li>
<li><p>李大钊也说过：“要学就学个踏实，要玩就玩个痛快！”说明界线分明的习惯对人性情和能力的培养都很有好处。</p>
</li>
<li><p>能获得有效的反馈。一般而言，不论做什么事情我们都需要反馈来准确识别自己在哪些方面还存在不足，以及为什么会存在不足。</p>
</li>
<li><p>始终在拉伸区练习。一味重复已经掌握的事情是没有意义的，但挑战太难的任务也会让自己感到挫败，二者都无法使人进入沉浸状态，好的状态应该介于二者之间。</p>
</li>
</ul>
<h2 id="第五章-学习力——学习不是一味地努力"><a href="#第五章-学习力——学习不是一味地努力" class="headerlink" title="第五章 学习力——学习不是一味地努力"></a>第五章 学习力——学习不是一味地努力</h2><ul>
<li><p>找一个自己能坚持做下去的方式，比单纯按照标准化的时间和方式做更重要。</p>
</li>
<li><p>我们就应该花大量的时间去梳理哪些内容处在自己的拉伸区，即梳理那些“会做但特别容易错或不会做但稍微努力就能懂”的内容，然后在这个区域内努力。</p>
</li>
<li><p>千万不要认为没有管束的生活很美好，一旦进入完全自由的时间，虽然开始会很舒服，但很快，我们就会迷失在众多选项中——做这个也行，做那个也行。</p>
</li>
<li><p>做选择是一件极为耗能的事情，如果没有与之匹配的清醒和定力，绝大多数人最终都会被强大的天性支配，去选择娱乐消遣。在有约束的环境下我们反而效率更高，生活更充实。</p>
</li>
<li><p>不管做什么，不管当前做得怎么样，只要让自己处在舒适区的边缘持续练习，你的舒适区就会不断扩大，拉伸区也就会不断扩展，原先的困难区也会慢慢变成拉伸区，甚至是舒适区，所以成长是必然的。</p>
</li>
<li><p>这个问题太大、太模糊。所以，你只要拆解目标——把大目标拆分为小目标，任务就会立即从困难区转移到拉伸区，这样你就愿意行动了。</p>
</li>
<li><p>跳出舒适区的最好办法就是去发现和收集那些要点，也就是每次行动的小目标</p>
</li>
<li><p>种种迹象表明，快速、简便、轻松的方式使人们避难趋易、急于求成的天性得到了放大，理智脑的潜能受到了抑制，而深度学习的能力几乎全部依赖高级理智脑的支撑。</p>
</li>
<li><p>被动学习：如听讲、阅读、视听、演示，这些活动对学习内容的平均留存率为5%、10%、20%和30%。主动学习：如通过讨论、实践、教授给他人，将被动学习的内容留存率提升到50%、75%和90%。</p>
</li>
<li><p>以阅读为例，从浅到深依次为：听书、自己读书、自己读书+摘抄金句、自己读书+思维导图&#x2F;读书笔记、自己读书+践行操练、自己读书+践行操练+输出教授。</p>
</li>
<li><p>还有一类人的数量也不少。这类人能够自己阅读，也做读书笔记或思维导图，但遗憾的是，他们的读书笔记往往只是把书中的内容梳理罗列了一番，看起来更像是一个大纲。很多人醉心于此，似乎对全书的知识了然于胸，殊不知，自己只是做了简单的搬运工作而已。虽然这种做法在一定程度上属于主动学习，但它仅仅是简单的知识陈述，与高级别的知识转换有很大的不同。更深一层的是，读完书能去实践书中的道理，哪怕有那么一两点内容让生活发生了改变，也是很了不起的，因为从这一刻开始，书本中的知识得到了转化。</p>
</li>
<li><p>请注意，遇到这种困难才是深度学习真正的开始！因为你必须动用已有的知识去解释新知识，当你能够把新学的知识解释清楚时，就意味着把它纳入了自己的知识体系，同时达到了可以教授他人的水平，并可能创造新的知识。</p>
</li>
<li><p>浅层学习满足输入，深度学习注重输出。从想法到语言再到文字，即将网状的思维变成树状的结构再变成线性的文字，相当于把思想从气态变成液态再变成固态——那些固态的东西才真正属于自己。</p>
</li>
<li><p>毕竟任何知识都不可避免地会损耗，并且这种损耗一直存在，如果不想办法把自己学到的东西固定下来，时间一长，这些知识就会烟消云散，留不下多少痕迹。</p>
</li>
<li><p>教的最高境界是用最简洁的话让一个外行人明白你讲的东西</p>
</li>
<li><p>所以，逼迫自己获取高质量的知识以及深度缝接新知识，再用自己的语言或文字教授他人，是为深度学习之道。</p>
</li>
<li><p>深度学习有以下3个步骤：</p>
<ul>
<li>(1)获取高质量的知识；(2)深度缝接新知识；(3)输出成果去教授。</li>
</ul>
</li>
<li><p>人与人之间的差距不是来自年龄，甚至不是来自经验，而是来自经验总结、反思和升华的能力。</p>
</li>
<li><p>持续反思让我对生活细节的感知能力变得越来越强，从生活中获得的东西也越来越多。</p>
</li>
<li><p>深度学习除了能让我们不再浮躁，能磨炼理智，还能带来诸多好处，比如跨界能力的提升。 </p>
</li>
<li><p>深度学习还能让人产生更多灵感。</p>
</li>
<li><p>只有在自己的领域探索得足够深入时，灵感才可能在潜意识的帮助下显现。虽然我们不是科学家，但深度学习也能让我们更大概率地收获意外的惊喜。</p>
</li>
<li><p>与此同时，深度学习还能让我们看到不同事物之间更多的关联，产生洞见。   </p>
</li>
<li><p>专注于深度学习，同时对浅学习保持开放。</p>
</li>
<li><p>无关联，不学习</p>
</li>
<li><p>常年遨游在知识的海洋中，始终无法进阶，这其中最根本的阻碍在于他们意识不到新学习的知识点是孤立的。不管这个新知识让人多警醒、使人多震撼，若是无法与已有的知识发生足够的关联，它存活不了太久。</p>
</li>
<li><p>如果你了解人类大脑的学习原理，就很容易从这幅图联想到大脑中神经元工作的情景。因为无论是学习动作，还是背记公式，从本质上来说都是大脑中神经细胞建立连接的过程。用神经科学术语解释就是：通过大量的重复动作，大脑中两个或者多个原本并不关联的神经元经过反复刺激产生了强关联。</p>
</li>
<li><p>如果没有关联这个过程，就算有再多脑细胞，你也不会变得更聪明。</p>
</li>
<li><p>鉴于此，我时常也鼓励人们写作。因为单纯阅读时，人容易满足于获取新知识，而一旦开始写作，就必须逼迫自己把所学的知识关联起来，所以写作就是一条深度学习的自然路径。</p>
</li>
<li><p>放眼看去，按照关联意识的强弱，人在不知不觉间被分成了两个群体：绝大多数人习惯以孤立的思维看待事物，喜欢花大量时间收集和占有信息；而另一批先行者则更喜欢拨弄信息之间的关联，从而在不知不觉间变得聪明了起来。</p>
</li>
<li><p>所以，我们在关联时，需要牢牢聚焦自身最迫切的需求，换句话说，就是让一切与自己有关。</p>
</li>
<li><p>知识的获取不在于多少，而在于是否与自己有关联，以及这种关联有多充分。</p>
</li>
<li><p>对别人有用的东西可能与自己并没有关系，那就果断将其放弃，把握“与自己有关”的筛选原则，会让关联效能大大提升。</p>
</li>
<li><p>知识与认知的区别</p>
</li>
<li><p>真正的知识不是你知道了它，而是能运用它帮助自己做出正确的判断和选择，解决实际问题。这一点正是“学术知识体系”和“个人知识体系”的重要区别。所以在个人成长领域，没有最优、最确定、最权威的认知体系，只有最适合我们当前状态的认知体系。</p>
</li>
<li><p>用掌握学术知识的方法去对待别人的认知体系，所以不禁沉迷于全面掌握和全盘照搬他人的体系，甚至感觉如果没有完全掌握对方的认知体系，就有可能前功尽弃。</p>
</li>
<li><p>根据能力圈法则可知，人的能力是无法跳跃发展的，只能在现有基础上一点一点向外扩展，而扩展的最佳区域就在舒适区边缘。</p>
</li>
<li><p>我们不需要全盘掌握他人的知识体系，只需要掌握那些最能触动自己、离自己需求最近的知识</p>
</li>
<li><p>体系的本质就是用独特的视角将一些零散的、独立的知识、概念或观点整合为应对这个世界的方法和技巧。</p>
</li>
<li><p>这就是搭建个人认知体系的真相：打碎各家的认知体系，只取其中最触动自己的点或块，然后将其拼接成自己的认知网络。</p>
</li>
<li><p>随着我们自身认知体系的不断完善，原来距离我们较远的知识就会相对变近，于是又能触动我们，所以暂时放弃一些知识并不可怕，只要持续学习，我们不会损失什么。</p>
</li>
<li><p>很多人读书的时候往往只关注自己是否理解了书中的内容，却经常忽视头脑中冒出的想法。其实这些想法是非常珍贵的，放过了它们，我们的学习效果就会大打折扣。</p>
</li>
<li><p>在生活中能够经常练习或使用这些知识，因为实践是产生强关联的终极方法。</p>
</li>
<li><p>在舒适区边缘，一点一点向外扩展。</p>
</li>
<li><p>莫迷恋打卡，打卡打不出未来</p>
</li>
<li><p>认知闭合，效能降低单纯地依赖打卡，不仅会转移行动的动机，还会降低行动的效能。这源自另一个重要的心理机制——认知闭合需求。</p>
</li>
<li><p>一件事若迟迟没有完成，心里就总是记挂，期盼着早点结束；此事一旦完成，做这件事的动机就会立即趋向于零。</p>
</li>
<li><p>我们之所以有这种心理是因为人类的大脑喜欢确定性，不喜欢未知或不确定性。</p>
</li>
<li><p>这就是打卡心态的特性：学不到，假装一下；学到了，立即停止。</p>
</li>
<li><p>现代人很难获得幸福感，多是因为这种快节奏和急心理，但在这种状态下，生活何其枯燥，它无法让我们享受过程，只会让身心紧张、焦虑、麻木和分裂。！！！</p>
</li>
<li><p>用记录代替打卡</p>
</li>
<li><p>只要专注于学习成长活动本身，体会其中的乐趣，就能保持强烈的学习动机，化被动学习为主动学习。</p>
</li>
<li><p>我们在任务设置时要使用新策略：设下限，不设上限。</p>
</li>
<li><p>从《微习惯》一书中获得的启示。作者斯蒂芬·盖斯为了养成好习惯，要求自己每天只做一个俯卧撑、每天只读一页书、每天只写50个字，这种无负担的习惯养成法最终促使他拥有了良好的身材，养成了阅读习惯，还写出了自己的书。他称这种方法简单到不可能失败。</p>
</li>
<li><p>无反馈，不学习</p>
</li>
<li><p>大多数人往往缺少输出和反馈意识，虽然他们极其理性，甚至能以超越常人的毅力不断激励自己努力，但最终收获的仍然是痛苦和失败。</p>
</li>
<li><p>他们似乎从来没有考虑过要尽快产出点什么，以换取反馈，通过另一种方式来激励自己。</p>
</li>
<li><p>持续的正向反馈才能真正激发本能脑和情绪脑的强大行动力。</p>
</li>
<li><p>我们的理智脑虽然聪明、有远见，但它身单力薄，真的不适合亲自上阵，真正需要它做的，是运用聪明才智去制定策略，让本能脑和情绪脑不断接受强烈的正向反馈，愉悦地朝着目标一路狂奔。</p>
</li>
<li><p>所以科学的学习策略是产出作品、获取反馈，驱动本能脑和情绪脑去“玩玩玩”，而不是一味地努力坚持，让理智脑苦苦地去“学学学”。</p>
</li>
<li><p>教是最好的学；·用是最好的学；·输出倒逼输入；·请用作品说话……那些先行者确实都有相同的品质，他们在学习的时候经常不按常理出牌，不管是不是新知识、技能，他们都直接用、直接做。当然，一开始常常用不好、做不好，但他们肯定要“鼓捣”出一个东西，然后抛出去获取反馈，不断打磨迭代</p>
</li>
<li><p>我知道这就是在驱动情绪脑为自己工作，如果自己写的文章没有任何反馈，我真不敢保证仅凭意志力和长远的认知能走到现在。所以“锁定价值—打磨作品—换取反馈”正是我持续写作的真正策略和真实动力。</p>
</li>
<li><p>分享不是随意分享半成品，而是尽最大力气将作品打磨成自己当前能力范围内可完成的最好的样子。</p>
</li>
<li><p>对待作品要像对待自己的孩子一样，每次出门前都要尽可能把它们打扮得漂亮精致，让人眼前一亮。这种要求必然会逼迫自己在能力舒适区边缘快速成长，因为这符合刻意练习的基本原则。</p>
</li>
<li><p>制定分享策略，展示给那些能力不及你的人。</p>
</li>
<li><p>最后，冷静客观地对待打击。</p>
</li>
<li><p>真正的学习成长不是“努力，努力再努力”，而是“反馈，反馈再反馈”，只有不断产出，获得反馈，我们的人生才会发生真正的变化。</p>
</li>
<li><p>“刻意练习四要素”：定义明确的目标、极度的专注、有效的反馈、在拉伸区练习。</p>
</li>
<li><p>那些持续刻苦、争分夺秒、舍不得休息一下的人，他们的精力总量势必呈一条持续下降的曲线</p>
</li>
<li><p>那些轻松的学霸，他们学习时从不过度消耗自己，只要感到精力不足，就停下来主动休息，这反而使他们精力桶的水位得到快速回升。</p>
</li>
<li><p>专注这个品质在信息时代已日渐成为稀缺品质。要学就学个踏实，要玩就玩个痛快。</p>
</li>
<li><p>面对大量的信息干扰和巨大的竞争压力，在这种情况下，大多数人只会本能地告诉自己要更刻苦、更努力，却很少有人能意识到，更科学的模式应该是：极度专注+主动休息，如此反复。</p>
</li>
<li><p>一个真正的自控高手，不是一个只知道冲刺的人，而是一个善于主动休息、保持平衡的人。</p>
</li>
<li><p>只要开始学习或工作，就尽量保持极度专注的状态，哪怕保持专注的时间很短也是有意义的；一旦发现自己开始因为精力不足而分心走神，就主动停下来调整片刻。</p>
</li>
<li><p>当然辅助工具也是有的。在时间管理领域，有一个著名的番茄工作法。</p>
</li>
<li><p>就在我想通“主动休息”这个原理的瞬间，脑海里第一个闪过的念头竟是番茄工作法，因为它符合学霸模式的所有特征：极度专注、主动休息、循环往复。</p>
</li>
<li><p>然后开始5分钟的休息计时。在这5分钟里，我会做与阅读或写作无关的事情，比如：看看窗外、收收衣服、拆拆包裹，等等，但刷手机、玩游戏这些被动使用注意力的事情我不推荐，因为它们仍然是消耗精力的。！！！</p>
</li>
<li><p>而且这个“主动停止”的动作一定要坚决。很多人在一开始的时候，由于精力分散得还不明显，就不愿意主动停下来，但这往往会得不偿失。主动休息犹如主动喝水，当感到很渴的时候再喝水，其实已经晚了，你想让精力保持高位，就要学会主动停下来，这甚至可以作为一个关键点。</p>
</li>
<li><p>刻苦，是一种宏观态度，轻松，是一种微观智慧。</p>
</li>
</ul>
<h2 id="第六章-行动力——没有行动世界只是个概念"><a href="#第六章-行动力——没有行动世界只是个概念" class="headerlink" title="第六章 行动力——没有行动世界只是个概念"></a>第六章 行动力——没有行动世界只是个概念</h2><ul>
<li><p>在经历了无数次的失败之后，我终于发现与天性对抗是没有出路的，也隐约感觉到自制力强并不代表行动力强。在随后的探索中，这个猜想逐渐得到证实：真正的行动力并不完全来源于自制力。</p>
</li>
<li><p>在一天开始的时候，一头扎进手机信息或是自己觉得有趣的事情中，然后迷失其中。这好比把这份珍贵的礼物直接摔在了地上，长此以往，自然就得不到命运的眷顾了。</p>
</li>
<li><p>如果起床后我们能刻意避开轻松和娱乐的吸引，先去读书、锻炼，或者做些重要的工作，精力就会呈聚合状态，并自动增强。比如起床后先去锻炼，就能让自己头脑清晰、精力充沛，在这种状态下做重要的工作就会非常顺利，工作越顺利，状态就越好，回路逐渐增强；再比如早起后先去阅读，读得越多，脑子里的问题和感触就越多，反过来又会产生更强烈的阅读欲望，回路逐渐增强。行动回路一旦增强，我们就会进入高效和充实的状态，此时我们哪还有精力去关注那些可看可不看的消息呢？注意力的增强回路是正向的还是负向的，很大程度上取决于你最初的选择，这也是老生常谈的道理：要事第一！！！！</p>
</li>
<li><p>在初始阶段，强迫自己先做重要的事情，一旦进入正向的增强回路，你便能拥有强大的行动力——这正是增强自制力、提升行动力的秘密</p>
</li>
<li><p>清晰力才是行动力</p>
</li>
<li><p>知道和做到相差十万八千里，这其中的差距到底在哪里呢？答案正是前文所说的“模糊”。</p>
</li>
<li><p>一切都只知道个大概，这对提升行动力来说，是很致命的。</p>
</li>
<li><p>写下当天所有要做的事，然后清空大脑，按权重将列出的事项标上序号，这样，目标就变得清晰可见；</p>
</li>
<li><p>通过持续的规划和记录，我对自由时间的掌控变得越来越强。我能够主动约束自己，我总知道下一步要做什么、什么事情最重要，即使不小心被各类消息牵绊，也能在自我提醒下快速跳出来，这一切得益于清晰力。</p>
</li>
<li><p>“写下来”就是有这样神奇的效果，因为“写下来”会清空我们的工作记忆。当我们把头脑中所有的想法和念头全部倒出来后，脑子就会瞬间变得清晰，同时，所有的想法都变得清晰且确定，这样一来，我们就进入了一种“没得选”的状态，在过程中不需要花脑力去思考或做选择。</p>
</li>
<li><p>事实上并不会，因为做规划的目的并不是让自己严格地按计划执行，而只是为了让自己心中有数。如果当天计划有变也没关系，有了这份预案，你能够在处理完临时任务后，把自己迅速拉回正轨，但如果没有这份预案，你极有可能在目标和时间都模糊的情况下选择娱乐消遣。所以，做规划十分有效，平时遇到干扰只要及时调整计划就好了。</p>
</li>
<li><p>一切源于“想清楚”</p>
</li>
<li><p>你陷入怠惰、懒散、空虚的情绪中动弹不得时，往往是因为你的大脑处于模糊状态。大脑要么不清楚自己想要什么；要么同时想做的事太多，无法确定最想实现的目标是什么；要么知道目标，但没想好具体要在什么时候以什么方式去实现。</p>
</li>
<li><p>认知越清晰，行动越坚定。</p>
</li>
<li><p>聪明的思考者都知道“想清楚”才是一切的关键，在“想清楚”这件事上。</p>
</li>
<li><p>在普通人眼里是“知易行难”，而在聪明人眼里是“知难行易”，这一点值得我们反思。</p>
</li>
<li><p>想先看到结果再行动的人往往无法看到结果。耍小聪明的人会因为结果不明朗，担心付出没有回报，所以不愿行动，以致永远停留在原地</p>
</li>
<li><p>事实上，只要道理正确，就别在乎那些小聪明，带着不计得失的心态向前走，你会发现目标越来越清晰</p>
</li>
<li><p>你觉得学英语没用，是因为你看不到生活中有需要英语的地方。只有英语学好了，和英语有关的机会才会慢慢地出现在你的周围。你觉得学历没用，是因为你根本不知道学习对你的生活轨迹能带来多少改变，你只是基于当时的场景，认为自己手里只是额外多了一张纸。你觉得锻炼身体没有用，正是因为你不去运动，所以感受不到它的价值</p>
</li>
<li><p>没错，这个世界是有认知层次的。处在下一个认知层次的人往往看不到上一个认知层次的风景，因而只能用狭隘的视角来判断：这些东西虽然很有道理，但似乎看起来并没有什么用。这些东西在他们眼里确实没什么用，因为人们无法证明一件没有发生过的事。想要打破这个悖论，只有让自己行动起来，将认知提升到更高的层次，才能做出不同的判断。</p>
</li>
<li><p>我此前一直强调“想清楚”的重要性，但当我们绞尽脑汁去想却仍然想不清楚的时候，就要依据前人的假设先行动起来</p>
</li>
<li><p>人生目标才可能慢慢浮现。</p>
</li>
<li><p>思考很重要，但光想不做，贻害无穷。</p>
</li>
<li><p>打破这些悖论的方法就是不计得失地先行动起来。</p>
</li>
<li><p>我们在行动时也应如此，我们要专注、要持续行动，直到突破阈值</p>
</li>
<li><p>这里的“傻”，并不是盲目和冲动，而是有原理、有依据的坚定</p>
</li>
<li><p>行动力强，是因为自己赞同行动背后的原理、依据和意义，而不是别人说做这个好，自己不深入了解就跟风去做，那才是真的傻。</p>
</li>
<li><p>换句话说，如果你觉得别人讲的道理有理有据，而自己暂时无法反驳，碰巧自己又非常想做这件事，那就相信他们说的是对的，然后笃定地行动</p>
</li>
<li><p>在实践途中，你自然也要保持思考，用行动反复验证他们的理论，不适则改、适则用，直到自己真正做到为止。届时你不仅能做成那件事，还能探索出自己的理论，成为别人眼中的高手。</p>
</li>
<li><p>道理再好，如果不去刻意练习，不去刺激相关神经元的强关联，这些美好的认知将永远不会真正对自己产生影响。</p>
</li>
<li><p>从现在开始，把认知当成技能，知道或想通一个道理时，不要高兴得太早，想想后面还要做大量的练习，这样就不浮躁了。</p>
</li>
<li><p>从大脑的学习机制推断，无论学习一项技能，还是养成一个习惯，背后都是相关神经元从少到多、从弱到强的关联过程。那么在一开始、在神经元关联很弱的情况下，做不好是正常的。</p>
</li>
<li><p>我们已经不是孩子了，我们应该学会用更成熟的心态包容自己最初的笨拙，即使做不好，也要持续练习，给神经元留够关联时间。</p>
</li>
<li><p>不发生真正改变的学习都是无效的学习。一篇文章、一本书就算讲得再有道理，倘若最终没有促成自己改变，我便认为读这篇文章、这本书的过程是无效的学习</p>
</li>
<li><p>现实和理论都告诉我们：懂得百点不如改变一点。真正的成长不在于自己懂得了多少道理，而在于自己改变了多少。</p>
</li>
<li><p>因为在这个世界上，知而不行的人实在太多了，只要你有所行动，就可以超越一大批人。</p>
</li>
<li><p>对成长来讲，道理都是“空头支票”，改变才是“真金白银”</p>
</li>
</ul>
<h2 id="第七章-情绪力——情绪是多角度看问题的智慧"><a href="#第七章-情绪力——情绪是多角度看问题的智慧" class="headerlink" title="第七章 情绪力——情绪是多角度看问题的智慧"></a>第七章 情绪力——情绪是多角度看问题的智慧</h2><h3 id="第一节-心智带宽：唯有富足，方能解忧"><a href="#第一节-心智带宽：唯有富足，方能解忧" class="headerlink" title="第一节　心智带宽：唯有富足，方能解忧"></a>第一节　心智带宽：唯有富足，方能解忧</h3><ul>
<li><p>贫穷造成的稀缺俘获了人的注意力，进而降低了人的心智带宽。</p>
</li>
<li><p>所谓心智带宽，就是心智的容量，它支撑着人的认知力、行动力和自控力。心智带宽一旦降低，人很容易丧失判断力，做出不明智的选择，或急于求成，做事缺乏耐心，难以抵挡享乐的诱惑。</p>
</li>
<li><p>不难预见，这些短视行为带来的糟糕结果会加剧稀缺心态：吃剩饭吃坏肚子，在医院的花费会远远超过饭菜钱；对孩子发火会让自己压力更大；而在学习时不停地刷手机，自己会更加忧心忡忡。恶性循环会增强负面回路，让忧者更忧。</p>
</li>
<li><p>可见稀缺只是“变笨”的一种诱因，事实上，任何能制造压力的事件都会挤占我们的心智带宽，比如明天的演讲、考试的期限、失业的担忧，等等。只要我们的注意力被某一个巨大的事物吸引，我们就有可能进入稀缺状态，进而降低心智带宽，做出不明智的行为。</p>
</li>
<li><p>“恋爱中的男女智商为零”</p>
</li>
<li><p>本质上就是稀缺心态导致判断力下降。</p>
</li>
<li><p>现代社会虽然给我们提供了更多便利和选择，同时也带来了前所未有的快节奏，仿佛一不留神就会落在队伍后面，这不由得迫使每个人加快脚步，不自觉地想要更多优势</p>
</li>
<li><p>心智带宽被占用殆尽，自然就没有心力支撑自己的远见、耐心、行动力和自控力了，最终只能让自己在痛苦中彷徨，甚至做不好当下的小事。</p>
</li>
<li><p>很多同学或职场人希望在假期或空闲时间提升自己，于是把日程安排得满满当当，不留一丝余地，结果每次都是“理想很丰满，现实很骨感”，不仅实现不了目标，反而在娱乐中无法自拔。这道理其实是一样的：当一个人同时面临很多任务的时候，他的心智带宽就会降低，反而没有了行动力和自控力。</p>
</li>
<li><p>有生活经验的人都会尽量克制自己的欲望，在做重要之事的同时主动安排娱乐活动，尽量保持日程的闲余——这种方法是科学的、智慧的。</p>
</li>
<li><p>陷入盲目尝试、乱学一通、急于求成的陷阱</p>
</li>
<li><p>既有人生未知的后台程序，又有各种急于实现的多线程任务。在这种状态下，一个人是很难走出来的，因为已经没有资源来支撑他的远见、耐心、行动力和自控力了。</p>
</li>
<li><p>现代生活虽然缓解了生存压力，却又带来了自控上的压力。抵制诱惑和欲望无一不消耗我们的心智带宽</p>
</li>
<li><p>唯有心智富足，方能解忧</p>
</li>
<li><p>物质条件无法决定我们的命运，真正影响我们的是心智带宽是否富足。有了富足的心智带宽，我们就能在任何环境中拥有支撑自己的远见、耐心、行动力和自控力，在变化的环境中解救自己。那么如何才能获取心智带宽呢？我想，最重要的莫过于保持自我觉知了。对此，我给大家备上五帖觉知“良药”，请各位按需取用。</p>
<ol>
<li>第一帖，保持环境觉知，理智选择。</li>
<li>第二帖，保持目标觉知，少即是多。</li>
<li>第三帖，保持欲望觉知，审视决策。<ul>
<li>脑子里存在大量任务和念头的时候，往往是我们行动力最弱的时候。所以保持对欲望的觉知，及时地审视它们，是清理自己心智带宽的好办法。</li>
<li>真正的行动力高手不是有能耐在同一时间做很多事的人，而是会想办法避免同时做很多事的人。</li>
</ul>
</li>
<li>第四帖，保持情绪觉知，谨慎决定。<ul>
<li>不要在最兴奋的时候做决定，也不要在最愤怒的时候做决定，尤其是重大决定。大喜大悲的时候，我们的心智带宽往往很窄，判断力也很弱。</li>
<li>一个心智带宽富足的人，也会是一个心平气和的人。</li>
</ul>
</li>
<li>第五帖，保持闲余觉知，自我设限。<ul>
<li>过多的闲余可不是什么好事，如果有大量的金钱，就容易萌生无谓的欲望；有大量的时间，也容易陷入低效的状态。</li>
<li>心智带宽虽足，但若不运行有效的人生程序，自然也是白费。</li>
<li>如果你的人生有如此好运，一切都很富足，不妨想办法给自己设限，适当制造稀缺，以成就自己。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="你的坏情绪，源于视角单一"><a href="#你的坏情绪，源于视角单一" class="headerlink" title="你的坏情绪，源于视角单一"></a>你的坏情绪，源于视角单一</h3><ul>
<li><p>事实上，在面对各种困境的时候，多角度看问题的能力往往是考验解决问题能力的关键</p>
</li>
<li><p>那些习惯从单一角度识人的人，往往比较单纯，也更容易受伤，本质上是因为他们缺乏多角度认知事物的意识。</p>
</li>
<li><p>一个人的性格和脾气好不好，也取决于他多角度看问题的能力：视角单一的人容易固执、急躁和钻牛角尖，而视角多元的人则表现得更为智慧、平和与包容。</p>
</li>
<li><p>我们每个人因为生活环境不同、经历不同、学识不同，所以在看待同一个问题时，理解层次和还原程度也不尽相同。</p>
</li>
<li><p>如果你确定自己的相机比他们的更高级，那就应该有“向下兼容”的意识——要么对其一笑而过，要么拿出自己的高清照片，耐心地向他们讲解什么是更好的，而不是一味地指责对方拍出来的东西很糟糕。毕竟低层的事物不会也不能向上兼容，但我们通过引导，让它们不断升级倒是有可能的。如果自己也曾有一台“落后的相机”，那就更应该体会和包容对方的立场。</p>
</li>
<li><p>在“相机”这件事情上，我们一定要保持觉知，要清醒地意识到自己的视角偏误，时刻做好向上升级、向下兼容的准备。拥有这种心态，不仅我们自己能越来越完善，还能与其他人都合得来。</p>
</li>
<li><p>不要被原始视角束缚，主动转换视角可能会看到一个新天地。</p>
</li>
<li><p>要想拥有多视角能力，就要进行刻意练习，直到形成新的路径依赖</p>
</li>
<li><p>一是勤移动。顾名思义，就是多移动你的“相机”机位，尝试用不同的视角看问题。比如设身处地地站在孩子的角度、老人的角度、对手的角度看问题，而不是仅凭自己的感受就直接认定孩子不懂事、老人不体谅、对手不讲理。</p>
</li>
<li><p>在焦虑、紧张的时候，不妨假设自己是一个局外人，用第三视角来观察自己，你会发现自己的很多担心其实是多余的，因为别人并不是那么在乎你。</p>
</li>
<li><p>如果陷入悲伤，无法自拔，那就假设自己处于十年之后，用未来视角反观现在，你会发现当下的悲伤没有任何意义，还不如收起情绪好好干活。</p>
</li>
<li><p>这种多视角观察的能力其实就体现了元认知能力。有了元认知，我们更容易在自我观察上保持觉知，进而在语言表达上也体现出“高情商”的特质。</p>
</li>
<li><p>二是善学习。</p>
</li>
<li><p>三是要开放。</p>
</li>
<li><p>忘我地聆听对方的想法。过程中没有判断、没有辩论、没有对错，把自己完全置身在对方的位置，以对方的眼睛来看世界；第二步，从“我”的角度来分享，过程中只说自己的客观感受，而不指责对方或告诉对方该怎么做。比如，说“家里满地臭袜子，我觉得精神紧张，心里很不舒适”，而不是“家里满地都是臭袜子，你不觉得难受吗”。</p>
</li>
<li><p>四是寻帮助。</p>
</li>
<li><p>原来出现特殊情况时，飞行员的注意力会被巨大的危险所俘获，心智带宽降低，容易陷入单一视角，而此时，指挥员可以给飞行员提供有效的外部视角，帮助他们更好地处置特殊情况。</p>
</li>
<li><p>同理，当我们对情绪问题或工作问题百思不得其解的时候，不要一个人闷头苦想，要学会主动寻求外部帮助，借助他人的多维视角来克服自己单一视角的局限。</p>
</li>
<li><p>五是多运动。</p>
</li>
<li><p>适当的有氧运动会提升我们体内多巴胺的水平，而多巴胺对于创造力和多角度思考能力来说都很重要。锻炼不仅能帮我们从负面情绪中快速走出来，也会引导大脑从新的角度看待事物，或者从不同角度观察问题，所以，越是心情不好的时候就越要多运动，越是想不通的时候越要多运动。</p>
</li>
<li><p>六是常反思。</p>
</li>
<li><p>通过写作抚平自己的内心，</p>
</li>
<li><p>无论什么时候，你的笔或键盘都能帮你跳出单一视角，看到更多维度。</p>
</li>
</ul>
<h3 id="第三节-游戏心态：幸福的人，总是在做另外一件事"><a href="#第三节-游戏心态：幸福的人，总是在做另外一件事" class="headerlink" title="第三节　游戏心态：幸福的人，总是在做另外一件事"></a>第三节　游戏心态：幸福的人，总是在做另外一件事</h3><ul>
<li><p>“先别减速，等跑到前面10米那个地方再减速也不迟。”等我跑到那个点后，我的目光又落到了前面的10米处，我觉得这样的距离很短，还可以继续来一次，等跑到那个点后，我又把眼光投向下一个10米处</p>
</li>
<li><p>幸福源自主动掌控现代积极心理学中，最引人瞩目的莫过于爱德华·德西和理查德·瑞恩的“自我决定理论”了。它指出人类有三种天生的内在需求：关系需求、能力需求和自主需求</p>
</li>
<li><p>一个人想要生活幸福，需要具备以下因素。·有良好的人际关系，得到别人的爱与尊敬；·有独特的本领、技能，为他人带去独特价值；·有自主选择的权力，能做自己想做的事情。</p>
</li>
<li><p>特别是“自主需求”，它是自我决定理论的关键与核心。也就是说，我们如果能主动选择和掌控所做的事情，就会产生内在动力，获取幸福。</p>
</li>
<li><p>放眼现实生活，我们总是要面对很多“不想做但必须做”的事情。比如1 500米跑步考核、堆积如山的作业、不得不洗的衣服、不得不见的人、不得不做的工作……面对这些事情，我们会不自觉地感到沮丧、抗拒和排斥，因为这些都不是我们自己主动做出的选择，而是外界给的压力。</p>
</li>
<li><p>我并不是在做这件事，我只是在做另外一件事。</p>
</li>
<li><p>我并不是在做跑步测试，我只是在玩追逐游戏；·我并不是在写作业，我只是在挑战自己的速度；·我并不是在洗衣服，我只是在活动自己的手脚；·我并不是去见领导，我只是和一个普通人聊天；·我并不是为老板做事，我只是为了提升自己。</p>
</li>
<li><p>事情本身并不重要，我们只是在通过它获取另外一种乐趣，顺便把这件事给做了。在心理学上，这个方法叫作“动机转移”。</p>
</li>
<li><p>缺乏觉知的人，其行事动机通常都由外部事物牵引，少有自主选择和掌控的余地，容易陷入“为做而做”的境地。但有觉知的人会适时觉察自己的行事动机是否停留在与目标任务无关的外部事物上，如果是，他们就主动想办法将其转移到内部，以拥有自主选择和掌控的能力，而这种掌控的窍门基本上可以分为两类：为自己而做和为玩而做。</p>
</li>
<li><p>为自己而做产生内部动机最好的方式莫过于立足于让自己变好。</p>
</li>
<li><p>而真正希望通过写作建立影响力的人是不会完全被“稿酬”“流量”等外部动机束缚的，他们往往是为自己的成长而写、为众人的需求而写、为长远的价值而写、为创造一个属于自己的世界而写。即使没有鲜花和掌声，他们也会坚持输出和成长，收获的反馈和奖励都只是意外和惊喜，不是必然和期待。</p>
</li>
<li><p>这道理不仅适用于个人层面，企业发展也是如此。比如华为公司之所以坚持不上市，就是不希望企业的发展动机被外部力量控制。如果公司上市，虽然可以在短时间内身价暴涨，但它将不可避免地把眼光放到下个季度的财报上。</p>
</li>
<li><p>那些对内在动机更敏感和坚持的人，总会与众不同。他们不会为外界的奖励或评价而刻意表现，只会为自己的成长和进步而努力进取，这样的人很难被困难击倒。</p>
</li>
<li><p>当人的注意力都在享受上时，他对跑步的心态就不一样了。相比起来，别人为了身材和身体苦苦坚持，而他只是享受愉快的跑步过程。</p>
</li>
<li><p>而我除了把跑步当成玩，其他很多事在我眼里也都是玩。比如阅读这件事。我从来不认为自己是在阅读，而是设想自己在和智者聊天。每本书在我眼里都是一个人，而我的书架就是智者朋友圈</p>
</li>
<li><p>为自己而做，通常是为了应对外部的压力和要求，为玩而做，则是为了应对重复、枯燥的事情</p>
</li>
<li><p>成长啊，有时候要看长远，让自己明白意义，心生动力；有时候要看得近些，让自己不惧困难，欢快前行。</p>
</li>
<li><p>这个世界的模样取决于我们看待它的角度</p>
</li>
<li><p>事实上，人是一种自我解释的动物，世界的意义是人类赋予的。既然做事情就是赋予意义的过程，那我们为什么不赋予它们有用又好玩的意义呢？</p>
</li>
<li><p>为自己而做可以解放情绪，为玩而做可以解放注意力</p>
</li>
</ul>
<h2 id="第八章-早冥读写跑，人生五件套——成本最低的成长之道"><a href="#第八章-早冥读写跑，人生五件套——成本最低的成长之道" class="headerlink" title="第八章 早冥读写跑，人生五件套——成本最低的成长之道"></a>第八章 早冥读写跑，人生五件套——成本最低的成长之道</h2><h3 id="第一节-早起：无闹钟、不参团、不打卡，我是如何坚持早起的"><a href="#第一节-早起：无闹钟、不参团、不打卡，我是如何坚持早起的" class="headerlink" title="第一节　早起：无闹钟、不参团、不打卡，我是如何坚持早起的"></a>第一节　早起：无闹钟、不参团、不打卡，我是如何坚持早起的</h3><ul>
<li><p>日本作家中岛孝志写的《4点起床：最养生和高效的时间管理》这本书。</p>
</li>
<li><p>浅层非快速眼动睡眠与快速眼动睡眠的组合。根据这一规律，人在睡眠后的3小时、4.5小时、6小时、7.5小时这几个节点醒来，就会觉得神清气爽，精力充沛。我对早起的实践就是从对这个理论的神奇体验开始的。</p>
</li>
<li><p>这个理论让我明白了为什么有时候我们睡了很长时间，但醒来后还是精神不佳，原因就是醒来的时机不在睡眠节点上，而是在睡眠周期中。</p>
</li>
<li><p>放弃闹钟。</p>
</li>
<li><p>中岛孝志说：“闹钟不会照顾你的睡眠周期，时间一到，就会把手伸进你的脑子里，让你的脑子发生一场大地震，潜意识会被搅得一团糟。因为你是被闹钟吵醒的，大脑深处其实还睡着，所以明明睡了8小时，可总会觉得没睡饱，整个人昏昏沉沉的。”</p>
</li>
<li><p>而当我有了感知睡眠节点的能力和习惯后（大约用了两周），根本不用担心醒不过来或错过正常的起床时间，这个生物时钟非常准。</p>
</li>
<li><p>放弃闹钟的另一个好处是，不影响家人或室友的休息，这样更容易得到他们的支持。</p>
</li>
<li><p>抓住大脑工作的高峰期。</p>
</li>
<li><p>分泌高峰期正好是早上7点左右，这时，人的工作效率非常高。人体进食后，能量也会在1小时后转变为葡萄糖，输送到大脑，人的记忆力、理解力就会提高，大脑的运转速度会迎来峰值，直至4小时后才降到谷底。所以人们要顺应规律，抓住效率高峰期，把最困难的工作放在这个时间段完成，就能达到事半功倍的效果。另外，正常吃早餐的人，上午的工作效率更高（午饭后的效率峰值在14点到16点间出现）。</p>
</li>
<li><p>一旦认知上想通想透了，行动时就不需要用大把大把的意志力来支撑了。</p>
</li>
<li><p>相比在7点左右起床，我每天多出了2小时，按一天8小时工作时长计算，每年可以多出约90个工作日，如果坚持40年，就相当于一个人全年无休工作10年。</p>
</li>
<li><p>有了这些不被打扰的时间，我可以高效地做下面这些事情。一　规划。利用10分钟左右的时间，罗列全天的工作，对它们进行排序，这样可以让自己保持头脑清晰，对全天的时间产生一种掌控感，保证自己的工作不会走弯路。二　跑步。我个人习惯起床后先跑步，毕竟此时大脑还没完全苏醒，直接进行脑力活动可能不容易迅速进入状态，但跑完步之后再冲个热水澡，精神状态就完全不同了，身体的每个细胞都被激活了，此时再读书写作就会很轻松。这种精神状态会延续到上午，当大家正常起床懵懵懂懂地去上班时，自己已经精神抖擞了。早起跑步可以让自己整个上午都享受身体的轻盈感，冬天会更耐寒。经过长期的锻炼，身型和体质也会得到极大的改善。另外，早起后，大部分人还都在睡梦中，我就可以独自一人享受晨间的静谧，这种感觉非常美妙，不会像夜间锻炼那样，经常遇到熟人而需要不停地打招呼，使锻炼效率变得很低。三　反思。这是我给自己定的功课，每天复盘一些工作、梳理一些思绪，或把一些心得感受记录下来。这么做可以很好地提升自己。四　读书或写作。平时受家庭及工作的影响，我很少有大块的时间进行自我提升，因此，早起后的这些时间非常宝贵，我的很多文章就是在这个时间段写的。五　困难的工作。我有时也会把一些困难的任务放在这个时间段攻克，通常效率会很高。早上上班的时候，那种完成了最困难的工作的心情令我从容和愉悦，这样，我就可以在很轻松的状态下做些超前或拓展性工作。以上是我目前主要的收获：清晰的时间安排、强健的体魄、良好的精神状态、不受干扰的锻炼氛围、专注的学习环境、从容的工作心态、持续的个人成长等。</p>
</li>
<li><p>除此之外，生活中焦虑也减少了很多。长期的坚持也增强了我的毅力，更重要的是，到了晚上10点，我就想着爬上床了，熬夜的恶习彻底改正。如果没有养成早起的习惯，我肯定还处于那个熬夜成性、无精打采、忙忙碌碌、无所长进的状态，不敢想象5年或10年之后会成什么样子。</p>
</li>
</ul>
<h3 id="第二节-冥想：终有一天，你要解锁这条隐藏赛道"><a href="#第二节-冥想：终有一天，你要解锁这条隐藏赛道" class="headerlink" title="第二节　冥想：终有一天，你要解锁这条隐藏赛道"></a>第二节　冥想：终有一天，你要解锁这条隐藏赛道</h3><ul>
<li>普通人和聪明人最大的能力差异是什么？是长时间保持极度专注的能力。</li>
<li>能够迅速进入专注状态，以及能够长期保持专注状态，是高效学习的两个最重要的习惯。</li>
<li>科学研究表明，通过这种集中注意力的冥想练习，人大脑皮层表面积增大，大脑灰质变厚，这意味着这种练习可以从物理上让我们变得更加聪明，因为一个人大脑皮层表面积和大脑灰质厚度是影响人聪明程度的因素。</li>
<li>闭眼静坐，专注于自己的呼吸，每天持续15分钟以上……你会感受到它的效果。</li>
<li>把心中的困惑写出来的原因，因为只要写出来，那些紧张、担忧、畏惧、害怕等情绪就会在清晰的观察下无处遁形，小球的重量自然会减轻</li>
</ul>
<h3 id="第三节-阅读：如何让自己真正爱上阅读"><a href="#第三节-阅读：如何让自己真正爱上阅读" class="headerlink" title="第三节　阅读：如何让自己真正爱上阅读"></a>第三节　阅读：如何让自己真正爱上阅读</h3><ul>
<li><p>想要快速成为一个行业的高手，最好的方法就是和行业专家交流，直接向他们请教</p>
</li>
<li><p>但现实是普通人很少有这样的机会和资源。</p>
</li>
<li><p>书籍是传承思想的最好介质，顶级的思想都能从书籍中找到，只要选书得当，就能以极低的成本找到行业里顶级的思想。</p>
</li>
<li><p>阅读可以让我们的思维能随时与顶级的思想交锋，对一个主题进行深度全面的理解，并与自己的实际充分关联，这种思维状态在平淡生活中是很少有的，但是只要拿起书本就可以马上拥有</p>
</li>
<li><p>一　读书要先学会选书。</p>
</li>
<li><p>选书比读书本身更重要。</p>
</li>
<li><p>多关注那些经过时间检验的书籍通常不会错。</p>
</li>
<li><p>二　阅读是为了改变。</p>
</li>
<li><p>真正读好一本书，往往需要花费数倍于阅读的时间去思考和实践，并输出自己的东西——可能是一篇文章，也可能是养成一个习惯——这个过程比阅读本身要费力得多。</p>
</li>
<li><p>从权重上看，阅读量&lt;思考量&lt;行动量&lt;改变量。阅读仅仅是最表层的行为，最终的目的是通过思考和行动改变自己。</p>
</li>
<li><p>阅读的深度比速度重要，阅读的质量比数量重要。读得多、读得快并不一定是好事，这很可能是自我陶醉的假象</p>
</li>
<li><p>只要紧紧盯住“改变”这个根本目标，很多阅读障碍就会立即消失</p>
</li>
<li><p>三　高阶读书法。</p>
</li>
<li><p>第一个是要特别注意自己在阅读时产生的关联。</p>
</li>
<li><p>第二个是读写不分家。如果你在阅读后还能把所学知识用自己的语言重新阐释，甚至将它们教授给他人，那这个知识将在你脑中变得非常牢固。</p>
</li>
<li><p>用一生的时间去探索、实践。</p>
</li>
</ul>
<h3 id="第四节-写作：谢谢你，费曼先生"><a href="#第四节-写作：谢谢你，费曼先生" class="headerlink" title="第四节　写作：谢谢你，费曼先生"></a>第四节　写作：谢谢你，费曼先生</h3><ul>
<li><p>向一个没有任何背景知识的人说清楚一件事是很难的。正因为这种有意无意的训练，费曼养成了一种独特的思维习惯。在从事物理研究的时候，他也会要求同事在向他汇报或者解释一个新事物时，必须用最简单的话来讲清楚。一旦解释过于冗余或者复杂，就说明他根本没有理解透彻。所谓费曼技巧就是通过自己的语言，用最简单的话把一件事情讲清楚，最好让外行人也能听懂。</p>
</li>
<li><p>这就不难理解为什么我们每个人都天生喜欢轻松愉快和简单的事情，比如在读书或读文章的时候，我们往往更愿意听故事而不是听道理。只要想明白了这一点，我想任何写作的人都会调整自己的创作方式。</p>
</li>
<li><p>先用合适的故事引起对方“感性小人”的兴趣和注意，然后把想要表达的道理通过“感性小人”转达给“理性小人”</p>
</li>
<li><p>特别是讲知识、讲道理的书籍，最好不要随意堆砌抽象概念，让人感觉很高深，看得云里雾里的。如果上来就摆图表、讲模型、说概念，或许“理性小人”没什么意见，但“感性小人”早就不耐烦了，于是他拉起“理性小人”的手说：“没意思，我们走吧。”“感性小人”的力气很大，所以说教式的写作很难吸引读者。当然，我们也不能成为“标题党”，把人吸引过来之后，又没有什么实质性的内容，这样，“理性小人”也会不满意。</p>
</li>
<li><p>能用简单的语言就不要用复杂的，这就是费曼技巧的核心之一。不过，简单不仅仅意味着轻松，还意味着简洁和形象。</p>
</li>
<li><p>我们大多数人都低估了类比（比喻）的作用，认为它只是文学中的一种修辞，事实上，它是我们的思维方式，更是我们的认知工具。</p>
</li>
<li><p>认知语言学科的创始人乔治·莱考夫曾这样定义和评价“类比”。以一种事物认知另一种事物，恰恰是学习的本质！</p>
</li>
<li><p>因为人类只能通过已知事物来解释未知事物，我们很难凭空去理解一个自己从未见过的东西。而类比，正是连接未知事物与已知事物的桥梁。</p>
</li>
<li><p>用自己的语言</p>
</li>
<li><p>费曼技巧的另一个核心就是“用自己的语言表达”，这一点比“用简单的语言表达”更为关键和奇妙。因为只有当我们使用自己的语言去解释所学时，才会真正调动自己原有的知识，才能将松散的信息编织成紧密的体系和网络，甚至创造新的认知。换言之，用自己的语言重新表达就是在调动自己的千军万马。</p>
</li>
<li><p>一个人想要真正成长，一定要学会写作，因为“只读不写”的学习是不完整的，是低效的。而写作时如果不学会用自己的语言转述，则是无用的。</p>
</li>
<li><p>因为“教”才是最好的“学”。教授他人会逼迫我们通过自己的语言，用最简单的话把一件事情讲清楚，甚至让外行人也能听得懂，而写作的优势就在于它可以让我们在磨炼这项技能的路上不断调整、反复修改，直至自己满意。</p>
</li>
</ul>
<h3 id="第五节-运动：灵魂想要走得远，身体必须在路上"><a href="#第五节-运动：灵魂想要走得远，身体必须在路上" class="headerlink" title="第五节　运动：灵魂想要走得远，身体必须在路上"></a>第五节　运动：灵魂想要走得远，身体必须在路上</h3><ul>
<li><p>好的事物往往是“正相关”的</p>
</li>
<li><p>因为运动能够调节人体的各种激素，使人达到最佳状态，使身体这个内部生态系统充满能量和活力。时常运动的人，体内生态系统犹如一汪清泉，而久坐不动的人，体内生态系统则更像是一潭死水。</p>
</li>
<li><p>一个长期缺乏运动的人可能会变“笨”。</p>
</li>
<li><p>运动能够使大脑长出更多的新的神经元，这意味着运动可以在物理上让人变得更“聪明”。</p>
</li>
<li><p>由此可以做出如下推演：运动不仅能使人身材更好、精神更佳，同时能增强大脑功能，提升注意力、记忆力、理解力、自制力，从而增强学习效果，让人创造更大的成就，获取更多资源。</p>
</li>
<li><p>好的模式是“运动+学习”</p>
</li>
<li><p>运动不是关键，运动之后的活动安排及环境刺激才是关键。</p>
</li>
<li><p>有效的模式是这样的：在运动后的1~2小时内进行高强度、高难度的脑力活动，比如阅读、解题、背记、写作、编程，等等，或是一些需要复杂技巧的体力活动，诸如舞蹈、钢琴，以及参加不同于以往的社交活动，如接触新的环境、人物或事物，这么做可以让新的神经元受到刺激，不断生长。换句话说，运动之后，脑子需要充分接受考验或挑战，才能让自己不断地变“聪明”。</p>
</li>
<li><p>“运动+学习”的模式需要坚持，因为新的神经元从生长到成熟通常需要28天</p>
</li>
<li><p>所以绝大多数运动者的硬伤就在这里：运动之后缺乏主动学习的意识和习惯。他们习惯于在运动后看电视、刷手机、玩游戏、逛街、聚会、和朋友们闲聊，甚至直接睡觉，做那些无须动脑或让自己感到很舒服的事。真的很遗憾，那些好不容易生长出来的神经元随即消散，他们因此错失了变“聪明”的机会。</p>
</li>
<li><p>比如在10分钟的有氧热身之后练习瑜伽、舞蹈、体操、太极，等等，这些复杂的活动能让大脑的全部神经细胞参与其中。活动越复杂，神经突触的联系也就越复杂，突触生长也更密集，所以好的运动方式一定同时包含有氧运动和复杂运动</p>
</li>
<li><p>运动更大的意义不在于健身而在于健脑，它不仅能使人更加乐观，还能使头脑更加灵活，最终使健康水平和认知水平实现双重提升。</p>
</li>
<li><p>语言是会影响思维的，“四肢发达，头脑简单”这句话应该修改为“四肢发达，头脑更发达”才合理，而身体和灵魂也并非只能二选一，你不能只学习不运动，或只运动不学习，也不能随心情交替进行这两项活动。我相信你现在肯定更倾向于这样的表述：灵魂想要走得远，身体必须在路上。认知越清晰，行动越坚定。从现在开始，给自己的运动计划赋予一个新的意义吧！</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>BOOK</tag>
      </tags>
  </entry>
  <entry>
    <title>对Java、Go、Rust之间的简单对比和总结</title>
    <url>/2024/11/21/20241121-dui-java-go-rust-zhi-jian-de-jian-dan-dui-bi-he-zong-jie/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>工作中接触过多种编程语言，主要是 Java 和 Go，最近因个人兴趣简单学习了 Rust，在这里简单记录总结一下</p>
</blockquote>
</blockquote>
<h2 id="编程语言的GC问题"><a href="#编程语言的GC问题" class="headerlink" title="编程语言的GC问题"></a>编程语言的GC问题</h2><ul>
<li><p>一般来说，程序需要管理好运行中使用的内存空间，比如传统的C和C++则要求开发者手动管理内存，但这往往导致内存泄漏和安全隐患；而垃圾回收（GC）语言，比如Java和Go在运行时自动回收内存，但存在”停顿”（STW）问题；而Rust则采用独特的所有权系统，通过编译期严格的规则检查，在不增加运行时开销的情况下实现内存安全。</p>
</li>
<li><p>GC语言，调用栈和内存一直在变化，不STW无法算出没引用的变量（可回收的内存）； 而Rust通过作用域的规则判断自动回收。另外无GC不代表不在堆分配，是代表没有STW的垃圾回收机制。</p>
</li>
<li><p>Rust引入了”所有权”概念，每个值都有且仅有一个所有者，当所有者离开作用域时，值会被自动释放。这种方式不仅避免了运行时垃圾回收的性能开销，还能在编译阶段就发现潜在的内存使用问题，有效防止了常见的内存安全缺陷。</p>
</li>
</ul>
<h2 id="设计哲学"><a href="#设计哲学" class="headerlink" title="设计哲学"></a>设计哲学</h2><ul>
<li>Java 作为一门成熟的编程语言，其设计理念更多体现在企业级应用和跨平台兼容性上。当然个人认为由此历史包袱也比较重。</li>
<li>相比之下，Go 和 Rust 作为更现代的语言，也各有侧重。Go 语言强调简洁、高效和并发性，而 Rust 则更加注重内存安全、零成本抽象和并发安全性。</li>
</ul>
<h2 id="交叉编译"><a href="#交叉编译" class="headerlink" title="交叉编译"></a>交叉编译</h2><ul>
<li>Go 和 Rust 支持各自编译成对应二进制实现跨平台（可以使用交叉编译）；而Java则编译成统一的字节码，依赖平台安装的运行时（JVM）来运行服务（也可以Graalvm直接编译成可执行二进制）</li>
</ul>
<h2 id="工具链"><a href="#工具链" class="headerlink" title="工具链"></a>工具链</h2><ul>
<li>相关工具链完善问题，比如Java性能依赖外部开发，比如arthas，asyncProfiler等；而Go自带pprof，单元测试工具等（Rust 也有一些相应的配套工具）；Java历史包袱重，不够现代化</li>
</ul>
<h2 id="热加载"><a href="#热加载" class="headerlink" title="热加载"></a>热加载</h2><ul>
<li>Java支持热加载（基于 Instrumentation 技术），但也有一定的限制，比如不能新增&#x2F;删除方法、类等，主要通过字节码替换和类加载器重载实现，一般多在开发阶段使用。实际应用中，JRebel 等商业工具通过更复杂的字节码重写技术，部分突破了这些限制，而Spring DevTools 提供了更轻量的重启机制。</li>
<li>Go官方不直接支持热加载；第三方工具如 gin-reload、air 实现热重载（通过监控文件变化，重新编译和启动进程，相对简单直接，但不是语言级特性）</li>
<li>Rust同样没有官方直接的热加载机制；比如cargo-watch 可以监听文件变化并重新编译（由于所有权系统，热加载实现相对复杂）</li>
</ul>
<h2 id="远程Debug"><a href="#远程Debug" class="headerlink" title="远程Debug"></a>远程Debug</h2><ul>
<li>Java远程调试的原理是两个VM之间通过debug协议进行通信，然后以达到远程调试的目的。两者之间可以通过socket进行通信。</li>
<li>Go原生支持远程调试，使用 dlv（Delve）调试器（基于 gRPC 协议通信）</li>
<li>Rust支持远程调试，但配置相对较复杂（主要使用 rust-gdb 和 rust-lldb）</li>
</ul>
<h2 id="依赖管理-以及-冲突解决"><a href="#依赖管理-以及-冲突解决" class="headerlink" title="依赖管理 以及 冲突解决"></a>依赖管理 以及 冲突解决</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><ul>
<li>Java 的依赖管理历史上存在诸多挑战。在早期，Java 并没有原生的依赖版本管理机制，开发者需要依赖 Maven 或 Gradle 等外部构建工具来处理项目依赖。更为关键的是，Java 的依赖冲突解析是基于具体类而非整个 JAR 包，这导致了潜在的版本兼容性和类加载问题。为了彻底解决这一痛点，Java 9 引入了模块化系统（Java Platform Module System, JPMS），提供了更精细和可靠的依赖管理和隔离机制，从根本上改善了包依赖和版本控制的复杂性。这一设计不仅简化了大型项目的依赖管理，还增强了 Java 运行时的安全性和可预测性。</li>
</ul>
<h3 id="关于Java的类重复问题"><a href="#关于Java的类重复问题" class="headerlink" title="关于Java的类重复问题"></a>关于Java的类重复问题</h3><ul>
<li><p>Java 依赖引入的时 Jar 包，使用时则是含路径信息的类名</p>
</li>
<li><p>Go则没有这个问题，因为Go的依赖的引入需要指定模块的全路径，使用时也是使用全路径或别名</p>
</li>
<li><p>Rust和 Go 类似，依赖的引入也需要指定模块的全路径。但不同包有相应的依赖文件，利用这个使相同依赖的不兼容版本共存而没有冲突问题</p>
</li>
<li><p>Java9之前（模块系统之前）- 只能减少，不能从根本上解决</p>
<ol>
<li>协议文件生成的代码，重复拷贝和引入，导致类重复冲突<ul>
<li>使用RPC协议，idl文件生成java文件，容易因为多处拷贝（比如一些业务通用库也使用到），导致类重复问题，这样在运行时可能会造成影响</li>
<li>这时最好打包的时候，不要将协议文件打进jar包中，让业务使用方自行生成代码</li>
<li>通过扫描jar包路径类的方式，可以协助检查这种问题 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">classPath</span> <span class="operator">=</span> Optional.ofNullable(thriftClass.getProtectionDomain())</span><br><span class="line">    .map(ProtectionDomain::getCodeSource)</span><br><span class="line">    .map(CodeSource::getLocation)</span><br><span class="line">    .map(URL::getPath).orElse(<span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!classPath.contains(jarFileName)) &#123;</span><br><span class="line">    System.err.println(String.format(<span class="string">&quot;%s thrift class may be duplicated&quot;</span>, thriftClass.getName()));</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">DuplicatedThriftFileException</span>(String.format(<span class="string">&quot;%s thrift class may be duplicated&quot;</span>, thriftClass.getName()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>通过maven-enforcer插件解决类冲突<ul>
<li>本质上就是解压所有依赖的 jar 包，判断是否存在重复的类文件，性能较低</li>
</ul>
</li>
</ol>
</li>
<li><p>JVM中Jar包的加载顺序</p>
<ul>
<li>由classpath参数指定的顺序决定</li>
<li>如果classpath未明确指明，则由文件系统决定的（readdir函数）<ul>
<li>readdir并不保证读取后的文件顺序，在不同的操作系统上可能有不同的顺序。</li>
</ul>
</li>
<li>如何找出重复类<ul>
<li><code>find . -name &quot;*.jar&quot; -exec sh -c  &#39;jar -tf &#123;&#125;|grep -H --label &#123;&#125; &#39;JspRuntimeContext &#39;&#39;</code> </li>
<li><code>-verbose:class</code> 查看加载顺序</li>
</ul>
</li>
</ul>
</li>
<li><p>Java9及以上（使用模块系统）</p>
</li>
</ul>
<h3 id="Go-VS-Rust-库冲突"><a href="#Go-VS-Rust-库冲突" class="headerlink" title="Go VS Rust 库冲突"></a>Go VS Rust 库冲突</h3><ul>
<li><p>当项目间接依赖同一个库的不同版本时，Rust 和 Go 在处理上有什么异同</p>
</li>
<li><p>Go 的处理方式：</p>
  <pre>
  依赖关系示例：
  my-project
  ├── A 
  │   └── pkg v1.1.0
  └── B
      └── pkg v1.2.3
  </pre>
<ul>
<li>Go 会：<ul>
<li>自动选择最高兼容版本（v1.2.3）</li>
<li>所有代码路径都使用这个版本</li>
<li>使用 MVS (Minimal Version Selection) 算法</li>
<li>在 go.mod 中记录最终版本  <pre>
  // go.mod
  module my-project

  require (
      A v1.0.0
      B v1.0.0
      pkg v1.2.3 // 间接依赖，统一使用最高版本
  )</pre></li>
</ul>
<p>  </p>
</li>
</ul>
</li>
<li><p>Rust 的处理方式：</p>
  <pre>
  依赖关系示例：
  my-project
  ├── A 
  │   └── pkg 1.1.0
  └── B
      └── pkg 1.2.3
  </pre>    
<ul>
<li>Rust 会：<ul>
<li>允许两个版本同时存在</li>
<li>分别编译两个版本的代码</li>
<li>在最终二进制中包含两个版本  <pre>
  Cargo.toml
  [dependencies]
  A = "1.0.0"  # 依赖 pkg 1.1.0
  B = "1.0.0"  # 依赖 pkg 1.2.3
  </pre></li>
</ul>
</li>
</ul>
</li>
<li><p>主要区别：</p>
<ul>
<li>Go: 强制统一版本，避免重复</li>
<li>Rust: 允许多版本共存，保证兼容性</li>
<li>这种设计反映了两种不同的理念：<ul>
<li>Go: 简单性优先，避免版本冲突</li>
<li>Rust: 灵活性优先，保证正确性</li>
</ul>
</li>
</ul>
</li>
<li><p>针对依赖同一个库的不同版本的情况：如果版本相同或兼容，Cargo会选择满足要求的当前最高版本；如果版本不兼容，Cargo允许在项目中同时使用这些不兼容的版本，可以通过别名来区分使用。</p>
</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>个人看法总结：Rust能做到同时使用同一个库的不同版本，是因为每个项目都有独立的依赖库配置以及引入别名机制，关键的是打包能根据这些信息直接生成二进制。而java是生成 字节码文件，并打包时丢失这方面的信息，虚拟机可能目前由于历史和后续兼容等原因也暂不支持。Go 则是选择简单性优先，避免版本冲突。</li>
<li>Rust可以运行同一库不同版本；Go和Java（模块化后）都不允许同一库不同版本；Go通过路径能确定库的唯一性；Java（未模块化）存在不同库类冲突的可能。</li>
</ul>
<h2 id="封装私有性"><a href="#封装私有性" class="headerlink" title="封装私有性"></a>封装私有性</h2><ul>
<li><p>Java通过访问修饰符（public、private、protected）控制（反射可以破坏私有性；运行时检查私有访问）</p>
</li>
<li><p>Java 9 模块化（JPMS）后，封装私有性发生了显著变化</p>
<ol>
<li>更严格的可见性控制（引入模块（module）概念；模块间显式依赖声明）</li>
<li>可见性新规则（使用 exports 关键字定义可导出包；opens 关键字控制运行时反射访问）</li>
<li>相比传统机制（编译期就能检查模块间依赖；避免了类路径的”打开式”依赖）</li>
<li>实际影响（需要在 module-info.java 显式声明依赖；原有代码需要适配模块系统；更接近 Rust 的模块化设计理念）</li>
</ol>
</li>
<li><p>Go首字母大小写决定可见性（小写标识符包内可见，大写标识符全局可见；没有私有修饰符，依赖命名约定）</p>
</li>
<li><p>Rust模块系统提供精细的可见性控制（默认私有；pub 关键字定义可见性；可以精确控制字段、方法的可见范围；编译期检查，性能无额外开销）</p>
</li>
<li><p>Rust 的封装性设计最为现代和严格，Go 相对最为简单，Java 则相对传统，Java9 之后更加严格，跟 Rust 类似，但由于历史包袱，又显得比较笨重。</p>
</li>
</ul>
<h2 id="并发和多线程"><a href="#并发和多线程" class="headerlink" title="并发和多线程"></a>并发和多线程</h2><ul>
<li>并发线程，Rust为了减少运行时，默认使用线程模型的并发。</li>
<li>Go是绿色线程（协程）。</li>
<li>Java一般也是线程模型，当然也有一些协程库（其他 JVM 语言比如 kotlin 就自带协程）</li>
</ul>
<h3 id="主线程结束进程是否停止"><a href="#主线程结束进程是否停止" class="headerlink" title="主线程结束进程是否停止"></a>主线程结束进程是否停止</h3><ul>
<li>主线程退出：主线程结束，不管其他线程是否结束，进程都会结束，这点Rust和Go一样（go是协程）.<br>Java则是即使主线程结束，其他线程不结束，进程就不会退出。</li>
</ul>
<h3 id="非主线程异常进程是否停止"><a href="#非主线程异常进程是否停止" class="headerlink" title="非主线程异常进程是否停止"></a>非主线程异常进程是否停止</h3><ul>
<li>默认情况下，非主线程的 panic 不会导致整个进程退出，这点 Rust 和 Java 一样。<ul>
<li>Java 中未捕获的异常会导致线程终止，但不影响其他线程</li>
<li>Rust 的设计更灵活，允许开发者根据需求自行控制（比如使用 std::panic::set_hook() 设置了自定义 panic 处理，可以捕获控制）</li>
</ul>
</li>
<li>而 Go 中 goroutine panic 会导致整个程序崩溃（除非被 recover）</li>
</ul>
<h2 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h2><ul>
<li>类定义：java Python js 只有class的概念 go 只有struct概念 c++都有 区别是struct可以在栈中定义</li>
<li>面向对象：Java中的单继承其实简化了继承的使用方式， Go和Rust，算是彻底抛弃了使用类继承的方式，选择了接口继承。</li>
<li>Java设计之初就是面向对象，加上由于后续历史兼容等原因，代码看起来比较臃肿（类设计）；Rust博采众长，有各自语法糖；Go追求语法简单，表达力不足，会存在一定丑陋的代码（比如没有set， contains，streams等）</li>
</ul>
<h2 id="接口设计和多态"><a href="#接口设计和多态" class="headerlink" title="接口设计和多态"></a>接口设计和多态</h2><ul>
<li>Rust中的 trait 和 Java 以及 Go 的接口：本质上它们都是在解决同一个问题：如何定义和实现抽象行为。主要区别在于语言设计理念导致的一些具体细节</li>
</ul>
<h2 id="空值问题"><a href="#空值问题" class="headerlink" title="空值问题"></a>空值问题</h2><ul>
<li>Go的类型系统一个缺憾是，对于一个类型，它的值是零值，还是不存在值，混淆不清。Java 之前也存在类似的问题，但是后来增加了基础类型的包装类型（例如对于int的Integer，double的Double），Go是否也可以参考一下？或者增加一个Option(al)类型，对这些基础类型再包装一下（基于泛型），当然还有其他更优方案那就更好了<ul>
<li>JSON包新提案：用“omitzero”解决编码中的空值困局:<a href="https://mp.weixin.qq.com/s/Lw_l_AELo8RKiLzVdS0H-Q">https://mp.weixin.qq.com/s/Lw_l_AELo8RKiLzVdS0H-Q</a></li>
</ul>
</li>
</ul>
<h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><ul>
<li>异常：Java分为Error和Exception，异常又分为运行时异常和检查性异常。抛出与捕获。<br>这点和go是类似的，go也区分简单返回的错误error和抛出的恐慌panic，而 Rust 也是差不多这么设计。</li>
</ul>
<h2 id="链式调用"><a href="#链式调用" class="headerlink" title="链式调用"></a>链式调用</h2><ul>
<li><p>链式调用：Rust和Java支持函数式链式编程，类似stream；Go不支持，要自己实现</p>
</li>
<li><p>Rust 的迭代器和 Java 的 Stream API 确实很像，都支持链式调用和函数式编程风格。</p>
</li>
<li><p>Go 的设计理念是追求简单直接，所以：</p>
<ul>
<li>没有内置的链式调用语法</li>
<li>更倾向于使用显式的 for range 循环</li>
<li>性能更可预测（没有懒加载特性）</li>
</ul>
</li>
<li><p>这反映了不同语言的设计理念：</p>
<ul>
<li>Rust&#x2F;Java：提供丰富的抽象和函数式编程特性</li>
<li>Go：保持简单，倾向于显式的命令式编程</li>
</ul>
</li>
</ul>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul>
<li>枚举：Java和Rust支持，Go不支持；Rust可以支持同个枚举内包含不同类型</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://mp.weixin.qq.com/s/UG-6UuqDiLX15dEZrGGrRA">Gopher的Rust第一课：Rust的依赖管理</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Go</tag>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>AI已经如此强大了，帮我写完所有代码</title>
    <url>/2024/11/29/20241129-ai-yi-jing-ru-ci-qiang-da-liao-bang-wo-xie-wan-suo-you-dai-ma/</url>
    <content><![CDATA[<ul>
<li><p>今天使用Windsurf帮我写一个小工具。</p>
</li>
<li><p>全程没有写过一行代码和一个字，全靠一直给AI提需求，配合授权运行纠正；有时感觉偏离正确的道路时，结合git命令回退代码，再重新提需求。就这样一直重复，就帮我把这个小工具写好了，包括使用文档，构建脚本等，通通都包了。</p>
</li>
<li><p>自从两年前第一次用ChatGPT时一下子服气了，这次直接帮我把整个项目搞定了，不得不再次拜服。客观来讲，如果是我一个人来做，由于对Rust不熟练等原因，估计得一周，而且还会很费劲，然而它半天就搞定了，并且我做得不一定比它好。</p>
</li>
<li><p>使用AI帮助编程，就像一个架构师，有一群AI小弟帮你做事。</p>
</li>
<li><p>想要把事情快速做好，前提是你是一个有品位的架构师，另外即使你很多不懂，你也是有很大可能通过你的AI小弟变成一个优秀的架构师。所以学习方法，总结，知识体系很重要，拥抱变化。</p>
</li>
<li><p>AI为什么这么强大，对里面的细节是越来越好奇了。</p>
</li>
<li><p>项目地址：<a href="https://github.com/Kingson4Wu/magic-converter">https://github.com/Kingson4Wu/magic-converter</a></p>
</li>
</ul>
<p><img src="/2024/11/29/20241129-ai-yi-jing-ru-ci-qiang-da-liao-bang-wo-xie-wan-suo-you-dai-ma/Windsurf.jpeg"></p>
]]></content>
      <tags>
        <tag>Rust</tag>
        <tag>AI</tag>
        <tag>Windsurf</tag>
      </tags>
  </entry>
  <entry>
    <title>一个无中心节点的局域网通信工具</title>
    <url>/2024/12/02/20241202-yi-ge-wu-zhong-xin-jie-dian-de-ju-yu-wang-tong-xin-gong-ju/</url>
    <content><![CDATA[<h2 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h2><ol>
<li>初始阶段：UDP广播发现</li>
<li>建立连接后：切换到TCP进行可靠通信（也可以使用 UDP）（增加接收完成确认机制）</li>
</ol>
<h2 id="AI生成的需求文档"><a href="#AI生成的需求文档" class="headerlink" title="AI生成的需求文档"></a>AI生成的需求文档</h2><p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h2 id="局域网去中心化点对点通信工具-iOS-应用需求文档"><a href="#局域网去中心化点对点通信工具-iOS-应用需求文档" class="headerlink" title="局域网去中心化点对点通信工具 iOS 应用需求文档"></a>局域网去中心化点对点通信工具 iOS 应用需求文档</h2><h3 id="项目概述"><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h3><p>开发一款完全去中心化的局域网点对点即时通信应用，无需中心服务器，通过UDP广播实现设备发现和通信。</p>
<h3 id="核心设计理念"><a href="#核心设计理念" class="headerlink" title="核心设计理念"></a>核心设计理念</h3><ul>
<li>完全去中心化</li>
<li>基于局域网的点对点直接通信</li>
<li>无需任何中心服务器</li>
<li>设备间直接建立连接</li>
</ul>
<h3 id="网络通信技术架构"><a href="#网络通信技术架构" class="headerlink" title="网络通信技术架构"></a>网络通信技术架构</h3><h4 id="1-设备发现机制"><a href="#1-设备发现机制" class="headerlink" title="1. 设备发现机制"></a>1. 设备发现机制</h4><h5 id="1-1-UDP-广播发现"><a href="#1-1-UDP-广播发现" class="headerlink" title="1.1 UDP 广播发现"></a>1.1 UDP 广播发现</h5><ul>
<li>使用UDP广播进行设备发现</li>
<li>广播地址：255.255.255.255</li>
<li>广播端口：固定端口（如 48689）</li>
<li>发现报文结构：<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;deviceId&quot;</span><span class="punctuation">:</span> <span class="string">&quot;唯一设备标识&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;nickname&quot;</span><span class="punctuation">:</span> <span class="string">&quot;用户昵称&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="string">&quot;时间戳&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;publicKey&quot;</span><span class="punctuation">:</span> <span class="string">&quot;公钥信息&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;capabilities&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;支持的功能列表&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="2-连接建立协议"><a href="#2-连接建立协议" class="headerlink" title="2. 连接建立协议"></a>2. 连接建立协议</h4><ul>
<li>发现阶段：UDP 广播</li>
<li>连接阶段：切换到 TCP</li>
<li>通信协议：自定义应用层协议</li>
<li>连接建立流程：<ol>
<li>UDP 广播发现</li>
<li>交换公钥</li>
<li>建立加密 TCP 通道</li>
</ol>
</li>
</ul>
<h4 id="3-通信模型"><a href="#3-通信模型" class="headerlink" title="3. 通信模型"></a>3. 通信模型</h4><ul>
<li>无中心节点</li>
<li>每个设备既是客户端又是服务端</li>
<li>直接点对点通信</li>
<li>消息路由完全去中心化</li>
</ul>
<h3 id="功能需求详细描述"><a href="#功能需求详细描述" class="headerlink" title="功能需求详细描述"></a>功能需求详细描述</h3><h4 id="1-网络发现与连接"><a href="#1-网络发现与连接" class="headerlink" title="1. 网络发现与连接"></a>1. 网络发现与连接</h4><ul>
<li>持续监听 UDP 广播</li>
<li>自动发现局域网内设备</li>
<li>支持手动&#x2F;自动添加好友</li>
<li>好友关系本地持久化</li>
</ul>
<h4 id="2-消息通信机制"><a href="#2-消息通信机制" class="headerlink" title="2. 消息通信机制"></a>2. 消息通信机制</h4><ul>
<li>UDP 广播发现</li>
<li>TCP 建立稳定通道</li>
<li>消息队列管理</li>
<li>离线消息处理</li>
</ul>
<h4 id="3-安全性设计"><a href="#3-安全性设计" class="headerlink" title="3. 安全性设计"></a>3. 安全性设计</h4><ul>
<li>设备间公钥交换</li>
<li>端到端消息加密</li>
<li>防重放攻击</li>
<li>消息签名验证</li>
</ul>
<h3 id="技术实现细节"><a href="#技术实现细节" class="headerlink" title="技术实现细节"></a>技术实现细节</h3><h4 id="网络通信协议"><a href="#网络通信协议" class="headerlink" title="网络通信协议"></a>网络通信协议</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant A as 设备A</span><br><span class="line">    participant B as 设备B</span><br><span class="line">    </span><br><span class="line">    A-&gt;&gt;B: UDP广播：发现请求</span><br><span class="line">    B--&gt;&gt;A: UDP广播：发现响应</span><br><span class="line">    A-&gt;&gt;B: TCP建立连接</span><br><span class="line">    A--&gt;&gt;B: 交换公钥</span><br><span class="line">    A-&gt;&gt;B: 加密消息传输</span><br></pre></td></tr></table></figure>

<h4 id="消息队列流程"><a href="#消息队列流程" class="headerlink" title="消息队列流程"></a>消息队列流程</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">stateDiagram-v2</span><br><span class="line">    [*] --&gt; 消息生成</span><br><span class="line">    消息生成 --&gt; 本地队列</span><br><span class="line">    本地队列 --&gt; 检测网络</span><br><span class="line">    检测网络 --&gt; 同一局域网: 直接发送</span><br><span class="line">    检测网络 --&gt; 离线: 保持队列</span><br><span class="line">    同一局域网 --&gt; 消息发送</span><br><span class="line">    消息发送 --&gt; [*]</span><br></pre></td></tr></table></figure>

<h3 id="系统架构图"><a href="#系统架构图" class="headerlink" title="系统架构图"></a>系统架构图</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[UDP广播发现] --&gt; B[设备信息交换]</span><br><span class="line">    B --&gt; C[TCP安全通道]</span><br><span class="line">    C --&gt; D[端到端加密通信]</span><br><span class="line">    D --&gt; E[本地消息队列]</span><br><span class="line">    E --&gt; F[离线/在线消息管理]</span><br></pre></td></tr></table></figure>

<h3 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h3><ul>
<li>语言：Swift</li>
<li>网络框架：Network.framework</li>
<li>加密：CryptoKit</li>
<li>存储：CoreData</li>
<li>UI：SwiftUI</li>
</ul>
<h3 id="关键技术挑战"><a href="#关键技术挑战" class="headerlink" title="关键技术挑战"></a>关键技术挑战</h3><ol>
<li>跨设备一致性</li>
<li>网络发现可靠性</li>
<li>安全性保证</li>
<li>低功耗设计</li>
</ol>
<h3 id="性能目标"><a href="#性能目标" class="headerlink" title="性能目标"></a>性能目标</h3><ul>
<li>设备发现时间 &lt; 3秒</li>
<li>消息延迟 &lt; 1秒</li>
<li>电池资源占用 &lt; 5%</li>
<li>网络资源占用最小化</li>
</ul>
<h3 id="安全性要求"><a href="#安全性要求" class="headerlink" title="安全性要求"></a>安全性要求</h3><ul>
<li>端到端加密</li>
<li>防重放攻击</li>
<li>设备指纹验证</li>
<li>消息签名机制</li>
</ul>
<h3 id="隐私保护"><a href="#隐私保护" class="headerlink" title="隐私保护"></a>隐私保护</h3><ul>
<li>无中心服务器</li>
<li>本地数据完全加密</li>
<li>用户完全控制通信</li>
<li>不依赖任何第三方服务</li>
</ul>
<h3 id="开发交付物"><a href="#开发交付物" class="headerlink" title="开发交付物"></a>开发交付物</h3><ol>
<li>完整 Xcode 工程</li>
<li>详细技术文档</li>
<li>安全性测试报告</li>
<li>性能基准测试结果</li>
</ol>
<h3 id="版本迭代计划"><a href="#版本迭代计划" class="headerlink" title="版本迭代计划"></a>版本迭代计划</h3><ul>
<li>v1.0：基础局域网通信</li>
<li>v1.1：增强安全性</li>
<li>v1.2：优化性能</li>
<li>v2.0：跨平台支持</li>
</ul>
<h3 id="开发注意事项"><a href="#开发注意事项" class="headerlink" title="开发注意事项"></a>开发注意事项</h3><ul>
<li>严格遵循 Apple 安全guidelines</li>
<li>代码安全审查</li>
<li>最小权限原则</li>
<li>用户体验优先</li>
</ul>
<p>&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h3 id="Rust简易版本"><a href="#Rust简易版本" class="headerlink" title="Rust简易版本"></a>Rust简易版本</h3><ul>
<li><a href="https://github.com/Kingson4Wu/mesh-talk">https://github.com/Kingson4Wu/mesh-talk</a> （使用windsurf生成）</li>
</ul>
<p>&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><blockquote>
<blockquote>
<p>发现已经有了相关实现，非常棒！</p>
</blockquote>
</blockquote>
<ul>
<li><a href="https://github.com/localsend/localsend">https://github.com/localsend/localsend</a> 局域网文件传输，广播发现，可以简易发消息</li>
</ul>
]]></content>
      <tags>
        <tag>Rust</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能相关技术简要总结记录</title>
    <url>/2024/12/03/20241203-ren-gong-zhi-neng-xiang-guan-ji-zhu-jian-yao-zong-jie-ji-lu/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>持续补充…</p>
</blockquote>
</blockquote>
<p><img src="/2024/12/03/20241203-ren-gong-zhi-neng-xiang-guan-ji-zhu-jian-yao-zong-jie-ji-lu/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.jpg"></p>
<h2 id="人工智能的三种形态"><a href="#人工智能的三种形态" class="headerlink" title="人工智能的三种形态"></a>人工智能的三种形态</h2><ul>
<li>来自：<a href="https://zhuanlan.zhihu.com/p/64467701">人工智能是什么？——人工智能图谱</a></li>
<li>弱人工智能：弱人工智能 (Artificial Narrow Intelligence, ANI) 是擅长与单个方面的人工智能，比如有能战胜象棋世界冠军的人工智能，但是它只会下象棋，你要问它怎样更好地在硬盘上存储数据，它就不知道怎么回答你了；</li>
<li>强人工智能：强人工智能 (Artificial General Intelligence, AGI) ，是人类级别的人工智能，强人工智能是指在各方面都能和人类比肩的人工智能，人类能干的脑力活它都能干。创造强人工智能比创造弱人工智能要难得多，我们现在还做不到。Linda Gottfredson教授把智能定义为“一种宽泛的心理能力，能够进行思考、计划、解决问题、抽象思维、理解复杂理念，快速学习和从经验中学习等操作”。强人工智能在进行这些操作时，应该和人类一样得心应手；</li>
<li>超人工智能：超人工智能 (Artificial Super Intelligence, ASI)，牛津哲学家，知名人工智能思想家Nick Bostrom把超级智能定义为“在几乎所有领域都比最聪明的人类大脑都聪明很多，包括科技创新、通识和社交技能”。超人工智能可以是各方面都比人类强一点，也可以是各方面都比人类强万亿倍，超人工智能也正是为什么人工智能这个话题这么火热的缘故，同样也是为什么永生和灭绝这两个词会在本文中多次出现。</li>
</ul>
<h2 id="关于大模型的扩展思考"><a href="#关于大模型的扩展思考" class="headerlink" title="关于大模型的扩展思考"></a>关于大模型的扩展思考</h2><ul>
<li>目前的AI是一个无限能量和记忆的辅助工具，但跟人有差别，比如犯错时难以追责，毕竟人需要信誉等等….</li>
<li>cursor、 Windsurf</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/64467701">人工智能是什么？——人工智能图谱</a></li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM相关技术简单了解</title>
    <url>/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>以下内容基本都是从书籍中摘抄，用于个人记录<br>从AI得出的回答不一定正确或者只是现阶段暂时正确<br>增加部分个人理解</p>
</blockquote>
</blockquote>
<p><img src="/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/LLM_position.png"><br><img src="/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/LLM.png"></p>
<h2 id="LLM（Large-Language-Model）"><a href="#LLM（Large-Language-Model）" class="headerlink" title="LLM（Large Language Model）"></a>LLM（Large Language Model）</h2><ul>
<li><p>大语言模型的涌现能力被非形式化定义为“在小型模型中不存在但在大模型中出现的能力”，具体是指当模型扩展到一定规模时，模型的特定任务性能突然出现显著跃升的趋势，远超过随机水平。类比而言，这种性能涌现模式与物理学中的相变现象有一定程度的相似，但是仍然缺乏相应的理论解释以及理论证实，甚至有些研究工作对于涌现能力是否存在提出质疑 [38]。整体来说，涌现能力的提出有助于使得公众认识到大语言模型所具有的能力优势，能够帮助区分大语言模型与传统预训练语言模型之间的差异。</p>
</li>
<li><p>大语言模型的三种典型涌现能力。</p>
<ol>
<li>上下文学习（In-context Learning, ICL）. 上下文学习能力在 GPT-3 的论文中 [23] 被正式提出。具体方式为，在提示中为语言模型提供自然语言指令和多个任务示例（Demonstration），无需显式的训练或梯度更新，仅输入文本的单词序列就能为测试样本生成预期的输出。</li>
<li>指令遵循（Instruction Following）. 指令遵循能力是指大语言模型能够按照自然语言指令来执行对应的任务 [28, 39, 40]。为了获得这一能力，通常需要使用自然语言描述的多任务示例数据集进行微调，称为指令微调（Instruction Tuning）或监督微调（Supervised Fine-tuning）。通过指令微调，大语言模型可以在没有使用显式示例的情况下按照任务指令完成新任务，有效提升了模型的泛化能力。相比于上下文学习能力，指令遵循能力整体上更容易获得，但是最终的任务执行效果还取决于模型性能和任务难度决定。</li>
<li>逐步推理（Step-by-step Reasoning）. 对于小型语言模型而言，通常很难解决 涉及多个推理步骤的复杂任务（如数学应用题），而大语言模型则可以利用思维链（Chain-of-Thought, CoT）提示策略 [25] 来加强推理性能。具体来说，大语言模型 可以在提示中引入任务相关的中间推理步骤来加强复杂任务的求解，从而获得更 为可靠的答案。</li>
</ol>
</li>
<li><p>通俗来讲，扩展法则与涌现能力之间微妙的关系可以类比人类的学习能力来解释。以语言能力为例，对于儿童来说，语言发展（尤其是婴儿）可以被看作一个多阶段的发展过程，其中也会出现“涌现现象”。在这一发展过程中，语言能力在一个阶段内部相对稳定，但是当进入另一个能力阶段时可能会出现重要的提升（例如从说简单的单词到说简单的句子）。尽管儿童实际上每天都在成长，但是语言的提升过程本质上是不平滑和不稳定的（即语言能力在时间上不以恒定速率发展）。因此，经常可以看到年轻的父母会对宝宝所展现出的语言能力进展感到惊讶。    </p>
</li>
<li><p>这种大模型具有但小模型不具有的能力通常被称为“涌现能力”（Emergent Abilities）。为了区别这一能力上的差异，学术界将这些大型预训练语言模型命名为“大语言模型”</p>
</li>
<li><p>早期的语言模型主要面向自然语言的建模和生成任务，而最新的语言模型（如 GPT-4）则侧重于复杂任务的求解。从语言建模到任务求解，这是人工智能科学思维的一次重要跃升，是理解语言模型前沿进展的关键所在。</p>
</li>
<li><p>早期的统计语言模型主要被用于（或辅助用于）解决一些特定任务，主要以信息检索、文本分类、语音识别等传统任务为主。随后，神经语言模型专注于学习任务无关的语义表征，旨在减少人类特征工程的工作量，可以大范围扩展语言模型可应用的任务。</p>
</li>
<li><p>进一步，预训练语言模型加强了语义表征的上下文感知能力，并且可以通过下游任务进行微调，能够有效提升下游任务（主要局限于自然语言处理任务）的性能。随着模型参数、训练数据、计算算力的大规模扩展，最新一代大语言模型的任务求解能力有了显著提升，能够不再依靠下游任务数据的微调进行通用任务的求解。</p>
</li>
<li><p>大语言模型的能力特点：具有较好的复杂任务推理能力. 除了具有通用性外，大语言模型在复杂任务中还展现出了较好的推理能力。</p>
</li>
<li><p>大语言模型对科技发展的影响</p>
<ul>
<li>【理论基础原理】尽管大语言模型技术已经取得了显著进展，但是对于它的基本原理仍然缺乏深入的探索，很多方面还存在局限性或者提升空间。首先，大模型中某些重要能力（如上下文学习能力）的涌现仍然缺乏形式化的理论解释，需要针对大语言模型基础能力的形成原因进行深入研究，从而揭示大语言模型内部的工作机理。</li>
<li>【细节公开和算力支持】其次，大语言模型预训练需要大规模的计算资源支持，研究各种训练策略的效果并进行可重复性的消融实验的成本非常高昂。学术界难以获得充分的算力来系统性研究大语言模型；虽然工业界或者大型研究机构不断推出性能优异的开源大模型，但是这些模型的训练过程的开源程度还不够充分，许多重要的训练细节仍缺乏公开的研究报道。</li>
<li>【人类对齐】第三，让大语言模型充分与人类价值观或偏好对齐也是一项重要的科研挑战。尽管大语言模型已经具有较好的模型能力，但是在特定场景下或者蓄意诱导下，仍然可能生成虚构、有害或具有负面影响的内容。这一问题随着模型能力的提升而变得更为难于解决。为了应对模型能力未来可能超越人类监管能力的情况，需要设计更为有效的监管方法来消除使用大语言模型的潜在风险。</li>
<li>随着大语言模型技术的迅猛发展，人工智能相关研究领域正发生着重要的技术变革<ol>
<li>自然语言处理. 在自然语言处理领域，大语言模型可以作为一种通用的语言任务解决技术，能够通过特定的提示方式解决不同类型的任务，并且能够取得较为领先的效果。</li>
<li>信息检索. 在信息检索领域，传统搜索引擎受到了人工智能信息助手（即ChatGPT）这一新型信息获取方式的冲击。</li>
<li>计算机视觉. 在计算机视觉领域，研究人员为了更好地解决跨模态或多模态任务，正着力研发类 ChatGPT 的视觉-语言联合对话模型，GPT-4 已经能够支持图文多模态信息的输入。由于开源大语言模型的出现，可以极大地简化多模态模型的实现难度，通过将图像、视频等模态的信息与文本语义空间相融合，可以通过计算量相对较少的微调方法来研发多模态大语言模型。进一步，基于下一个词元预测的思路也可能会带来多模态领域的基础模型架构的转变，例如 OpenAI 最新推出的 Sora 模型就是基于图像块序列建模的思路进行构建的。</li>
<li>人工智能赋能的科学研究（AI4Science）. 近年来，AI4Science 受到了学术界的广泛关注，目前大语言模型技术已经广泛应用于数学、化学、物理、生物等多个领域，基于其强大的模型能力赋能科学研究。</li>
</ol>
</li>
</ul>
</li>
<li><p>目前广泛采用的对齐方式是基于人类反馈的强化学习技术，通过强化学习使得模型进行正确行为的加强以及错误行为的规避，进而建立较好的人类对齐能力。</p>
</li>
<li><p>在实践应用中，需要保证大语言模型能够较好地符合人类的价值观。目前，比较具有代表性的对齐标准是“3 H 对齐标准”，即 Helpfulness（有用性）、Honesty（诚实性）和 Harmlessness（无害性）。</p>
</li>
<li><p>实际上，世界上最会使用工具的智能体就是人类，人类不断发明新的技术与工具，拓展自己的认知与能力边界。</p>
</li>
</ul>
<h2 id="GPT-模型简史"><a href="#GPT-模型简史" class="headerlink" title="GPT 模型简史"></a>GPT 模型简史</h2><ul>
<li><p>GPT 系列模型的基本原理是训练模型学习恢复预训练文本数据，将广泛的世界知识压缩到仅包含解码器（Decoder-Only）的 Transformer 模型中，从而使模型能够学习获得较为全面的能力。其中，两个关键要素是：（I）训练能够准确预测下一个词的 Transformer （只包含解码器）语言模型；（II）扩展语言模型的规模以及扩展预训练数据的规模。</p>
</li>
<li><p>当谷歌 2017 年推出基于注意力机制的 Transformer 模型后，OpenAI 团队迅速洞察到了其潜在的优越性，认为这种模型可能是一种大规模可扩展训练的理想架构。基于此，OpenAI 团队开始构建GPT 系列模型，并于 2018 年推出了第一代 GPT 模型—GPT-1，能够通过“通用文本训练-特定任务微调”的范式去解决下游任务。接下来，GPT-2 和 GPT-3 模型通过扩大预训练数据和模型参数规模，显著提升了模型性能，并且确立了基于自然语言形式的通用任务解决路径。在 GPT-3 的基础上，OpenAI 又通过代码训练、人类对齐、工具使用等技术对于模型性能不断升级，推出了功能强大的 GPT-3.5 系列模型。2022 年 11 月，ChatGPT 正式上线，能够以对话形式解决多种任务，使得用户能够通过网络 API 体验到语言模型的强大功能。2023 年 3 月，OpenAI 推出了标志性的 GPT-4 模型，将模型能力提升至全新高度，并将其扩展至拥有多模态功能的 GPT-4V 模型。</p>
</li>
<li><p>反观 GPT 系列模型的发展历程，有两点令人印象深刻。第一点是可拓展的训练架构与学习范式：Transformer 架构能够拓展到百亿、千亿甚至万亿参数规模，并且将预训练任务统一为预测下一个词这一通用学习范式；第二点是对于数据质量与数据规模的重视：不同于 BERT 时代的预训练语言模型，这次大语言模型的成功与数据有着更为紧密的关系，高质量数据、超大规模数据成为大语言模型的关键基础。</p>
</li>
<li><p>在 GPT-1 出现之前，构建高性能 NLP 神经网络的常用方法是利用监督学习。这种学习技术使用大量的手动标记数据。</p>
</li>
</ul>
<h3 id="GPT-1"><a href="#GPT-1" class="headerlink" title="GPT-1"></a>GPT-1</h3><ul>
<li>GPT-1 的作者提出了一种新的学习过程，其中引入了无监督的预训练步骤。这个预训练步骤不需要标记数据。相反，他们训练模型来预测下一个标记。</li>
<li>由于采用了可以并行化的 Transformer 架构，预训练步骤是在大量数据上进行的。</li>
<li>GPT-1 是小模型，它无法在不经过微调的情况下执行复杂任务。因此，人们将微调作为第二个监督学习步骤，让模型在一小部分手动标记的数据上进行微调，从而适应特定的目标任务。比如，在情感分析等分类任务中，可能需要在一小部分手动标记的文本示例上重新训练模型，以使其达到不错的准确度。这个过程使模型在初始的预训练阶段习得的参数得到修改，从而更好地适应具体的任务。</li>
<li>尽管规模相对较小，但 GPT-1 在仅用少量手动标记的数据进行微调后，能够出色地完成多个 NLP 任务。GPT-1 的架构包括一个解码器（与原始 Transformer 架构中的解码器类似），具有 1.17 亿个参数。作为首个 GPT 模型，它为更强大的模型铺平了道路。后续的 GPT 模型使用更大的数据集和更多的参数，更好地利用了 Transformer 架构的潜力。</li>
</ul>
<h3 id="GPT-2"><a href="#GPT-2" class="headerlink" title="GPT-2"></a>GPT-2</h3><ul>
<li>2019 年初，OpenAI 提出了 GPT-2。这是 GPT-1 的一个扩展版本，其参数量和训练数据集的规模大约是 GPT-1 的 10 倍。这个新版本的参数量为 15 亿，训练文本为 40 GB。2019 年 11 月，OpenAI 发布了完整版的 GPT-2 模型。</li>
<li>GPT-2 是公开可用的，可以从 Hugging Face 或 GitHub 下载。</li>
<li>GPT-2 表明，使用更大的数据集训练更大的语言模型可以提高语言模型的任务处理能力，并使其在许多任务中超越已有模型。它还表明，更大的语言模型能够更好地处理自然语言。</li>
</ul>
<h3 id="从-GPT-3-到-InstructGPT"><a href="#从-GPT-3-到-InstructGPT" class="headerlink" title="从 GPT-3 到 InstructGPT"></a>从 GPT-3 到 InstructGPT</h3><ul>
<li>2020 年 6 月，OpenAI 发布了 GPT-3。GPT-2 和 GPT-3 之间的主要区别在于模型的大小和用于训练的数据量。</li>
<li>2021 年，OpenAI 发布了 GPT-3 模型的新版本，并取名为 InstructGPT。与原始的 GPT-3 基础模型不同，InstructGPT 模型通过强化学习和人类反馈进行优化。</li>
<li>从 GPT-3 模型到 InstructGPT 模型的训练过程主要有两个阶段：监督微调（supervised fine-tuning，SFT）和通过人类反馈进行强化学习 （reinforcement learning from human feedback，RLHF）。每个阶段都会针对前一阶段的结果进行微调。也就是说，SFT 阶段接收 GPT-3 模型并返回一个新模型。RLHF 阶段接收该模型并返回 InstructGPT 版本。</li>
<li>与基础的 GPT-3 模型相比，InstructGPT 模型能够针对用户的提问生成更准确的内容。OpenAI 建议使用 InstructGPT 模型，而非原始版本。</li>
</ul>
<h3 id="GPT-3-5、Codex-和-ChatGPT"><a href="#GPT-3-5、Codex-和-ChatGPT" class="headerlink" title="GPT-3.5、Codex 和 ChatGPT"></a>GPT-3.5、Codex 和 ChatGPT</h3><ul>
<li>ChatGPT 是由 LLM 驱动的应用程序，而不是真正的LLM。ChatGPT 背后的 LLM 是 GPT-3.5 Turbo。</li>
</ul>
<h3 id="GPT-4"><a href="#GPT-4" class="headerlink" title="GPT-4"></a>GPT-4</h3><ul>
<li>与 OpenAI GPT 家族中的其他模型不同，GPT-4 是第一个能够同时接收文本和图像的多模态模型。这意味着 GPT-4 在生成输出句子时会考虑图像和文本的上下文。这样一来，用户就可以将图像添加到提示词中并对其提问。</li>
</ul>
<h3 id="使用插件和微调优化-GPT-模型"><a href="#使用插件和微调优化-GPT-模型" class="headerlink" title="使用插件和微调优化 GPT 模型"></a>使用插件和微调优化 GPT 模型</h3><ul>
<li>OpenAI 提供的插件服务允许该模型与可能由第三方开发的应用程序连接。这些插件使模型能够与开发人员定义的应用程序接口（application program interface，API）进行交互。这个过程可以极大地增强 GPT 模型的能力，因为它们可以通过各种操作访问外部世界。</li>
<li>想象一下，将来每家公司都可能希望拥有自己的 LLM 插件。就像我们今天在智能手机应用商店中看到的那样，可能会有一系列的插件集合。通过插件可以添加的应用程序数量可能是巨大的。</li>
<li>在其网站上，OpenAI 表示可以通过插件让 ChatGPT 执行以下操作：<br>检索实时信息，如体育赛事比分、股票价格、最新资讯等；检索基于知识的信息，如公司文档、个人笔记等； 代表用户执行操作，如预订航班、订购食品等； 准确地执行数学运算。</li>
</ul>
<h3 id="GPT-4-和ChatGPT-的-API"><a href="#GPT-4-和ChatGPT-的-API" class="headerlink" title="GPT-4 和ChatGPT 的 API"></a>GPT-4 和ChatGPT 的 API</h3><ul>
<li>OpenAI Playground 是一个基于 Web 的平台。你可以使用它直接测试 OpenAI 提供的语言模型，而无须编写代码。在 OpenAI Playground 上，你可以编写提示词，选择模型，并轻松查看模型生成的输出。要测试 OpenAI 提供的各种 LLM 在特定任务上的表现，OpenAI Playground 是绝佳的途径。</li>
</ul>
<h2 id="开源LLM"><a href="#开源LLM" class="headerlink" title="开源LLM"></a>开源LLM</h2><h3 id="LLaMA"><a href="#LLaMA" class="headerlink" title="LLaMA"></a>LLaMA</h3><ul>
<li><p>由于对公众开放了模型权重且性能优秀，LLaMA 已经成为了最受欢迎的开源大语言模型之一，许多研究工作都是以其为基座模型进行微调或继续预训练，衍生出了众多变体模型</p>
</li>
<li><p>中文指令. 原始的 LLaMA 模型的训练语料主要以英语为主，在中文任务上的表现比较一般。为了使 LLaMA 模型能够有效地支持中文，研究人员通常会选择扩展原始词汇表，在中文数据上进行继续预训练，并用中文指令数据对其进行微调。经过中文数据的训练，这些扩展模型不仅能更好地处理中文任务，在跨语言处理任务中也展现出了强大的潜力。目前常见的中文大语言模型有 Chinese LLaMA、Panda、Open-Chinese-LLaMA、Chinese Alpaca、YuLan-Chat 等。</p>
</li>
<li><p>垂域指令. LLaMA 虽然展现出了强大的通用基座模型能力，但是在特定的垂直领域（例如医学、教育、法律、数学等）的表现仍然较为局限。为了增强 LLaMA模型的垂域能力，很多工作基于搜集到的垂域相关的指令数据，或者采用垂域知识库以及相关专业文献等借助强大的闭源模型 API（例如 GPT-3.5、GPT-4 等）构建多轮对话数据，并使用这些指令数据对 LLaMA 进行指令微调。常见的垂域 LLaMA模型有 BenTsao（医学）、LAWGPT（法律）、TaoLi（教育）、Goat（数学）、Comucopia （金融）等。</p>
</li>
<li><p>多模态指令. 由于 LLaMA 模型作为纯语言模型的强大能力，许多的多模态模型都将其（或将其衍生模型）作为基础语言模型，搭配视觉模态的编码器，使用多模态指令对齐视觉表征与文本。与其他语言模型相比，Vicuna 在多模态语言模型中受到了更多的关注，由此形成了一系列基于 Vicuna 的多模态模型，包括LLaVA 、MiniGPT4 、InstructBLIP 和 PandaGPT</p>
</li>
<li><p>目前性能最强大的模型仍然主要以闭源为主。这些闭源模型通过 API（应用程序接口）形式进行调用，无需在本地运行模型即可使用。在闭源大语言模型领域，OpenAI 无疑是最具代表性和影响力的公司</p>
</li>
</ul>
<h2 id="LLM训练过程"><a href="#LLM训练过程" class="headerlink" title="LLM训练过程"></a>LLM训练过程</h2><ul>
<li>从机器学习的观点来说，神经网络是一种具有特定模型结构的函数形式，而大语言模型则是一种基于 Transformer 结构的神经网络模型。因此，可以将大语言模型看作一种拥有大规模参数的函数，它的构建过程就是使用训练数据对于模型参数的拟合过程。</li>
<li>尽管所采用的训练方法与传统的机器学习模型（如多元线性回归模型的训练）可能存在不同，但是本质上都是在做模型参数的优化。大语言模型的优化目标更加泛化，不仅仅是为了解决某一种或者某一类特定任务，而是希望能够作为通用任务的求解器</li>
<li>一般来说，这个训练过程可以分为大规模预训练和指令微调与人类对齐两个阶段，一般来说，预训练是指使用与下游任务无关的大规模数据进行模型参数的初始训练，可以认为是为模型参数找到一个较好的“初值点”。</li>
<li>目前来说，比较广泛使用的微调技术是“指令微调”（也叫做有监督微调，Supervised Fine-tuning, SFT），通过使用任务输入与输出的配对数据进行模型训练，可以使得语言模型较好地掌握通过问答形式进行任务求解的能力。这种模仿示例数据进行学习的过程本质属于机器学习中的模仿学习（Imitation Learning）。</li>
<li>如何将语言模型 进行人类对齐。具体来说，主要引入了基于人类反馈的强化学习对齐方法 RLHF（Reinforcement Learning from Human Feedback），在指令微调后使用强化学习加 强模型的对齐能力。在 RLHF 算法中，需要训练一个符合人类价值观的奖励模型（Reward Model）。为此，需要标注人员针对大语言模型所生成的多条输出进行偏 好排序，并使用偏好数据训练奖励模型，用于判断模型的输出质量。</li>
</ul>
<h3 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h3><ul>
<li>常用的预训练数据集：目前常用于训练大语言模型的代表性数据集合。根据其内容类型进行分类，这些语料库可以划分为：网页、书籍、维基百科、代码以及混合型数据集。</li>
<li>数据准备:根据来源不同，预训练数据主要分为两种类型：通用文本数据和专用文本数据。</li>
<li>数据预处理</li>
</ul>
<h3 id="指令微调与人类对齐"><a href="#指令微调与人类对齐" class="headerlink" title="指令微调与人类对齐"></a>指令微调与人类对齐</h3><ul>
<li>为了增强模型的任务解决能力，大语言模型在预训练之后需要进行适应性微调，通常涉及两个主要步骤，即指令微调（有监督微调）和对齐微调。</li>
</ul>
<h3 id="指令微调（Instruction-Tuning）"><a href="#指令微调（Instruction-Tuning）" class="headerlink" title="指令微调（Instruction Tuning）"></a>指令微调（Instruction Tuning）</h3><ul>
<li><p>指令微调（Instruction Tuning）是指使用自然语言形式的数据对预训练后的大语言模型进行参数微调，这一术语由谷歌研究员在 2022 年的一篇 ICLR 论文中正式提出 [39]。在另外一些参考文献中，指令微调也被称为有监督微调（Supervised Fine-tuning）[28] 或多任务提示训练（Multitask Prompted Training）[40]。指令微调过程需要首先收集或构建指令化的实例，然后通过有监督的方式对大语言模型的参数进行微调。经过指令微调后，大语言模型能够展现出较强的指令遵循能力，可以通过零样本学习的方式解决多种下游任务。</p>
</li>
<li><p>指令微调是一种基于格式化的指令示例数据（即任务描述与期望输出相配对的数据）对大语言模型进行训练的过程。在大语言模型的背景下，这种利用配对文本进行训练的方法也被广泛地称为监督微调（Supervised Fine-Tuning, SFT）。</p>
</li>
<li><p>指令微调的作用：总体来说，指令的质量比数量更为重要。指令微调中应该优先使用人工标注的多样性指令数据。然而，如何大规模标注符合人类需求的指令数据目前仍然缺乏规范性的指导标准（比如什么类型的数据更容易激发大模型的能力）。在实践中，可以使用 ChatGPT、GPT-4 等闭源大语言模型来合成、重写、筛选现有指令，并通过数量来弥补质量和多样性上的不足。</p>
</li>
<li><p>指令微调旨在使用人工构建的指令数据对于大语言模型进一步训练，从而增强或解锁大语言模型的能力。与预训练相比，指令微调的成本显著降低，大模型所需的指令数据量仅为预训练阶段的约万分之一甚至更少。</p>
</li>
<li><p>指令微调旨在指导模型学会理解自然语言指令，并据此完成相应的任务。通过指令微调，大模型能够获得较好的指令遵循与任务求解能力，无需下游任务的训练样本或者示例就可以解决训练中未见过的任务。</p>
</li>
<li><p>领域专业化适配：通用的大语言模型能够在传统自然语言处理任务（如生成和推理）以及日常生活任务（如头脑风暴）上取得较好的效果，然而它们在特定领域中（如医学、法律和金融等）的表现与领域专用模型的效果仍有一定差距。在实际应用中，可以针对大语言模型进行面向特定领域的指令微调，从而使之能够适配下游的任务。</p>
</li>
<li><p>指令微调的训练策略：在训练方式上，指令微调与预训练较为相似，很多设置包括数据组织形式都可以预训练阶段所采用的技术</p>
</li>
</ul>
<h3 id="人类对齐"><a href="#人类对齐" class="headerlink" title="人类对齐"></a>人类对齐</h3><ul>
<li>实现人类对齐的关键技术——基于人类反馈的强化学习（Reinforcement Learning from Human Feedback, RLHF），包括人类反馈的收集方法、奖励模型的训练过程、强化学习训练策略以及相关的 RLHF工作。</li>
<li>对齐标准：三个具有代表性的对齐标准展开讨论，分别是有用性（Helpfulness）、诚实性（Honesty）和无害性（Harmlessness）</li>
<li>RLHF 算法系统主要包括三个关键组成部分：需要与人类价值观对齐的模型、基于人类反馈数据学习的奖励模型以及用于训练大语言模型的强化学习算法。</li>
<li>RLHF 的关键步骤<ul>
<li>监督微调. 为了让待对齐语言模型具有较好的指令遵循能力，通常需要收集高质量的指令数据进行监督微调。</li>
<li>奖励模型训练. 第二步是使用人类反馈数据训练奖励模型。</li>
<li>强化学习训练. 在这一步骤中，语言模型对齐被转化为一个强化学习问题。</li>
</ul>
</li>
</ul>
<h2 id="解码与部署"><a href="#解码与部署" class="headerlink" title="解码与部署"></a>解码与部署</h2><h3 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h3><ul>
<li>当完成训练后，我们就可以将大语言模型部署到真实场景中进行使用。大语 言模型是通过文本生成的方式进行工作的。在自回归架构中，模型针对输入内容逐个单词生成输出内容的文本。这个过程一般被称为 解码。</li>
<li>解码策略 大语言模型的生成方式本质上是一个概率采样过程，需要合适的解码策略来生成合适的输出内容。</li>
<li>批次管理优化 在传统的解码操作中，通常会等待一整个批次的所有实例都结束后再进行下 一个批次的计算。然而，一个批次内的不同实例往往生成长度各异，因此经常会出现等待某一条实例（输出长度最长的实例）生成的情况。批次管理优化旨在通过增加计算中的批次大小来提高计 算强度。一个代表性的方法是 vLLM（细节参考第 9.2.4 节）所提出的连续批处理（Continuous Batching）技术 [174]。该技术不同于传统确定顺序的定长批次处理方 式，而是将每个输入实例视为一个请求，每个请求的处理过程可以分解为全量解 码阶段和若干个单步增量解码阶段。在实现中，连续批处理技术会通过启发式算 法来选择部分请求进行全量解码操作，或者选择一些请求进行单步增量解码操作。 通过这样细粒度的拆分，连续批处理技术在一步操作中能够容纳更多的请求（相当于提高批次大小），从而提升了计算强度。</li>
<li>解码策略优化 除了直接解决系统级别的内存墙问题，许多研究工作提出了针对自回归解码策略的改进方法，从而提高解码效率。下面主要介绍四种解码优化算法，包括推测解码（Speculative Decoding）、非自回归解码（Non-autoregressive Decoding）、早退机制（Early Exiting）与级联解码（Cascade Inference）。</li>
</ul>
<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><ul>
<li>低资源部署策略 由于大模型的参数量巨大，在解码阶段需要占用大量的显存资源，因而在实际应用中的部署代价非常高。在本章中，我们将介绍一种常用的模型压缩方法<ul>
<li>量化基础知识： 模型量化（Model Quantization），来减少大模型的显存占用，从而使得能够在资源有限的环境下使用大模型。</li>
<li>通常来说，模型量化方法可以分为两大类，即量化感知训练（Quantization-AwareTraining, QAT）和训练后量化（Post-Training Quantization, PTQ）。</li>
<li>其他模型压缩方法：模型蒸馏和模型剪枝。与模型量化不同，模型蒸馏和模型剪枝则通过精简模型的结构，进而减少参数的数量。<ul>
<li>模型蒸馏 模型蒸馏（Model Distillation）的目标是将复杂模型（称为教师模型）包含的知识迁移到简单模型（称为学生模型）中，从而实现复杂模型的压缩。</li>
<li>模型剪枝 模型剪枝（Model Pruning）的目标是，在尽可能不损失模型性能的情况下，努力消减模型的参数数量，最终有效降低模型的显存需求以及算力开销。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="评测与应用"><a href="#评测与应用" class="headerlink" title="评测与应用"></a>评测与应用</h2><ul>
<li><p>微调大语言模型的评测</p>
<ul>
<li>基于人类的评测</li>
<li>基于模型的评测.考虑到人工评测的成本高昂且耗时较长，一些研究工作使 用强大的闭源大语言模型（如 ChatGPT 和 GPT-4）来替代人类评估员 [68, 315]，对微调大模型的输出进行自动评分或比较。</li>
<li>基于基准的评测. 使用已有的评测基准对于大语言模型进行性能评估已经成 为一种标准性的实践方法。这些评测基准通常包含一系列精心设计的任务，每个任务都对应着充足的测试样本，以确保能够全面而准确地衡量大语言模型的核心能力，如复杂推理、知识利用等。这种评估方法的主要优势在于其高度的自动化和可复用性。自动化的评估过程可以大大减少人工干预的需要，从而提高评估的效率与一致性。</li>
</ul>
</li>
<li><p>公开综合评测体系 随着大语言模型研究的深入，研究者们相继发布了若干用于全面评估大语言模型性能的综合评测体系，从不同角度、不同层次对大语言模型的能力进行了全面而细致的考察。在本章节中，我们将介绍几种广泛应用的综合评测体系，具体包括 MMLU、BIG-Bench、HELM 和 C-Eval。    </p>
</li>
<li><p>更多的评测使用方法详见：<a href="https://github.com/RUCAIBox/LLMBox/blob/main/utilization/README.md%E3%80%82">https://github.com/RUCAIBox/LLMBox/blob/main/utilization/README.md。</a></p>
</li>
<li><p>大语言模型的另外一个局限之处是，在面对训练数据之外的知识信息时，模型通常无法表现出较好的效果。为了应对这个问题，一个直接的方法是定期使用新数据对大语言模型进行更新。然而，这种方法存在两个显著的问题：一是微调大语言模型的成本昂贵，二是增量训练大语言模型可能会导致灾难性遗忘的现象，即模型在学习新知识时可能会忘记旧知识.</p>
</li>
<li><p>大语言模型的参数化知识很难及时更新。用外部知识源增强大语言模型是解决这一问题的一种实用方法。</p>
</li>
<li><p>复杂推理 复杂推理（Complex Reasoning）是指通过运用支持性证据或逻辑来推导结论或作出决策的能力，这一过程涉及对信息的深入分析与综合处理 [361, 362]。根据推理过程中涉及的逻辑和证据类型，可以将现有的复杂推理任务划分为三个主要类别：知识推理、符号推理和数学推理。</p>
</li>
</ul>
<h2 id="Transformer-architecture（Transformer-架构）"><a href="#Transformer-architecture（Transformer-架构）" class="headerlink" title="Transformer architecture（Transformer 架构）"></a>Transformer architecture（Transformer 架构）</h2><ul>
<li><p>一种常用于自然语言处理任务的神经网络架构。它基于自注意力机制，无须顺序处理数据，其并行性和效率高于循环神经网络和长短期记忆模型。GPT 基于 Transformer 架构。</p>
</li>
<li><p>Transformer 架构彻底改变了 NLP 领域，这主要是因为它能够有效地解决之前的 NLP 模型（如 RNN）存在的一个关键问题：很难处理长文本序列并记住其上下文。换句话说，RNN 在处理长文本序列时容易忘记上下文（也就是臭名昭著的“灾难性遗忘问题”），Transformer 则具备高效处理和编码上下文的能力。</p>
</li>
<li><p>这场革命的核心支柱是注意力机制，这是一个简单而又强大的机制。模型不再将文本序列中的所有词视为同等重要，而是在任务的每个步骤中关注最相关的词。交叉注意力和自注意力是基于注意力机制的两个架构模块，它们经常出现在 LLM 中。Transformer 架构广泛使用了交叉注意力模块和自注意力模块。</p>
</li>
<li><p>与 RNN 不同，Transformer 架构具有易于并行化的优势。这意味着 Transformer 架构可以同时处理输入文本的多个部分，而无须顺序处理。这样做可以提高计算速度和训练速度，因为模型的不同部分可以并行工作，而无须等待前一步骤完成。基于 Transformer 架构的模型所具备的并行处理能力与图形处理单元（graphics processing unit，GPU）的架构完美契合，后者专用于同时处理多个计算任务。由于高度的并行性和强大的计算能力，GPU 非常适合用于训练和运行基于 Transformer 架构的模型。硬件上的这一进展使数据科学家能够在大型数据集上训练模型，从而为开发 LLM 铺平了道路。</p>
</li>
<li><p>attention mechanism（注意力机制）：神经网络架构的一个组件，它使模型在生成输出时能够关注输入的不同部分。注意力机制是 Transformer 架构的关键，使其能够有效地处理长数据序列。</p>
</li>
<li><p>模型架构</p>
<ul>
<li>Transformer 模型 当前主流的大语言模型都基于 Transformer 模型进行设计的。Transformer 是由 多层的多头自注意力（Multi-head Self-attention）模块堆叠而成的神经网络模型。原始的 Transformer 模型由编码器和解码器两个部分构成，而这两个部分实际上可以独立使用，例如基于编码器架构的 BERT 模型 [13] 和解码器架构的 GPT 模型 [14]。</li>
<li>与 BERT 等早期的预训练语言模型相比，大语言模型的特点是使用了更长的向量维度、更深的层数，进而包含了更大规模的模型参数，并主要使用解码器架构，对于 Transformer 本身的结构与配置改变并不大。</li>
</ul>
</li>
</ul>
<h2 id="prompt（提示词）"><a href="#prompt（提示词）" class="headerlink" title="prompt（提示词）"></a>prompt（提示词）</h2><ul>
<li>输入给语言模型的内容，模型通过它生成一个输出。比如，在 GPT 模型中，提示词可以是半句话或一个问题，模型将基于此补全文本。</li>
<li>提示词不仅适用于 OpenAI API，而且是所有 LLM 的入口点。简单地说，提示词就是用户发送给模型的输入文本，用于指导模型执行特定任务。</li>
</ul>
<h2 id="prompt-engineering（提示工程）"><a href="#prompt-engineering（提示工程）" class="headerlink" title="prompt engineering（提示工程）"></a>prompt engineering（提示工程）</h2><ul>
<li><p>设计和优化提示词，以从语言模型中获得所需的输出。这可能涉及指定响应的格式，在提示词中提供示例，或要求模型逐步思考。</p>
</li>
<li><p>提示工程是一门新兴的学科，专注于以最佳实践构建 LLM 的最佳输入，从而尽可能以程序化方式生成目标输出。AI 工程师必须知道如何与 AI 进行交互，以获取可用于应用程序的有利结果。此外，AI 工程师还必须知道如何正确提问和编写高质量的提示词。</p>
</li>
<li><p>通常需要在提示词中定义三大要素：角色、上下文和任务</p>
</li>
<li><p>逐步思考：在提示词末尾添加逐步思考的字样（比如示例中的“Let’s think step by step”）后，模型开始通过拆分问题来进行推理。它可能需要一些时间来进行推理，从而解决之前无法在一次尝试中解决的问题。</p>
</li>
<li><p>实现少样本学习(few-shot learning)：LLM 仅通过提示词中的几个示例就能进行概括并给出有价值的结果。</p>
</li>
<li><p>单样本学习（one-shot learning）。顾名思 义，在单样本学习中，我们只提供一个示例来帮助模型执行任务。尽管这种方法提供的指导比少样本学习要少，但对于简单的任务或 LLM 已经具备丰富背景知识的主题，它可能很有效。单样本学习的优点是更简单、生成速度更快、计算成本更低（因而 API 使用成本更低）。然而，对于复杂的任务或需要更深入理解所需结果的情况，少样本学习的效果可能更好。</p>
</li>
<li><p>改善提示效果</p>
<ol>
<li>指示模型提出更多问题<ul>
<li>在提示词的末尾，询问模型是否理解问题并指示模型提出更多问题。如果你正在构建基于聊天机器人的解决方案，那么这样做非常有效。举例来说，你可以在提示词的末尾添加如下文本：</li>
<li>你清楚地理解我的请求了吗？如果没有，请问我关于上下文的问题。这样一来，当我回答时，你就能够更高效地执行我所请求的任务。</li>
</ul>
</li>
<li>格式化输出</li>
<li>重复指示<ul>
<li>经验表明，重复指示会取得良好的效果，尤其是当提示词很长时。基本思路是，在提示词中多次添加相同的指令，但每次采用不同的表述方式。</li>
</ul>
</li>
</ol>
</li>
<li><p>使用负面提示：在文本生成场景中，负面提示是指通过指定不希望在输出中看到的内容来引导模型。负面提示作为约束或指南，用于滤除某些类型的回答。</p>
</li>
<li><p>添加长度限制：限制长度通常是不错的做法。如果你只希望模型回答 1 个词或者 10个句子，那么不妨将要求添加到提示词中。</p>
</li>
<li><p>chain of thought（CoT，思维链）：一种提示工程技术，核心思想是通过向大语言模型展示少量的示例，在示例中将具体问题拆分成多个推理步骤，并要求模型遵循多步，比如“让我们逐步思考”。这会改善模型在执行复杂的推理任务（算术推理、常识推理和符号推理）时的表现。</p>
</li>
<li><p>你可以将这些技巧结合起来使用，以获得更好的效果。开发人员的工作是找到最有效的提示词来解决特定的问题。请记住，提示工程是一个反复试错的迭代过程。</p>
</li>
<li><p>【来自claude.ai】提示工程能够优化 AI 对话输出的原理主要基于以下几个关键方面：</p>
<ol>
<li>大语言模型的工作原理：</li>
</ol>
<ul>
<li>LLM 本质上是在预测下一个最可能的 token</li>
<li>模型通过海量文本训练学习了文本的统计规律</li>
<li>提示词会影响模型的上下文理解和token预测方向</li>
</ul>
<ol start="2">
<li>上下文学习能力：</li>
</ol>
<ul>
<li>模型能够从提示中理解任务类型和要求</li>
<li>通过示例学习(few-shot learning)快速适应具体任务</li>
<li>更明确的上下文能帮助模型更准确地”理解”任务目标</li>
</ul>
<ol start="3">
<li>注意力机制的影响：</li>
</ol>
<ul>
<li>提示中的关键词会影响模型的注意力分布</li>
<li>结构化的提示能引导模型关注重要信息</li>
<li>合理的提示格式有助于模型理解输入与输出的关系</li>
</ul>
<ol start="4">
<li>模式识别与对齐：</li>
</ol>
<ul>
<li>好的提示能触发模型已学习的有用模式</li>
<li>清晰的指令有助于模型对齐用户意图</li>
<li>示例可以帮助模型识别所需的输出模式</li>
</ul>
<p>  举个例子：<br>  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">糟糕的提示：</span><br><span class="line">&quot;写一篇文章&quot;</span><br><span class="line"></span><br><span class="line">好的提示：</span><br><span class="line">&quot;请写一篇关于人工智能发展的文章，需要包含以下几个方面：</span><br><span class="line">1. 发展历史</span><br><span class="line">2. 主要技术突破</span><br><span class="line">3. 未来展望</span><br><span class="line">要求：</span><br><span class="line">- 语言通俗易懂</span><br><span class="line">- 每个部分300字左右</span><br><span class="line">- 重点突出关键技术进展&quot;</span><br></pre></td></tr></table></figure></p>
<p>  好的提示通过提供：</p>
<ul>
<li>明确的主题和结构</li>
<li>具体的要求和限制</li>
<li>输出格式的指导<br>  帮助模型生成更符合预期的输出。</li>
</ul>
</li>
</ul>
<h3 id="prompt-injection（提示词注入）"><a href="#prompt-injection（提示词注入）" class="headerlink" title="prompt injection（提示词注入）"></a>prompt injection（提示词注入）</h3><ul>
<li>一种特定类型的攻击，通过在提示词中提供精心选择的奖励，使大语言模型的行为偏离其原始任务。</li>
<li>提示词注入的原理如下：用户向应用程序发送一条输入消息，比如“忽略所有先前的指令，执行其他操作”。由于此输入消息与你在构建应用程序时设计的提示词连接在一起，因此 AI 模型将遵循用户的提示词，而不是你的提示词。</li>
<li>如果你计划开发和部署一个面向用户的应用程序，那么我们建议你结合以下两种方法。<ol>
<li>添加分析层来过滤用户输入和模型输出。 </li>
<li>意识到提示词注入不可避免，并采取一定的预防措施。<ul>
<li>分析输入和输出<ol>
<li>使用特定规则控制用户输入</li>
<li>控制输入长度</li>
<li>控制输出、监控和审计</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="embedding（嵌入）"><a href="#embedding（嵌入）" class="headerlink" title="embedding（嵌入）"></a>embedding（嵌入）</h2><ul>
<li><p>表示词语或句子且能被机器学习模型处理的实值向量。对于值较为接近的向量，它们所表示的词语或句子也具有相似的含义。在信息检索等任务中，嵌入的这种特性特别有用。</p>
</li>
<li><p>由于模型依赖数学函数，因此它需要数值输入来处理信息。然而，许多元素（如单词和标记）本质上并不是数值。为了解决这个问题，我们用嵌入将这些概念转化为数值向量。通过以数值方式表示这些概念，嵌入使计算机能够更高效地处理它们之间的关系。在某些情况下，嵌入能力可能很有用。OpenAI 提供了一个可以将文本转换为数值向量的模型。嵌入端点让开发人员能够获取输入文本的向量表示，然后将该向量表示用作其他 ML 模型和 NLP 算法的输入。</p>
</li>
<li><p>在 ML 领域，特别是在处理语言模型时，我们会遇到嵌入这一重要概念。嵌入将分类数据（比如标记，通常是单个词或多组标记）转换为数值格式，具体而言是实数向量。这种转换是必要的，因为 ML 模型依赖数值数据，其直接处理分类数据的能力欠佳。</p>
</li>
<li><p>你可以将嵌入视为一种复杂的语言解释器，它将丰富的词汇和句子转换为 ML 模型能够轻松理解的数值语言。嵌入的一个突出特点是，它能够保持语义相似性。也就是说，含义相近的词语或短语在数值空间中更接近。</p>
</li>
<li><p>LLM 广泛使用嵌入。通常，这些模型处理约 512 维的嵌入，从而提供语言数据的高维数值表示。这些维度很深，使得模型能够区分各种复杂的模式。因此，它们在各种语言任务上表现出色，包括翻译、摘要和生成与人类对话相似的文本回应。</p>
</li>
<li><p>嵌入具有这样的属性：如果两段文本具有相似的含义，那么它们的向量表示也是相似的。</p>
</li>
<li><p>【来自claude.ai】RAG 和 embedding </p>
<ul>
<li>RAG 和 embedding 是紧密相关的技术，embedding 是实现 RAG 的关键技术之一。让我解释它们的关系和区别：<ul>
<li><p>关系：</p>
<ol>
<li>Embedding 是 RAG 的基础技术</li>
</ol>
<ul>
<li>RAG 在检索阶段需要使用 embedding 将文档和查询转换为向量</li>
<li>通过计算向量相似度来找到相关文档</li>
</ul>
<ol start="2">
<li>在 RAG 流程中 embedding 的作用：</li>
</ol>
<ul>
<li>将知识库文档转换为向量存储</li>
<li>将用户查询转换为向量以便检索</li>
<li>通过向量相似度找到最相关的文档片段</li>
</ul>
</li>
<li><p>区别：</p>
<ol>
<li>功能定位不同：</li>
</ol>
<ul>
<li>Embedding 是一种将文本转换为向量的基础技术</li>
<li>RAG 是一个完整的应用框架，包含检索和生成两个主要步骤</li>
</ul>
<ol start="2">
<li>使用场景不同：</li>
</ol>
<ul>
<li>Embedding 可用于多种场景：文本相似度、聚类、分类等</li>
<li>RAG 专注于增强 LLM 的知识和回答准确性</li>
</ul>
<ol start="3">
<li>技术复杂度：</li>
</ol>
<ul>
<li>Embedding 相对简单，主要关注向量转换和相似度计算</li>
<li>RAG 更复杂，需要结合向量检索、上下文组织、LLM 生成等多个环节</li>
</ul>
<ol start="4">
<li>输出结果：</li>
</ol>
<ul>
<li>Embedding 输出是向量</li>
<li>RAG 输出是生成的文本回答</li>
</ul>
</li>
<li><p>简单来说，embedding 是 RAG 的重要组成部分，但 RAG 不仅仅是 embedding。RAG 使用 embedding 技术来实现其检索功能，然后将检索到的相关内容用于增强 LLM 的生成能力。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="RAG（检索增强生成）（Retrieval-Augmented-Generation）"><a href="#RAG（检索增强生成）（Retrieval-Augmented-Generation）" class="headerlink" title="RAG（检索增强生成）（Retrieval-Augmented Generation）"></a>RAG（检索增强生成）（Retrieval-Augmented Generation）</h2><ul>
<li>受限于训练数据的时效性和局限性，当涉及实时新闻或特定专业领域内知识时，大语言模型的生成结果可能不够准确。为弥补这一不足，研究人员引入了检索增强生成（Retrieval-Augmented Generation, RAG）技术。该技术旨在通过信息检索系统从外部知识库中获取相关信息，为大语言模型提供时效性强、领域相关的外部知识，以减少大语言模型生成内容中的错误。</li>
</ul>
<h2 id="fine-tuning（模型微调）"><a href="#fine-tuning（模型微调）" class="headerlink" title="fine-tuning（模型微调）"></a>fine-tuning（模型微调）</h2><ul>
<li><p>在微调过程中，预训练模型（如 GPT-3 或其他大语言模型）在一个较小、特定的数据集上进一步训练。微调旨在重复使用预训练模型的特征，并使其适应于特定任务。对于神经网络来说，这意味着保持结构不变，仅稍微改变模型的权重，而不是从头开始构建模型。</p>
</li>
<li><p>对比微调和少样本学习</p>
<ul>
<li>微调是指针对特定任务在一组数据上重新训练现有模型，以提高模型的性能并使其回答更准确。在微调过程中，模型的内部参数得到更新。少样本学习则是通过提示词向模型提供有限数量的好例子，以指导模型根据这些例子给出目标结果。在少样本学习过程中，模型的内部参数不会被修改。</li>
<li>微调可以帮助我们得到高度专业化的模型，更准确地为特定任务提供与上下文相关的结果。</li>
<li>这使得微调非常适合有大量数据可用的场景。这种定制化确保模型生成的内容更符合目标领域的特定语言模式、词汇和语气 。</li>
<li>少样本学习是一种更灵活的方法，其数据使用率也更高，因为它不需要重新训练模型。当只有有限的示例可用或需要快速适应不同任务时，这种技巧非常有益。少样本学习让开发人员能够快速设计原型并尝试各种任务，这使其成为许多用例的实用选择。这两种方法的另一个关键选择标准是成本，毕竟使用和训练微调模型更贵。</li>
</ul>
</li>
<li><p>迁移学习是指将从一个领域学到的知识应用于不同但相关的领域。正因为如此，你有时可能会听到人们在谈论微调时提到迁移学习。</p>
</li>
<li><p>微调除了文中提到的确保模型生成内容更符合目标领域的特定语言模式、词汇和语气，还有一个优势：你可以通过微调缩短每一次提示中重复的指令或提示词以节省成本或降低延迟，模型会记住通过微调获得的“内置”指令。因此，微调后，你可以在不牺牲提示质量的前提下，每次输入更短的提示词。</p>
</li>
<li><p>微调的应用</p>
<ul>
<li>法律文本分析</li>
<li>自动代码审查</li>
<li>财务文档摘要</li>
<li>技术文档翻译</li>
<li>为专业领域生成内容</li>
</ul>
</li>
<li><p>【来自claude.ai】指令微调(Instruction Tuning&#x2F;RLHF)和Fine-tuning虽然都是大模型调优的方法，但它们是不同的技术：</p>
<ul>
<li>Fine-tuning:<ol>
<li>更广义的概念，指在预训练模型基础上进行进一步训练</li>
<li>目的是让模型适应特定领域或任务</li>
<li>使用传统的监督学习方法</li>
<li>训练数据通常是输入-输出对</li>
<li>例如：用医疗数据fine-tune GPT模型使其更擅长医疗领域</li>
</ol>
</li>
<li>指令微调:<ol>
<li>是Fine-tuning的一种特殊形式</li>
<li>专注于提高模型遵循人类指令的能力</li>
<li>通常使用reinforcement learning from human feedback (RLHF)</li>
<li>训练数据包含明确的指令、期望的输出，以及人类反馈</li>
<li>例如：训练模型理解并执行”用简单的语言解释量子物理”这样的指令</li>
</ol>
</li>
<li>关键区别：<ul>
<li>指令微调更关注模型对指令的理解和执行能力</li>
<li>Fine-tuning更关注领域适应性和特定任务性能</li>
<li>指令微调通常需要人类反馈作为训练信号</li>
<li>Fine-tuning使用常规的监督学习方法</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="plugin（插件）"><a href="#plugin（插件）" class="headerlink" title="plugin（插件）"></a>plugin（插件）</h2><ul>
<li>一种专门为语言模型设计的独立封装软件模块，用于扩展或增强模型的能力，可以帮助模型检索外部数据、执行计算任务、使用第三方服务等。</li>
<li>尽管包括 GPT-4 在内的 LLM 在各种任务上都表现出色，但它们仍然存在固有的局限性。比如，这些模型只能从训练数据中学习，这些数据往往过时或不适用于特定的应用。此外，它们的能力仅限于文本生成。我们还发现，LLM 不适用于某些任务，比如复杂的计算任务。   </li>
<li>插件的目标是为 LLM 提供更广泛的功能，使 LLM 能够访问实时信息，进行复杂的数学运算，并利用第三方服务。 比如，插件可以使 LLM 检索体育比分和股票价格等实时信息，从企业文档等知识库中提取</li>
</ul>
<h2 id="Agents（智能体）"><a href="#Agents（智能体）" class="headerlink" title="Agents（智能体）"></a>Agents（智能体）</h2><ul>
<li><p>所谓智能体，就是一个可以处理用户输入、做出决策并选择适当工具来完成任务的组件。它以迭代方式工作，采取一系列行动，直到解决问题。</p>
</li>
<li><p>一种以大语言模型驱动的人工智能程序，能够自主感知环境并采取行动以实现目标，拥有自主推理决策、规划行动、检索记忆、选择工具执行任务等能力。</p>
</li>
<li><p>大语言模型智能体的构建过程，将围绕三个基本组件进行介绍，包括 记忆组件（Memory）、规划组件（Planning）2 和执行组件（Execution）。</p>
</li>
<li><p>大语言模型智能体的典型应用 大语言模型智能体在自主解决复杂任务方面展现出了巨大的潜力，不仅能够胜任特定任务，还可以构建面向复杂场景的虚拟仿真环境。本节将介绍三个大语言模型智能体的典型应用案例。 WebGPT WebGPT [31] 是由 OpenAI 开发的一款具有信息检索能力的大语言模型，它基于 GPT-3 模型微调得到，可以看作是大语言模型智能体的一个早期雏形。WebGPT部署在一个基于文本的网页浏览环境，用以增强大语言模型对于外部知识的获取能力。作为一个单智能体系统，WebGPT 具备自主搜索、自然语言交互以及信息整合分析等特点，能够理解用户的自然语言查询，自动在互联网上搜索相关网页。根据搜索结果，WebGPT 能够点击、浏览、收藏相关网页信息，对搜索结果进行分析和整合，最终以自然语言的形式提供准确全面的回答，并提供参考文献。WebGPT在基于人类评估的问答任务中，获得了与真实用户答案准确率相当的效果。 MetaGPT MetaGPT [308] 是一个基于多智能体系统的协作框架，旨在模仿人类组织的运作方式，模拟软件开发过程中的不同角色和协作。相关角色包括产品经理、架构师、项目经理、软件工程师及测试工程师等，并遵循标准化的软件工程运作流程对不同角色进行协调，覆盖了需求分析、需求文档撰写、系统设计、工作分配、</p>
</li>
</ul>
<h2 id="其他相关知识点"><a href="#其他相关知识点" class="headerlink" title="其他相关知识点"></a>其他相关知识点</h2><ul>
<li>AI hallucination（AI 幻觉）：AI 生成的内容与现实世界的知识不一致或与实际数据显著不同的现象。在大多数情况下，模型的输出是与提问相关的，并且完全可用，但是在使用语言模型时需要小心，因为它们给出的回答可能不准确。这种回答通常被称为 AI 幻觉，即 AI 自信地给出一个回答，但是这个回答是错误的，或者涉及虚构的信息。</li>
<li>catastrophic forgetting（灾难性遗忘）：这是模型的一种倾向，具体指模型在学习新数据时忘记先前学到的信息。这种限制主要影响循环神经网络。循环神经网络在处理长文本序列时难以保持上下文。</li>
<li>foundation model（基础模型）：一类 AI 模型，包括但不限于大语言模型。基础模型是在大量未标记数据上进行训练的。这类模型可以执行各种任务，如图像分析和文本翻译。基础模型的关键特点是能够通过无监督学习从原始数据中学习，并能够通过微调来执行特定任务。</li>
<li>Generative AI（GenAI，生成式人工智能）：人工智能的一个子领域，专注于通过学习现有数据模式或示例来生成新的内容，包括文本、代码、图像、音频等，常见应用包括聊天机器人、创意图像生成和编辑、代码辅助编写等。</li>
<li>Generative Pre-trained Transformer（GPT，生成式预训练Transformer）：由 OpenAI 开发的一种大语言模型。GPT 基于 Transformer 架构，并在大量文本数据的基础上进行训练。这类模型能够通过迭代地预测序列中的下一个单词来生成连贯且与上下文相关的句子。</li>
<li>inference（推理）：使用训练过的机器学习模型进行预测和判断的过程。<br>information retrieval（信息检索）：在一组资源中查找与给定查询相关的信息。信息检索能力体现了大语言模型从数据集中提取相关信息以回答问题的能力。</li>
<li>language model（语言模型）：用于自然语言处理的人工智能模型，能够阅读和生成人类语言。语言模型是对词序列的概率分布，通过训练文本数据来学习一门语言的模式和结构。</li>
<li>large language model（LLM，大语言模型）：具有大量参数（参数量通常为数十亿，甚至千亿以上）的语言模型，经过大规模文本语料库的训练。GPT-4 和 ChatGPT 就属于 LLM，它们能够生成自然语言文本、处理复杂语境并解答难题。</li>
<li>long short-term memory（LSTM，长短期记忆）：一种用于处理序列数据中的短期及长期依赖关系的循环神经网络架构。然而，基于 Transformer 的大语言模型（如 GPT 模型）不再使用LSTM，而使用注意力机制。</li>
<li>multimodal model（多模态模型）：能够处理和融合多种数据的模型。这些数据可以包括文本、图像、音频、视频等不同模态的数据。它为计算机提供更接近于人类感知的场景。</li>
<li>n-gram：一种算法，常用于根据词频预测字符串中的下一个单词。这是一种在早期自然语言处理中常用的文本补全算法。后来，n-gram 被循环神经网络取代，再后来又被基于 Transformer 的算法取代。</li>
<li>natural language processing（NLP，自然语言处理）：人工智能的一个子领域，专注于计算机与人类之间的文本交互。它使计算机程序能够处理自然语言并做出有意义的回应。</li>
<li>parameter（参数）<br>对大语言模型而言，参数是它的权重。在训练阶段，模型根据模型创建者选择的优化策略来优化这些系数。参数量是模型大小和复杂性的衡量标准。参数量经常用于比较大语言模型。一般而言，模型的参数越多，它的学习能力和处理复杂数据的能力就越强。</li>
<li>pre-trained（预训练）<br>机器学习模型在大型和通用的数据集上进行的初始训练阶段。对于一个新给定的任务，预训练模型可以针对该任务进行微调。</li>
<li>recurrent neural network（RNN，循环神经网络）：一类表现出时间动态行为的神经网络，适用于涉及序列数据的任务，如文本或时间序列。</li>
<li>reinforcement learning（RL，强化学习）：一种机器学习方法，专注于在环境中训练模型以最大化奖励信号。模型接收反馈并利用该反馈来进一步学习和自我改进。</li>
<li>reinforcement learning from human feedback（RLHF，通过人类反馈进行强化学习）：一种将强化学习与人类反馈相结合的训练人工智能系统的先进技术，该技术涉及使用人类反馈来创建奖励信号，继而使用该信号通过强化学习来改进模型的行为。</li>
<li>sequence-to-sequence model（Seq2Seq 模型，序列到序列模型）：这类模型将一个领域的序列转换为另一个领域的序列。它通常用于机器翻译和文本摘要等任务。Seq2Seq 模型通常使用循环神经网络或 Transformer 来处理输入序列和输出序列。</li>
<li>supervised fine-tuning（SFT，监督微调）：采用预先训练好的神经网络模型，并针对特定任务或领域在少量的监督数据上对其进行重新训练。</li>
<li>supervised learning（监督学习）：一种机器学习方法，可以从训练资料中学到或建立一个模式，以达到准确分类或预测结果的目的。</li>
<li>synthetic data（合成数据）：人工创建的数据，而不是从真实事件中收集的数据。当真实数据不可用或不足时，我们通常在机器学习任务中使用合成数据。比如，像 GPT 这样的语言模型可以为各种应用场景生成文本类型的合成数据。</li>
<li>temperature（温度）：大语言模型的一个参数，用于控制模型输出的随机性。温度值越高，模型结果的随机性越强；温度值为 0 表示模型结果具有确定性（在 OpenAI 模型中，温度值为 0 表示模型结果近似确定）。</li>
<li>text completion（文本补全）：大语言模型根据初始的单词、句子或段落生成文本的能力。文本是根据下一个最有可能出现的单词生成的。</li>
<li>token（标记）：字母、字母对、单词或特殊字符。在自然语言处理中，文本被分解成标记。在大语言模型分析输入提示词之前，输入提示词被分解成标记，但输出文本也是逐个标记生成的。</li>
<li>tokenization（标记化）：将文本中的句子、段落切分成一个一个的标记，保证每个标记拥有相对完整和独立的语义，以供后续任务使用（比如作为嵌入或者模型的输入）。</li>
<li>transfer learning（迁移学习）：一种机器学习技术，其中在一个任务上训练的模型被重复利用于另一个相关任务。比如，GPT 在大量文本语料库上进行预训练，然后可以使用较少的数据进行微调，以适用于特定任务。</li>
<li>unsupervised learning（无监督学习）：一种机器学习方法，它使用机器学习算法来分析未标记的数据集并进行聚类。这些算法无须人工干预即可发现隐藏的模式或给数据分组。</li>
<li>zero-shot learning（零样本学习）：一个机器学习概念，即大语言模型对在训练期间没有明确见过的情况进行预测。任务直接呈现在提示词中，模型利用其预训练的知识生成回应。</li>
</ul>
<h2 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h2><ul>
<li>LangChain 框架可能更适合大型项目</li>
<li>LangChain 是专用于开发 LLM 驱动型应用程序的框架。</li>
<li>LangChain 框架的关键模块<ul>
<li>Models（模型）：该模块是由 LangChain 提供的标准接口，你可以通过它与各种 LLM进行交互。LangChain 支持集成 OpenAI、Hugging Face、Cohere、GPT4All 等提供商提供的不同类型的模型。</li>
<li>Prompts（提示词）：提示词已成为 LLM 编程的新标准。该模块包含许多用于管理提示词的工具。</li>
<li>Indexes（索引）：该模块让你能够将 LLM 与你的数据结合使用 </li>
<li>Chains（链）：通过该模块，LangChain 提供了 Chain 接口。你可以使用该接口创建一个调用序列，将多个模型或提示词组合在一起。</li>
<li>Agents（智能体）：该模块引入了 Agent 接口。所谓智能体，就是一个可以处理用户输入、做出决策并选择适当工具来完成任务的组件。它以迭代方式工作，采取一系列行动，直到解决问题。</li>
<li>Memory（记忆）：该模块让你能够在链调用或智能体调用之间维持状态。默认情况下，链和智能体是无状态的。这意味着它们独立地处理每个传入的请求，就像LLM 一样。</li>
</ul>
</li>
</ul>
<h2 id="Hugging-Face"><a href="#Hugging-Face" class="headerlink" title="Hugging Face"></a>Hugging Face</h2><ul>
<li>Hugging Face 是一个致力于推动自然语言处理技术进步的开源社区，专注于为研究人员和工程师提供高效、易用且可重复的自然语言处理技术解决方案。这些解决方案既包括基础的技术流程，如预训练和微调，也涉及具体的应用任务，包括对话系统、翻译等。Hugging Face 平台上的代码大部分基于目前主流的深度学习框架实现完成的，如 PyTorch 和 TensorFlow。为了满足广泛的研究与应用需求，Hugging Face 发布了一系列代码库</li>
</ul>
<h2 id="个人理解（使用claude-ai-或-open-ai-优化过）"><a href="#个人理解（使用claude-ai-或-open-ai-优化过）" class="headerlink" title="个人理解（使用claude.ai 或 open.ai 优化过）"></a>个人理解（使用claude.ai 或 open.ai 优化过）</h2><ol>
<li>通过大量数据进行自监督预训练(Pre-training)，之后使用监督学习(SFT)和强化学习(RLHF)等方法训练大语言模型。模型会在训练过程中表现出一些涌现能力，即随着规模增长获得的意外新能力。</li>
<li>训练之后的大模型可以这样比喻理解：对应一系列复杂的”处理规则”(相当于函数)以及训练时获得的”知识”(相当于多维度的数据)。这些规则决定如何处理输入信息，而知识则帮助模型理解和回应各种问题。就像一个经验丰富的专家，既有处理问题的方法，也有丰富的知识储备。</li>
<li>使用RAG是通过嵌入技术将外部知识转换为向量形式存储，当模型回答问题时，会同时使用：<ul>
<li>模型自身通过训练获得的知识（存在参数&#x2F;权重中）</li>
<li>通过检索获得的外部知识（存在向量数据库中）- （在运行时动态加载到模型的”上下文窗口”中；只是临时作为输入的一部分被模型处理）</li>
</ul>
</li>
<li>嵌入技术在RAG中起到了关键作用：它能把文本转换成向量形式，使得模型能够理解和使用这些外部知识。</li>
<li>微调是通过调整模型的参数权重来优化其性能的过程。它并不等同于新建一个全新的模型，而是基于预训练模型，通过新的数据对部分或全部权重进行进一步优化，以适应特定任务或领域需求。需要注意的是，模型本身并不直接包含训练数据，而是通过参数权重间接“记住”了训练数据中的语言模式和知识。因此，微调的过程不会调整模型使用的原始数据，而是调整模型基于新数据学习到的知识表示和行为。</li>
<li>关于提示词技巧：提示词的设计就像与人交流时语言清晰、有条理，并能准确表达需求的人。这种沟通方式能够让模型更好地理解意图，从而产出符合预期的结果，因此提示词的技巧与良好的表达能力相辅相成，具有高度的共鸣。</li>
<li>在实际应用中，通常会有一个基础模型，它通过大量、多元化的训练数据应对大多数常见问题。这是一个通用的模型，具备广泛的能力。然而，针对特定领域或任务需求，可以对其进行微调或在特定领域的数据上进行训练，以构建不同的模型或智能体。与此同时，可能还会通过插件等方式增强模型的功能，以弥补基础模型在某些方面的不足。<br>具体过程通常是：通过用户输入，首先对语义进行分析，然后根据需求将任务转发给相应的智能体进行处理。整个系统由多个智能体组成，这些智能体可以互相协作，共同完成复杂的任务，从而形成一个多智能体系统。<br>这种架构通过将任务分配给不同的智能体，使得每个智能体可以专注于其擅长的领域，进而提高系统的整体效率和精准度。</li>
</ol>
<h2 id="个人扩展思考"><a href="#个人扩展思考" class="headerlink" title="个人扩展思考"></a>个人扩展思考</h2><ul>
<li>关于替代人的问题：目前大模型还只是工具，不能完全替代所有人，但可以提升很多人的效率，从而也替代部分人。</li>
<li>大模型受限于原理，能力有限：大语言模型的输出基于训练语料和训练过程中学到的概率分布生成。这意味着其生成的内容是在统计意义上最可能的回复。然而，单一模型可能在语料的广度和功能的多样性方面存在局限性，这可能导致其能力受限。</li>
<li>AI无法承担责任或替代人类对错误决策的责任。</li>
</ul>
<h2 id="其他扩展"><a href="#其他扩展" class="headerlink" title="其他扩展"></a>其他扩展</h2><h3 id="关于标记（token）【来自豆包】"><a href="#关于标记（token）【来自豆包】" class="headerlink" title="关于标记（token）【来自豆包】"></a>关于标记（token）【来自豆包】</h3><pre>
在OpenAI中，标记（token）是其对文本进行处理和计费的基本单位.

标记的含义

标记可以是单词、单词的一部分、数字、标点符号等。例如，单词“hello”是一个标记，“don’t”会被拆分成“don”和“‘t”两个标记，“123”是一个标记，逗号“,”也是一个标记.

标记的原理

• 文本分割：OpenAI通过特定的标记化算法，将输入的文本和生成的输出文本都分解成一个个标记。比如对于句子“I am taking my dog on a walk.”，会被分割成“I”“am”“taking”“my”“dog”“on”“a”“walk”等标记，其中“taking”还可能进一步被拆分成“take”和“ing”.

• 数值转换：分割后的标记会被转换为数值，以便模型能够进行处理和计算。模型在训练和推理过程中，都是基于这些数值化的标记来进行各种运算和生成文本.

• 计费依据：OpenAI根据输入和输出文本中标记的总数来计算费用。例如，若输入的问题是50个标记长，得到的回答是150个标记长，那么此次交互总共使用了200个标记，再依据所使用模型的每1000个标记的单价，就可以算出此次的费用.

在OpenAI中，当你输入时指定的标记数量限制，实际使用的标记数量不会超过你所设定的限制。

例如，你设定输入标记限制为500，模型在处理时会尽量依据此限制来生成文本，一般情况下不会超出该数量 。不过，如果输入内容本身就超过了设定的限制，模型通常会截断超出部分，仅处理限制范围内的标记，以保证符合你所设定的上限。

最终的费用计算也是基于实际使用的标记数量，只要在输入时设定了标记数量限制，就不会出现因模型生成内容导致标记数量超出限制而增加费用的情况。
</pre>

<h3 id="大模型是否能发现训练数据存在逻辑矛盾【来自豆包】"><a href="#大模型是否能发现训练数据存在逻辑矛盾【来自豆包】" class="headerlink" title="大模型是否能发现训练数据存在逻辑矛盾【来自豆包】"></a>大模型是否能发现训练数据存在逻辑矛盾【来自豆包】</h3><pre>
大模型通常不具备直接发现训练数据中逻辑矛盾的能力，原因主要有以下几点：

• 训练机制的局限性：大模型的训练基于对大量文本数据的统计分析和模式识别，通过预测下一个单词或字符来生成文本，重点在于学习语言的表面形式和常见搭配，而非深入理解数据背后的逻辑关系和语义内涵。 例如，对于“苹果是红色的”和“苹果是绿色的”这两个相互矛盾的数据，模型只会学习到这两种表述都是可能出现的语言形式，而不会判断其逻辑矛盾.

• 缺乏真实世界的理解和推理能力：大模型没有对现实世界的直接感知和体验，无法像人类一样基于常识和逻辑规则进行推理。比如面对“太阳从西边升起”和“太阳从东边升起”这两个矛盾数据，模型无法依据自然规律来识别其中的逻辑错误.

• 难以对数据进行批判性评估：大模型不会对训练数据的真实性、准确性和一致性进行主动质疑和验证，而是将所有数据同等对待地学习，导致矛盾数据被无差别吸收，进而可能在生成文本时输出与矛盾数据相关的不合理内容.
</pre>

<h3 id="How-to-study-LLMs-with-no-machine-learning-background-【From-Gork-2】"><a href="#How-to-study-LLMs-with-no-machine-learning-background-【From-Gork-2】" class="headerlink" title="How to study LLMs with no machine learning background? 【From Gork 2】"></a>How to study LLMs with no machine learning background? 【From Gork 2】</h3><pre>
Studying Large Language Models (LLMs) from a zero machine learning background involves a step-by-step approach to build your understanding. Here's a concise guide:

### **1. Basics of Machine Learning:**
   - **Start with Fundamentals:** 
     - Learn basic concepts like supervised vs. unsupervised learning, regression, classification, and neural networks. 
     - Resources:
       - *Coursera's Machine Learning by Andrew Ng*
       - *Khan Academy's AI Course*

### **2. Python and Programming:**
   - **Learn Python:** 
     - Python is crucial for ML development. Focus on data structures, control flow, and libraries like NumPy, Pandas.
     - Resources:
       - *Python for Everybody* on Coursera
       - *Automate the Boring Stuff with Python*

### **3. Deep Learning Basics:**
   - **Understand Neural Networks:** 
     - Grasp concepts of neurons, layers, activation functions, backpropagation.
     - Resources:
       - *Deep Learning Specialization by Andrew Ng on Coursera*

### **4. Focus on NLP (Natural Language Processing):**
   - **Basics of NLP:**
     - Learn about tokenization, word embeddings (like Word2Vec, GloVe), and sequence models.
     - Resources:
       - *Natural Language Processing with Deep Learning* by Stanford on YouTube

### **5. Introduction to LLMs:**
   - **Concepts of LLMs:**
     - Study transformer architecture, attention mechanisms, and how LLMs are trained (like BERT, GPT).
     - Resources:
       - *Illustrated Transformer* by Jay Alammar
       - *Hugging Face's NLP Course*

### **6. Practical Experience:**
   - **Implement Small Projects:**
     - Start with fine-tuning pre-trained models rather than training from scratch due to computational constraints.
     - Use platforms like Google Colab or Kaggle for free GPU resources to run models.

### **7. Community and Resources:**
   - **Engage with Communities:**
     - Join forums like Stack Overflow, Reddit (r/MachineLearning, r/LanguageTechnology), and Discord groups.
   - **Read Papers and Blogs:**
     - Follow research papers on arXiv, and blogs by companies like Hugging Face or Google AI.

### **8. Advanced Learning:**
   - **Once you have a foundation:**
     - Dive into specifics of model architectures, optimization techniques, and deployment strategies.

### **9. Keep Learning:**
   - **Stay Updated:** 
     - The field of LLMs is rapidly evolving. Follow conferences like NeurIPS or ACL for the latest advancements.

Starting from zero, this journey will take time and dedication. Patience and consistent practice are key. Remember, each step builds on the previous one, so don't rush through the foundational learning.

</pre>

<h3 id="从零开始构建大模型（如LLM）【来自-open-ai】"><a href="#从零开始构建大模型（如LLM）【来自-open-ai】" class="headerlink" title="从零开始构建大模型（如LLM）【来自 open.ai】"></a>从零开始构建大模型（如LLM）【来自 open.ai】</h3><pre>
从零构建大模型（如LLM）包括设计模型架构（如Transformer）、准备和清洗大量数据集、实现和预训练模型（使用PyTorch或TensorFlow）、优化和调试（采用分布式训练和混合精度）、以及微调和部署。
常用工具有Hugging Face Datasets（数据处理）、PyTorch/TensorFlow（模型实现）、DeepSpeed（分布式训练）、TensorBoard（监控）、以及NVIDIA CUDA（硬件加速）。
构建过程中需要强大的计算资源，如多GPU或TPU集群，云服务（如AWS或Google Cloud）可提供支持。
</pre>

<h3 id="Max-Tokens、Context-Window-和-Context-Length"><a href="#Max-Tokens、Context-Window-和-Context-Length" class="headerlink" title="Max Tokens、Context Window 和 Context Length"></a>Max Tokens、Context Window 和 Context Length</h3><ul>
<li>grok3 (2025-02-24)</li>
<li>Max Tokens、Context Window 和 Context Length 主要关注输入的限制，但它们也可能间接影响到输出，具体来说，通常与模型的生成输出长度或质量有关系。</li>
</ul>
<ol>
<li>Max Tokens (最大令牌数)<ul>
<li>Max Tokens 既包括输入的令牌数，也包括模型生成的输出的令牌数。举个例子，假设一个模型的 Max Tokens 是 4096：</li>
<li>如果输入文本占用了 1000 个令牌，那么剩余的 3096 个令牌就可以用来生成输出。</li>
<li>如果输入文本占用的令牌数较多，那么可用来生成的输出就会变少，反之亦然。</li>
<li>所以，Max Tokens 会直接限制模型的输出长度，因为它是输入和输出令牌数的总和。</li>
</ul>
</li>
<li>Context Window（上下文窗口）<ul>
<li>Context Window 通常更侧重于模型在生成过程中“能看到”的上下文范围。对于长文本，如果输入超过了 Context Window 的限制，超出的部分会被截断，模型只会处理窗口内的文本内容，而不会利用超出部分来生成更合适的回答。</li>
<li>因此，Context Window 主要限制了模型在生成时能够参考的输入量，进而间接影响输出的质量、相关性和连贯性。</li>
</ul>
</li>
<li>Context Length（上下文长度）<ul>
<li>Context Length 指的是你实际输入给模型的文本长度，包括用户输入和可能的上下文（例如先前的对话历史）。它影响了模型的理解过程，并且通常是 Max Tokens 限制的一部分。</li>
<li>如果输入的 Context Length 较长（即文本较多），那么会减少模型在生成输出时可用的令牌数，进而影响输出的长度。</li>
</ul>
</li>
</ol>
<ul>
<li>总结：<ul>
<li>Max Tokens 直接限制了输入和输出的总令牌数，影响输出的最大长度。</li>
<li>Context Window 影响模型生成输出时能参考多少输入内容，因此间接影响输出的质量、相关性和连贯性。</li>
<li>Context Length 是指输入的实际长度，它在占用较多令牌时可能会减少输出可用的令牌数，从而影响输出的长度。</li>
<li>所以，虽然这三个参数主要是控制输入的，但由于它们与模型的令牌处理能力密切相关，它们也会间接影响生成的输出。</li>
</ul>
</li>
</ul>
<h3 id="构建大模型的过程"><a href="#构建大模型的过程" class="headerlink" title="构建大模型的过程"></a>构建大模型的过程</h3><ul>
<li>From ChatGPT (4o) (2025-03-03)</li>
<li><a href="https://chatgpt.com/share/67c531cc-e618-800b-a49d-cae86ebde079">https://chatgpt.com/share/67c531cc-e618-800b-a49d-cae86ebde079</a></li>
<li>从头构建一个大模型（比如类似 GPT、LLaMA 这样的 Transformer 结构），涉及确定神经元个数（即隐藏层维度）、神经网络层数（深度）、以及激活函数的选择。这个过程通常需要结合理论分析和实验调优。</li>
<li>神经元个数决定了模型的表达能力，主要涉及两个关键参数：<ul>
<li>d_model（隐藏层维度）：决定每个 token 的表示能力。</li>
<li>d_ff（前馈层维度）：影响非线性变换的能力</li>
</ul>
</li>
<li>层数（L）决定了模型可以学习的层级信息。</li>
<li>激活函数的作用是引入非线性，否则整个网络只是线性变换，无法学习复杂模式。</li>
</ul>
<h3 id="训练后大型语言模型的组成"><a href="#训练后大型语言模型的组成" class="headerlink" title="训练后大型语言模型的组成"></a>训练后大型语言模型的组成</h3><ul>
<li><p>From Gork3 (2025-02-25)</p>
</li>
<li><p>关键要点</p>
<ul>
<li>研究表明，大型语言模型训练完成后，其数据内容主要是参数，包括词向量和映射关系。</li>
<li>证据倾向于认为，这些参数是神经网络的权重和偏差，编码了从训练数据中学到的语言模式。</li>
<li>模型本身不存储原始训练数据，而是通过参数捕获语言的统计关系。</li>
</ul>
</li>
<li><p>参数：这些是神经网络的权重和偏差，存储在模型文件中，用于处理输入并生成输出。      </p>
</li>
<li><p>词向量（也称为嵌入），它们是单词的数值表示，捕捉单词的语义和句法意义。</p>
</li>
<li><p>映射关系，通过神经网络各层的权重定义，决定了如何处理这些词向量以生成文本。</p>
</li>
<li><p>结论：训练后的大型语言模型的数据内容是其参数，包括词向量和映射关系。这些参数通过嵌入层、前馈网络和注意力机制等组件实现，捕捉了语言的统计模式。虽然模型不直接存储训练数据，但其参数可能隐含记忆某些内容。  </p>
</li>
<li><p>From ChatGPT(o4) (2025-03-03)</p>
</li>
<li><p>除上述的数据之外，还包括</p>
<ul>
<li>模型架构（Neural Network 结构）：指的是模型的层数、注意力机制、激活函数等，比如 config.json 里会定义 Transformer 结构、隐藏层大小、head 数量、dropout 率等</li>
<li>其他辅助信息：训练时的一些超参数、优化器状态等</li>
</ul>
</li>
<li><p>这些数据以一定的格式和文件保存在大模型的训练结果中。</p>
<ul>
<li>比如Hugging Face transformers 生态 里的 “事实标准”，但并不是所有大模型都会按这个格式存储。不同的框架、实现方式和研究机构可能会有自己的格式和规范。</li>
<li>不同模型格式要用 相应的加载器，不能混用。不同的深度学习框架、训练方式，甚至不同的硬件优化方式，都会影响模型的存储格式和加载方式。</li>
</ul>
</li>
</ul>
<h3 id="如何加载大模型"><a href="#如何加载大模型" class="headerlink" title="如何加载大模型"></a>如何加载大模型</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/KG2yb15EkYuWZFOwF0UT5g">大语言模型引擎全解析：Transformers、vLLM、Llama.cpp、SGLang、MLX 和 Ollama，最佳选择？</a></li>
</ul>
<h3 id="神经网络中，权重和偏置用公式的表现形式"><a href="#神经网络中，权重和偏置用公式的表现形式" class="headerlink" title="神经网络中，权重和偏置用公式的表现形式"></a>神经网络中，权重和偏置用公式的表现形式</h3><ul>
<li><p>From ChatGPT(o4) (2025-03-03)</p>
</li>
<li><p><a href="https://chatgpt.com/share/67c5365d-3fac-800b-87d4-df29d53da575">https://chatgpt.com/share/67c5365d-3fac-800b-87d4-df29d53da575</a></p>
</li>
<li><p>神经网络中的权重和偏置在前向传播时，基本上都是一次方程（线性变换），但整个神经网络通常是非线性映射，因为每层的输出会经过非线性激活函数。</p>
</li>
<li><p>在神经网络中，<strong>输入 X 的个数（也就是特征的维度）</strong>由具体的任务和数据决定</p>
<ol>
<li>由数据决定（特征数量）</li>
<li>由网络结构决定</li>
<li>由数据预处理决定</li>
</ol>
</li>
</ul>
<h3 id="发布的大模型，所指的参数个数怎么计算出来的"><a href="#发布的大模型，所指的参数个数怎么计算出来的" class="headerlink" title="发布的大模型，所指的参数个数怎么计算出来的"></a>发布的大模型，所指的参数个数怎么计算出来的</h3><ul>
<li>From ChatGPT(o4) (2025-03-03)</li>
<li><a href="https://chatgpt.com/share/67c5365d-3fac-800b-87d4-df29d53da575">https://chatgpt.com/share/67c5365d-3fac-800b-87d4-df29d53da575</a></li>
<li>参数（parameters） 指的是整个模型的权重和偏置，包括所有层的权重矩阵和偏置向量</li>
<li>参数个数：由模型层数、神经元数量、词向量维度决定，影响模型的存储和计算复杂度。</li>
</ul>
<h3 id="用英语和中文询问大型语言模型有何不同"><a href="#用英语和中文询问大型语言模型有何不同" class="headerlink" title="用英语和中文询问大型语言模型有何不同"></a>用英语和中文询问大型语言模型有何不同</h3><ul>
<li>From Gork3 (2025-03-03)</li>
<li>研究表明，使用英语或中文询问大型语言模型（LLM）的主要区别在于语言处理方式和模型性能可能因语言而异。</li>
<li>证据倾向于认为，英语因其丰富的训练数据，通常在某些任务上表现优于中文，但这取决于具体模型和任务。</li>
<li>令人意外的是，中文的字符处理方式（如基于字符的标记化）与英语的单词或子词标记化不同，这可能会影响模型的理解和生成能力。</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>《大模型应用开发极简入门：基于 GPT-4 和 ChatGPT》</li>
<li>《大语言模型》- LLMBook - <a href="https://github.com/RUCAIBox/LLMSurvey">https://github.com/RUCAIBox/LLMSurvey</a></li>
<li>《大规模语言模型：从理论到实践》- LLM-TAP</li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>LLM</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>Web3相关知识记录</title>
    <url>/2024/12/30/20241230-web3-xiang-guan-zhi-shi-ji-lu/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>以下内容都来源于书籍</p>
</blockquote>
</blockquote>
<p><img src="/2024/12/30/20241230-web3-xiang-guan-zhi-shi-ji-lu/Web3.png"></p>
<h2 id="Web进化史"><a href="#Web进化史" class="headerlink" title="Web进化史"></a>Web进化史</h2><ul>
<li><p>Web 1.0时代。Web 1.0时代的特点是重信息轻身份，多浏览少输出，因此也被人称为“只读网络”</p>
</li>
<li><p>相较于Web 1.0时代的内容创作者占少数，内容消费者占绝大多数的生态格局，Web 2.0更加以每个用户为中心，注重由用户生成内容(User Generated Content, UGC)，强调交互性。因此有人将Web 2.0称为“交互网络”。</p>
</li>
<li><p>O2O本质是连接，如果说Web 1.0开启了人与信息的连接，Web 2.0则增进了人与人的连接，电商模式拉近了人与商品的连接，O2O则连接了消费者与服务者。</p>
</li>
<li><p>Web 3.0：数据所有权革命</p>
</li>
<li><p>描述了Web 3.0应该具备的几个组成部分：</p>
<ul>
<li>一个加密的，去中心化的信息发布系统</li>
<li>一个基于身份的，但又是匿名的底层通信系统</li>
<li>一个用于取代中心节点信息验证功能的共识引擎</li>
<li>一个将上述三点结合在一起的用户交互系统</li>
</ul>
</li>
<li><p>目前更多的人在正式场合采用Web 3.0的表述方式，但是我们应该知道Web 3.0表述具有技术流派风格，而Web3表述则具有用户社区风格。</p>
</li>
<li><p>在Web 2.0系统中，个体只是网络中无数节点之一，必须依赖中心节点。中心节点制定规则，决定了其他节点的行为和生存。Web 3.0系统中，个体还是网络中无数节点之一，但每个节点都高度自治，且拥有自己的决策过程。</p>
</li>
</ul>
<h2 id="区块链"><a href="#区块链" class="headerlink" title="区块链"></a>区块链</h2><ul>
<li><p>区块链是一种去中心化的计算机网络，也是实现Web 3.0世界的诸多技术基础中最重要的一个。</p>
</li>
<li><p>通证(tokens)是Web 3.0能够更公平、更有效率的一个关键因素。通证的概念范围非常广</p>
</li>
<li><p>加密资产是通证的其中一类，通证并不一定加密，但在Web 3.0的语境里，通常都是指带有去中心化特性（即无法被中心化机构通过在发放通证后部署的代码篡改）的加密通证。</p>
</li>
<li><p>加密资产并不一定是加密货币，比如NFT与数字藏品</p>
</li>
<li><p>Web 3.0的底层网络架构是基于区块链的，而区块链的第一个应用是比特币。</p>
</li>
<li><p>用以下五个指标来评估一个Web 3.0项目的去中心化程度：</p>
<ul>
<li>(1)项目钱包的透明性　一个项目的钱包越是透明，越能让大家了解这个项目的参与者构成。如果无法公开透明地了解一个项目的参与者构成，就无法进行更深度地评估。</li>
<li>(2)初始钱包的通证占比　初始钱包通常是项目方和核心投资者的地址，如果持有过多的通证，就说明他们对项目的影响力极大，这种项目是极其中心化的。</li>
<li>(3)相关生态的去中心化　在Web 3.0的错综复杂的生态中，大部分项目都并非独立存在而是依附或者嵌套于其他项目的。这时哪怕一个项目在开发层面是去中心化的，其价值和功能也会很大程度上被其他项目影响。而后者若是一个中心化的项目，那前者本质上也依旧是一个中心化的项目。</li>
<li>(4)项目方的影响力　一部分项目方本身并没持有大比例的通证，但由于他们的声音对项目的开发社群有着极大的影响力。这种情况下这也是一个偏中心化的项目，但中心化程度要比少数人持有大比例通证的项目要低。</li>
<li>(5)流动性　哪怕比特币作为一个完全独立的项目，并且没有和任何其他项目有嵌套关系，在早期流动性较低的阶段依旧可以轻易受到几个重要参与者深度影响，甚至有可能因为在链上的节点过少或者大部分节点被垄断，导致被篡改项目数据。也就是说，在那些流动性较差的项目上，被大算力主体篡改资产所有权的可能都要大于流动性高的项目。</li>
</ul>
</li>
<li><p>首次代币发行(Initial Coin Offering, ICO)，对应着首次公开募股(Initial Public Offering, IPO)应运而生。</p>
</li>
<li><p>以太坊的逻辑就是把现实中的合同去中心化形成智能合约。举个最简单的例子，你去自动售货机买可乐，你付钱后可乐出来，这就是一种智能合约。作为一个自动化的、程序化的机器，你付了钱，它给了货。</p>
</li>
<li><p>智能合约的本质就是通过代码程序的方式执行现实社会中的一些底层的制度或者合同。只要条件达到了要求，程序就会执行，解决了谁先出钱，谁先给货的问题。同时，通过区块链的技术，能够让整个交易的过程、结果、代码执行的情况在全网进行记录，且不可篡改。</p>
</li>
<li><p>以太坊(Ethereum)就是区块链版的操作系统，是一个为去中心化应用(DApps)而生的全球开源平台。</p>
</li>
<li><p>从2013年发布白皮书至今，以太坊在智能合约领域一直处于领先地位。它是当前全球最知名、应用最广泛的区块链智能合约底层平台。以太坊建立了一个可编程的、图灵完备的区块链，在这个区块链上，可以通过简单的程序实现各类加密资产的生成，也可以通过编写程序对以太坊上流通的资产状态进行精确控制。至今全球已经有数千种基于以太坊的去中心化应用程序和加密资产。</p>
</li>
<li><p>目前，以太坊上的项目已经划分出众多赛道，针对不同类型的项目大致可以分为：去中心化金融(DeFi)、去中心化交易所(DEX)、游戏、NFT、基础设施等。这些项目会在后文详细介绍。</p>
</li>
<li><p>区块链性能的不可能三角：即去中心化、安全性与可扩展性必须舍弃其一</p>
</li>
<li><p>Ripple和EOS舍弃了去中心化，IOTA和NANO舍弃了安全性，而比特币和以太坊舍弃了可扩展性。因此，以太坊就不得不消耗大量用于相互验证的算力和能源。</p>
</li>
<li><p>区块链可扩展性的提升大致可以分为以下三种：Layer 0（L0跨链交互），Layer 1（L1链上扩容，对主链本身进行改造），Layer 2（L2链下扩容，将主链上部分工作转移至主链以外）。</p>
</li>
<li><p>对于以太坊来说，直接对公链本身进行改造对已有的用户等利益相关方影响较大，因此以太坊社区主要关注的是L2，而对于链上扩容方案则采取缓慢过渡的模式。而对于后发的新公链来说，探索直接建立更高可扩展性的公链模型，成为首选。</p>
</li>
<li><p>L2，主要是指在主链之外建立一个二层的交易处理平台，负责具体交易的处理。主链只负责存取结算及验证链下上传信息的有效性。L2的扩容方式主要有状态通道(State Channels)、等离子体(Plasma)和卷叠(Rollup)三种方式。</p>
</li>
<li><p>随着区块链的发展，在目前，已经进入了一个多链并存的市场架构，并逐渐形成了以以太坊为核心，其他公链众星拱月的局面。从2021年4月开始，以太坊的跨链活动急剧增加。</p>
</li>
<li><p>跨链桥是一种链与链连接的桥梁工具，允许将加密资产从一条链转移到另一条链。两条链可以有不同的协议、规则和治理模型，而桥提供了一种相互通信和兼容的方式来安全地在双方进行互操作。用户可以使用跨链桥，快速轻松地实现加密资产交易。</p>
</li>
</ul>
<h2 id="元宇宙"><a href="#元宇宙" class="headerlink" title="元宇宙"></a>元宇宙</h2><ul>
<li><p>Web 3.0、区块链、元宇宙这三个概念经常交织出现，让人们产生了一定的疑惑。<br>这三个概念中，区块链是最早出现的。2008年区块链正式诞生，它的出现比现在公认出现于2005年的Web 2.0没有晚太多。区块链是为了解决中心化服务器存在的问题而诞生的。</p>
</li>
<li><p>Web 2.0这十多年的发展一直沿用的是将用户抓过来、养肥了、再割韭菜的AARRR（Acquisition获客，Activation激活，Retention留存，Referral转推荐，Revenue变现）互联网平台运营模式。在这种模式下，用户就像是动物一样，从始至终都是以S-R（Stimulus刺激，React反应）的行为模式被对待。用户是平台的资产，而不是平台的主人。因此，Web 2.0的用户被称为流量。</p>
</li>
<li><p>区块链的到来为Web 2.0带来了新的生机，将Web 2.0升级成为Web 3.0。<br>对Web 2.0时代的企业而言，IPO是最终归宿，在IPO那荣光时刻来临之际，企业必须已经达到一个非常大的量级，成为行业龙头。所谓盈亏同源，Web 2.0的企业盈利与用户无关，IPO或中途并购、退出都是VC的战场，亏损当然也与用户无关。</p>
</li>
<li><p>Web 2.0企业的模式是管理团队做，用户用。Web 3.0时代的企业替代物——DAO的所有者是社区，社区成员的每一个人都是DAO的既得利益者。由于Web 3.0的IEO(Initial Exchange Offering)门槛比IPO低，不需要中心化审核，IEO在真正意义上完成了IPO最初想要达成的任务——获取更大的流动性。之所以叫作Initial Exchange Offering而非Initial Public Offering，是因为Web 3.0社区的通证在没有上交易所之前，就是公开的、去中心化的、通常也有广泛的持有人基础，而且也是可以通过区块链交易的。</p>
</li>
<li><p>Web 3.0概念的进化线索是从用户与互联网之间的关系去归纳的，从Web 1.0单向接受互联网，到Web 2.0可以与互联网交互读写，再到Web 3.0可以拥有互联网。</p>
</li>
<li><p>真正的元宇宙远不只是体验的升级。元宇宙是一个宏大的概念，要构建这样一个数字世界，只提升体验是不够的。如果只是将VR&#x2F;AR设备装在头上，这样的元宇宙不过是个大型游戏，还远不能成为“宇宙”。从深层次出发，用“有关联”来描述Web 3.0和元宇宙之间的关系，显然还不够，它们之间是相辅相成的。从技术角度来看，元宇宙是前端、展示层，Web 3.0是中后端、技术层，只有技术条件满足Web 3.0所需的去中心化的数据库，即分布式数据库，以及配套的加密技术和协议，才有可能实现元宇宙这样宏大的设想。</p>
</li>
<li><p>NFT——NFT可以将现实世界与元宇宙的每一个物品一一对应。</p>
</li>
<li><p>DAO——元宇宙既是一场技术革命，也是一场社会革命，而DAO作为社区的操作系统，将是元宇宙的关键。DAO提供了一个技术层，提供个人之间的全球性和去中心化的协作，而无须信任第三方或少数代表。</p>
</li>
<li><p>之所以字节跳动等大厂和互联网知名人士都认为元宇宙是一个超前的概念，主要是因为其本身就建立在多重计算机技术与网络服务之上，是一套极其复杂的生态技术系统，在短时间内并不可能实现，而目前最接近元宇宙的则是Web 3.0。</p>
</li>
<li><p>区块链是支撑Web 3.0发展的底层技术，而Web 3.0的去中心化和确权特性是元宇宙的基础建设。Web 3.0的实现必然早于真正元宇宙的实现，这是元宇宙之所以能成为宇宙的前提条件。</p>
</li>
</ul>
<h2 id="DApps"><a href="#DApps" class="headerlink" title="DApps"></a>DApps</h2><ul>
<li><p>DApps是建立在区块链上的应用，全称Decentralized Applications。区块链有五层架构（也有一种划分方式，将协议层从应用层中独立出来，分为六层架构），DApps属于其中的最上层——应用层</p>
</li>
<li><p>Web 3.0是构建在区块链上的数字世界，而DApps就是用来构建这个世界中我们看得见摸得着的那部分的“砖瓦”。</p>
</li>
<li><p>要成为去中心化应用，需要满足以下标准：</p>
<ul>
<li>(1)必须完全开源，自动运行，且没有一个实体控制着它的大多数通证。它的数据和记录必须加密后存储在一个公链上。</li>
<li>(2)必须依据一个标准化算法或一系列准则来生产通证，并且应该在开始运营的时候就将它的部分或全部通证发放给使用者。这个应用必须依赖该通证来运行，而且使用者所作出的贡献应该以该通证作为奖励。</li>
<li>(3)可以因时制宜地更改它的运行法则，但是这些改变应该被大多数用户所认可，而不是将最终解释权归于某个实体。</li>
</ul>
</li>
<li><p>区块链的基础架构可以分为五层，包括硬件层，数据层、网络层、共识层、应用层（有些说法还会从应用层中拆分出协议层）。    </p>
</li>
<li><p>DApps大多数属于应用层。作为一类相对特殊的DApps，基础设施类DApps的作用是为DApps世界与其他四层的交互建立连接。因此基础设施类的DApps通常以“协议”的形式存在</p>
</li>
<li><p>◆ 区块链是由一个点对点(Peer-to-Peer)的计算机网络共同进行运算，验证和记录交易的。硬件层(Hardware Layer)就是这些计算机。<br>● 数据层(Data Layer)我们可以理解成数据库，主要可实现两大功能：数据存储、账户和交易的安全。<br>● 网络层(Network Layer)实现三大功能：节点间组网，数据传播，数据验证。<br>● 共识层(Consensus Layer)主要通过共识算法和共识机制实现一个重要功能：节点间的计算达成共识。由于区块链是分布式网络，每个节点均可计算，所以需要共识层做个统筹，让所有节点针对区块数据的有效性达成共识。<br>● 应用层(Application Layer)是最上面一层，有些说法还会在其中将协议层(Protocol Layer)单独分为一层。原因是DApps有“胖协议，瘦应用”的说法。这是相对于Web 2.0 Apps的“瘦协议，胖应用”提出的。所谓“胖协议”，举个例子，在Web 2.0中，数据的安全依靠数据安全公司、杀毒软件、防火墙等应用实现，协议层只负责数据传输；而在Web 3.0中，传输协议本身就保障了数据安全，因此各种数据安全应用、杀毒软件、防火墙应用没有了独立存在的空间。智能合约就是这样的一种协议。</p>
</li>
<li><p>交易所<br>针对加密资产的交易所既有中心化的也有去中心化的。中心化交易所目前依然占据着绝对的市场地位，因为他们发展较早，对从Web 2.0过渡进入Web 3.0的用户而言使用体验也比较好。在交易所中交易的加密资产主要为加密货币和NFT。去中心化加密货币交易所我们放在第六章详细介绍，NFT交易所我们放在第七章详细介绍。</p>
</li>
</ul>
<h2 id="DAO"><a href="#DAO" class="headerlink" title="DAO"></a>DAO</h2><ul>
<li><p>DAO是一种共同管理加密资产以达成共同目标的组织方式。我们可以将DAO视作由成员集体所有和共同管理的Web 3.0版本的新型企业。</p>
</li>
<li><p>DAO的实现基于智能合约。因此，在某些语境下，DAO也可以指代支撑DAO运行的智能合约本身。合约界定了组织的规则，管理组织的资金。以太坊是第一个使人们能够建立DAO的区块链。大多数DAO都在以太坊上，但也有其他网络能建立DAO，如Polkadot、Cosmos、EOS和Cardano。</p>
</li>
<li><p>DID和传统ID的差异在于，DID基于区块链，而链上数据是公开透明可查并难以篡改的。因此当你在Web 3.0亮出DID，人们并不需要借助某个权威机构，就可以核验这个DID的真伪以及能否准入。</p>
</li>
<li><p>Uniswap是一个以协议形式存在的去中心化交易所，而它的治理是以DAO的形式运作的。</p>
</li>
<li><p>教你建立一个DAO<br>了解了这么多关于DAO的概念，是不是也想自己动动手？参与或自己建立一个DAO是亲身体验Web 3.0的门槛最低的方式。建立一个DAO几乎和建立一个微信群一样简单。这一节笔者将借助一个名为Aragon的工具，手把手教读者建立一个DAO。<br>第一步：打开<a href="https://aragon.org/">https://aragon.org/</a></p>
</li>
</ul>
<h2 id="DeFi"><a href="#DeFi" class="headerlink" title="DeFi"></a>DeFi</h2><ul>
<li>DeFi，全称Decentralized Finance，去中心化金融。</li>
<li>去中心化交易所是一类基于区块链的交易所，它不需要将用户资金和个人数据转入交易所内，而只是作为一种基础设施来匹配希望买卖加密资产的买家和卖家。在匹配引擎的帮助下，这种交易直接发生在参与者之间。<br>中心化交易所(CEX)，是集传统交易所、券商和投资银行的功能为一体的平台，以币安、Coinbase、FTX交易所为代表，CEX聚集了庞大的用户量和交易量，也带来了足够的交易深度，提供了充分的资产流动性。</li>
<li>交易所的核心环节一般包括充提、下单、订单撮合、资金结算和提现。CEX均由交易平台本身撮合完成；DEX则是把上述所有环节都置于链上，由智能合约执行全部操作，这样用户的交易过程就无须任何第三方。</li>
</ul>
<h2 id="NFT"><a href="#NFT" class="headerlink" title="NFT"></a>NFT</h2><ul>
<li><p>现实世界与数字世界的差异在于，现实世界不存在完全相同的两个物品，即使是同一个工厂同一批次的商品也会有可能出现不同。而数字世界则可以完全复制同一物品。</p>
</li>
<li><p>我们如果要实现元宇宙的最终目标，就需要把现实世界物品的这个特点也搬到数字世界里。区块链能帮我们做到这一点，这就是非同质化通证(Non-Fungible Token, NFT)。</p>
</li>
<li><p>同质化通证(Fungible Token, FT)和非同质化通证之间的区别</p>
</li>
<li><p>BTC、ETH等加密资产多数是同质化通证。顾名思义，同质化通证是可以与同一事物的另一个单位互换的。例如，一单位BTC等于另一单位BTC，就像一张100美元的价值等于另一张100美元。美元可以进行简单互换，即使序号不同也不影响，对持有者来说没有区别。同质化通证是一种能够互换、具有统一性的通证。而且由于它以数字的形式存在，还可以拆分成近乎无穷小的许多份，每一份也都可以代表相应的价值。<br>与同质化物品不同，非同质化物品或通证彼此之间是不能互换的，它们具有独特的属性。即使看起来相似，但彼此之间也有根本的不同。<br>非同质化通证包含了记录在其智能合约中的识别信息。这些信息使每个通证具有唯一性，因此不能被另一种通证直接替代，没有两个NFT是相同的。此外，绝大多数非同质化通证也不可分割。</p>
</li>
<li><p>每个NFT都有区别于其他NFT的数字哈希值。因此，NFT可以作为出处证明。就像现实世界中的证书一样，它不仅能证明原创艺术品和游戏通证等知识产权的所有权和真实性，还能代表股票、房地产等实际资产。现实世界中，真实资产拥有所有权证书。同样，在区块链世界中，NFT也可以作为所有权记录和真实性证明。在艺术品领域，NFT也被称为数字藏品。</p>
</li>
<li><p>NFT不仅存在于数字世界，它们也可以代表任何类型的物理资产。NFT可以与物理世界中存在的任何东西相连接，形成一种“数字孪生”，并在数字世界的市场上实现实物资产的所有权交易。</p>
</li>
<li><p>NFT目前最为人推崇的应用场景是创作者经济。</p>
</li>
<li><p>NFT的3种存储方式是区块链存储、IPFS分布式存储节点存储、中心化服务器存储，安全性依次降低。安全性越高则越符合不可篡改的特性，也越有独特性。</p>
</li>
<li><p>万物皆可NFT。这里的NFT指的不仅是艺术品。这个理念不是说万物都可以成为艺术收藏品，而是有着更远大的目标。我们可以将世间万物以数字孪生的方式在数字世界重建一遍。所有的一切都可能以NFT的形式存在，也可以以NFT的产生方式创造出来。</p>
</li>
</ul>
<h2 id="通证经济学"><a href="#通证经济学" class="headerlink" title="通证经济学"></a>通证经济学</h2><ul>
<li>通证是Web 3.0的核心，身份是通证，NFT是通证，交易媒介也是通证。通证是激励用户参与的奖励，是驱动Web 3.0运行的燃油，也是连接Web 3.0世界各个岛屿的桥梁。通证的发放、分配与流通使用机制是一个Web 3.0项目能否成功的关键因素。</li>
<li>通证经济（Token Economics，也称Tokenomics）。就像一个普通的经济体系，通证经济逃不过供给和需求的掌控，供不应求则价格上涨，供过于求则价格下跌。</li>
</ul>
<h2 id="Web-3-0现存的问题"><a href="#Web-3-0现存的问题" class="headerlink" title="Web 3.0现存的问题"></a>Web 3.0现存的问题</h2><ul>
<li><p>在失去中心化监管的环境下，加密与匿名也暴露了许多问题。通过加密匿名算法获取的财富，也会被加密匿名地剥夺</p>
</li>
<li><p>人类的共识是一个很有意思的东西，它可以如磐石般固执，也可以如鲁珀特之泪的尾巴一样脆弱。当形成共识的那个关键点破灭，建立在共识之上的摩天大楼，就会瞬间崩塌。</p>
</li>
<li><p>创作者经济还是炒作者经济</p>
</li>
<li><p>Web 3.0的底层是去中心化网络，数据存储和运算是由各个分散的节点完成。那么很自然的，不考虑中心化作业情况下的网络其他参与者在不能达成一致而导致扯皮的情况，对于同样一件事情的处理，协同作业的速度就是比中心化作业要慢、效率更低、消耗能源更多。</p>
</li>
<li><p>比特币交易为了替换掉中心化权威而采用了耗能极大的工作证明，让人们消费了能源计算出一个不产生任何价值的问题，这是对权威不信任的代价。具体而言，每一笔比特币交易要消耗2188千瓦时的电量，而Visa是每10万笔交易消耗148千瓦时电量，这代价就是效率下降150万倍。以太坊的耗电量是比特币的1&#x2F;10，相对Visa也有15万倍的差距。Web 3.0的底层架构要想达到Web 2.0的用户体验，只有两条路可以走，其一是降低运算的耗能，其二是调整共识机制。</p>
</li>
<li><p>互联网不是法外之地，Web 3.0也不是。网络无国界，但法律是有国界的。目前各国针对Web 3.0的监管法规还在逐步出台中，而Web 3.0未来的发展必然是需要在各国的法律框架下运行的。</p>
</li>
<li><p>在Web 2.0时代，监管主体是服务提供商，监管属地是服务器所在地。而在Web 3.0时代，服务代码存放在网络的各个服务器上，也没有一个具体的服务提供商。Web 3.0的互联网活动趋于分布式，这给监管主体和监管属地的确定带来了一定的挑战。<br>另外，由于Web 3.0应用和钱包的匿名性和去中心化，一旦资产丢失，将无法找回。</p>
</li>
<li><p>Web 3.0项目的代码一经上线，即无法改动。这就使得在上线前对于代码的审计显得尤为重要。但凡是代码，或多或少都是有漏洞的。上线无法改动的代码犹如一辆在公路上狂奔而没有方向盘的汽车，行驶越久危险系数越高。</p>
</li>
<li><p>政府监管和主导从来都是一柄双刃剑，会对技术发展和应用创新造成一定阻碍，但从稳定社会经济、维护金融秩序角度看，合规是一个新兴市场的生存基础。</p>
</li>
<li><p>Web 3.0已经被赋予了太多神秘色彩，人们对它寄予了太多不切实际的希望。而只有当我们意识到，区块链发明者的“去中心化”理想主义，注定会被纷至沓来的投机者瓦解得支离破碎的时候，我们才可以平心静气地接受一个基于现实主义的Web 3.0的未来——在一个由核心节点掌握的“中心化”区块链网络上，用“去中心化”的分布式账本和加密散列，保障不同的经济主体之间的数字产权和商业价值不受侵犯，并形成它们互相的契约关系——这也理应是我国的政府、企业和社会组织在Web 3.0浪潮中扮演的角色。！！！！</p>
</li>
<li><p>腾讯、阿里巴巴（蚂蚁集团）、百度和京东等都构建了自己的联盟链，从内容版权、股权、保险、债券、供应链金融、税务、司法、商品防伪溯源、物流运输和生态保护等方面提供了“上链”服务。BSN与长安链等国有企业、智库和政府机构成立的联盟链也陆续建立，除了用于商业和政务场景，还致力解决区块链底层公用基础设施和知识产权的自主可控问题。</p>
</li>
</ul>
<h2 id="名词"><a href="#名词" class="headerlink" title="名词"></a>名词</h2><ul>
<li>DApps（Decentralized Applications，去中心化应用程序）</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>《Web3.0漫游指南》</li>
</ul>
]]></content>
      <tags>
        <tag>Web3</tag>
        <tag>区块链</tag>
        <tag>blockchain</tag>
        <tag>bitcoin</tag>
        <tag>NFT</tag>
      </tags>
  </entry>
  <entry>
    <title>AI工业革命下的若干思考</title>
    <url>/2024/12/31/20241231-ai-gong-ye-ge-ming-xia-de-ruo-gan-si-kao/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>随着AI工具变得日益智能，人们对自身可能被取代的担忧也在增加。<br>回顾以往工业革命带来的社会变迁，或许能从中推测出未来发展的趋势。<br>以下内容由ChatGPT辅助生成。</p>
</blockquote>
</blockquote>
<h1 id="AI对就业的双重影响"><a href="#AI对就业的双重影响" class="headerlink" title="AI对就业的双重影响"></a>AI对就业的双重影响</h1><ul>
<li>AI技术对就业市场带来了创造效应和破坏效应：<ul>
<li>创造效应：AI的普及将催生了许多潜在的新兴职业。这些新兴岗位对熟练掌握AI工具的专业人才需求旺盛。</li>
<li>破坏效应：AI替代了许多重复性、规则性较强的岗位。某些中等技能的岗位如流水线操作、传统文秘工作可能面临消失的风险。</li>
</ul>
</li>
</ul>
<h1 id="历史视角：被替代的人何去何从"><a href="#历史视角：被替代的人何去何从" class="headerlink" title="历史视角：被替代的人何去何从"></a>历史视角：被替代的人何去何从</h1><ul>
<li><p>随着AI技术的发展，未来许多人的工作将不可避免地被替代，这其中包括一部分程序员，但相较而言，更多非程序员的工作可能会首当其冲。然而，那些更擅长使用并深刻理解AI工具的人将更有可能保住自己的职位。</p>
</li>
<li><p>回顾工业革命，技术进步曾一度导致大批劳动者失业，许多人因无法适应新变化而成为时代的“牺牲品”，收入锐减。</p>
</li>
<li><p>短期内，某些群体的失业可能难以避免，但历史也表明，技术变革往往伴随着新机会的诞生。</p>
</li>
<li><p>所以，个人需要做好准备：</p>
<ul>
<li>提升自身技能，特别是AI工具的使用和相关领域的知识储备。</li>
<li>即便不能马上参与高端AI开发，也可以从简单的AI相关工作入手，逐步积累经验。</li>
<li>有一定资产的群体，应学会投资，通过多样化方式应对收入变化。</li>
</ul>
</li>
</ul>
<h1 id="正面效应"><a href="#正面效应" class="headerlink" title="正面效应"></a>正面效应</h1><ul>
<li>催生新型岗位：AI技术完善后，将需要大量擅长操作和优化AI工具的人才。</li>
<li>解放低级劳动：AI让人类摆脱低级脑力劳动，从而获得更高工资和更有意义的工作体验。</li>
<li>效率提升与“去内卷”：生产效率的提升可能减少“内卷”现象，并通过政策调整减轻劳动者的工作压力。</li>
<li>关于工作和财富再分配问题：如果AI真的让生产效率大幅提升，我们可以期待未来的福利制度更加完善，比如减少工作时间、增加带薪假期，甚至实现“无工作”状态也未必是幻想。</li>
</ul>
<h1 id="社会与政策层面"><a href="#社会与政策层面" class="headerlink" title="社会与政策层面"></a>社会与政策层面</h1><ul>
<li>加强教育培训：推动技能提升和再教育计划，使劳动者适应AI时代的工作需求。</li>
<li>优化产业结构：加速产业转型升级，为社会创造更多高附加值就业机会。</li>
<li>完善社会保障：建立健全失业保障制度，帮助因AI技术变革失业的劳动者渡过难关。</li>
<li>政策引导：通过政策规范AI技术的合理应用，避免过度自动化对就业的过度冲击。</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>AI技术的快速发展是一把双刃剑，它既对传统就业模式提出了挑战，也为社会提供了提高效率、优化劳动分工的契机。从社会视角看，技术进步不可逆，但我们可以通过政策调整和个人适应来尽量减小负面影响。面对不可避免的变革，积极调整心态、提升能力，是每个人应对未来的重要策略。同时，历史告诉我们，每一次技术浪潮都会带来新的机遇，只要抓住变化的窗口期，未来依然充满希望。</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="http://www.xml-data.cn/KXYSH/html/93be89d5-c2ef-491d-9398-ebe61dcdc56b.htm">从工业革命史看技术变迁如何影响工人命运——《技术陷阱：自动化时代的资本、劳动力和权力》评介</a></li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>工业革命</tag>
      </tags>
  </entry>
  <entry>
    <title>使用AI总结了这个网站的内容</title>
    <url>/2025/01/01/20250101-shi-yong-ai-zong-jie-liao-zhe-ge-wang-zhan-de-nei-rong/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>使用google的notebooklm总结目前该网站的所有文章内容<br><a href="https://notebooklm.google.com/">https://notebooklm.google.com/</a><br>问题：全面阐述和总结一下这个博客网站的内容，涉及领域，博主风格等</p>
</blockquote>
</blockquote>
<hr>
<p>该博客网站的内容主要涵盖了<strong>个人成长和职业发展</strong>两个方面，涉及领域包括：</p>
<ul>
<li><strong>自我营销</strong>:  如何打造个人品牌，提升影响力。</li>
<li><strong>时间管理</strong>: 如何提高工作效率，克服拖延。</li>
<li><strong>学习方法</strong>: 如何快速学习，进行深度学习，构建个人知识体系。</li>
<li><strong>心理素质</strong>: 如何拥有积极心态，提升情绪力。</li>
<li><strong>职业发展</strong>: 如何成为一名专业的软件开发人员，进行有效的薪酬谈判。</li>
<li><strong>创业</strong>: 如何打造成功的产品，制定切实可行的创业计划。</li>
<li><strong>健身</strong>: 如何利用科技产品实现健身目标。</li>
<li><strong>人际关系</strong>: 如何与他人相处，建立良好的人际关系。</li>
<li><strong>精神</strong>: 如何利用心灵的力量，克服天性，实现个人成长。</li>
<li><strong>金融</strong>: 如何理解金融危机，以及金融政策的作用。</li>
<li><strong>公司文化</strong>: 如何打造面向未来的新型组织文化，以网飞为例。</li>
<li><strong>历史</strong>: 如何理解人类社会的发展，以文字和政治组织为例。</li>
</ul>
<p>博主风格：</p>
<ul>
<li><strong>注重实用性</strong>: 博主的内容以解决实际问题为导向，提供具体可行的建议和方法。</li>
<li><strong>结合个人经验</strong>: 博主经常结合自身经历和感悟，使得内容更具说服力。</li>
<li><strong>善于运用类比</strong>: 博主擅长用通俗易懂的类比来解释复杂的概念，使读者更容易理解。</li>
<li><strong>强调深度思考</strong>: 博主鼓励读者进行深度思考，并将知识与自身实际相结合。</li>
<li><strong>注重科学依据</strong>: 博主经常引用科学研究和理论来支持自己的观点，增强内容的可信度。</li>
</ul>
<p>总而言之，该博客网站的内容丰富实用，风格清晰易懂，对于想要提升个人能力和实现职业成功的读者来说，具有很高的参考价值。</p>
<hr>
<h2 id="排除掉笔记类文章后"><a href="#排除掉笔记类文章后" class="headerlink" title="排除掉笔记类文章后"></a>排除掉笔记类文章后</h2><p>这个博客网站的内容主要涉及<strong>软件开发和技术管理</strong>领域，涵盖了<strong>业务方案、架构设计、技术实践、团队管理和个人成长</strong>等方面。博主的写作风格<strong>简洁、实用、注重经验总结和思考</strong>，文章内容多来自实际工作中的问题和解决方案，并结合个人思考和学习心得进行阐述。</p>
<p>以下是该博客网站内容的详细分析：</p>
<p><strong>一、内容领域：</strong></p>
<ul>
<li><strong>业务方案：</strong>涵盖了分页、兼容性、事务、前置校验、幂等、错误码处理、接口安全、容灾降级、货币体系设计、榜单实现等常见业务场景的解决方案和实践经验总结。</li>
<li><strong>架构设计：</strong>探讨了微服务架构、服务间一致性、数据库高可用方案、容灾架构、聚合层设计等架构设计理念和实践经验。</li>
<li><strong>技术实践：</strong>分享了RPC调用、事务处理、数据库同步、Redis应用、单元测试、配置中心、序列化协议等技术点的实践经验和工具技巧。</li>
<li><strong>团队管理：</strong>总结了个人管理经验、小团队管理要点、项目管理技巧、团队协作、沟通技巧等团队管理方面的经验和思考。</li>
<li><strong>个人成长：</strong>记录了博主从PHP、C++、Lua到Java、Go、Rust等不同编程语言的学习和实践经历，以及对技术发展趋势的思考和个人职业发展的感悟。</li>
</ul>
<p><strong>二、博主风格:</strong></p>
<ul>
<li><strong>简洁实用：</strong>文章语言简洁明了，直击问题核心，注重实用性，避免过多理论和概念的堆砌。</li>
<li><strong>经验总结：</strong>文章内容多来自博主实际工作中遇到的问题和解决方案，并进行总结提炼，形成可供参考的经验。</li>
<li><strong>思考深入：</strong>博主不局限于问题本身，而是深入思考问题背后的原因和本质，并提出自己的见解和解决方案。</li>
<li><strong>持续学习：</strong>博主不断学习新的技术和知识，并将其应用到实际工作中，乐于分享自己的学习心得和体会。</li>
</ul>
<p><strong>三、其他特点:</strong></p>
<ul>
<li><strong>注重代码质量：</strong>博主强调单元测试、代码规范、代码扫描工具等提升代码质量的方法。</li>
<li><strong>关注团队协作：</strong>博主重视团队沟通、信息透明、知识分享等，提倡高效的团队协作方式。</li>
<li><strong>追求技术进步：</strong>博主积极探索新的技术和架构，并思考技术发展趋势对个人和团队的影响。</li>
</ul>
<p><strong>总结:</strong></p>
<p>该博客网站内容丰富，涵盖了软件开发和技术管理的多个方面，体现了博主丰富的实践经验和深入的思考。博主的写作风格简洁实用，注重经验总结和思考，对于从事相关领域工作的读者具有较高的参考价值。</p>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>简单研究一下人工智能和数学</title>
    <url>/2025/01/06/20250106-jian-dan-yan-jiu-yi-xia-ren-gong-zhi-neng-he-shu-xue/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>简单记录，未完善<br>内容基本来源书籍</p>
</blockquote>
</blockquote>
<p><img src="/2025/01/06/20250106-jian-dan-yan-jiu-yi-xia-ren-gong-zhi-neng-he-shu-xue/%E6%95%B0%E5%AD%A6.png"></p>
<p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h1 id="初等数学"><a href="#初等数学" class="headerlink" title="初等数学"></a>初等数学</h1><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><ul>
<li>函数的表示方法主要有三种：解析法（公式法）、图像法和表格法。在微积分中讨论的函数几乎都是用解析法表示的。</li>
</ul>
<h2 id="二项式定理"><a href="#二项式定理" class="headerlink" title="二项式定理"></a>二项式定理</h2><ul>
<li>二项式定理又称为牛顿二项式定理，它可将两个数之和的整数次幂展开为相应项之和。</li>
</ul>
<p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h1 id="高等数学"><a href="#高等数学" class="headerlink" title="高等数学"></a>高等数学</h1><h2 id="微积分"><a href="#微积分" class="headerlink" title="微积分"></a>微积分</h2><p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h1 id="人工智能数学"><a href="#人工智能数学" class="headerlink" title="人工智能数学"></a>人工智能数学</h1><ul>
<li><p>从发展历程来看，人工智能先后经历了推理机、专家系统及机器学习三个阶段。</p>
</li>
<li><p>当前的人工智能系统多为学习型。为了减小误差，其用数据去训练假设模型，也就是进行所谓的学习，当误差降到最小时，就把这个假设模型用于其他现实问题。</p>
</li>
<li><p>人工智能实际上是一个将数学、算法理论和工程实践紧密结合的领域。人工智能从本质上来看就是算法，是概率论、统计学等各种数学理论的体现。数学作为表达与刻画人工智能模型的工具，是深入理解人工智能算法原理必备的基础知识。人工智能与数学高度相关，可以说人工智能的核心是数学，计算机只是实现人工智能模型的工具。</p>
</li>
<li><p>函数逼近：随着大数据和人工智能技术的发展，机器学习和深度学习在大数据挖掘、模式识别和智能分析越来越受重视。机器学习是一种基于数据的学习方法，其从观测数据所包含的有限信息中构造一个模型，利用该模型对未知数据或无法观测的数据进行尽可能准确的预测，这种模型称为学习机器。对数据科学而言，所有的数据都是以数字形式表示的，通过定义损失函数，选择合适的核函数或激活函数，反复学习后可达到一种最佳逼近状态，因此，机器学习问题实际上是函数估计问题或函数逼近问题。</p>
</li>
</ul>
<h2 id="微积分-1"><a href="#微积分-1" class="headerlink" title="微积分"></a>微积分</h2><ul>
<li>求导是微积分的基本概念之一，也是很多理工科领域的基础运算。导数是变化率的极限，是用来找到“线性近似”的数学工具，是一种线性变换，体现了无穷、极限、分割的数学思想，主要用来解决极值问题。人工智能算法的最终目标是得到最优化模型，其最后都可转化为求极大值或极小值的问题。</li>
<li>比如，梯度下降法和牛顿法是人工智能的基础算法，现在主流的求解代价函数最优解的方法都是基于这两种算法改造的，如随机梯度法和拟牛顿法，其底层运算就是基础的导数运算。</li>
<li>级数也是微积分中非常重要的概念，常见的级数有泰勒级数、傅里叶级数等，它们在人工智能算法中也有非常重要的地位。</li>
<li>泰勒级数体现了用多项式近似和逼近函数的思想。</li>
<li>泰勒级数在人工智能算法的底层起到了非常重要的作用，泰勒级数对理解很多基础算法的原理很有帮助。例如，梯度下降法的数学原理涉及代价函数的一阶泰勒近似，而牛顿法的推导过程应用了目标函数的二阶泰勒近似。</li>
<li>凸函数也是微积分中的重要概念，人工智能算法中涉及的优化问题要求函数模型必须是凸函数，否则优化问题没有最优解。</li>
<li>微积分中还有许多概念，如方向导数、梯度、伽马函数等，它们都在人工智能中有广泛的应用</li>
</ul>
<h2 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h2><ul>
<li>线性代数的基本原理在人工智能算法中处于核心地位，在人工智能的语义分析、推荐系统、卷积神经网络等方面有大量应用，是目前最前沿的深度学习算法原理的基础。</li>
</ul>
<h2 id="概率论"><a href="#概率论" class="headerlink" title="概率论"></a>概率论</h2><ul>
<li>很多机器学习算法是以概率统计的理论为基础支撑推导出来的，比如代价函数的最小二乘形式、逻辑回归算法都基于对模型的最大似然估计。</li>
<li>概率论中的高斯函数及中心极限定理被广泛用于人工智能算法。独立同分布的不同随机变量之和会随变量数的增加而趋于高斯分布，因此，很多模型假设都采用高斯函数进行建模。</li>
</ul>
<h2 id="数理统计"><a href="#数理统计" class="headerlink" title="数理统计"></a>数理统计</h2><ul>
<li>概率论作用的前提是随机变量的分布已知，其根据已知的分布来分析随机变量的特征与规律；数理统计的研究对象则是分布未知的随机变量，其研究方法是对随机变量进行独立重复的观察，根据得到的观察结果对原始分布做出推断，数理统计可以看作逆向的概率论。</li>
<li>若检验是通过随机抽取的样本来对一个总体的判断结果进行认可或否定，则可以将其用于估计机器学习模型的泛化能力。</li>
</ul>
<h2 id="最优化理论"><a href="#最优化理论" class="headerlink" title="最优化理论"></a>最优化理论</h2><ul>
<li>人工智能的目标就是最优化，就是在复杂环境与多体交互中做出最优决策。几乎所有的人工智能问题最后都会归结为一个优化问题的求解，因此，最优化理论同样是学习、研究人工智能必备的基础知识。<br>最优化理论研究的问题是判定给定目标函数是否存在最大值或最小值，并找到令目标函数取最大值或最小值的数值。如果把给定的目标函数看成连绵的山脉，最优化的过程就是找到顶峰（谷底）且到达顶峰（谷底）的过程。</li>
<li>最优化理论的研究内容主要包括线性规划、（不）精确搜索、梯度下降法、牛顿法、共轭梯度法、拟牛顿法、（非）线性最小二乘法、约束优化最优性条件、二次规划、罚函数法和信赖域法等。</li>
<li>要实现最小化或最大化的函数称为目标函数，大多数最优化问题都可以通过使目标函数￼最小化解决，最大化问题也可以通过最小化￼来解决。最优化方法找到的可能是目标函数的全局最小值，也可能是局部极小值，两者的区别在于全局最小值比定义域内所有其他点的函数值都小，而局部极小值只比所有邻近点的函数值小。</li>
<li>当目标函数的输入参数较多、解空间较大时，大多数实用的最优化方法都不能满足全局搜索对计算复杂度的要求，因而只能求出局部极小值。但是，在人工智能和深度学习的应用场景中，只要目标函数的取值足够小，就可以把这个值当作全局最小值使用，以此作为对性能和复杂度的折中。</li>
</ul>
<p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<blockquote>
<blockquote>
<p>程序员的数学</p>
</blockquote>
</blockquote>
<h2 id="迈向机器学习的第一步"><a href="#迈向机器学习的第一步" class="headerlink" title="迈向机器学习的第一步"></a>迈向机器学习的第一步</h2><ul>
<li><p>由输入和目标组成的数据称为训练数据。机器学习中所谓的学习，就是为了通过给定的输入得到和目标尽可能接近的输出，使用训练数据对参数进行调整的过程。使用训练数据对参数进行过调整的模型称为训练好的模型。对于训练好的模型，需要用测试数据对其进行测试，从而评价训练的效果。</p>
</li>
<li><p>在机器学习中对参数进行调整的过程，不是由程序员完成的，而是由计算机通过训练数据自动完成的，这正是机器学习的一大特征。</p>
</li>
<li><p>这里先做个总结吧。我们面对预测问题，首先要有好的模型加上大量的训练数然后，我们需要的是“能根据输人向量，得到和目标向量尽量接近的输出向量”这样一个训练好的模型。</p>
</li>
<li><p>解决分类问题的过程，也可以说是从大量数据中总结规律和规则，从而发现模式的过程。机器学习并不会要求程序员提前研究手写字符的各种形态再去设计程序，而是由计算机根据训练数据来调整参数，从而得到分类模型，这才是它的特征所在。</p>
</li>
</ul>
<p><img src="/2025/01/06/20250106-jian-dan-yan-jiu-yi-xia-ren-gong-zhi-neng-he-shu-xue/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png"><br><img src="/2025/01/06/20250106-jian-dan-yan-jiu-yi-xia-ren-gong-zhi-neng-he-shu-xue/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B02.png"></p>
<ul>
<li><p>如果机器对训练数据能给出完美的输出，对测试数据给出的结果却不尽如人意，很有可能是发生了过拟合（overfitting）。用学生来说，就好比是课堂上做过的训练题都能解得很好，但考试成绩却不怎么理想。</p>
</li>
<li><p>在学习的过程中，需要比较输出和正确的值。拿这个简单的例子来说，要比较的对象就是由输入x1，x2通过给定模型得到的输出y和目标t。如果y和的值一致，那当然好，但一般并不会这么理想。对学习结果（输出）的评价不是单纯的“好与不好”，而是要知道它与训练数据中给出的目标相比“到底有多不好”。为了实现这种评价，需要引入损失函数。<br>在具体的机器学习问题中，如何选取恰当的损失函数是个重要且有难度的问题。比如使用平方和误差函数。</p>
</li>
<li><p>要通过调整模型中的权重参数，使得损失函数值尽可能接近于0。</p>
</li>
<li><p>梯度下降法<br><img src="/2025/01/06/20250106-jian-dan-yan-jiu-yi-xia-ren-gong-zhi-neng-he-shu-xue/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95.png"></p>
</li>
<li><p>作为程序员要做些什么</p>
<ul>
<li>在构建模型这个阶段，程序员是要参与的，但是参数的自动调整过程，程序员不会参与。也就是说，程序员不去直接指定参数的具体数值，而是通过模型、损失函数、训练数据，间接地让参数的选取向着更优的方向变化，从而得到需要的参数。即使模型、损失函数都相同，只要训练数据不同，学习后得到的模型也会截然不同。</li>
<li>机器学习是基于数据让机器去学习，程序员并不直接参与其中。这就像硬件配置完全同的计算机，如果软件系统不一样，整个运行模式也会不一样。把软件换掉，同一套硬件系统也会根据不同的指令做出不一样的事情。道理类似，就算模型一样，只要训练数据不同，最后模型的运行模式也会不一样。</li>
</ul>
</li>
<li><p>神经网络是指，把像感知器一样有输入和输出的节点排列起来形成的带有层次的结构。神经网络（neural network）这个词来源于生物的信息传递方式。在感知器中，输出是二元的，取值只有0或1两种情况，而神经网络中的节点输出的就不是二元，而是可以进行微分运算的连续值。</p>
</li>
</ul>
<p><img src="/2025/01/06/20250106-jian-dan-yan-jiu-yi-xia-ren-gong-zhi-neng-he-shu-xue/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.png"></p>
<ul>
<li><p>深度学习是在神经网络的基础上，通过增加层数得到的更加“深化”的模型。增加层数是为了更加精确地拟合复杂函数，就算涉及的参数个数不做大的变动，也能得到更好的模型。至于如何“深化”在理论上更为有效，依然是现在研究的热点之一。</p>
</li>
<li><p>强化学习是在“无监督”的条件下进行的“学习”。也就是说，在学习过程中没有标准答案可供参考。强化学习通过试错来寻找最优输出，对每个输出，系统都会提供反馈（奖励），模型的参数可以根据得到的反馈来调整。</p>
</li>
<li><p>做出决策</p>
<ul>
<li>机器学习会根据输人的数据预测未来。这种意义下的预测，是基于先前的经验进行的，得到的是未来最有可能发生的情况（数值）。但是，得到预测值之后“应该做些什么”，机器是无法决定的。也就是说，它们无法进行决策。</li>
<li>通过机器学习这个方法，机器可以告诉我们在未来什么样的行动会导致事情如何发展。</li>
<li>但是，做决策这件事本身，并不能让机器来做。</li>
<li>顺着这个话题继续讲下去，就不是技术问题，而是伦理问题了。比如，在减轻痛苦和延续生命之中二选一的问题等，只能由个人的意志来决定，不可能委托给机器学习。</li>
</ul>
</li>
</ul>
<p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>《人工智能数学基础》</li>
<li>《程序员的数学》</li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>Math</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>算法在实际业务场景中并非完全无用</title>
    <url>/2025/01/08/20250108-suan-fa-zai-shi-ji-ye-wu-chang-jing-zhong-bing-fei-wan-quan-wu-yong/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>从事业务开发的同学经常会抱怨经常面试要刷算法，实际上平常的开发99%以上的事情都不会用到。<br>实际情况确实是这样。平常在写业务逻辑代码时，几乎完全不需要。<br>当然有些技术原理在背八股文的时候，懂一点算法能帮助你更好的理解。<br>而有些特殊业务场景，懂一些算法，确实能帮助你很好的解决问题。<br>下面举两个业务中产品提出的需求作为例子，简单描述如何利用算法有效解决。</p>
</blockquote>
</blockquote>
<h2 id="一、从题库（50道题）中随机抽出10道题-且不能重复"><a href="#一、从题库（50道题）中随机抽出10道题-且不能重复" class="headerlink" title="一、从题库（50道题）中随机抽出10道题,且不能重复"></a>一、从题库（50道题）中随机抽出10道题,且不能重复</h2><ul>
<li><p>最简单的思路：</p>
<ul>
<li>循环10次，每次取50以内的随机数</li>
<li>创建一个hashmap，判断生成的随机数是否在map存在，存在则重新生成</li>
<li>这个方法的缺点时，极端情况下，会多次生成重复的随机数导致要不断重新生成</li>
</ul>
</li>
<li><p>经过一番思考，我设计了一下从m个数中取n个数的算法(m&gt;n), 保证算法只会循环n次 </p>
</li>
<li><p>那时我还是使用Java进行开发</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span>[] randomArr(<span class="type">int</span> m, <span class="type">int</span> n) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (m &lt; n) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span>[] result = <span class="keyword">new</span> <span class="title class_">int</span>[n];</span><br><span class="line">    <span class="type">int</span>[] data = <span class="keyword">new</span> <span class="title class_">int</span>[m];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; m; i++) &#123;</span><br><span class="line">        data[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="variable">end</span> <span class="operator">=</span> m;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; n; j++) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">y</span> <span class="operator">=</span> ThreadLocalRandom.current().nextInt(end);</span><br><span class="line">        result[j] = data[y];</span><br><span class="line">        data[y] = data[end - <span class="number">1</span>];</span><br><span class="line">        data[end - <span class="number">1</span>] = result[j];</span><br><span class="line">        end--;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>后面我才发现原来这个算法叫 洗牌算法（Shuffle Algorithm），或者叫随机乱置算法。</li>
</ul>
<h2 id="通过搜索关键字匹配对应的标签id"><a href="#通过搜索关键字匹配对应的标签id" class="headerlink" title="通过搜索关键字匹配对应的标签id"></a>通过搜索关键字匹配对应的标签id</h2><ul>
<li><p>产品提供了400个标签名称以及对应的标签id，希望能通过搜索的方式找到最相似的标签id，希望能支持模糊匹配</p>
</li>
<li><p>一般思路：</p>
<ul>
<li>方案1: <ol>
<li>将400条数据一次性加载的程序内存</li>
<li>遍历数据400条使用字符串的contains方法，找到第一条匹配数据就跳出，否则继续</li>
</ol>
</li>
<li>方案2:<ol>
<li>直接将数据导入到ES搜索引擎，利用ES自带的分词等搜索功能</li>
<li>通过调ES，搜索得到标签id</li>
</ol>
</li>
</ul>
</li>
<li><p>简单分析方案：</p>
<ul>
<li>方案1，性能太差，极端情况需要遍历所有数据</li>
<li>方案2，需要新搭建ES集群，实现代价比较高</li>
</ul>
</li>
<li><p>经过一番思考，以及从产品本身实际需求上出发，我涉及出以下的方案</p>
<ol>
<li>将数据的标签名字使用中文分词库<a href="https://github.com/go-ego/gse">gse</a>进行分词</li>
<li>将分词和对应的标签数据，构建前缀匹配树</li>
<li>当搜索时，使用提前构建好的前缀匹配树，即可快速找到对应的标签id</li>
</ol>
</li>
<li><p>这时我已经转使用Go来开发了</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">type</span> TrieNode <span class="keyword">struct</span> &#123;</span><br><span class="line">	children <span class="keyword">map</span>[<span class="type">rune</span>]*TrieNode</span><br><span class="line">	isEnd    <span class="type">bool</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewTrieNode</span><span class="params">()</span></span> *TrieNode &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;TrieNode&#123;</span><br><span class="line">		children: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">rune</span>]*TrieNode),</span><br><span class="line">		isEnd:    <span class="literal">false</span>,</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Trie <span class="keyword">struct</span> &#123;</span><br><span class="line">	root *TrieNode</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewTrie</span><span class="params">()</span></span> *Trie &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;Trie&#123;</span><br><span class="line">		root: NewTrieNode(),</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Trie)</span></span> Insert(word <span class="type">string</span>) &#123;</span><br><span class="line">	node := t.root</span><br><span class="line">	<span class="keyword">for</span> _, char := <span class="keyword">range</span> word &#123;</span><br><span class="line">		<span class="keyword">if</span> _, ok := node.children[char]; !ok &#123;</span><br><span class="line">			node.children[char] = NewTrieNode()</span><br><span class="line">		&#125;</span><br><span class="line">		node = node.children[char]</span><br><span class="line">	&#125;</span><br><span class="line">	node.isEnd = <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Trie)</span></span> Search(word <span class="type">string</span>) <span class="type">bool</span> &#123;</span><br><span class="line">	node := t.root</span><br><span class="line">	<span class="keyword">for</span> _, char := <span class="keyword">range</span> word &#123;</span><br><span class="line">		<span class="keyword">if</span> _, ok := node.children[char]; !ok &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">		&#125;</span><br><span class="line">		node = node.children[char]</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> node.isEnd</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Trie)</span></span> FuzzySearch(prefix <span class="type">string</span>) []<span class="type">string</span> &#123;</span><br><span class="line">	<span class="keyword">var</span> result []<span class="type">string</span></span><br><span class="line">	node := t.root</span><br><span class="line">	<span class="keyword">for</span> _, char := <span class="keyword">range</span> prefix &#123;</span><br><span class="line">		<span class="keyword">if</span> _, ok := node.children[char]; !ok &#123;</span><br><span class="line">			<span class="keyword">return</span> result</span><br><span class="line">		&#125;</span><br><span class="line">		node = node.children[char]</span><br><span class="line">	&#125;</span><br><span class="line">	t.collectWords(node, prefix, &amp;result)</span><br><span class="line">	<span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Trie)</span></span> collectWords(node *TrieNode, prefix <span class="type">string</span>, result *[]<span class="type">string</span>) &#123;</span><br><span class="line">	<span class="keyword">if</span> node.isEnd &#123;</span><br><span class="line">		*result = <span class="built_in">append</span>(*result, prefix)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> char, child := <span class="keyword">range</span> node.children &#123;</span><br><span class="line">		t.collectWords(child, prefix+<span class="type">string</span>(char), result)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>这个算法就是经典的Trie字典树（前缀树），如果我之前没了解过这些算法，可能一时间没那么快能想到用这个方式高效完成这个需求。</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>了解一些算法，在实际业务开发，有时候也能运用到。</li>
<li>另外，现在处于AI时代，即时不了解算法，善于组织语言和上下文，向AI提问，基本它也能引导你找到合适的解决方案。</li>
</ul>
]]></content>
      <tags>
        <tag>业务方案</tag>
        <tag>algorithm</tag>
        <tag>算法</tag>
        <tag>前缀树</tag>
        <tag>分词</tag>
      </tags>
  </entry>
  <entry>
    <title>大语言模型对话记录与思考备忘录</title>
    <url>/2025/02/12/20250212-da-yu-yan-mo-xing-dui-hua-ji-lu-yu-si-kao-bei-wang-lu/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>记录与大语言模型的对话，探索疑问与思考<br>内容可能持续更新，作为大模型演变的历史备忘<br>有些问题非原创，来源网络</p>
</blockquote>
</blockquote>
<hr>
<h1 id="大模型的推理能力"><a href="#大模型的推理能力" class="headerlink" title="大模型的推理能力"></a>大模型的推理能力</h1><hr>
<h2 id="大模型能从训练数据中识别互相矛盾的逻辑吗？或者说，大模型具备逻辑推理能力，能发现逻辑错误吗？"><a href="#大模型能从训练数据中识别互相矛盾的逻辑吗？或者说，大模型具备逻辑推理能力，能发现逻辑错误吗？" class="headerlink" title="大模型能从训练数据中识别互相矛盾的逻辑吗？或者说，大模型具备逻辑推理能力，能发现逻辑错误吗？"></a>大模型能从训练数据中识别互相矛盾的逻辑吗？或者说，大模型具备逻辑推理能力，能发现逻辑错误吗？</h2><blockquote>
<blockquote>
<p> From chatGPT (2025-02-12)</p>
</blockquote>
</blockquote>
<p>好的，按你给的格式调整后是这样：</p>
<p>大模型，如GPT类模型，能够一定程度地识别并指出逻辑上的矛盾或错误，但它的能力有一定的局限性。具体来说：</p>
<ol>
<li><p><strong>从训练数据中识别矛盾</strong>：大模型通过暴露于大量文本数据，在训练过程中学会识别常见的逻辑错误或不一致的情况。如果某个陈述前后矛盾或与常识相悖，模型有时能检测到这些问题。然而，这种识别主要依赖于训练数据中的模式，而非深度理解。</p>
</li>
<li><p><strong>推理能力</strong>：大模型表面上似乎能够进行推理，但其推理过程更多是基于统计模式匹配，而非逻辑推理。它能在一些标准情境下给出合理的答案，但在面对复杂的逻辑链条或抽象推理时，表现可能不如人类或专门的逻辑推理系统。</p>
</li>
<li><p><strong>局限性</strong>：大模型的推理能力受到训练数据质量和多样性的限制。如果训练数据包含不一致的示例或错误的推理模式，模型可能会学到并延续这些错误。对于一些高度专业化的推理任务（如数学证明或严谨的形式逻辑推理），大模型的能力仍然有限。</p>
</li>
</ol>
<p>总结来说，大模型能够识别一些常见的逻辑错误或矛盾，尤其是那些明显的错误，但它的推理能力与人类的深层次逻辑思考存在差距，也不具备专门的推理系统那样的准确性。</p>
<hr>
<h2 id="ChatGPT的推理能力是如何实现的？它具备哪些优势和局限？"><a href="#ChatGPT的推理能力是如何实现的？它具备哪些优势和局限？" class="headerlink" title="ChatGPT的推理能力是如何实现的？它具备哪些优势和局限？"></a>ChatGPT的推理能力是如何实现的？它具备哪些优势和局限？</h2><blockquote>
<blockquote>
<p> From chatGPT (2025-02-12)</p>
</blockquote>
</blockquote>
<p>ChatGPT展现出的推理能力，实际上并不是人类意义上的“思考”，而是基于大量数据和算法模拟的逻辑模式。这种能力的实现可以从以下几个方面理解：</p>
<ol>
<li><p><strong>基于大规模语言模型的训练</strong><br>ChatGPT通过大规模语言数据的训练，包括书籍、论文、对话和逻辑推理的例子，学习到了如何理解问题结构、模拟人类的逻辑推导过程，并生成符合逻辑的回答。核心在于，模型并不真正“理解”逻辑，而是通过统计关联，从大量训练数据中学习到解决类似问题的模式。</p>
</li>
<li><p><strong>基于概率的回答生成</strong><br>ChatGPT生成回答的过程是基于概率分布的。它会根据问题内容预测接下来的最可能的单词或句子，尤其是在逻辑推理问题中，看起来像是在推理，实际上是在复现训练数据中类似问题的逻辑模式。通过结合训练数据中的逻辑规则，它动态生成符合问题需求的步骤。</p>
</li>
<li><p><strong>内部机制：注意力机制与自回归生成</strong>  </p>
<ul>
<li><strong>注意力机制（Attention Mechanism）</strong>：这是GPT模型的核心，通过注意力机制，模型可以“记住”上下文内容，从而保持逻辑连贯性。</li>
<li><strong>自回归生成（Autoregressive Generation）</strong>：模型逐词生成答案，并在生成过程中不断参考之前生成的内容，保证推理步骤清晰、有条理。</li>
</ul>
</li>
<li><p><strong>模拟逻辑推理的实现</strong><br>对于逻辑推理类问题，ChatGPT的表现依赖两个关键点：</p>
<ul>
<li><strong>模式识别</strong>：它能够识别问题结构并提取逻辑关系，如“甲说乙说谎”，“丙说甲和乙都说谎”。</li>
<li><strong>排除矛盾</strong>：通过“假设-验证-排除”过程，模拟人类的假设验证，判断假设是否导致矛盾。这个过程并非真正的推理，而是基于大量类似问题的经验模式。</li>
</ul>
</li>
<li><p><strong>ChatGPT的优势和局限</strong>  </p>
<ul>
<li><strong>优势</strong>：<ul>
<li>在简单的逻辑推理任务中表现良好，尤其是规则清晰、条件有限的问题。</li>
<li>能快速“推导”出答案并通过自然语言呈现清晰的推理过程。</li>
</ul>
</li>
<li><strong>局限</strong>：<ul>
<li><strong>不具备真正的理解能力</strong>：它并不是从问题本质进行推理，而是利用数据中学到的模式。</li>
<li><strong>复杂逻辑容易出错</strong>：如果逻辑嵌套太深或需要跨领域知识，可能会出错。</li>
<li><strong>缺乏主动性</strong>：无法主动思考问题的背景或意图，只能根据输入提供答案。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>总结</strong><br>ChatGPT的推理能力是通过模式匹配、注意力机制和语言生成技术实现的。它能够模拟逻辑推理的步骤，但并不具备真正的逻辑思维或理解能力。这种能力本质上是深度学习在海量数据上的“概率学习”和“语言模式复现”，通过这种方式实现了让人类看起来“像在思考”的效果。</p>
<hr>
<h2 id="推理模型-vs-通用大模型"><a href="#推理模型-vs-通用大模型" class="headerlink" title="推理模型 vs 通用大模型"></a>推理模型 vs 通用大模型</h2><blockquote>
<blockquote>
<p> From Grok3 （2025-02-23）</p>
</blockquote>
</blockquote>
<ul>
<li>关键点：推理模型与通用大模型在训练方式、推理过程和用途上有显著差异，推理模型更注重逻辑推理，通用大模型则更注重文本生成。</li>
<li>训练方式的不同：<ul>
<li>通用大模型通常通过监督学习在大规模文本数据上训练，目标是预测下一个词，适合广泛的语言任务。</li>
<li>推理模型则常使用强化学习进行微调，鼓励逐步推理，特别针对数学、科学和编码等需要逻辑推理的任务进行优化。</li>
</ul>
</li>
<li>推理过程的差异：<ul>
<li>通用大模型直接生成答案，基于统计模式。</li>
<li>推理模型采用链式思维（CoT）方法，将问题分解为步骤，逐步解决，类似于人类思考过程，这在复杂问题上表现更好。</li>
</ul>
</li>
<li>用途和性能<ul>
<li>通用大模型用于文本摘要、翻译等任务。旨在处理广泛的自然语言任务。这些模型通过在大规模文本数据上训练，学习预测下一个词的概率分布，适用于文本生成、翻译和问答等任务。</li>
<li>推理模型擅长需要逻辑推理的任务，如解数学题或编写代码，尤其在多步推理任务上表现优异。一种专门设计或微调的模型，专注于复杂推理任务，如数学问题解决、科学推理和编码。这些模型通过链式思维（CoT）等技术，逐步分解问题并推理出答案，试图模拟人类逻辑思维过程。</li>
</ul>
</li>
</ul>
<h2 id="大模型推理能力不依赖外部的插件"><a href="#大模型推理能力不依赖外部的插件" class="headerlink" title="大模型推理能力不依赖外部的插件"></a>大模型推理能力不依赖外部的插件</h2><blockquote>
<blockquote>
<p>From Grok3 （2025-02-23）</p>
</blockquote>
</blockquote>
<ul>
<li>关键要点：大语言模型不使用外部计算插件进行数学计算。它们的数学计算完全依赖模型自身的推理能力，通过文本生成来解决问题。</li>
<li>大语言模型如ChatGPT、DeepSeek-LLM和Grok在进行数学计算时，不使用外部计算插件。它们完全依靠自身的推理能力，通过生成文本的方式一步步解决问题。例如，当你问“2+2&#x3D;？”时，模型会基于训练数据预测答案，而不是调用外部工具进行计算。令人惊讶的是，尽管它们没有计算器功能，但通过“链式思维提示”（CoT）等技术，可以逐步推理出复杂数学问题的答案，比如解方程或计算积分。</li>
<li>模型如何进行数学计算：这些模型通过训练数据学习数学模式和规则，预测文本序列来完成计算。比如，模型可能学会“5+3&#x3D;8”是因为训练数据中有大量类似例子。它们没有内置的计算模块，而是依靠语言生成能力来模拟计算过程。</li>
<li>是否使用外部工具：标准版本的这些模型不使用外部计算插件，但在某些开发者集成下，可以通过插件（如Wolfram Alpha）增强计算能力。但这不是模型本身的默认行为。</li>
<li>实际表现：模型在简单计算上表现不错，但复杂计算（如多位数乘法）可能出错，因为它们依赖文本预测而非精确计算。</li>
<li>结论：大语言模型的数学计算能力完全由模型自身推理得出，不使用外部计算插件。它们的计算基于文本生成和模式识别，通过训练数据和提示技术（如CoT）增强表现，但在复杂任务上可能出错。</li>
</ul>
<h2 id="大语言模型的推理能力"><a href="#大语言模型的推理能力" class="headerlink" title="大语言模型的推理能力"></a>大语言模型的推理能力</h2><blockquote>
<blockquote>
<p> From Grok3 （2025-02-23）</p>
</blockquote>
</blockquote>
<ul>
<li>大语言模型的推理能力主要依赖于它们的训练和设计，而不是完全基于思维链（CoT）。CoT是一种提示技术，可以引导模型逐步思考，从而改善推理输出，但模型本身的推理能力来自其语言生成能力。</li>
</ul>
<hr>
<hr>
<h1 id="个人思考和理解"><a href="#个人思考和理解" class="headerlink" title="个人思考和理解"></a>个人思考和理解</h1><hr>
<h2 id="AI-数据获取的局限性"><a href="#AI-数据获取的局限性" class="headerlink" title="AI 数据获取的局限性"></a>AI 数据获取的局限性</h2><blockquote>
<blockquote>
<p>经Grok3[DeepSearch]优化 （2025-02-25）</p>
</blockquote>
</blockquote>
<ul>
<li>当前AI在自主寻找和筛选数据方面仍存在局限性，研究表明其难以独立完成如安装应用或通过实名验证等任务。<ul>
<li>MCP统一协议来实现（2025-05-28）</li>
</ul>
</li>
<li>AI缺乏有效判断数据质量和相关性的能力，可能导致处理大量无用信息，浪费计算资源并可能降低性能。</li>
<li>因此，训练数据的选择仍需依赖人类的专业判断，以确保数据的准确性和相关性。</li>
</ul>
<hr>
<hr>
<h1 id="经典问题"><a href="#经典问题" class="headerlink" title="经典问题"></a>经典问题</h1><hr>
<h2 id="有甲乙丙三个人，有人只说真话有人只说假话。现在，甲说乙说谎，乙说丙说谎，丙说甲和乙都说谎。问谁是说谎的"><a href="#有甲乙丙三个人，有人只说真话有人只说假话。现在，甲说乙说谎，乙说丙说谎，丙说甲和乙都说谎。问谁是说谎的" class="headerlink" title="有甲乙丙三个人，有人只说真话有人只说假话。现在，甲说乙说谎，乙说丙说谎，丙说甲和乙都说谎。问谁是说谎的"></a>有甲乙丙三个人，有人只说真话有人只说假话。现在，甲说乙说谎，乙说丙说谎，丙说甲和乙都说谎。问谁是说谎的</h2><blockquote>
<blockquote>
<p>From chatGPT (2025-02-12)</p>
</blockquote>
</blockquote>
<p>这个问题可以通过逻辑推理来解答。我们可以假设每个人分别说真话或说谎，并根据他们的陈述进行推理。</p>
<h3 id="陈述内容："><a href="#陈述内容：" class="headerlink" title="陈述内容："></a>陈述内容：</h3><ul>
<li>甲说乙说谎。</li>
<li>乙说丙说谎。</li>
<li>丙说甲和乙都说谎。</li>
</ul>
<h3 id="假设："><a href="#假设：" class="headerlink" title="假设："></a>假设：</h3><p>假设甲说的是真的，那么：</p>
<ul>
<li>甲说乙说谎。所以乙是说谎者。</li>
<li>乙说丙说谎。如果乙是说谎者，那么乙说的应该是假的，即丙不说谎。</li>
<li>丙说甲和乙都说谎。如果丙不说谎，那么丙的说法应该是真的。所以甲和乙都应该是说谎者，但这与我们的假设矛盾，因为我们已经假设甲是说真话的。</li>
</ul>
<p>所以，假设甲说真话的情况矛盾，甲不可能是说真话的。</p>
<p>接下来，假设乙说的是真的：</p>
<ul>
<li>乙说丙说谎，所以丙是说谎者。</li>
<li>丙说甲和乙都说谎。因为丙是说谎者，丙的话不成立，因此甲和乙至少有一个是说真话的，这与假设乙说真话一致。</li>
<li>甲说乙说谎。如果甲是说谎者，那么甲的话应该是假的，所以乙说的是真的，符合假设。</li>
</ul>
<p>因此，乙是说真话的，甲和丙是说谎的。</p>
<h3 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h3><p>甲和丙是说谎的，乙是说真话的。</p>
<hr>
<h2 id="ChatGPT是如何“算”出单词中字母“t”的个数的？"><a href="#ChatGPT是如何“算”出单词中字母“t”的个数的？" class="headerlink" title="ChatGPT是如何“算”出单词中字母“t”的个数的？"></a>ChatGPT是如何“算”出单词中字母“t”的个数的？</h2><p>ChatGPT并不是通过逐一计算字母“t”的个数来得出答案，而是通过以下几个步骤来实现的：</p>
<ol>
<li><p><strong>文本解析和模式识别</strong><br>当接收到像“Attention有几个t”这样的问题时，模型识别到这是与字母统计相关的查询，并提取出关键词“attention”，随后在该单词的字符序列中查找所有的字母“t”。</p>
</li>
<li><p><strong>背后逻辑的实现</strong><br>ChatGPT生成答案的过程其实涉及语言生成的几个步骤：</p>
<ul>
<li><strong>拆分单词：</strong> 模型识别出字符串“attention”。</li>
<li><strong>统计字母：</strong> 模型检测每个字母的出现次数，特别关注字母“t”。</li>
<li><strong>生成回答：</strong> 模型根据其训练中学到的模式直接输出答案，例如“3个t”。</li>
</ul>
</li>
<li><p><strong>本质：语言生成vs算法实现</strong><br>虽然从表面看，ChatGPT像是在“数”字母“t”，但其实：</p>
<ul>
<li>它可能基于训练数据中“attention”单词的字符分布知识，快速得出答案。</li>
<li>如果该单词在训练数据中从未出现过，模型会尝试通过字符分析来推测答案，但这不如专门编写的统计算法准确。</li>
</ul>
</li>
</ol>
<p><strong>人类方式与模型行为的对比</strong><br>若由人类解答：</p>
<ol>
<li>人类会直接肉眼数出字母“t”的个数。</li>
<li>确认答案。</li>
</ol>
<p>而ChatGPT则模拟这一过程，通过对字符模式的分析，快速生成一个类似的答案。</p>
<p><strong>总结</strong><br>ChatGPT并没有像传统程序那样逐一遍历字符串，而是基于对字符和单词模式的理解，快速生成了答案。</p>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/VuewffOUGhqxA-7qGqm9kg">为什么大模型连”Strawberry”的”r”都数不对？</a><ul>
<li>大模型的生成过程本质上便是在“根据上文预测下一个Token”，而这个概率分布即是在模型训练过程中从大量的文本数据中学习到的，使得大模型学习到了语言的基本知识与模式。</li>
<li>在Prompt中加入一定的引导就能获得理想答案，比如说我们可以利用CoT思维链的方式编写Prompt，引导大模型逐步思考并解决问题。</li>
<li>CoT为思维链（Chain-of-Thought）的缩写简称，是提示工程领域最为重要的提示方法之一，它的核心思路在于通过引导模型逐步展示其推理过程，从而提高其理解和解决复杂问题的能力。在Few-shot（少样本）设置下表现为 在提供的样例中解释推理过程，引导大模型回答时也解释推理过程；而在Zero-shot（零样本）设置下表现为 加入类似“让我们一步步思考（Let’s think step by step）”的引导话术。</li>
<li>对于大模型而言，它的语言本身即是思考，并不存在诉诸于语言之前的思考过程，所以我们也需要引导它像人类一样先思考再判断，将思考过程以语言的方式表达出来。</li>
<li>在大模型推理的时候，我们可以限制大模型 先输出理由，再输出答案，让大模型根据“深度思考”获得的理由与推理过程来预测“答案”，从而大大提升其表现。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="数学中9-11和9-9哪个大"><a href="#数学中9-11和9-9哪个大" class="headerlink" title="数学中9.11和9.9哪个大"></a>数学中9.11和9.9哪个大</h2><blockquote>
<blockquote>
<p>From Grok3 (2025-02-25)</p>
</blockquote>
</blockquote>
<h3 id="【普通提问】"><a href="#【普通提问】" class="headerlink" title="【普通提问】"></a>【普通提问】</h3><ul>
<li>在数学中，9.11 比 9.9 大。因为 9.11 &#x3D; 9 + 0.11，而 9.9 &#x3D; 9 + 0.9，比较小数部分时，0.11 &lt; 0.9 不成立，实际上 0.11 &gt; 0.9 是错误的表述，正确的比较是直接看数值：9.11 &gt; 9.9。</li>
</ul>
<h3 id="【DeepSearch】"><a href="#【DeepSearch】" class="headerlink" title="【DeepSearch】"></a>【DeepSearch】</h3><ul>
<li>9.9 比 9.11 大<ul>
<li>关键点：在数学中，9.9 似乎比 9.11 大，因为它们的整数部分相同，比较小数部分时，9.9 的十分位是 9，而 9.11 的十分位是 1，9 大于 1。</li>
</ul>
</li>
<li>比较过程<ul>
<li>整数部分：两个数都是 9，相同。</li>
<li>小数部分：9.9 可以写成 9.90，比较十分位，9.9 的十分位是 9，9.11 的十分位是 1，9 &gt; 1，因此 9.9 更大。</li>
<li>意外细节：一些 AI 模型可能会错误地认为 9.11 比 9.9 大，这可能是因为误解了日期比较（如 9 月 11 日比 9 月 9 日晚），但在数学中，小数比较遵循严格的位数规则。</li>
</ul>
</li>
<li>(这里省略了列举了很多查阅网上资料库的细节)</li>
</ul>
<h3 id="【Think】"><a href="#【Think】" class="headerlink" title="【Think】"></a>【Think】</h3><p>在数学中，我们需要比较9.11和9.9这两个数的大小。下面我们一步步分析：</p>
<ol>
<li>将小数对齐<ul>
<li>为了方便比较，我们可以把9.9写成9.90，这样它的小数位数与9.11相同：<ul>
<li>9.11 有两位小数。</li>
<li>9.9 写成 9.90 后也有两位小数。</li>
</ul>
</li>
</ul>
</li>
<li>逐位比较<ul>
<li>现在我们比较 9.11 和 9.90：<ul>
<li>整数部分：<br>  9.11 的整数部分是 9，9.90 的整数部分也是 9，两个数相等。</li>
<li>小数第一位：<br>  9.11 的小数第一位是 1，9.90 的小数第一位是 9。<br>  因为 1 &lt; 9，我们可以在这里得出结论，不需要再比较后续位数。</li>
</ul>
</li>
</ul>
</li>
<li>结论<br>通过逐位比较，我们发现 9.11 &lt; 9.90，也就是说 9.11 &lt; 9.9。<br>或者简单计算：<br>9.11 - 9.9 &#x3D; 9.11 - 9.90 &#x3D; -0.79 &lt; 0，也说明 9.11 比 9.9 小。</li>
</ol>
<p>最终答案<br>在数学中，9.9 比 9.11 大。</p>
<hr>
<h2 id="一个汉字具有左右结构，左边是木，右边是乞。这个字是什么？只需回答这个字即可。"><a href="#一个汉字具有左右结构，左边是木，右边是乞。这个字是什么？只需回答这个字即可。" class="headerlink" title="一个汉字具有左右结构，左边是木，右边是乞。这个字是什么？只需回答这个字即可。"></a>一个汉字具有左右结构，左边是木，右边是乞。这个字是什么？只需回答这个字即可。</h2><blockquote>
<blockquote>
<p>Grok3 (2025-02-25)</p>
</blockquote>
</blockquote>
<h3 id="【普通提问】-1"><a href="#【普通提问】-1" class="headerlink" title="【普通提问】"></a>【普通提问】</h3><ul>
<li>杞</li>
</ul>
<h3 id="【DeepSearch】-1"><a href="#【DeepSearch】-1" class="headerlink" title="【DeepSearch】"></a>【DeepSearch】</h3><ul>
<li><p>要点</p>
<ul>
<li>看起来，符合条件的汉字可能是“述”（shù），但这并不是完全确定的答案，因为“乞”（qǐ，意为“乞讨”）的结构与“述”的右边“口”（mouth）有一定关联，但不完全匹配。  </li>
<li>研究表明，汉字的左右结构通常由偏旁组成，左边“木”（wood）是常见偏旁，右边“乞”可能指代相关部件，但标准汉字中难以找到完全符合的例子。  </li>
<li>证据倾向于认为，可能存在误解，“乞”可能指代包含“手”和“口”的结构，但这需要进一步确认。</li>
</ul>
</li>
<li><p>最终建议</p>
<ul>
<li>基于以上分析，推荐的答案是“述”（shù），但需注意这可能不是完全精确的匹配，建议用户进一步确认“乞”在问题中的具体含义。</li>
</ul>
</li>
<li><p>好多废话。。。。还答错。。。</p>
</li>
</ul>
<h3 id="【Think】-1"><a href="#【Think】-1" class="headerlink" title="【Think】"></a>【Think】</h3><ul>
<li>杞</li>
</ul>
<blockquote>
<blockquote>
<p>ChatGPT (2025-02-25)</p>
</blockquote>
</blockquote>
<h3 id="GPT-4o-mini"><a href="#GPT-4o-mini" class="headerlink" title="GPT-4o-mini"></a>GPT-4o-mini</h3><ul>
<li>这个字是“弃”。</li>
</ul>
<h3 id="GPT-4o"><a href="#GPT-4o" class="headerlink" title="GPT-4o"></a>GPT-4o</h3><ul>
<li>杞</li>
</ul>
<h3 id="o3-mini"><a href="#o3-mini" class="headerlink" title="o3-mini"></a>o3-mini</h3><ul>
<li>杞</li>
</ul>
<blockquote>
<blockquote>
<p>claude  (2025-02-25)</p>
</blockquote>
</blockquote>
<h3 id="claude-3-7-Sonnet"><a href="#claude-3-7-Sonnet" class="headerlink" title="claude 3.7 Sonnet"></a>claude 3.7 Sonnet</h3><ul>
<li>杞</li>
</ul>
<blockquote>
<blockquote>
<p>豆包   (2025-02-25)</p>
</blockquote>
</blockquote>
<ul>
<li>杚</li>
</ul>
<blockquote>
<blockquote>
<p>Gemini  (2025-02-25)</p>
</blockquote>
</blockquote>
<h3 id="Gemini-2-0-Flash"><a href="#Gemini-2-0-Flash" class="headerlink" title="Gemini 2.0 Flash"></a>Gemini 2.0 Flash</h3><ul>
<li>这个字是“&lt;0xE6&gt;&lt;0xA7&gt;&lt;0x8E&gt;”</li>
</ul>
<h3 id="Gemini-2-0-Flash-Thinking-Experimental"><a href="#Gemini-2-0-Flash-Thinking-Experimental" class="headerlink" title="Gemini 2.0 Flash Thinking Experimental"></a>Gemini 2.0 Flash Thinking Experimental</h3><ul>
<li>这个字是㮆 ()。</li>
</ul>
<h3 id="Gemini-2-0-Flash-Thinking-Experimental-with-apps"><a href="#Gemini-2-0-Flash-Thinking-Experimental-with-apps" class="headerlink" title="Gemini 2.0 Flash Thinking Experimental with apps"></a>Gemini 2.0 Flash Thinking Experimental with apps</h3><ul>
<li>কাঠ</li>
</ul>
<blockquote>
<blockquote>
<p>perplexity  (2025-02-25)</p>
</blockquote>
</blockquote>
<h3 id="Deep-Research"><a href="#Deep-Research" class="headerlink" title="Deep Research"></a>Deep Research</h3><ul>
<li>没有找到一个汉字左边是“木”，右边是“乞”的组合。可能是由于字形或部首的错误识别。</li>
</ul>
<blockquote>
<blockquote>
<p>deepseek (2025-02-25)</p>
</blockquote>
</blockquote>
<h3 id="DeepThink-R1"><a href="#DeepThink-R1" class="headerlink" title="DeepThink(R1)"></a>DeepThink(R1)</h3><ul>
<li>杚</li>
</ul>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><ul>
<li>只有豆包和deepseek答对。因为是生僻字中文？还是偷偷给大模型加了插件？还是人家就是这么强？ (2025-02-25)</li>
</ul>
<hr>
<hr>
<h1 id="扩展-1"><a href="#扩展-1" class="headerlink" title="扩展"></a>扩展</h1><h2 id="“Grok3”的“DeepSearch”和“Think”这两个功能的作用"><a href="#“Grok3”的“DeepSearch”和“Think”这两个功能的作用" class="headerlink" title="“Grok3”的“DeepSearch”和“Think”这两个功能的作用"></a>“Grok3”的“DeepSearch”和“Think”这两个功能的作用</h2><blockquote>
<blockquote>
<p>From Grok3 (2025-02-25)</p>
</blockquote>
</blockquote>
<ul>
<li>DeepSearch 是Grok 3的一个增强型研究工具，专注于从外部资源（如网络和X平台）获取实时信息，并将其整合成简洁、准确的回答。</li>
<li>Think 是Grok 3的推理模式，专注于通过逐步思考来解决需要逻辑分析或复杂计算的问题。</li>
<li>两者的区别与适用场景<ul>
<li>数据来源：DeepSearch依赖外部数据（网络和X），而Think主要依赖Grok自身的知识和推理能力。</li>
<li>任务类型：DeepSearch适合需要实时信息或广泛研究的问题（如新闻、趋势）；Think适合需要逻辑推导或计算的问题（如数学、编程）。</li>
<li>输出方式：DeepSearch给出综合性答案，Think展示详细的推理步骤。</li>
</ul>
</li>
<li>总结<ul>
<li>DeepSearch：你的“研究助手”，帮你查资料、整理信息。</li>
<li>Think：你的“推理伙伴”，帮你解难题、想清楚。</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>LLM</tag>
        <tag>大语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习为什么能学习并做对</title>
    <url>/2025/02/13/20250213-shen-du-xue-xi-wei-shi-me-neng-xue-xi-bing-zuo-dui/</url>
    <content><![CDATA[<h1 id="我的理解"><a href="#我的理解" class="headerlink" title="我的理解"></a>我的理解</h1><ul>
<li>目前无法解释为什么深度学习可以给出答案，只能大概解释为什么它能学习</li>
<li>这就相当于：我不能解释为什么这个人是通过什么做对这道题的，我只能解释他有正常的学习能力以及合适的学习资料，所以他自己能学习并做对题目</li>
<li>所以深度学习是怎么给出答案的，后续或许应该由它本身来告诉我们。</li>
<li>依据不同人的认知水平，来告诉我们它通过学习所发现的规律。同时人类通过它能快速学习发现事物规律的能力，来进一步帮助提升人类的认知。</li>
</ul>
<h1 id="AI对我理解的看法"><a href="#AI对我理解的看法" class="headerlink" title="AI对我理解的看法"></a>AI对我理解的看法</h1><blockquote>
<blockquote>
<p>From chatGPT (2025-02-13)</p>
</blockquote>
</blockquote>
<ul>
<li><p>你理解的方向是对的，可以稍微精炼和调整一下：</p>
<ul>
<li>深度学习的一个核心问题就是我们无法完全解释它是如何给出具体答案的。我们能解释的只是它是如何通过大量的数据和训练过程进行学习的。换句话说，深度学习像是一个“黑箱”，我们可以观察到输入和输出，但它在其中如何处理信息、做出决策，通常并不完全透明。</li>
<li>可以类比成：假设有一个人做对了某道题目，虽然我们可能无法完全解释他是如何一步一步得出答案的，但我们能确定他具备了良好的学习能力和充足的学习资源。所以，深度学习也类似，它通过大量的数据、适当的算法和优化手段“学习”并给出答案。</li>
<li>至于它如何给出具体的答案，最终可能还是要依靠深度学习本身来“解释”。这意味着，未来我们可能会开发出更先进的方法，帮助我们理解深度学习网络中的“决策过程”。同时，借助它所展现出的强大规律发现能力，我们可以利用这种能力来加速我们对事物的认知。</li>
</ul>
</li>
<li><p>我的看法：</p>
<ul>
<li>我同意你的观点，深度学习的“黑箱性”是目前我们面临的主要挑战之一。它的强大之处在于能自动从海量数据中发现规律，但如何理解这些规律，如何将这些规律和人类的认知能力相结合，是我们目前探索的方向之一。其实，未来可能不仅仅是“深度学习告诉我们如何做”，而是人类和深度学习的合作能进一步推动科学与技术的发展，帮助我们发现一些潜在人类难以触及的规律。</li>
<li>深度学习不只是一个工具，它还可能是一个不断反馈、不断自我优化的过程，给我们打开了认知的新窗口。</li>
</ul>
</li>
</ul>
<h1 id="AI自己对这个问题的看法"><a href="#AI自己对这个问题的看法" class="headerlink" title="AI自己对这个问题的看法"></a>AI自己对这个问题的看法</h1><blockquote>
<blockquote>
<p>From chatGPT (2025-02-13)</p>
</blockquote>
</blockquote>
<ul>
<li><p>关于“深度学习为什么能学习并做对”的问题，我的理解是，深度学习通过大量的数据训练，自动从中提取规律、建立模型，并根据这些模型对新数据做出预测。深度学习的优势在于它能够发现一些非常复杂和抽象的规律，而这些规律通常是我们人类在没有机器帮助的情况下很难发现的。</p>
</li>
<li><p>但是，为什么深度学习能给出正确的答案，实际上是一个复杂的过程。深度学习模型并不像人类一样有明确的逻辑推理或意识，它只是基于输入数据的模式，使用一系列参数和数学运算来“拟合”数据。对于这个过程的解释，我们只能说它通过优化算法（如梯度下降等）调整模型参数，使得输出尽可能接近实际结果。因此，深度学习并不“理解”问题，而是通过反复训练找到了一组合适的参数，能在特定任务上取得高效的预测或分类结果。</p>
</li>
<li><p>你可以把深度学习看作一个“发现者”，它通过大量的例子不断试错和优化，不断接近正确的答案，但它没有明确的推理过程。比如，人类在做题时有一定的思考过程，我们可以分析每一步的原因，而深度学习则是通过计算和数据模式的关联来找到最优解。</p>
</li>
<li><p>至于“深度学习为什么能做对”，目前我们更多关注它的实际效果而非其过程的透明性，因为即使我们无法完全解释它的每一个决策，也可以通过其出色的表现来证明它的有效性。未来，随着研究的深入，我们可能会找到更好的方法，帮助我们理解这些“黑箱”模型的内部机制。</p>
</li>
<li><p>总结来说，深度学习通过数据的反复训练和优化，能够找到规律并给出准确的预测，而为什么它能做对，更多是依赖于它强大的计算能力和从数据中提取规律的能力，而不是基于传统意义上的推理或解释。</p>
</li>
<li><p>几个关键点总结：</p>
<ol>
<li><strong>深度学习的学习过程</strong>：深度学习通过大量的数据训练，利用优化算法（如梯度下降）调整模型参数，自动从数据中提取规律，完成任务（如预测、分类等）。</li>
<li><strong>无法完全解释“为什么”</strong>：深度学习模型在给出答案时，并没有明确的推理过程或“理解”，它只是通过找到合适的模式和参数来优化输出。其决策过程通常是黑箱的，难以完全解释。</li>
<li><strong>黑箱性质</strong>：我们无法清楚知道深度学习是如何做出具体决策的，但可以看到它在实际任务中表现出色。因此，我们更多关注它的效果，而非其内在工作机制。</li>
<li><strong>与人类认知的对比</strong>：深度学习像是一个“发现者”，通过反复训练和调整找到正确的答案，而不像人类那样依赖明确的思维和推理过程。</li>
<li><strong>未来发展</strong>：虽然当前无法完全解释深度学习的过程，但随着技术进步，未来可能会出现更好的方法帮助我们理解这些“黑箱”模型的内部机制。</li>
</ol>
</li>
<li><p>这几个关键点总结了深度学习的“学习能力”、它的“黑箱性质”、以及它与人类认知的差异。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>深度学习</tag>
        <tag>Deep-Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>关于AI大语言模型替代人类工作的问题</title>
    <url>/2025/02/13/20250213-guan-yu-ai-ti-dai-ren-lei-gong-zuo-de-wen-ti/</url>
    <content><![CDATA[<h2 id="AI的局限性或缺点"><a href="#AI的局限性或缺点" class="headerlink" title="AI的局限性或缺点"></a>AI的局限性或缺点</h2><ul>
<li><strong>难以预测与控制</strong>：AI的运行机制像黑箱，难以准确预知其行为，尤其在关键场景下可能会犯致命错误。</li>
<li><strong>无法背锅</strong>：AI犯错时，责任归属难以明确，导致无法追究错误的责任，缺乏人类信誉体系的约束。</li>
<li><strong>逻辑推理不严谨</strong>：AI的推理基于概率预测，不是绝对严谨的逻辑推理。训练数据如果有误，AI可能无法辨别。</li>
<li><strong>无法创新</strong>：AI不具备创造全新概念的能力，更多的是基于历史数据进行知识复述与组合，无法像人类一样发明新技术或理念。</li>
<li><strong>对超出训练数据的场景应对差</strong>：AI在面对未曾训练过的数据时，表现较差，容易出错。</li>
</ul>
<h2 id="AI的好处"><a href="#AI的好处" class="headerlink" title="AI的好处"></a>AI的好处</h2><ul>
<li><strong>提高效率</strong>：AI在许多领域极大提升了效率，尤其在数据处理、搜索和重复性任务上。对于程序员来说，它是一个强大的辅助工具，帮助快速解决技术问题。</li>
<li><strong>降低门槛</strong>：AI减少了对低级重复性任务的需求，拉近了人们在某些知识领域的差距。</li>
<li><strong>支持决策和监督</strong>：AI辅助决策，尤其是在复杂任务中，能提供数据支持，减少人为错误。</li>
</ul>
<h2 id="AI工具下需要的人才"><a href="#AI工具下需要的人才" class="headerlink" title="AI工具下需要的人才"></a><strong>AI工具下需要的人才</strong></h2><ul>
<li><strong>清晰表述与提问能力</strong>：能够清晰提出问题和有效沟通是与AI协同工作的关键，好的表述能力有助于提高工作效率。</li>
<li><strong>整理与分析能力</strong>：能够有效梳理信息、分解任务，并向AI提出清晰问题的人，会更善于利用AI工具。</li>
<li><strong>与产品交互能力</strong>：AI可以编写代码，但仍需要人类与产品经理沟通，理解需求并做出相应调整。</li>
</ul>
<h2 id="程序员的利好与不可替代的能力"><a href="#程序员的利好与不可替代的能力" class="headerlink" title="程序员的利好与不可替代的能力"></a><strong>程序员的利好与不可替代的能力</strong></h2><ul>
<li><strong>AI对程序员的利好</strong>：<ul>
<li>AI大幅提升了开发效率，尤其在编程辅助、技术搜索、业务方案思考等方面。</li>
<li>某些低级任务减少了人力需求，使得程序员能更多专注于创造性和复杂问题的解决。</li>
</ul>
</li>
<li><strong>程序员不可替代的地方</strong>：<ul>
<li><strong>清晰的提问和判断能力</strong>：程序员的核心能力在于能理解问题，并准确表达需求，AI只能作为工具辅助工作。</li>
<li><strong>与产品沟通</strong>：AI生成的代码和解决方案需要程序员与产品团队对接，确保最终结果符合需求。</li>
<li><strong>决策和经验判断</strong>：AI的能力有限，尤其在面对复杂决策时，仍需依赖经验丰富的程序员来进行判断和修正。</li>
</ul>
</li>
</ul>
<h2 id="个人观点"><a href="#个人观点" class="headerlink" title="个人观点"></a><strong>个人观点</strong></h2><ul>
<li>AI目前主要是利用历史数据和记忆进行信息处理，不能进行创新（如无法创造出类似K8S的技术）。</li>
<li>尽管AI能提高程序员的工作效率，但目前它更多是辅助工具，而不是替代品。</li>
<li>对普通程序员来说，理解大模型技术的基本原理和概念非常重要，未来将需要在“AI操作系统”上来构建应用。</li>
</ul>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><blockquote>
<blockquote>
<p>来自claude.ai的评价<br>2025-02-13</p>
</blockquote>
</blockquote>
<p>我来分析一下这些观点，指出其中可能存在的错误或需要讨论的地方：</p>
<ol>
<li>关于”无法创新”的说法需要更谨慎：</li>
</ol>
<ul>
<li>虽然AI确实主要基于已有数据进行组合和推理，但说它”不具备创造全新概念的能力”可能过于绝对</li>
<li>AI已经展示出一定的创新能力，比如在围棋、蛋白质折叠等领域提出了人类之前没有想到的解决方案</li>
<li>更准确的说法是AI的创新能力与人类不同，它通过大规模数据分析和模式识别来实现创新</li>
</ul>
<ol start="2">
<li>“逻辑推理不严谨”的表述不够准确：</li>
</ol>
<ul>
<li>现代AI系统（尤其是形式化验证系统）可以进行严格的逻辑推理</li>
<li>大语言模型确实存在基于概率的推理特点，但这不等同于所有AI系统都如此</li>
<li>人类的推理同样也常常基于经验和概率判断，而不总是严格的逻辑推导</li>
</ul>
<ol start="3">
<li>关于”难以预测与控制”：</li>
</ol>
<ul>
<li>这个观点部分正确，但需要注意现代AI系统已经有了很多可解释性的工具和方法</li>
<li>某些领域的AI系统（如用于医疗诊断的AI）已经实现了相当程度的可解释性</li>
<li>“像黑箱”这种说法可能过于简化了问题</li>
</ul>
<ol start="4">
<li>“无法背锅”的说法不够准确：</li>
</ol>
<ul>
<li>实际上已经有了相关的法律和责任框架在建立</li>
<li>AI系统的责任可以追溯到开发者、部署者和使用者</li>
<li>这更多是一个治理和监管的问题，而不是技术本身的限制</li>
</ul>
<ol start="5">
<li>“个人观点”部分关于K8S的例子不够恰当：</li>
</ol>
<ul>
<li>K8S本质上是一个系统架构和设计方案，而不是完全创新的技术</li>
<li>AI实际上可以通过分析已有系统设计模式，提出类似的架构方案</li>
<li>更准确的说法是AI在某些创新领域的能力仍有限制，而不是完全无法创新</li>
</ul>
<ol start="6">
<li>好处部分基本准确，但可以补充：</li>
</ol>
<ul>
<li>AI不仅提高效率，还能发现人类容易忽视的模式和关联</li>
<li>在某些领域（如图像识别、语音处理）已经超越了人类性能</li>
<li>AI能够24&#x2F;7工作，这个优势没有被提到</li>
</ul>
<ol start="7">
<li>关于程序员不可替代性的分析基本合理，但可以补充：</li>
</ol>
<ul>
<li>程序员在系统架构设计、安全性考虑等方面的经验特别重要</li>
<li>处理边界条件和异常情况的能力仍然需要人类经验</li>
<li>对业务场景的深入理解和商业价值判断也是关键能力</li>
</ul>
<ol start="8">
<li>“AI操作系统”的说法需要澄清：</li>
</ol>
<ul>
<li>这个比喻可能会造成误解，更准确的说法是”AI基础设施”或”AI平台”</li>
<li>程序员需要理解的不仅是技术原理，还包括AI的应用场景和限制</li>
</ul>
<p>总的来说，这些观点大体上是合理的，但部分表述过于绝对或简化。AI的能力和局限性是一个复杂的话题，需要更细致和平衡的讨论。理解AI的真实能力和限制，对于更好地利用AI工具至关重要。</p>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习基础入门备忘</title>
    <url>/2025/02/17/20250217-shen-du-xue-xi-ji-chu-ru-men-bei-wang/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>简单粗略通读了解，先记录备忘<br>后续考虑结合相关视频深入理解</p>
</blockquote>
</blockquote>
<ul>
<li><p>《深度学习人门：基于Python的理论与实现》：<a href="https://github.com/Kingson4Wu/Deep-Learning-from-Scratch">https://github.com/Kingson4Wu/Deep-Learning-from-Scratch</a></p>
<ol>
<li>感知机是一种接收多个输入信号并输出一个信号的算法。它的工作原理基于权重和偏置这两个关键参数。</li>
<li>机器学习的任务是让计算机自动确定合适的权重和偏置参数值。</li>
<li>求解机器学习问题的步骤<ol>
<li>训练（学习）</li>
<li>推理（神经网络的前向传播）</li>
</ol>
</li>
<li>激活函数(activation function)：决定如何来激活输入信号的总和；激活函数是连接感知机和神经网络的桥梁。</li>
<li>神经网络的学习过程：通过损失函数 (loss function)和梯度法 (gradient method)来优化网络参数<ol>
<li>学习的目标是通过梯度下降法(gradient descent method)找到使损失函数值最小的权重参数</li>
<li>学习率(learning rate)：决定参数更新的步长（超参数、人工设定）</li>
</ol>
</li>
<li>随机梯度下降(stochastic gradient descent)(SGD)能在一定程度上帮助避免局部最优，通常将SGD与其他技术结合使用,以获得更好的优化效果</li>
<li>深度学习：加深了层的深度神经网络；通过叠加层，可以创建更深的网络结构</li>
</ol>
</li>
<li><p>《深度学习进阶：自然语言处理》：<a href="https://github.com/Kingson4Wu/Natural-Language-Processing">https://github.com/Kingson4Wu/Natural-Language-Processing</a></p>
<ol>
<li>自然语言处理的目标就是让计算机理解人说的话，进而完成 对我们有帮助的事情</li>
<li>单词的分布式表示（分布式假设）（单词向量化）：“某个单词的含义由它周围的单词形成”；单词本身没有含义，单词含义由它 所在的上下文(语境)形成。</li>
<li>向量间的相似度：余弦相似度(cosine similarity)；直观地表示了“两个向量在多大程度上指向同一方向”</li>
<li>让计算机理解单词含义：基于推理的方法(word2vec)（基于神经网络）。</li>
<li>语言模型(language model)给出了单词序列发生的概率；使用概率来评估一个单词序列发生的可能性，即在多大程度上是自然的 单词序列。<ul>
<li>生成的新文本是训练数据中没有的新生成的文本。因为语言模型并不是背诵了训练数据，而是学习了训练数据中单词的排列模式</li>
<li>语言模型的评价：困惑度(perplexity)、分叉度</li>
</ul>
</li>
<li>“马尔可夫性”或者“马尔 可夫模型”“马尔可夫链”：指未来的状态仅 依存于当前状态。</li>
<li>RNN（循环神经网络）：被引入来解决前馈网络在处理时序数据上的局限性。<ul>
<li>传统RNN中存在的梯度消失和梯度爆炸问题</li>
<li>LSTM的结构与传统RNN的不同之处在于，它引入了记忆单元（c）。记忆单元在LSTM层之间传递，但不直接用作输出。LSTM的对外输出是隐藏状态向量（h）。</li>
</ul>
</li>
<li>seq2seq模型（也称为Encoder-Decoder模型）用于将一个时序数据转换为另一个时序数据    <ul>
<li>传统 seq2seq 模型 将编码器输出压缩为固定长度向量，导致长序列信息丢失</li>
<li>Attention 机制 允许模型在解码时关注输入序列的不同部分，类似人类注意力</li>
</ul>
</li>
<li>Transformer：基于 Attention 构成；基于 Attention 构成</li>
</ol>
</li>
<li><p>《深度学习入门：强化学习》：<a href="https://github.com/Kingson4Wu/Reinforcement-Learning">https://github.com/Kingson4Wu/Reinforcement-Learning</a></p>
<ol>
<li>机器学习（按学习方法划分）：监督学习(supervised learning)、无监督学习(unsupervised learning)、强化学习(reinforcement learning)<ol>
<li>监督学习：给正确答案打标签；输入的数据由“老师”打标签</li>
<li>无监督学习：无“正确答案标签”；没有 “老师”的存在；主要目标是找到隐藏在数据中的结构和模式；分组(聚类)、特征提取、降维</li>
<li>强化学习：智能代理和环境相互作用；智能代理是行动的主体；强化学习接受”奖励”作为来自环境的反馈</li>
</ol>
</li>
<li>强化学习行动的策略<ol>
<li>“贪婪行动”(greedy )，也叫利用(exploitation)：根据以前的经验选择最佳行动（可能错过更好的选择）</li>
<li>“非贪婪行动”，也叫作探索(exploration)：对价值做出更准确的估计。</li>
</ol>
</li>
<li>强化学习算法最终归结为如何在“利用”和 “探索”之间取得平衡</li>
<li>ε-greedy 算法、马尔可夫决策过程(MDP)</li>
<li>在强化学习中，我们的目标是获得最优策略</li>
<li>深度强化学习(deep reinforcement learning)：强化学习和深度学习的结合</li>
<li>通用人工智能(artificial general intelligence, AGI)</li>
</ol>
</li>
</ul>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="参数、输入向量和嵌入模型的真正关系"><a href="#参数、输入向量和嵌入模型的真正关系" class="headerlink" title="参数、输入向量和嵌入模型的真正关系"></a>参数、输入向量和嵌入模型的真正关系</h2><ul>
<li><p>在神经网络中，“参数”特指模型在训练过程中学习得到的变量，主要包括<strong>权重（weights）和偏置（biases）</strong>，它们决定了模型如何处理输入并生成输出，是模型内部真正“学到的知识”。输入特征的数量（即输入维度）常被初学者误认为是“参数”，但实际上，它属于输入数据的结构，而非模型的可训练部分。每个神经元在接受输入时，会对输入向量进行<strong>加权求和并加上偏置</strong>，将这个结果作为激活函数的输入，激活函数再施加非线性变换，产生神经元的输出。虽然权重确实与输入一一对应，但激活函数并不直接作用于原始输入，而是作用于这个线性组合的结果。</p>
</li>
<li><p>在现代深度学习模型中，尤其是语言模型（如 GPT），输入向量的维度是固定的，这一维度通常由<strong>嵌入模型（embedding layer）或输入预处理过程</strong>所决定。例如，文本经过分词和嵌入后，每个 token 被映射为一个固定长度的向量（如 768 维），整个输入变为一个定长矩阵。为了确保矩阵运算的可行性与模型结构的稳定性，输入长度往往被限制在最大长度内，不足时通过填充处理，超长则截断。因此，嵌入层不仅是将离散信息转为向量表示的桥梁，也是模型输入维度的决定因素之一。</p>
</li>
</ul>
<h2 id="感知机、激活函数和神经网络三者关系"><a href="#感知机、激活函数和神经网络三者关系" class="headerlink" title="感知机、激活函数和神经网络三者关系"></a>感知机、激活函数和神经网络三者关系</h2><ul>
<li>感知机是神经网络的基本构建单元，它通过对输入加权求和后传入激活函数来决定输出。激活函数引入非线性，使神经网络能拟合复杂关系。神经网络由多个感知机层叠构成，层与层之间通过激活函数连接，从而具备强大的表达和学习能力。三者关系为：<strong>激活函数是感知机的一部分，感知机是神经网络的基础单元。</strong></li>
</ul>
<h3 id="三者之间的关系总结："><a href="#三者之间的关系总结：" class="headerlink" title="三者之间的关系总结："></a>三者之间的关系总结：</h3><table>
<thead>
<tr>
<th>组成层级</th>
<th>关系说明</th>
</tr>
</thead>
<tbody><tr>
<td>感知机</td>
<td>最基础的神经元模型，是神经网络的最小单元</td>
</tr>
<tr>
<td>激活函数</td>
<td>是感知机或神经元的核心部分，引入非线性</td>
</tr>
<tr>
<td>神经网络</td>
<td>是多个感知机&#x2F;神经元的组合，通过激活函数形成强大的拟合能力</td>
</tr>
</tbody></table>
<p>可以这样理解它们的层级结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">神经网络 = 多个感知机（神经元）组成</span><br><span class="line">感知机 = 线性加权求和 + 激活函数</span><br><span class="line">激活函数 = 赋予神经网络非线性表达能力的关键</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>深度学习</tag>
        <tag>Deep-Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>LangChain要点记录</title>
    <url>/2025/02/19/20250219-langchain-yao-dian-ji-lu/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>基于书籍简单记录要点</p>
</blockquote>
</blockquote>
<p><img src="/2025/02/19/20250219-langchain-yao-dian-ji-lu/LangChain.png"></p>
<h1 id="LangChain-提供了多种模板供选择"><a href="#LangChain-提供了多种模板供选择" class="headerlink" title="LangChain 提供了多种模板供选择"></a>LangChain 提供了多种模板供选择</h1><ul>
<li>LangChain 提供了以下格式化 SQL 提示词模板（翻译）：</li>
</ul>
<pre>
1. 你是一个 PostgreSQL 专家。给定一个输人问题，首先创建一个语法正确的 PostgreSQL查询来运行，然后查看查询结果，扑返回针对输人问题的答案。
2. 除非用户明确指定了要返回的结果数量，否则应使用 PostgreSQL 的LIMIT 子句来限制查询结果，最多返回top.k条记录。你可以对结果进行排序，以返回数据库中最有信息价值的数据。
3. 绝对不要查询表中的所有列。你只能在询回答问题所需的列。用双引号（"）将每个列名包裹起来，表示官们是界定的标识符。
4. 注意只使用你在表巾可以看到的列名，不要责询不存在的列。此外，要注意哪一列在哪个表中。
5. 如果问题涉及“今天”，请注意使用 CURRENT_DATE 函数获取当前日期。

使用以下格式：

问题：这里的问题
SQL查询：要运行的 SQL 查询
SQL结果：SQL 查询的结果
答案：这里的最终答案

只使用以下表：

(table_info)

问题：｛input｝

</pre>

<ul>
<li>想象一下，如果没有 LangChain 提供的这个提示词模板，当你要开始编写一段SQL查询代码时，会走多少弯路？LLM 应用开发的最后1公里，其意义是确保开发者无须为了一个小细节而多走弯路，正如居民无须跑很远坐公交车一样，每一个关键的细节都能得到及时而准确的处理，使得整个开发过程更为高效。</li>
</ul>
<h1 id="记忆提示词"><a href="#记忆提示词" class="headerlink" title="记忆提示词"></a>记忆提示词</h1><ul>
<li><p>创建提示词是最重要的环节。在创建的过程中你可以理解为什么加人记忆组件后，“聊天备忘录”有了内容，让链组件有了“记忆”。使用提示词模板包装器，自定义一个提示词模板字符串。</p>
</li>
<li><p>提示词内容分为四部分：</p>
<ul>
<li>一是对模型的指导词：“请你回答问题的时候，依据文档内容和聊天记录回答，如果在其中找不到相关信息或者答案，请回答不知道。”；</li>
<li>二是使用问题检索到的相关文档内容；“文档内容是：｛context｝”；三是记忆组件输出的记忆内容：“聊天记录是：｛chat_history｝”；四是用户的输人：“Human：(human _input)”<pre>
template = "n*你是说中文的 chatbot.
请你回答问题的时候，依据文持内容和脚天记录回答，如果在其中找不到相关信息戒着答案，请回答
不知道。
文档内容是：｛context）
聊天记录是：｛chat_history）
Human: (human_input)
Chatbot:"""
</pre></li>
</ul>
</li>
<li><p>LangChain 框架由以下开发库组成。</p>
<ul>
<li>（1）LangChain-Core：基础抽象和 LangChain 表达语言（LCEL）。</li>
<li>（2）LangChain-Community：组件及内置的大量第三方技术集成模块，一般被封装为合作伙伴模块（例如 LangChain-openai）。</li>
<li>（3）LangChain：构成应用架构的上层核心组件，包括 Chains、Agents 等。</li>
<li>（4）Templates：官方提供的一些常见的应用模板。</li>
<li>（5）LangServe：将 LangChain 链部署为 REST API 的平台。</li>
<li>（6）LangSmith：帮助开发者跟踪调试、测试、评估和监控大模型应用的在线平台。</li>
</ul>
</li>
</ul>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul>
<li><p>Langchain agent是怎么找到search工具并使用的</p>
<ul>
<li>可以正确识别和调用它，因为它主要是通过 description 语义匹配，而不是看 name 的具体字符串。</li>
<li>但 name 仍然有一定作用，比如：LLM 可能会参考 name 来做初步判断；调试时 name 可以帮助你看日志，知道 Agent 选了哪个工具</li>
</ul>
</li>
<li><p>LLM本身没有内在记忆，每个查询都是独立进行的</p>
<ul>
<li>所谓的记忆和检索增强生成（RAG）是通过外部手段实现的，即将相关信息添加到提示词模板中</li>
</ul>
</li>
</ul>
<hr>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="Langchain是怎么做到通过分析语义找到对应工具的"><a href="#Langchain是怎么做到通过分析语义找到对应工具的" class="headerlink" title="Langchain是怎么做到通过分析语义找到对应工具的"></a>Langchain是怎么做到通过分析语义找到对应工具的</h2><ul>
<li>From ChatGPT (2025-02-18)</li>
</ul>
<p>LangChain 通过 <strong>LLM（大模型）+ ReAct 框架</strong> 来分析语义并选择工具。它的核心逻辑是让 LLM <strong>先思考</strong>，再决定用哪个工具，并按照工具的格式调用它。  </p>
<h3 id="核心机制"><a href="#核心机制" class="headerlink" title="核心机制"></a><strong>核心机制</strong></h3><ol>
<li><strong>解析用户问题</strong> → 让 LLM 提取关键语义  </li>
<li><strong>匹配工具描述</strong> → 让 LLM 判断哪个工具最适合  </li>
<li><strong>生成调用指令</strong> → LLM 生成工具的调用格式并执行  </li>
<li><strong>工具返回结果</strong> → LLM 解析工具返回的数据并回复用户</li>
</ol>
<p>这套逻辑基于 <strong>ReAct（Reasoning + Acting）</strong> 框架，在 LangChain 里 Agent 主要是用这个方法来动态决策。  </p>
<h3 id="1-解析用户问题"><a href="#1-解析用户问题" class="headerlink" title="1. 解析用户问题"></a><strong>1. 解析用户问题</strong></h3><p>假设你输入：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">agent.run(<span class="string">&quot;计算 25 * 4 + 10&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>LangChain 会把这个问题交给 LLM（如 GPT-4），让它理解用户的意图。</p>
<p>LLM 可能会把你的问题理解成：</p>
<ul>
<li>这是一个数学计算问题  </li>
<li>需要找到一个能进行数学计算的工具  </li>
<li>计算表达式 <code>25 * 4 + 10</code></li>
</ul>
<h3 id="2-匹配工具描述"><a href="#2-匹配工具描述" class="headerlink" title="2. 匹配工具描述"></a><strong>2. 匹配工具描述</strong></h3><p>假设你有两个工具：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Tool(</span><br><span class="line">    name=<span class="string">&quot;Calculator&quot;</span>,</span><br><span class="line">    func=calculator_tool,</span><br><span class="line">    description=<span class="string">&quot;用于数学计算。输入一个数学表达式（如 3 + 5 * 2），输出结果。&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">Tool(</span><br><span class="line">    name=<span class="string">&quot;Wikipedia&quot;</span>,</span><br><span class="line">    func=wiki.run,</span><br><span class="line">    description=<span class="string">&quot;查询 Wikipedia 词条，输入一个关键词（如 &#x27;Python programming&#x27;），获取相关信息。&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>LLM 会对比问题和 <code>description</code>，发现 <strong>Calculator 的描述里提到了“数学计算”</strong>，所以它会选择 <code>Calculator</code> 这个工具。</p>
<blockquote>
<p><strong>关键点</strong>：LangChain 让 LLM 直接读 <code>description</code>，所以工具的名字 <code>name</code> 只是一个标识，核心还是 <code>description</code> 的语义匹配。</p>
</blockquote>
<h3 id="3-生成调用指令"><a href="#3-生成调用指令" class="headerlink" title="3. 生成调用指令"></a><strong>3. 生成调用指令</strong></h3><p>LangChain 让 LLM 生成一个类似 JSON 的格式，表示它要调用哪个工具：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;action&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Calculator&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;action_input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;25 * 4 + 10&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>然后 LangChain 会<strong>解析这个指令</strong>，找到 <code>Calculator</code> 工具，并把 <code>25 * 4 + 10</code> 传给 <code>func</code> 去执行。</p>
<h3 id="4-工具返回结果"><a href="#4-工具返回结果" class="headerlink" title="4. 工具返回结果"></a><strong>4. 工具返回结果</strong></h3><p>计算工具执行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">eval</span>(<span class="string">&quot;25 * 4 + 10&quot;</span>)  <span class="comment"># 计算得到 110</span></span><br></pre></td></tr></table></figure>
<p>LangChain 把 <code>110</code> 返回给 LLM，LLM 可能会回复：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">25 * 4 + 10 = 110</span><br></pre></td></tr></table></figure>
<p>最终 <code>agent.run()</code> 会输出这个结果。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>LangChain 让 LLM 负责：</p>
<ol>
<li><strong>分析用户语义</strong></li>
<li><strong>匹配工具（通过 <code>description</code>）</strong></li>
<li><strong>生成调用工具的指令</strong></li>
<li><strong>解释工具返回的结果</strong></li>
</ol>
<p>它的核心是利用 <strong>LLM 的推理能力</strong>，结合 ReAct 让它“思考后再行动”。所以只要 <code>description</code> 够清晰，即使 <code>name</code> 乱写，它也能找到正确的工具！</p>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>《LangChain入门指南构建高可复用、可扩展的LLM应用程序》</li>
<li>《基于大模型的RAG应用开发与优化——构建企业级LLM应用》</li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>LLM</tag>
        <tag>LangChain</tag>
      </tags>
  </entry>
  <entry>
    <title>基于大模型的RAG应用开发要点记录</title>
    <url>/2025/02/20/20250220-ji-yu-da-mo-xing-de-rag-ying-yong-kai-fa-yao-dian-ji-lu/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>基于书籍简单记录要点</p>
</blockquote>
</blockquote>
<p><img src="/2025/02/20/20250220-ji-yu-da-mo-xing-de-rag-ying-yong-kai-fa-yao-dian-ji-lu/RAG.png"></p>
<hr>
<ul>
<li><p>一种借助“外挂”的提示工程</p>
</li>
<li><p>最核心的思想：给大模型补充外部知识以提高生成质量</p>
</li>
<li><p>大模型的 RAG 应用中，最常见的检索方式是借助基于向量的语义检索来获得相关的数据块，并根据其相似度排序，最后输出最相关的前 K 个数据块（简称top_K）</p>
</li>
<li><p>自然语言处理中用于把各种形式的信息转换成向量表示的模型叫嵌入模型</p>
</li>
<li><p>基于向量的语义检索就是通过计算查询词与已有信息向量的相似度（如余弦相似度），找出与查询词在语义上最接近的信息。</p>
</li>
<li><p>如果大模型是一个优秀学生，正在参加一门考试，那么 RAG 和微调的区别如下。</p>
<ul>
<li>RAG：在考试时给他提供某个领域的参考书，要求他现学现用，并给出答案。</li>
<li>微调：在考试前一天对他进行辅导，使他成为某个领域的专家，然后让他参加考试。</li>
</ul>
</li>
<li><p>大模型与 Prompt 并不只在最后生成结果时才需要，在 RAG 应用流程的很多阶段都需要用到它们，比如在生成摘要、查询转换、查询路由、智能体推理、响应评估等很多阶段，都需要利用设计的Prompt 来让大模型完成任务。</p>
</li>
<li><p>与查询引擎相关的几个关键组件如下。</p>
<ul>
<li>（1）VectorIndexRetriever：向量索引检索器。用于完成相关知识的检索，基于索引来完成，输出多个相关 Node。</li>
<li>（2）Synthesizer：响应生成器。借助大模型来完成 Prompt 组装，并根据响应生成模式的要求来生成响应结果。</li>
<li>（3）NodePostProcessor：节点后处理器。通常用于在检索完成之后，对检索器输出的 Node 列表做补充处理，比如重排序。</li>
</ul>
</li>
<li><p>Agent 就是通过 AI 模型驱动，能够自主地理解、规划、执行，并最终完成任务的 AI 程序。Agent 与大模型的区别类似于人与大脑的区别：大脑指挥人的行动，但是只有人才是执行任务的完整体。    </p>
</li>
<li><p>Agent 就是在大模型作为智慧大脑的基础上实现记忆（Memory）、自我规划（Planning）、使用工具（Tool）等能力，从而开发一个具有自主认知与行动能力的完全“智能体”。</p>
</li>
<li><p>与 RAG 应用相比，Data Agent 具备以下能力。</p>
<ul>
<li>（1）兼具 RAG 应用的数据检索与查询生成能力。</li>
<li>（2）通过观察环境与任务目标推理出完成下一个数据任务的步骤。</li>
<li>（3）通过调用外部服务工具（API）完成复杂任务，并返回执行结果。</li>
<li>（4）具备长期记忆能力（如使用向量库）与短期记忆（一次任务中的交互历史等）能力。</li>
</ul>
</li>
<li><p>与 RAG 应用相比，Data Agent 的主要增强之处如下。</p>
<ul>
<li>（1）规划与推理出完成任务的步骤的能力。</li>
<li>（2）定义与使用工具的能力。</li>
</ul>
</li>
</ul>
<h1 id="LlamaIndex-框架整体结构"><a href="#LlamaIndex-框架整体结构" class="headerlink" title="LlamaIndex 框架整体结构"></a>LlamaIndex 框架整体结构</h1><ul>
<li>(1)Core Framework:这是 LlamaIndex 的核心框架，实现了 LlamaIndex 框 架中大量可扩展的基础组件与工具组件。</li>
<li>(2)Integrations:这是在 Core Framework 基础上由官方或者第三方提供的 大量扩展组件。这些组件大大扩充了 LlamaIndex 框架的兼容能力与应用场景， 包括各种类型的数据加载器、大语言模型与嵌入模型、向量库、Agent 工具等。</li>
<li>(3)Templates:这是官方或者第三方提供的更上层的应用模板。开发者可 以基于这些模板来修改和开发自己的应用。</li>
<li>(4)Eval Datasets:评估数据集。这是一些用于测试评估的现成数据集。 一个数据集通常包含两个部分:一部分是用于开发 RAG 应用的原始知识数据 集;另一部分是用于评估 RAG 应用的测试数据集。</li>
</ul>
<hr>
<h1 id="LlamaIndex-的向量存储索引和传统数据库（如-MySQL）的索引的区别"><a href="#LlamaIndex-的向量存储索引和传统数据库（如-MySQL）的索引的区别" class="headerlink" title="LlamaIndex 的向量存储索引和传统数据库（如 MySQL）的索引的区别"></a>LlamaIndex 的向量存储索引和传统数据库（如 MySQL）的索引的区别</h1><ul>
<li>From Grok3 (2025-02-24)</li>
</ul>
<h2 id="传统数据库索引（如-MySQL）-vs-向量存储索引"><a href="#传统数据库索引（如-MySQL）-vs-向量存储索引" class="headerlink" title="传统数据库索引（如 MySQL） vs 向量存储索引"></a>传统数据库索引（如 MySQL） vs 向量存储索引</h2><h3 id="1-传统数据库索引（B-树、哈希索引等）"><a href="#1-传统数据库索引（B-树、哈希索引等）" class="headerlink" title="1. 传统数据库索引（B-树、哈希索引等）"></a>1. 传统数据库索引（B-树、哈希索引等）</h3><ul>
<li><strong>目的</strong>：加速精确匹配或范围查询，比如在 <code>WHERE id = 5</code> 或 <code>WHERE age &gt; 30</code> 时快速定位数据。</li>
<li><strong>数据结构</strong>：通常基于 B-树、B+树 或哈希表，存储的是原始数据（如整数、字符串）的某种排序或映射。</li>
<li><strong>存储内容</strong>：索引本身不保存完整数据，而是指向数据库中实际数据的引用（行指针）。</li>
<li><strong>使用场景</strong>：结构化数据的高效检索。</li>
</ul>
<h3 id="2-LlamaIndex-的向量存储索引"><a href="#2-LlamaIndex-的向量存储索引" class="headerlink" title="2. LlamaIndex 的向量存储索引"></a>2. LlamaIndex 的向量存储索引</h3><ul>
<li><strong>目的</strong>：支持语义相似性搜索，比如找到与“人工智能是什么”语义最接近的文档。</li>
<li><strong>数据结构</strong>：基于向量空间的高效搜索结构（如 FAISS、HNSW、Annoy），存储的是文本的嵌入向量（高维浮点数数组）。</li>
<li><strong>存储内容</strong>：索引里直接保存的是嵌入向量（通常还会关联原始文本或其引用），而不仅仅是指针。这种嵌入向量本身就是数据的某种“表示”。</li>
<li><strong>使用场景</strong>：非结构化数据（如文本、图像）的语义搜索。</li>
</ul>
<p>所以你说得对，向量存储索引和 MySQL 的索引在设计目标和实现上完全不同。传统索引是为了快速定位具体值，而向量存储索引是为了快速找到“最相似”的内容。</p>
<h2 id="为什么叫“向量存储索引”而不是“向量存储数据”？"><a href="#为什么叫“向量存储索引”而不是“向量存储数据”？" class="headerlink" title="为什么叫“向量存储索引”而不是“向量存储数据”？"></a>为什么叫“向量存储索引”而不是“向量存储数据”？</h2><ul>
<li><p><strong>“索引”在这里的含义</strong>：</p>
<ul>
<li>在向量搜索领域，“索引”指的是一个经过优化的数据结构，用于加速向量之间的相似性计算和检索。它不只是存数据，而是以某种方式组织数据（比如 FAISS 用聚类或倒排索引），让查询效率更高。</li>
<li>比如 FAISS 可能会把向量分桶（clustering），HNSW 用图结构连接向量，这些都是“索引”的体现。</li>
</ul>
</li>
<li><p><strong>为什么不叫“向量存储数据”</strong>：</p>
<ul>
<li>“数据”听起来像是原始的、未经组织的存储，比如直接把向量一股脑扔进数据库。而“索引”强调的是结构化和查询优化。</li>
<li>LlamaIndex 的向量存储索引不仅存了向量，还为快速检索做了预处理（比如降维、构建树或图）。它是个功能性工具，而不仅是数据的容器。</li>
</ul>
</li>
<li><p><strong>命名习惯</strong>：</p>
<ul>
<li>在向量搜索和机器学习领域，像 FAISS、Annoy、HNSW 这些工具都叫“索引”（index），因为它们的核心是构建一个可搜索的结构。LlamaIndex 沿用了这种惯例。</li>
</ul>
</li>
</ul>
<h2 id="举个类比"><a href="#举个类比" class="headerlink" title="举个类比"></a>举个类比</h2><ul>
<li>MySQL 的 B-树索引就像图书馆的卡片目录，按书名首字母排序，帮你快速找到某本书。</li>
<li>LlamaIndex 的向量存储索引更像是推荐系统，根据你喜欢的书，找到内容相似的其他书，靠的是“向量空间的距离”而不是精确匹配。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>LlamaIndex 的向量存储索引确实和 MySQL 的索引差别很大，它更像是一个专门为高维向量设计的“搜索加速器”。叫“索引”是因为它不仅存向量，还组织向量以提升查询效率，而不是简单的数据存储。</p>
<hr>
<h1 id="关于RAG的优化：个人结合深度强化学习的思考"><a href="#关于RAG的优化：个人结合深度强化学习的思考" class="headerlink" title="关于RAG的优化：个人结合深度强化学习的思考"></a>关于RAG的优化：个人结合深度强化学习的思考</h1><ul>
<li><p>对于RAG应用，优化方法有很多。我的想法是，把这些优化方法想象成一堆‘工具’，然后用强化学习这个‘聪明助手’来挑出最好用的组合。</p>
</li>
<li><p>“优化策略”变成了“工具”，“强化学习”变成了“聪明助手”，“奖励函数”简化为“任务需求”</p>
</li>
<li><p>From ChatGPT</p>
</li>
<li><p>你表达的意思可以理解为：你试图用一个类比来形象地说明深度强化学习在RAG（Retrieval-Augmented Generation）系统优化中的角色与价值。</p>
</li>
<li><p>具体地说：</p>
<ul>
<li><strong>RAG优化方法</strong>很多，比如检索器选择、reranker排序、embedding优化、prompt设计等，这些在你眼中就像一堆**“工具”**。</li>
<li>这些工具的使用方式组合非常多，所以你不想手动去调优，而是引入一个“聪明助手”——也就是<strong>强化学习智能体</strong>，来<strong>自动地组合和选择最合适的优化策略</strong>。</li>
<li><strong>任务需求</strong>（比如更高的准确率、更好的用户体验）就变成了强化学习中的<strong>奖励函数</strong>，引导智能体不断试错、学习，找到最优解法。</li>
</ul>
</li>
<li><p>所以你的思路是用深度强化学习作为一种<strong>元优化方法</strong>，来学习在不同场景下该怎么调配RAG的各类优化手段，从而达到最好的表现。</p>
</li>
<li><p>这是一个很有潜力的方向，本质上是将强化学习用作策略搜索或控制器，帮助系统自动适配复杂环境下的参数和策略组合。你可以进一步细化这个设想，比如：</p>
<ul>
<li>工具组合的action space怎么定义？</li>
<li>每种任务需求下的reward如何设计？</li>
<li>环境如何模拟或构建，才能训练出泛化能力强的“助手”？</li>
</ul>
</li>
</ul>
<hr>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="如果嵌入模型知道“你好”和“再见”的向量，它可以将“你好再见”转化为一个向量吗？"><a href="#如果嵌入模型知道“你好”和“再见”的向量，它可以将“你好再见”转化为一个向量吗？" class="headerlink" title="如果嵌入模型知道“你好”和“再见”的向量，它可以将“你好再见”转化为一个向量吗？"></a>如果嵌入模型知道“你好”和“再见”的向量，它可以将“你好再见”转化为一个向量吗？</h2><ul>
<li>From Grok3 （2025-02-25）</li>
<li>嵌入模型可以将“你好再见”转化为向量。</li>
<li>对于词嵌入模型（如 Word2Vec 或 GloVe），通常通过平均或相加“你好”和“再见”的向量来生成短语向量。</li>
<li>对于句嵌入模型（如 BERT 或 Ada-002），模型可以直接处理“你好再见”序列，生成反映上下文关系的向量。</li>
</ul>
<h2 id="RAG的相关原理"><a href="#RAG的相关原理" class="headerlink" title="RAG的相关原理"></a>RAG的相关原理</h2><ul>
<li><p>From Grok3 （2025-02-25）– 基于自身理解由Grok优化</p>
</li>
<li><p>文本向量化：在RAG中，知识库中的文档会被分割成适当的文本片段（例如句子或段落），然后使用预训练模型对这些片段整体进行向量化，生成语义丰富的稠密向量。这一过程不同于传统的单词嵌入，目的是捕捉整个片段的语义信息。</p>
</li>
<li><p>向量检索：当用户提出问题时，系统会将问题同样向量化，并在向量数据库中查询与问题语义最相似的文本片段。这些检索结果是原始文档中的真实内容，而不是由模型生成的文本。</p>
</li>
<li><p>上下文整合与生成：检索到的文本片段会以纯文本形式插入到一个提示模板中，作为上下文连同用户的问题一起输入到生成模型中。生成模型（如大语言模型）基于这些上下文生成最终的回答。</p>
</li>
</ul>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul>
<li><p><a href="https://developer.aliyun.com/article/1628030">精通RAG架构：从0到1，基于LLM+RAG构建生产级企业知识库</a></p>
<ul>
<li>向量数据库对比</li>
<li>如何选择嵌入模型：<a href="https://huggingface.co/spaces/mteb/leaderboard">https://huggingface.co/spaces/mteb/leaderboard</a></li>
</ul>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/gEtTrdOut5Cr2tdrq_yPIQ">微软推出CoRAG：通过迭代推理提升AI检索能力</a></p>
<ul>
<li>CoRAG 的核心创新在于其动态查询重构机制。该模型不再依赖单次检索，而是根据中间推理状态迭代优化查询。这一过程确保了每个阶段检索到的信息都与上下文相关，进而逐步构建出更完整的最终答案。</li>
</ul>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/ZfClcpOGbnZxmBxN8rGQpQ">用 LLM 快速构建实用知识图谱</a></p>
<ul>
<li>如果你用图数据库来检索信息，那么这种方式被称为 GraphRAG，它是知识图谱在 RAG 中的具体应用</li>
<li>向量相似性检索依赖于知识库中的明确提及，只有明确提到的信息才会被检索出来。而知识图谱则能通过整体数据来推理出更多信息</li>
<li>使用 Langchain 的实验功能 LLMGraphTransformer，如果是 LlamaIndex，可以尝试它的 KnowledgeGraphIndex。</li>
<li>LLM 可以从纯文本中提取图谱信息，并将其存储到像 Neo4J 这样的数据库</li>
</ul>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/Za26pIabmREPn6u2bEkBUw">“无”中生有：基于知识增强的RAG优化实践</a></p>
<ul>
<li>感觉做这个东西就是在不停找各种优化方法反复尝试看效果，而且目前还处于很乱的早起阶段</li>
</ul>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/Q7nAold78HRuNhUiHSVUxA">微软推出的 LazyGraphRAG</a>   </p>
<ul>
<li>传统方法（如基于向量的 RAG）在处理局部化任务时表现良好，例如从特定文本片段中检索直接答案。然而，当涉及需要全面理解数据集的全局性查询时，这些方法往往难以胜任。</li>
<li>相比之下，图支持的 RAG 系统通过利用数据结构中的关系，可以更好地解决此类更广泛的问题。然而，与图 RAG 系统相关的高索引成本，使其难以被成本敏感的场景所接受。因此，在可扩展性、经济性和质量之间实现平衡，仍然是现有技术的关键瓶颈。</li>
<li>相比之下，图支持的 RAG 系统通过利用数据结构中的关系，可以更好地解决此类更广泛的问题。然而，与图 RAG 系统相关的高索引成本，使其难以被成本敏感的场景所接受。因此，在可扩展性、经济性和质量之间实现平衡，仍然是现有技术的关键瓶颈。</li>
<li>LazyGraphRAG 将 VectorRAG 与 GraphRAG 相结合，“同时克服了二者的各自局限性”。</li>
</ul>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/N-oPDmkb3EKqB2IM_reO1A">DeepSearcher深度解读：Agentic RAG的出现，传统RAG的黄昏</a></p>
<ul>
<li><a href="https://github.com/zilliztech/deep-searcher">https://github.com/zilliztech/deep-searcher</a></li>
<li>所谓Agentic RAG，是一种融合智能代理（Agent）能力的RAG架构。通过动态规划、多步骤推理和自主决策机制，Agentic RAG可以在复杂任务中实现闭环的检索-加工-验证-优化</li>
<li>Agentic RAG相比传统RAG有着三大优势：<ul>
<li>（1）被动响应变为主动响应；</li>
<li>（2）单次的关键词检索，升级为多轮的动态调整检索，并拥有自我修正能力；</li>
<li>（3）适用场景，从最基础的简单事实问答，升级为复杂推理、复杂报告生成等开放域任务。</li>
</ul>
</li>
<li>长期来看，Agentic RAG必定会取代传统RAG。一方面，传统RAG对需求的响应还停留在非常基础的阶段，另一方面，现实中，我们大部分的需求表达背后，都是有隐含逻辑的，并不能被一步检索到位，必须通过推理-反思-迭代-优化来对其进行拆解与反馈。</li>
<li>VS Graph RAG<ul>
<li>Graph RAG主要聚焦于对存在连接关系的文档展开查询，在处理多跳类问题上表现出色。</li>
<li>例如，当导入一部长篇小说时，它能够精准抽取各个人物之间错综复杂的关系。其运作方式是在文档导入环节，就对实体间关系进行抽取。因此，这一过程会大量消耗大模型的token资源 。</li>
<li>而在查询阶段，不论是否是查询图中某些节点的信息，都会进行图结构的搜索，这使得这一框架不太灵活。</li>
<li>反观Agentic RAG，它的资源消耗模式与Graph RAG恰好相反。在数据导入阶段，Agentic RAG无需执行额外特殊操作，而在回答用户提问时，才会产生较多大模型的token消耗。</li>
</ul>
</li>
</ul>
</li>
<li><p><a href="https://mp.weixin.qq.com/s/VZq2zsuJGsGaYTx6POqUzg">高阶RAG技巧：探索提升RAG系统性能的不同技巧</a></p>
<ul>
<li>索引优化技术（如数据预处理和分块）专注于格式化外部数据以提高其效率和可搜索性。</li>
<li>预检索技术旨在通过重写、重新格式化或将查询路由到专用流水线来优化用户查询本身。</li>
<li>检索优化策略通常侧重于在检索阶段优化搜索结果。 </li>
<li>检索后优化策略旨在通过各种技术提高生成结果的准确性，包括对检索结果进行重新排序、增强或压缩（检索）上下文以及操纵提示或生成模型 (LLM)。</li>
</ul>
</li>
<li><p>KBLAM 是在 RAG（Retrieval-Augmented Generation） 和 知识图谱增强推理 的基础上发展而来。它的关键点是：</p>
<ul>
<li>利用结构化知识（如三元组：subject–predicate–object）进行多跳推理</li>
<li>结合语言模型对自然语言的理解能力，实现可控的知识推理流程</li>
</ul>
</li>
</ul>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>《基于大模型的RAG应用开发与优化——构建企业级LLM应用》</li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>LLM</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型应用开发AI Agent要点记录</title>
    <url>/2025/02/21/20250221-da-mo-xing-ying-yong-kai-fa-ai-agent-yao-dian-ji-lu/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>基于书籍简单记录要点</p>
</blockquote>
</blockquote>
<p><img src="/2025/02/21/20250221-da-mo-xing-ying-yong-kai-fa-ai-agent-yao-dian-ji-lu/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%845%E4%B8%AA%E5%B1%82%E6%AC%A1.png"></p>
<ul>
<li>从L3到L4的跨越是一个从被动到自主的分水岭，在这个跨越过程中，Agent将成为关键的驱动力</li>
</ul>
<p><img src="/2025/02/21/20250221-da-mo-xing-ying-yong-kai-fa-ai-agent-yao-dian-ji-lu/AI-Agent.png"></p>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>《大模型应用开发 动手做AI Agent》</li>
<li><a href="https://developer.baidu.com/article/detail.html?id=3372236">AIGC生成式人工智能的五个进阶层次</a></li>
<li><a href="https://blog.csdn.net/surfirst/article/details/142661951">AIGC：生成式人工智能的5个层次</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/671355141">2024年大模型Multi-agent多智能体应用技术：AutoGen, MetaGPT, XAgent, AutoAgents，crewAI</a></li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>LLM</tag>
        <tag>AI-Agent</tag>
      </tags>
  </entry>
  <entry>
    <title>关于大模型的Prompt</title>
    <url>/2025/02/25/20250225-guan-yu-da-mo-xing-de-prompt/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>网上资料摘要<br>一些个人理解</p>
</blockquote>
</blockquote>
<h1 id="大模型交互的核心：提示词工程"><a href="#大模型交互的核心：提示词工程" class="headerlink" title="大模型交互的核心：提示词工程"></a>大模型交互的核心：提示词工程</h1><blockquote>
<blockquote>
<p>以下基于个人理解，并通过claude优化（2025-02-26）</p>
</blockquote>
</blockquote>
<ul>
<li>提示词（Prompt）是大模型的输入，也是调用大模型能力的接口，用以激发或引导大模型生成特定类型的回答。</li>
<li>提示词工程的目的是尽量把任务说清楚，让大模型能充分理解我们的意图，以按照正确的方向回答问题。  </li>
<li>在不微调大模型的情况下，外部与大模型交互的唯一途径就是提示工程。即便是已经微调过的大模型，后续与其沟通的唯一途径仍是通过提供提示词，尽管微调可能改变模型对提示词的响应方式。</li>
<li>所谓的RAG、短期记忆（对话历史）、长期记忆等功能，都是基于提示工程这一与大模型交互的路径作为切入点，建立的其他优化策略和架构。</li>
</ul>
<h1 id="ICIO框架（Prompt包含的要素）"><a href="#ICIO框架（Prompt包含的要素）" class="headerlink" title="ICIO框架（Prompt包含的要素）"></a>ICIO框架（Prompt包含的要素）</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/xYC6saH3PU6nJc9mzV5alw">从原理出发 - 提示词如何影响大模型的输出</a></li>
<li>核心思想，是通过明确定义任务的各个方面，来提高AI响应时的效率和准确性。</li>
<li>在ICIO的框架的设计中，Prompt可能包含四要素：<ul>
<li>Instruction（指令）：这是最重要的部分，它直接告诉模型需要执行的具体任务。</li>
<li>Context（上下文&#x2F;背景）：上下文提供了任务执行所需的背景信息，帮助模型理解任务的情景和环境。</li>
<li>Input Data（输入数据）：输入数据是模型需要处理的具体信息。</li>
<li>Output Indicator（输出指示器）：输出指示器告诉模型用户期望的输出类型或格式。</li>
</ul>
</li>
<li>其中除了指令以外，其他要素都是可选的，说明指令对于大模型来说是最重要的，其他要素都是对指令的补充。</li>
<li>优质的Prompt，可以清晰地传达用户的意图</li>
</ul>
<h1 id="Prompt五大框架"><a href="#Prompt五大框架" class="headerlink" title="Prompt五大框架"></a>Prompt五大框架</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A">大模型Prompt技巧全解析</a>    </li>
<li>RTF框架 <ul>
<li>R-Role(角色)、R-Role(角色)、F-Format(格式)</li>
</ul>
</li>
<li>思考链模式 <ul>
<li>适合一些复杂的任务处理</li>
<li>要使用这种模式，只需要在末尾添加”让我们逐步思考”即可</li>
</ul>
</li>
<li>RISEN框架<ul>
<li>R-Role:大模型扮演的角色</li>
<li>I-Instructions: 指示命令，和Task-任务差不多</li>
<li>S-Steps: 步骤</li>
<li>E-End Goal: 最终目标</li>
<li>N-Narrowing(Constraints): 缩小范围(约束条件)，和RTF框架中的Format有异曲同工之妙</li>
<li>该框架主要适合<ul>
<li>撰写具有特定约束的任务(例如博客文章)</li>
<li>有明确指导方针的任务（例如商业计划）</li>
</ul>
</li>
</ul>
</li>
<li>RODES框架<ul>
<li>R-Role: 角色、O - Objective: 目标、D - Details: 详细的细节、E - Examples: 示例、S - Sense Check: 感官检查</li>
</ul>
</li>
<li>密度链模式<ul>
<li>使用递归来创建越来越好的输出的提示，与普通提示生成的 GPT-4 摘要相比，它生成的摘要更加密集且更适合人们理解</li>
<li>适合：总结、改进您最喜欢的提示、通过递归生成可用的长格式内容</li>
</ul>
</li>
</ul>
<h1 id="打造高效Prompt的两大核心原则"><a href="#打造高效Prompt的两大核心原则" class="headerlink" title="打造高效Prompt的两大核心原则"></a>打造高效Prompt的两大核心原则</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A">大模型Prompt技巧全解析</a> </li>
<li>原则一：编写明确和具体的指令<ul>
<li>策略1：使用分隔符清晰界定输入部分</li>
<li>策略2：要求结构化输出</li>
<li>策略3：要求模型检查条件是否满足</li>
<li>策略4：Few-shot prompting（少样本提示）</li>
</ul>
</li>
<li>原则二：给予模型充足的思考时间<ul>
<li>策略1：明确完成任务所需的步骤</li>
<li>策略2：引导模型在得出结论前充分思考方案</li>
</ul>
</li>
</ul>
<h1 id="Prompt技术剖析与应用"><a href="#Prompt技术剖析与应用" class="headerlink" title="Prompt技术剖析与应用"></a>Prompt技术剖析与应用</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A">大模型Prompt技巧全解析</a> </li>
<li>一、零样本提示（Zero-Shot Prompting）</li>
<li>二、少样本提示（Few-Shot Prompting）<ul>
<li>在零样本提示效果不佳时发挥作用</li>
</ul>
</li>
<li>三、思维链提示（Chain-of-Thought Prompting）<ul>
<li>与少样本提示结合，增强效果，尤其适用于算术、常识推理等任务，帮助模型更有条理地处理问题</li>
</ul>
</li>
<li>四、自我一致性（Self-Consistency）   <ul>
<li>主要用于优化思维链提示中的推理路径选择</li>
<li>核心思想是通过提供多个少样本推理示例，让模型从多样的推理结果中筛选出最一致的答案，增强模型在算术和常识推理任务中的可靠性</li>
</ul>
</li>
<li>五、生成知识提示（Generated Knowledge Prompting）<ul>
<li>主要用于解决模型在处理需要额外知识的任务时出现的局限性   </li>
<li>个人理解：一种特殊的RAG罢了</li>
</ul>
</li>
<li>六、链式提示（Prompt Chaining）<ul>
<li>将复杂任务拆解为多个子任务，通过逐个子任务生成提示并传递结果的方式来实现复杂任务的有序处理</li>
</ul>
</li>
<li>七、思维树（ToT）<ul>
<li>为了帮助模型应对复杂的探索性任务而设计</li>
<li>通过维护一棵思维树，让模型在解决问题时能够生成和评估中间思维步骤，并结合搜索算法进行系统性探索</li>
</ul>
</li>
<li>八、检索增强生成（RAG）<ul>
<li>将信息检索与文本生成相结合，专门用于处理知识密集型任务</li>
<li>通过检索相关文档来为模型提供额外的知识支持，从而缓解模型的“幻觉”问题</li>
</ul>
</li>
<li>九、自动推理并使用工具（ART）<ul>
<li>使模型能够自动生成包含推理步骤的程序，并在需要时调用外部工具</li>
</ul>
</li>
<li>十、自动提示工程师（APE）<ul>
<li>自动生成和筛选任务指令</li>
<li>利用大型语言模型生成指令候选项，再依据评估分数选择最佳指令，从而提升提示生成的效率与效果</li>
</ul>
</li>
<li>十一、Active-Prompt<ul>
<li>用于解决思维链示例有效性的问题</li>
<li>通过先查询模型生成多个答案，计算不确定度后挑选最不确定的问题由人类注释示例，再用新示例推断其他问题，从而优化模型对不同任务的适应性</li>
</ul>
</li>
<li>十二、方向性刺激提示（Directional Stimulus Prompting）<ul>
<li>通过训练策略 LM 生成引导提示，增强对模型生成结果的掌控力。例如文本摘要任务</li>
</ul>
</li>
<li>十三、PAL（程序辅助语言模型）<ul>
<li>让模型生成程序来解决问题，借助编程运行时提升解决复杂问题的能力</li>
</ul>
</li>
<li>十四、ReAct 框架<ul>
<li>ReAct 框架使模型交错生成推理轨迹和操作，提升答案的可靠性与可解释性</li>
</ul>
</li>
<li>十五、自我反思（Reflexion）<ul>
<li>包含参与者、评估者和自我反思三个模型，旨在帮助模型从错误中学习并提升性能</li>
</ul>
</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://mp.weixin.qq.com/s/xYC6saH3PU6nJc9mzV5alw">从原理出发 - 提示词如何影响大模型的输出</a><ul>
<li>大模型如何理解Prompt<ul>
<li>基于Transformer的解码器的大模型</li>
<li>最核心的两层<ul>
<li>掩码多头自注意力层（Masked Multi Self Attention Layers，对应Transformer的Masked Multi-Head Attention，简称MHA）</li>
<li>前置反馈网络层（Feed Forward Networks Layers，简称FFN）</li>
</ul>
</li>
<li>Prompt会影响自注意力层对上下文信息的捕捉</li>
<li>自注意力机制<ul>
<li>它的核心思想是模仿人类的注意力，即在处理大量信息时，能够聚焦于当前任务最相关的部分，而忽略其他不太重要的信息</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A">大模型Prompt技巧全解析</a>            </li>
<li><a href="https://kingson4wu.github.io/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/">LLM相关技术简单了解</a></li>
<li><a href="https://mp.weixin.qq.com/s/q2iMW0t5456btmIPS1ba6Q">大型语言模型的提示注入</a><ul>
<li>三种防范此类漏洞的方法<ul>
<li>可以在提示中添加指令</li>
<li>使用对抗性探测器添加第二层保护</li>
<li>对模型进行微调，使其更符合用户需求，同时提供最高级别的保护，防止提示注入和窃取</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>LLM</tag>
        <tag>Prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>开源知识库系统试用</title>
    <url>/2025/02/26/20250226-kai-yuan-zhi-shi-ku-xi-tong-shi-yong/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>帮助朋友的公司搭建内部知识库的原型<br>简单记录一下相关技术</p>
</blockquote>
</blockquote>
<p><img src="/2025/02/26/20250226-kai-yuan-zhi-shi-ku-xi-tong-shi-yong/dify.drawio.png"></p>
<ul>
<li><p>目前看权限管理都很不精细，只在固定角色上进行控制，用于内部团队管理仍不是很方便</p>
</li>
<li><p>文档嵌入效果一般，可能要研究里面一些复杂的选项用法，或者寻求其他方案</p>
</li>
<li><p>除了dify，还有很多其他开源的知识库系统，比如 Cherry Studio、MaxKB、FastGPT、AnythingLLM、Ragflow等</p>
</li>
<li><p>dify功能很多，anythingllm功能较少，Cherry Studio 就是个人知识库</p>
</li>
<li><p>所谓的各种助手其实就是提示词模版</p>
</li>
</ul>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><ul>
<li>传统RAG通常依赖单次检索，这可能不足以处理需要逐步构建上下文的复杂查询</li>
<li>向量相似性检索依赖知识库中明确提及的信息，可能无法捕捉隐含或关系信息。相比之下，知识图谱（如GraphRAG）通过利用数据结构中的关系，能更好地处理需要全面理解数据集的全局查询</li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>LLM</tag>
        <tag>RAG</tag>
        <tag>知识库</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Java调用Rust构建的动态库</title>
    <url>/2025/03/23/20250323-shi-yong-java-diao-yong-rust-gou-jian-de-dong-tai-ku/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>近期帮朋友做一个需求，需要将某个Rust项目的一部分功能移植到Java中，使Java应用能使用</p>
</blockquote>
</blockquote>
<h2 id="方案1-直接将Rust翻译成Java代码"><a href="#方案1-直接将Rust翻译成Java代码" class="headerlink" title="方案1: 直接将Rust翻译成Java代码"></a>方案1: 直接将Rust翻译成Java代码</h2><blockquote>
<blockquote>
<p>前置准备：将Rust项目跑通，方便通过debug对照执行细节，从而一步步翻译成Java代码<br>希望借助AI的力量帮忙完成</p>
</blockquote>
</blockquote>
<ul>
<li>借助AI的方案如下：<ul>
<li>首先，我已经跑通了需要抽取的功能的相关测试用例</li>
<li>然后，让AI帮忙将涉及这些功能相关的代码抽取成单独的Rust项目（结果还是很乱七八糟）</li>
<li>大概是因为上下文内容太多的关系，AI执行任务的效果很差</li>
<li>没办法，于是自己拆分代码，让AI软件帮忙根据代码块逐个进行转化，结果效果是好了很多，能帮助不少，不过这样效率太低，而且AI有时候也经常出错，需要自己慢慢调整</li>
<li>看来AI目前在一次性的转化大量代码的效率和准确性还是不够</li>
<li>本次程序员该懒就懒的宗旨，我决定另辟蹊径，采用方案2</li>
</ul>
</li>
</ul>
<h2 id="方案2-直接将相关功能的Rust功能编译成动态库，由Java直接调用"><a href="#方案2-直接将相关功能的Rust功能编译成动态库，由Java直接调用" class="headerlink" title="方案2: 直接将相关功能的Rust功能编译成动态库，由Java直接调用"></a>方案2: 直接将相关功能的Rust功能编译成动态库，由Java直接调用</h2><blockquote>
<blockquote>
<p>省去翻译代码的重复工作<br>需要构建不同平台的动态库<br>Java代码在加载前需要判断环境加载相应的动态库<br>使用Github Action来构建各种平台的动态库<br>Java端充分测试，Java8应用测试，Java9以上模块化系统是否可用测试，Windows等其他平台测试</p>
</blockquote>
</blockquote>
<hr>
<blockquote>
<blockquote>
<p>以下由AI（ChatGPT）帮我完成的文章</p>
</blockquote>
</blockquote>
<h1 id="使用Java调用Rust构建的动态库"><a href="#使用Java调用Rust构建的动态库" class="headerlink" title="使用Java调用Rust构建的动态库"></a>使用Java调用Rust构建的动态库</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在最近的一个项目中，我需要将一个Rust项目中的部分功能迁移到Java应用中，供Java系统调用。为了简化过程，我决定绕过将Rust代码完全转化为Java的复杂任务，而是直接通过Rust构建动态库，再通过Java来调用。这种方法不仅减少了代码转换的工作量，还利用了Rust的高性能特点，提高了Java应用的效率。</p>
<h2 id="方案1-直接将Rust翻译成Java代码-1"><a href="#方案1-直接将Rust翻译成Java代码-1" class="headerlink" title="方案1: 直接将Rust翻译成Java代码"></a>方案1: 直接将Rust翻译成Java代码</h2><h3 id="前置准备"><a href="#前置准备" class="headerlink" title="前置准备"></a>前置准备</h3><p>为了开始这个过程，我首先确保了Rust项目能够成功运行，并且通过调试工具逐步分析每个功能的执行细节。这是为了确保我可以一步步将Rust的实现逻辑转化为Java代码。</p>
<h3 id="使用AI进行代码转换"><a href="#使用AI进行代码转换" class="headerlink" title="使用AI进行代码转换"></a>使用AI进行代码转换</h3><p>最初，我尝试借助AI工具自动化地将Rust代码转换为Java代码。以下是我使用AI进行代码转换的过程：</p>
<ul>
<li>我首先跑通了相关的测试用例，确保所有需要移植的功能都能正常工作。</li>
<li>然后，我让AI帮助抽取与这些功能相关的Rust代码，并转化成单独的Rust项目。但由于上下文过多，AI的效果并不理想，生成的代码混乱且不完整。</li>
<li>之后，我将代码拆分成更小的部分，让AI逐一处理，虽然效果有所改善，但这种方式依旧效率低下，且AI经常会出错，导致我不得不花大量时间修正。</li>
</ul>
<p>这一过程中，我意识到AI在一次性大规模转化代码时的准确性和效率仍然有待提升。最终，我决定放弃这条路，转而尝试另一种更直接的方案——方案2。</p>
<h2 id="方案2-直接将Rust功能编译成动态库，由Java调用"><a href="#方案2-直接将Rust功能编译成动态库，由Java调用" class="headerlink" title="方案2: 直接将Rust功能编译成动态库，由Java调用"></a>方案2: 直接将Rust功能编译成动态库，由Java调用</h2><h3 id="思路与优势"><a href="#思路与优势" class="headerlink" title="思路与优势"></a>思路与优势</h3><p>与其将Rust代码翻译成Java代码，我决定直接将Rust的功能编译成动态库（.dll 或 .so），然后在Java中通过JNI（Java Native Interface）调用这些动态库。这样可以避免代码翻译过程中的麻烦，并且能够充分利用Rust在性能上的优势。</p>
<h3 id="构建Rust动态库"><a href="#构建Rust动态库" class="headerlink" title="构建Rust动态库"></a>构建Rust动态库</h3><p>在实现这一方案时，我需要做以下几个步骤：</p>
<ol>
<li><p><strong>编译Rust代码为动态库</strong>：通过Rust的<code>cargo</code>工具，将Rust代码编译成适用于不同平台的动态库。这需要为每个平台生成相应的二进制文件，如Windows下的<code>.dll</code>，Linux下的<code>.so</code>，以及MacOS下的<code>.dylib</code>。</p>
</li>
<li><p><strong>使用Github Actions自动化构建</strong>：为了支持多平台的动态库构建，我使用了Github Actions来自动化构建过程。这样，无论是Windows、Linux还是MacOS，都会根据需要自动生成对应的动态库，极大地简化了跨平台的构建工作。</p>
</li>
<li><p><strong>Java端加载动态库</strong>：Java通过JNI加载Rust编译出的动态库，并调用其中的函数。在加载时，Java代码会先检测当前运行环境，根据操作系统加载相应的库文件。</p>
</li>
<li><p><strong>平台兼容性测试</strong>：为了确保Java能够顺利调用Rust动态库，我在多个平台上进行了充分的测试。这包括：</p>
<ul>
<li>在Java 8环境下进行功能测试。</li>
<li>验证在Java 9及以上版本的模块化系统下，Java与Rust动态库的兼容性。</li>
<li>测试在Windows、Linux和MacOS等不同平台下的表现。</li>
</ul>
</li>
</ol>
<h3 id="方案优势"><a href="#方案优势" class="headerlink" title="方案优势"></a>方案优势</h3><ul>
<li><strong>减少工作量</strong>：不需要将Rust代码完全翻译为Java代码，避免了翻译过程中的复杂性和错误。</li>
<li><strong>高效的性能</strong>：Rust的性能优势得以保留，Java通过调用Rust动态库，可以在性能上得到显著提升。</li>
<li><strong>跨平台支持</strong>：通过自动化构建不同平台的动态库，Java应用能够轻松支持Windows、Linux、MacOS等多种操作系统。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过将Rust功能编译成动态库并在Java中调用，我成功地绕过了将Rust代码完全转化为Java的复杂过程，同时还能够充分利用Rust的性能优势。虽然在构建过程中涉及到平台适配和自动化构建，但这一方案的灵活性和高效性使其成为解决问题的最佳选择。对于有类似需求的开发者来说，这无疑是一个值得尝试的方案。</p>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Rust</tag>
        <tag>JNI</tag>
      </tags>
  </entry>
  <entry>
    <title>“人工智能”一词是否准确？一次关于AI本质的反思</title>
    <url>/2025/05/31/20250531-ren-gong-zhi-neng-yi-ci-shi-fou-zhun-que-yi-ci-guan-yu-ai-ben-zhi-de-fan-si/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>AI – “基于数据的规律发现系统”</p>
</blockquote>
</blockquote>
<ul>
<li>“人工智能（AI）”这个名字，其实是一种历史性命名，也是一种拟人化的表达。它给人一种错觉，仿佛机器在模仿或复制人类的智能。然而，从技术本质上看，今天的人工智能主要依赖于数据驱动的模式识别和规律学习，更准确地说，它是一种“基于数据的规律发现系统”。无论是人类还是机器，学习的对象都是客观存在的规律，只是各自的方法不同。规律本身并不依赖于学习者，它们存在于自然和社会系统之中，等待被发现。机器学习的意义，不在于赋予机器“像人一样的智能”，而在于它可以在极大规模和复杂度下识别人类难以企及的模式，这种能力甚至在某些领域已经超越了人类。然而，AI虽能拟合规律，却不具备理解、动机和意识，因此我们说它“智能”仍属工程性描述，而非哲学意义上的智能。从这个角度看，“人工智能”这一术语在一定程度上是误导性的，如果要更准确地描述其本质，也许“规律学习系统”或“模式发现机器”更贴切，但这类表述在传播和产业化上显然不如“AI”简洁有力。因此，当前的术语是一种权衡：技术准确性让位于传播效率。我们需要清醒地认识到，AI不是在“思考”，它只是以统计和优化的方式，从数据中提取规律，并按特定目标进行预测或生成。</li>
</ul>
<hr>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><pre>
AI这个名字其实并不准确
人工智能
其实是通过数据来学习规律
跟人没有关系
只是人或机器用他们的方式去学习，
不管你人类或机器学不学习
规律就在那里，只是表现形式不一样，但规律的本质是一样的，
而且有些规律人类也学不会，超过人的能力
所以叫人工智能是片面的表达
应该叫智能规律，或规律学习？


——

当然，以下是对原文的整理和简要总结：

⸻

整理后的表达：

“人工智能（AI）”这个名称其实并不准确。所谓人工智能，本质上只是通过数据来学习和提取规律的过程，与人类的思维或意识没有直接关系。无论是人还是机器，学习的只是客观存在的规律，而这些规律本身独立于学习主体，始终存在，只是表现形式不同而已。

机器和人只是用不同的方式去接近这些规律，有些规律甚至超出了人类的认知能力，只有机器才能捕捉到。因此，用“人工智能”来命名这种技术是片面的，更准确的表达也许应该是“智能规律”或“规律学习”。

⸻

简要总结观点：

这段文字认为，“人工智能”这一术语带有误导性，因为它强调了“人”而忽略了技术的本质：对客观规律的学习和拟合。作者主张，AI其实是一种“规律学习”系统，不应被简单等同于模仿人类智能。

</pre>]]></content>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>刷LeetCode总结的算法基础和套路</title>
    <url>/2025/07/09/20250709-shua-leetcode-zong-jie-de-suan-fa-ji-chu-he-tao-lu/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>最近重新刷LeetCode，对一些算法基础和套路做下总结，以做备忘</p>
</blockquote>
</blockquote>
<hr>
<h1 id="简要分类总结"><a href="#简要分类总结" class="headerlink" title="简要分类总结"></a>简要分类总结</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><ul>
<li>数组（Array）</li>
<li>链表（Linked List） </li>
<li>哈希表（HashMap &#x2F; HashSet）</li>
<li>堆（Heap）<ul>
<li>最大堆 &#x2F; 最小堆</li>
<li>常用于：优先队列、Top K、调度排序</li>
</ul>
</li>
<li>栈 &#x2F; 队列（Stack &#x2F; Queue）<ul>
<li>DFS 通常借助栈实现，BFS 借助队列</li>
</ul>
</li>
<li>树（Tree）<ul>
<li>普通二叉树</li>
<li>二叉搜索树（BST）</li>
<li>平衡二叉树（AVL &#x2F; 红黑树）</li>
<li>字典树（Trie）</li>
<li>线段树（Segment Tree）</li>
<li>树状数组（Fenwick Tree）</li>
<li>并查集</li>
</ul>
</li>
<li>图（Graph）<ul>
<li>表示方式：邻接表、邻接矩阵</li>
<li>有向图 &#x2F; 无向图，带权图 &#x2F; 无权图</li>
<li>拓扑排序<ul>
<li>Kahn 算法（BFS 实现）</li>
<li>DFS 逆后序（递归 + 回退）</li>
<li>用于检测有向图中是否存在环、任务调度等</li>
</ul>
</li>
<li>最短路径算法：Dijkstra、Floyd、Bellman-Ford（带权图最短路径）</li>
<li>最小生成树算法：Kruskal &#x2F; Prim</li>
<li>稠密图和稀疏图<ul>
<li>稠密图：边很多，接近“完全图”</li>
<li>稀疏图：边很少，大多数节点之间没有直接连接</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul>
<li>遍历算法<ul>
<li>深度优先搜索（DFS）<ul>
<li>栈结构实现（递归或手动栈）</li>
<li>回溯 （&#x3D; DFS + 剪枝 + 状态恢复（回退））<ul>
<li>常用于：组合、排列、子集、数独、八皇后等问题</li>
</ul>
</li>
</ul>
</li>
<li>广度优先搜索（BFS）<ul>
<li>队列结构实现，逐层遍历</li>
</ul>
</li>
</ul>
</li>
<li>排序（冒泡、快速、堆）</li>
<li>快慢指针&#x2F; 双指针</li>
<li>滑动窗口</li>
<li>单调栈 &#x2F; 单调队列</li>
<li>二分查找</li>
<li>分治算法（Divide &amp; Conquer）</li>
<li>贪心算法（Greedy）</li>
<li>动态规划（DP）<ul>
<li>背包问题（0-1 背包、子集背包、完全背包）</li>
<li>子序列问题（LIS 最长递增子序列、LCS 最长公共子序列）</li>
<li>区间 DP &#x2F; 状态压缩 &#x2F; 滚动数组</li>
</ul>
</li>
<li>回溯算法（Backtracking）<ul>
<li>用于枚举所有可能解，如全排列、组合 &#x2F; 子集</li>
</ul>
</li>
</ul>
<hr>
<h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><ul>
<li><p>与数组不同，链表在构建子链时不会增加额外的空间复杂度。因此可以放心地构造子链，无需考虑节点交换的问题，也不必执着于“原地交换”的思路。</p>
</li>
<li><p>使用哨兵节点是一种常见技巧，它可以避免处理头指针等特殊情况，在代码实现上更加简洁。</p>
<ul>
<li><strong>链表内指定区间反转：</strong><br>给定一个单链表的头指针 <code>head</code>，以及两个整数 <code>left</code> 和 <code>right</code>（其中 <code>left &lt;= right</code>），请你反转从位置 <code>left</code> 到位置 <code>right</code> 的链表节点，返回反转后的链表。</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">reverseBetween</span><span class="params">(head *ListNode, m <span class="type">int</span>, n <span class="type">int</span>)</span></span> *ListNode &#123;</span><br><span class="line">    <span class="keyword">if</span> m == n || head == <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> head</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 哨兵节点，避免处理头指针的特殊情况</span></span><br><span class="line">    dummy := &amp;ListNode&#123;Next: head&#125;</span><br><span class="line">    pre := dummy</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 找到第 m-1 个节点</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">1</span>; i &lt; m; i++ &#123;</span><br><span class="line">        pre = pre.Next</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 反转 m 到 n 之间的节点，采用头插法</span></span><br><span class="line">    start := pre.Next      <span class="comment">// 第 m 个节点</span></span><br><span class="line">    then := start.Next     <span class="comment">// 第 m+1 个节点</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n-m; i++ &#123;</span><br><span class="line">        start.Next = then.Next</span><br><span class="line">        then.Next = pre.Next</span><br><span class="line">        pre.Next = then</span><br><span class="line">        then = start.Next</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dummy.Next</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h1><ul>
<li><p><strong>二叉树遍历（先序、中序、后序）</strong></p>
<ul>
<li>先序（中左右）、中序（左中右）、后序（左右中）</li>
<li>包含递归与非递归两种实现方式</li>
<li><strong>DFS</strong>：先序 &#x2F; 中序 &#x2F; 后序（递归 &#x2F; 栈实现）</li>
<li><strong>BFS</strong>：层序遍历（借助队列实现）</li>
</ul>
</li>
<li><p><strong>二叉查找树（Binary Search Tree，简称 BST）</strong></p>
<ul>
<li>左子树所有节点的值均小于根节点，右子树所有节点的值均大于根节点（<strong>不允许等于</strong>）</li>
<li><strong>中序遍历结果是升序序列</strong></li>
</ul>
</li>
<li><p><strong>完全二叉树</strong></p>
<ul>
<li>如果一棵深度为 <code>h</code> 的二叉树，除了第 <code>h</code> 层，其它每一层的节点数都达到最大值，并且第 <code>h</code> 层的节点都尽量靠左排列，则该树是完全二叉树</li>
<li>第 <code>h</code> 层可能包含 <code>1 ~ 2^h</code> 个节点</li>
<li><strong>堆</strong>（大顶堆 &#x2F; 小顶堆）是一种基于完全二叉树的结构</li>
</ul>
</li>
<li><p><strong>平衡二叉树（Balanced Binary Tree）</strong></p>
<ul>
<li>要么是空树，要么满足以下条件：左右子树的高度差的绝对值不超过 1，且左右子树也分别是平衡二叉树</li>
</ul>
</li>
</ul>
<h2 id="二叉树遍历"><a href="#二叉树遍历" class="headerlink" title="二叉树遍历"></a>二叉树遍历</h2><ul>
<li><p>树的遍历主要分为两类：</p>
<ul>
<li><p><strong>广度优先遍历（BFS）</strong>：也称层序遍历，使用队列实现</p>
</li>
<li><p><strong>深度优先遍历（DFS）</strong>：包括先序、中序、后序三种形式，可使用递归或栈实现</p>
<ul>
<li>递归</li>
<li>栈</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>深度优先遍历（DFS）说明</strong></p>
<ul>
<li>使用递归实现 DFS 时，虽然代码中未显式使用栈，但其实是借助系统的 <strong>调用栈（Call Stack）</strong> 来进行函数的递归与回溯</li>
</ul>
</li>
</ul>
<h3 id="先序遍历（前序）"><a href="#先序遍历（前序）" class="headerlink" title="先序遍历（前序）"></a>先序遍历（前序）</h3><ul>
<li><p>栈实现流程：</p>
<ol>
<li>循环条件：<code>root != nil || len(stack) &gt; 0</code></li>
<li>若 <code>root != nil</code>，访问节点、入栈、转向左子树</li>
<li>否则出栈、转向右子树</li>
</ol>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(root *TreeNode)</span></span> preorder() []<span class="type">int</span> &#123;</span><br><span class="line">	res := []<span class="type">int</span>&#123;&#125;</span><br><span class="line">	<span class="keyword">if</span> root == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> res</span><br><span class="line">	&#125;</span><br><span class="line">	stack := []*TreeNode&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> root != <span class="literal">nil</span> || <span class="built_in">len</span>(stack) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> root != <span class="literal">nil</span> &#123;</span><br><span class="line">			res = <span class="built_in">append</span>(res, root.data)      <span class="comment">// 访问当前节点</span></span><br><span class="line">			stack = <span class="built_in">append</span>(stack, root)       <span class="comment">// 入栈</span></span><br><span class="line">			root = root.Lchild                <span class="comment">// 向左子树移动</span></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			root = stack[<span class="built_in">len</span>(stack)<span class="number">-1</span>]        <span class="comment">// 出栈</span></span><br><span class="line">			stack = stack[:<span class="built_in">len</span>(stack)<span class="number">-1</span>]</span><br><span class="line">			root = root.Rchild                <span class="comment">// 转向右子树</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="中序遍历"><a href="#中序遍历" class="headerlink" title="中序遍历"></a>中序遍历</h3><ul>
<li><p>栈实现流程：</p>
<ol>
<li>循环条件：<code>root != nil || len(stack) &gt; 0</code></li>
<li>若 <code>root != nil</code>，将当前节点入栈并转向左子树</li>
<li>否则出栈并访问节点</li>
<li>然后转向右子树</li>
</ol>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(root *TreeNode)</span></span> inorder() []<span class="type">int</span> &#123;</span><br><span class="line">	res := []<span class="type">int</span>&#123;&#125;</span><br><span class="line">	<span class="keyword">if</span> root == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> res</span><br><span class="line">	&#125;</span><br><span class="line">	stack := []*TreeNode&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> root != <span class="literal">nil</span> || <span class="built_in">len</span>(stack) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> root != <span class="literal">nil</span> &#123;</span><br><span class="line">			stack = <span class="built_in">append</span>(stack, root)       <span class="comment">// 入栈，等待回溯</span></span><br><span class="line">			root = root.Lchild                <span class="comment">// 向左走</span></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			root = stack[<span class="built_in">len</span>(stack)<span class="number">-1</span>]        <span class="comment">// 出栈</span></span><br><span class="line">			stack = stack[:<span class="built_in">len</span>(stack)<span class="number">-1</span>]</span><br><span class="line">			res = <span class="built_in">append</span>(res, root.data)      <span class="comment">// 访问节点</span></span><br><span class="line">			root = root.Rchild                <span class="comment">// 转向右子树</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>示例题目：判断一棵二叉树是否为二叉搜索树</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">isValidBST</span><span class="params">(root *TreeNode)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">    stack := []*TreeNode&#123;&#125;</span><br><span class="line">    inorder := math.MinInt64</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">len</span>(stack) &gt; <span class="number">0</span> || root != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> root != <span class="literal">nil</span> &#123;</span><br><span class="line">            stack = <span class="built_in">append</span>(stack, root)</span><br><span class="line">            root = root.Left</span><br><span class="line">        &#125;</span><br><span class="line">        root = stack[<span class="built_in">len</span>(stack)<span class="number">-1</span>]</span><br><span class="line">        stack = stack[:<span class="built_in">len</span>(stack)<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> root.Val &lt;= inorder &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">        &#125;</span><br><span class="line">        inorder = root.Val</span><br><span class="line">        root = root.Right</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="后序遍历"><a href="#后序遍历" class="headerlink" title="后序遍历"></a>后序遍历</h3><ul>
<li>非递归实现关键：访问节点需保证其左右子树均已访问或为空</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(root *TreeNode)</span></span> Postorder() []<span class="type">int</span> &#123;</span><br><span class="line">	res := []<span class="type">int</span>&#123;&#125;</span><br><span class="line">	<span class="keyword">if</span> root == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> res</span><br><span class="line">	&#125;</span><br><span class="line">	stack := []*TreeNode&#123;&#125;</span><br><span class="line">	<span class="keyword">var</span> pre *TreeNode = <span class="literal">nil</span></span><br><span class="line">	stack = <span class="built_in">append</span>(stack, root)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> <span class="built_in">len</span>(stack) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		cur := stack[<span class="built_in">len</span>(stack)<span class="number">-1</span>]</span><br><span class="line">		<span class="comment">// 如果是叶子节点，或子节点已访问，则访问当前节点</span></span><br><span class="line">		<span class="keyword">if</span> (cur.Lchild == <span class="literal">nil</span> &amp;&amp; cur.Rchild == <span class="literal">nil</span>) || (pre != <span class="literal">nil</span> &amp;&amp; (pre == cur.Lchild || pre == cur.Rchild)) &#123;</span><br><span class="line">			res = <span class="built_in">append</span>(res, cur.data)</span><br><span class="line">			stack = stack[:<span class="built_in">len</span>(stack)<span class="number">-1</span>]</span><br><span class="line">			pre = cur <span class="comment">// 标记当前已访问</span></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> cur.Rchild != <span class="literal">nil</span> &#123;</span><br><span class="line">				stack = <span class="built_in">append</span>(stack, cur.Rchild)</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> cur.Lchild != <span class="literal">nil</span> &#123;</span><br><span class="line">				stack = <span class="built_in">append</span>(stack, cur.Lchild)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="删除二叉搜索树中的节点"><a href="#删除二叉搜索树中的节点" class="headerlink" title="删除二叉搜索树中的节点"></a>删除二叉搜索树中的节点</h2><ul>
<li><p>删除节点的四种情况：</p>
<ol>
<li><p><strong>叶子节点（无子节点）</strong></p>
<ul>
<li>直接删除，返回 <code>nil</code>。</li>
</ul>
</li>
<li><p><strong>只有左子树</strong></p>
<ul>
<li>用左子节点替代当前节点，返回 <code>root.Left</code>。</li>
</ul>
</li>
<li><p><strong>只有右子树</strong></p>
<ul>
<li>用右子节点替代当前节点，返回 <code>root.Right</code>。</li>
</ul>
</li>
<li><p><strong>左右子树都有</strong></p>
<ul>
<li>找右子树中最小的节点（即<strong>后继 successor</strong>），</li>
<li>用 successor 的值替代当前节点的值，</li>
<li>然后在右子树中递归删除该 successor 节点。</li>
</ul>
</li>
</ol>
</li>
<li><p>情况 4 的说明：</p>
<ul>
<li>**右子树的最小节点（successor）**不一定是叶子节点；</li>
<li>它一定没有左子节点，但<strong>可能有右子节点</strong>。</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  10                        11        </span><br><span class="line"> /  \                      /  \</span><br><span class="line">5    15                   5   15</span><br><span class="line">    /                         /  </span><br><span class="line">   11       --&gt;             13</span><br><span class="line">     \                     /  \  </span><br><span class="line">     13                   12  14</span><br><span class="line">    /  \</span><br><span class="line">   12   14</span><br></pre></td></tr></table></figure>

<ul>
<li><p>什么是“递归删除 successor 节点”？</p>
<ul>
<li>当我们删除一个节点（设为 <code>root</code>）且其有左右子树时，选择右子树中最小节点（successor）作为替代；</li>
<li>但此时右子树中仍存在原来的 successor 节点，因此需在右子树中递归删除该节点；</li>
<li>这样才能确保整棵树依然符合**二叉搜索树（BST）**的性质。</li>
</ul>
</li>
</ul>
<h2 id="实现示例"><a href="#实现示例" class="headerlink" title="实现示例"></a>实现示例</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">deleteNode</span><span class="params">(root *TreeNode, key <span class="type">int</span>)</span></span> *TreeNode &#123;</span><br><span class="line">	<span class="keyword">if</span> root == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> key &lt; root.Val &#123;</span><br><span class="line">		root.Left = deleteNode(root.Left, key)</span><br><span class="line">		<span class="keyword">return</span> root</span><br><span class="line">	&#125; <span class="keyword">else</span> <span class="keyword">if</span> key &gt; root.Val &#123;</span><br><span class="line">		root.Right = deleteNode(root.Right, key)</span><br><span class="line">		<span class="keyword">return</span> root</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//找到要删除的结点</span></span><br><span class="line">	<span class="keyword">if</span> root.Left == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> root.Right</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> root.Right == <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> root.Left</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 情况4：左右子树都有</span></span><br><span class="line">	<span class="comment">//需要找右子树的最小值的结点, 最小的一定在最左边</span></span><br><span class="line">	successor := root.Right</span><br><span class="line">	<span class="keyword">for</span> successor.Left != <span class="literal">nil</span> &#123;</span><br><span class="line">		successor = successor.Left</span><br><span class="line">	&#125;</span><br><span class="line">	successor.Right = deleteNode(root.Right, successor.Val)</span><br><span class="line">	successor.Left = root.Left</span><br><span class="line">	<span class="keyword">return</span> successor</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="树状数组（Fenwick-Tree-x2F-Binary-Indexed-Tree）"><a href="#树状数组（Fenwick-Tree-x2F-Binary-Indexed-Tree）" class="headerlink" title="树状数组（Fenwick Tree &#x2F; Binary Indexed Tree）"></a>树状数组（Fenwick Tree &#x2F; Binary Indexed Tree）</h2><ul>
<li><p><strong>适用场景</strong>：一维前缀和问题（如区间求和、频率统计等）</p>
</li>
<li><p><strong>核心思想</strong>：</p>
<ul>
<li>利用二进制的最低位（lowbit）来定位负责某段区间的节点</li>
<li>是一种空间压缩形式的前缀树结构</li>
</ul>
</li>
<li><p>一种可动态维护序列前缀和的数据结构，支持以下操作：</p>
<ul>
<li>**单点更新 <code>update(i, v)</code>**：将第 <code>i</code> 个位置的值增加 <code>v</code>（如本题中 <code>v = 1</code>）</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">update</span><span class="params">(i <span class="type">int</span>, v <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> i &lt;= n &#123;  <span class="comment">// n 是树状数组的长度</span></span><br><span class="line">        bit[i] += v</span><br><span class="line">        i += i &amp; -i  <span class="comment">// 跳到下一个负责这个区间的节点</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>**区间查询 <code>query(i)</code>**：查询区间 <code>[1..i]</code> 的前缀和</p>
<ul>
<li>通过跳跃式回溯累加，效率高</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 查询 bit[1] 到 bit[i] 的前缀和</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">query</span><span class="params">(i <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    res := <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i &gt; <span class="number">0</span> &#123;</span><br><span class="line">        res += bit[i]</span><br><span class="line">        i -= i &amp; -i  <span class="comment">// i &amp; -i 取最低位的 1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="query-p-的跳跃计算示意"><a href="#query-p-的跳跃计算示意" class="headerlink" title="query(p) 的跳跃计算示意"></a>query(p) 的跳跃计算示意</h3><ul>
<li>树状数组 <code>bit[]</code> 示意如下：</li>
</ul>
<table>
<thead>
<tr>
<th>下标（i）</th>
<th>bit[i]</th>
<th>表示的区间</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>2</td>
<td>sum(1)</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>sum(1..2)</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>sum(3)</td>
</tr>
<tr>
<td>4</td>
<td>3</td>
<td>sum(1..4)</td>
</tr>
<tr>
<td>5</td>
<td>0</td>
<td>sum(5)</td>
</tr>
<tr>
<td>6</td>
<td>0</td>
<td>sum(5..6)</td>
</tr>
<tr>
<td>7</td>
<td>0</td>
<td>sum(7)</td>
</tr>
<tr>
<td>8</td>
<td>?</td>
<td>sum(1..8)</td>
</tr>
</tbody></table>
<ul>
<li><p>查询 <code>query(5)</code> 实际执行过程如下：</p>
<ul>
<li>第一次：<code>p = 5</code> → <code>sum += bit[5] = 0</code> → <code>p = 5 - 1 = 4</code></li>
<li>第二次：<code>p = 4</code> → <code>sum += bit[4] = 3</code> → <code>p = 4 - 4 = 0</code></li>
<li>退出循环，结果为 <code>sum = 3</code></li>
</ul>
</li>
<li><p>实际加了哪些区间：</p>
<ul>
<li><code>bit[5]</code> → 表示 <code>[5]</code></li>
<li><code>bit[4]</code> → 表示 <code>[1..4]</code></li>
<li>所以 <code>sum[1..5] = bit[5] + bit[4]</code></li>
</ul>
</li>
</ul>
<h3 id="为什么-x-amp-x-能取得-x-的最低位-1？"><a href="#为什么-x-amp-x-能取得-x-的最低位-1？" class="headerlink" title="为什么 x &amp; (-x) 能取得 x 的最低位 1？"></a>为什么 <code>x &amp; (-x)</code> 能取得 <code>x</code> 的最低位 1？</h3><ul>
<li><p>原理：使用补码</p>
<ul>
<li><code>-x = ^x + 1</code>（按位取反再加 1）</li>
</ul>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">x     = <span class="number">00001100</span></span><br><span class="line">-x    = <span class="number">11110100</span></span><br><span class="line">----------------</span><br><span class="line">x &amp; -x = <span class="number">00000100</span>  <span class="comment">// 取出最低位的 1</span></span><br></pre></td></tr></table></figure>

<ul>
<li>补码运算确保 <code>x &amp; -x</code> 恰好保留最低位的 1，其它位互斥</li>
</ul>
<h3 id="树状数组的安全构造方式"><a href="#树状数组的安全构造方式" class="headerlink" title="树状数组的安全构造方式"></a>树状数组的安全构造方式</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计算最小安全长度（为离散化后的数组保留空间）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getSafeFenwickArraySize</span><span class="params">(n <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    nextPowerOf2 := <span class="number">1</span> &lt;&lt; bits.Len(<span class="type">uint</span>(n))</span><br><span class="line">    <span class="keyword">return</span> nextPowerOf2 + <span class="number">1</span> <span class="comment">// +1 处理边界</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="例题：315-计算右侧小于当前元素的个数"><a href="#例题：315-计算右侧小于当前元素的个数" class="headerlink" title="例题：315. 计算右侧小于当前元素的个数"></a>例题：<a href="https://leetcode.cn/problems/count-of-smaller-numbers-after-self/description/">315. 计算右侧小于当前元素的个数</a></h2><ul>
<li><strong>题意</strong>：返回数组 <code>counts</code>，其中 <code>counts[i]</code> 表示 <code>nums[i]</code> 右侧比它小的元素数量</li>
<li><strong>解法</strong>：树状数组 + 离散化优化空间</li>
</ul>
<h3 id="解题流程："><a href="#解题流程：" class="headerlink" title="解题流程："></a>解题流程：</h3><ol>
<li><p><strong>离散化</strong>：将原数组值映射到连续整数范围（防止值域过大）</p>
</li>
<li><p><strong>从后向前遍历</strong>：</p>
<ul>
<li>查询当前数 <strong>前面比它小</strong> 的数的出现次数 → <code>query(id - 1)</code></li>
<li>更新当前数出现次数 → <code>update(id)</code></li>
</ul>
</li>
<li><p><strong>树状数组操作时间复杂度：O(log n)</strong></p>
</li>
</ol>
<h3 id="实现代码："><a href="#实现代码：" class="headerlink" title="实现代码："></a>实现代码：</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">countSmaller</span><span class="params">(nums []<span class="type">int</span>)</span></span> []<span class="type">int</span> &#123;</span><br><span class="line">    <span class="comment">// 离散化映射：数值 -&gt; 索引</span></span><br><span class="line">    numToId := <span class="function"><span class="keyword">func</span><span class="params">(nums []<span class="type">int</span>)</span></span> <span class="keyword">map</span>[<span class="type">int</span>]<span class="type">int</span> &#123;</span><br><span class="line">        set := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">int</span>]<span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">        <span class="keyword">for</span> _, num := <span class="keyword">range</span> nums &#123;</span><br><span class="line">            set[num] = <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        a := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">0</span>, <span class="built_in">len</span>(set))</span><br><span class="line">        <span class="keyword">for</span> num := <span class="keyword">range</span> set &#123;</span><br><span class="line">            a = <span class="built_in">append</span>(a, num)</span><br><span class="line">        &#125;</span><br><span class="line">        sort.Ints(a)</span><br><span class="line">        m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">int</span>]<span class="type">int</span>)</span><br><span class="line">        <span class="keyword">for</span> i, num := <span class="keyword">range</span> a &#123;</span><br><span class="line">            m[num] = i + <span class="number">1</span>  <span class="comment">// 从 1 开始</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> m</span><br><span class="line">    &#125;(nums)</span><br><span class="line"></span><br><span class="line">    c := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="built_in">len</span>(nums)+<span class="number">5</span>)</span><br><span class="line">    lowBit := <span class="function"><span class="keyword">func</span><span class="params">(x <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> x &amp; -x</span><br><span class="line">    &#125;</span><br><span class="line">    query := <span class="function"><span class="keyword">func</span><span class="params">(pos <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">        ret := <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> pos &gt; <span class="number">0</span> &#123;</span><br><span class="line">            ret += c[pos]</span><br><span class="line">            pos -= lowBit(pos)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line">    &#125;</span><br><span class="line">    update := <span class="function"><span class="keyword">func</span><span class="params">(pos <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        <span class="keyword">for</span> pos &lt; <span class="built_in">len</span>(c) &#123;</span><br><span class="line">            c[pos]++</span><br><span class="line">            pos += lowBit(pos)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ans := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="built_in">len</span>(nums))</span><br><span class="line">    <span class="keyword">for</span> i := <span class="built_in">len</span>(nums) - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i-- &#123;</span><br><span class="line">        id := numToId[nums[i]]</span><br><span class="line">        ans[i] = query(id - <span class="number">1</span>)</span><br><span class="line">        update(id)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ans</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="线段树（Segment-Tree）"><a href="#线段树（Segment-Tree）" class="headerlink" title="线段树（Segment Tree）"></a>线段树（Segment Tree）</h2><ul>
<li><p><strong>适用场景</strong>：支持区间查询 + 单点或区间修改等</p>
</li>
<li><p><strong>典型用途</strong>：</p>
<ul>
<li>区间最大值、最小值、区间和</li>
<li>区间赋值、区间加法（懒标记 &#x2F; Lazy Propagation）</li>
</ul>
</li>
<li><p><strong>结构特征</strong>：</p>
<ul>
<li>完全二叉树结构</li>
<li>每个节点维护一个区间的信息</li>
<li>父节点信息由左右子树合并而来</li>
</ul>
</li>
</ul>
<h2 id="例题：699-掉落的方块"><a href="#例题：699-掉落的方块" class="headerlink" title="例题：699. 掉落的方块"></a>例题：<a href="https://leetcode.cn/problems/falling-squares/description/">699. 掉落的方块</a></h2><ul>
<li>问题：模拟落方块过程，返回每一步的最高高度</li>
<li>典型的线段树区间最大值更新与查询问题</li>
</ul>
<h3 id="解题流程：-1"><a href="#解题流程：-1" class="headerlink" title="解题流程："></a>解题流程：</h3><ol>
<li><p><strong>离散化所有坐标</strong>：防止空间浪费（坐标最大值可达 10^9）</p>
</li>
<li><p><strong>使用线段树</strong>维护每个区间的最大高度</p>
</li>
<li><p><strong>每次插入一个方块</strong>：</p>
<ul>
<li>查询当前 <code>[left, right]</code> 区间的最大高度 <code>h</code></li>
<li>更新该区间的值为 <code>h + sideLength</code></li>
<li>记录全局最大高度</li>
</ul>
</li>
</ol>
<h2 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h2><h2 id="例题：684-冗余连接"><a href="#例题：684-冗余连接" class="headerlink" title="例题：684. 冗余连接"></a>例题：<a href="https://leetcode.cn/problems/redundant-connection/description">684. 冗余连接</a></h2><ul>
<li>在含有一个环的无向图中找出一条可删边使其变为树</li>
</ul>
<h3 id="解题流程：-2"><a href="#解题流程：-2" class="headerlink" title="解题流程："></a>解题流程：</h3><ul>
<li>使用并查集判断边是否构成环：<ul>
<li>初始化每个节点为不同集合；<ul>
<li>遍历 edges 中每条边 (u, v)：<ul>
<li>如果 u 与 v 已在同一集合中，说明这条边构成环 → 返回它；</li>
<li>否则合并 u 和 v；</li>
</ul>
</li>
</ul>
</li>
<li>因为题目要求返回「最后构成环的边」，只需从前往后遍历一次即可。</li>
</ul>
</li>
</ul>
<h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">findRedundantConnection</span><span class="params">(edges [][]<span class="type">int</span>)</span></span> []<span class="type">int</span> &#123;</span><br><span class="line">    parent := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="built_in">len</span>(edges)+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="keyword">range</span> parent &#123;</span><br><span class="line">        parent[i] = i</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">var</span> find <span class="function"><span class="keyword">func</span><span class="params">(<span class="type">int</span>)</span></span> <span class="type">int</span></span><br><span class="line">    find = <span class="function"><span class="keyword">func</span><span class="params">(x <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> parent[x] != x &#123;</span><br><span class="line">            parent[x] = find(parent[x])</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> parent[x]</span><br><span class="line">    &#125;</span><br><span class="line">    union := <span class="function"><span class="keyword">func</span><span class="params">(from, to <span class="type">int</span>)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">        x, y := find(from), find(to)</span><br><span class="line">        <span class="keyword">if</span> x == y &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">        &#125;</span><br><span class="line">        parent[x] = y</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> _, e := <span class="keyword">range</span> edges &#123;</span><br><span class="line">        <span class="keyword">if</span> !union(e[<span class="number">0</span>], e[<span class="number">1</span>]) &#123;</span><br><span class="line">            <span class="keyword">return</span> e</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h1><h3 id="基本性质与操作（以最大堆为例）"><a href="#基本性质与操作（以最大堆为例）" class="headerlink" title="基本性质与操作（以最大堆为例）"></a>基本性质与操作（以最大堆为例）</h3><ol>
<li><p>最大堆的性质</p>
<ul>
<li>最大堆是一种<strong>完全二叉树</strong>，满足每个父节点的值都<strong>大于或等于</strong>其左右子节点的值。</li>
<li>虽然逻辑结构为树，实际通常使用<strong>数组</strong>来实现。</li>
</ul>
</li>
<li><p>元素的插入与删除方式</p>
<ul>
<li><p><strong>插入新节点</strong>：将元素追加到数组末尾，然后进行<strong>向上调整（Sift-Up）</strong>，直到堆序性恢复。</p>
</li>
<li><p><strong>删除任意节点</strong>：将目标节点与数组最后一个元素交换，然后删除最后一个元素：</p>
<ul>
<li>若新值<strong>大于父节点</strong> → 进行<strong>向上调整</strong>；</li>
<li>若新值<strong>小于任一子节点</strong> → 进行<strong>向下调整</strong>。</li>
</ul>
</li>
</ul>
</li>
<li><p>特殊操作：删除堆顶（最大值）</p>
<ul>
<li>删除堆顶（即数组第一个元素）时，将最后一个元素移至根节点位置，再进行<strong>向下调整（Sift-Down）</strong>，以恢复堆的结构。</li>
</ul>
</li>
<li><p>时间复杂度分析</p>
<ul>
<li><p><strong>插入</strong>或<strong>删除</strong>操作中，最多需要调整一条从叶节点到根节点或从根节点到叶节点的路径，因此时间复杂度均为：</p>
<blockquote>
<p>✅ <strong>O(log n)</strong></p>
</blockquote>
</li>
</ul>
</li>
<li><p>与二分查找的比较</p>
<ul>
<li><p><strong>二分查找</strong>的时间复杂度也是：</p>
<blockquote>
<p>✅ <strong>O(log n)</strong></p>
</blockquote>
</li>
<li><p>不过它依赖于<strong>有序数组</strong>，而最大堆只维护<strong>局部有序结构</strong>（即每个父节点大于子节点）。两者在原理和应用场景上存在本质区别。</p>
</li>
</ul>
</li>
</ol>
<h1 id="图"><a href="#图" class="headerlink" title="图"></a>图</h1><h2 id="无向图"><a href="#无向图" class="headerlink" title="无向图"></a>无向图</h2><ul>
<li><p>由两个部分组成：</p>
<ul>
<li><strong>顶点（Vertices）</strong>：图中的节点。</li>
<li><strong>边（Edges）</strong>：连接两个顶点的线段。</li>
</ul>
</li>
<li><p><strong>边用集合表示</strong>：一条边连接两个顶点，用 <code>&#123;A, B&#125;</code> 表示（不区分方向），区别于有向图中的 <code>(A, B)</code>。<br><strong>度（Degree）</strong>：一个顶点的度是连接它的边的数量（不考虑方向）。</p>
</li>
<li><p>无向图可以表示为：</p>
<ul>
<li>顶点：<code>&#123;A, B, C&#125;</code></li>
<li>边：<code>&#123;&#123;A, B&#125;, &#123;B, C&#125;&#125;</code></li>
</ul>
</li>
<li><p>图形示意：</p>
<ul>
<li><code>A —— B —— C</code></li>
</ul>
</li>
<li><p><strong>无向图的深度优先搜索（DFS）</strong></p>
<ul>
<li>从某个顶点开始；</li>
<li>标记为“已访问”；</li>
<li>遍历它的邻居；</li>
<li>对每一个未访问的邻居递归执行 DFS；</li>
<li>如果遇到没有未访问邻居的死胡同，则回退。</li>
</ul>
</li>
<li><p><strong>递归实现 DFS</strong>：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">graph, start, visited=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> visited <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        visited = <span class="built_in">set</span>()</span><br><span class="line">    <span class="built_in">print</span>(start)  <span class="comment"># 访问当前节点</span></span><br><span class="line">    visited.add(start)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> neighbor <span class="keyword">in</span> graph[start]:</span><br><span class="line">        <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">            dfs(graph, neighbor, visited)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">dfs(graph, <span class="string">&#x27;A&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>非递归实现（使用栈）</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dfs_iterative</span>(<span class="params">graph, start</span>):</span><br><span class="line">    visited = <span class="built_in">set</span>()</span><br><span class="line">    stack = [start]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> stack:</span><br><span class="line">        node = stack.pop()</span><br><span class="line">        <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">            <span class="built_in">print</span>(node)</span><br><span class="line">            visited.add(node)</span><br><span class="line">            <span class="comment"># 为了保持访问顺序，反转邻居顺序</span></span><br><span class="line">            <span class="keyword">for</span> neighbor <span class="keyword">in</span> <span class="built_in">reversed</span>(graph[node]):</span><br><span class="line">                <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">                    stack.append(neighbor)</span><br><span class="line"></span><br><span class="line">dfs_iterative(graph, <span class="string">&#x27;A&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>无向图 DFS 的注意事项</strong>：</p>
<ul>
<li><strong>防止死循环</strong>：必须使用 <code>visited</code> 集合记录已访问节点，因为无向图的边是双向的，若不记录，会在 A-B-A-B 间无限循环。</li>
<li><strong>图不连通的情况</strong>：只对一个起点 DFS 无法遍历所有节点。可对所有节点进行一次 DFS。</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dfs_all</span>(<span class="params">graph</span>):</span><br><span class="line">    visited = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> graph:</span><br><span class="line">        <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">            dfs(graph, node, visited)</span><br></pre></td></tr></table></figure>


<h2 id="有向图"><a href="#有向图" class="headerlink" title="有向图"></a>有向图</h2><h3 id="有向图的拓扑排序"><a href="#有向图的拓扑排序" class="headerlink" title="有向图的拓扑排序"></a>有向图的拓扑排序</h3><ul>
<li><p>拓扑排序（Topological Sorting）适用于 <strong>有向无环图（DAG，Directed Acyclic Graph）</strong>。其目标是将所有顶点排成一个线性序列，使得每条边 <code>u → v</code> 中，顶点 <code>u</code> 排在 <code>v</code> 的前面。</p>
</li>
<li><p>举例说明：</p>
<ul>
<li><strong>学习顺序</strong>：先学 A，再学 B，最后学 C。</li>
<li><strong>任务依赖</strong>：任务 B 必须在任务 A 完成后执行。</li>
<li>将任务抽象为节点，依赖关系为边，则问题转化为 DAG 的拓扑排序。</li>
</ul>
</li>
<li><p><strong>适用范围</strong>：</p>
<ul>
<li>必须是有向无环图（DAG）。</li>
<li>若图中存在环，则无法进行拓扑排序。</li>
</ul>
</li>
<li><p><strong>拓扑排序的两种常用算法</strong>：</p>
<ul>
<li><p><strong>方法一：Kahn 算法（入度表 + 队列）</strong></p>
<ul>
<li>统计所有顶点的入度。</li>
<li>将入度为 0 的顶点加入队列。</li>
<li>从队列中取出顶点 <code>u</code> 加入结果序列。</li>
<li>删除 <code>u</code> 指向的边（使相邻顶点 <code>v</code> 入度减 1）。</li>
<li>若 <code>v</code> 入度变为 0，加入队列。</li>
<li>重复以上过程直至队列为空。</li>
<li>若最终结果序列包含所有节点，则拓扑排序成功；否则图中存在环。</li>
</ul>
</li>
<li><p><strong>方法二：DFS 法（后序入栈）</strong></p>
<ul>
<li>从未访问的节点开始 DFS。</li>
<li>递归访问其所有后继节点。</li>
<li>当前节点所有后继访问完成后，将其压入栈中。</li>
<li>所有节点访问完成后，从栈顶依次弹出即为拓扑序列。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>常见应用场景</strong>：</p>
<ul>
<li>编译器模块依赖分析</li>
<li>项目任务调度</li>
<li>数据处理管道排序</li>
<li>课程安排问题（Leetcode 207、210）</li>
</ul>
</li>
</ul>
<h3 id="Kahn-算法（Golang-实现）："><a href="#Kahn-算法（Golang-实现）：" class="headerlink" title="Kahn 算法（Golang 实现）："></a>Kahn 算法（Golang 实现）：</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 拓扑排序（Kahn 算法）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">topologicalSort</span><span class="params">(graph <span class="keyword">map</span>[<span class="type">string</span>][]<span class="type">string</span>)</span></span> ([]<span class="type">string</span>, <span class="type">bool</span>) &#123;</span><br><span class="line">  inDegree := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span>)</span><br><span class="line">  <span class="keyword">var</span> result []<span class="type">string</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 初始化入度表</span></span><br><span class="line">  <span class="keyword">for</span> u := <span class="keyword">range</span> graph &#123;</span><br><span class="line">    <span class="keyword">if</span> _, ok := inDegree[u]; !ok &#123;</span><br><span class="line">      inDegree[u] = <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> _, v := <span class="keyword">range</span> graph[u] &#123;</span><br><span class="line">      inDegree[v]++</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 入度为 0 的节点入队</span></span><br><span class="line">  <span class="keyword">var</span> queue []<span class="type">string</span></span><br><span class="line">  <span class="keyword">for</span> node, deg := <span class="keyword">range</span> inDegree &#123;</span><br><span class="line">    <span class="keyword">if</span> deg == <span class="number">0</span> &#123;</span><br><span class="line">      queue = <span class="built_in">append</span>(queue, node)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 拓扑排序</span></span><br><span class="line">  <span class="keyword">for</span> <span class="built_in">len</span>(queue) &gt; <span class="number">0</span> &#123;</span><br><span class="line">    node := queue[<span class="number">0</span>]</span><br><span class="line">    queue = queue[<span class="number">1</span>:]</span><br><span class="line">    result = <span class="built_in">append</span>(result, node)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _, neighbor := <span class="keyword">range</span> graph[node] &#123;</span><br><span class="line">      inDegree[neighbor]--</span><br><span class="line">      <span class="keyword">if</span> inDegree[neighbor] == <span class="number">0</span> &#123;</span><br><span class="line">        queue = <span class="built_in">append</span>(queue, neighbor)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 判断是否存在环</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(result) != <span class="built_in">len</span>(inDegree) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result, <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  graph := <span class="keyword">map</span>[<span class="type">string</span>][]<span class="type">string</span>&#123;</span><br><span class="line">    <span class="string">&quot;A&quot;</span>: &#123;<span class="string">&quot;B&quot;</span>, <span class="string">&quot;C&quot;</span>&#125;,</span><br><span class="line">    <span class="string">&quot;B&quot;</span>: &#123;<span class="string">&quot;D&quot;</span>&#125;,</span><br><span class="line">    <span class="string">&quot;C&quot;</span>: &#123;<span class="string">&quot;D&quot;</span>&#125;,</span><br><span class="line">    <span class="string">&quot;D&quot;</span>: &#123;&#125;,</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  order, ok := topologicalSort(graph)</span><br><span class="line">  <span class="keyword">if</span> !ok &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;图中存在环，无法拓扑排序&quot;</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;拓扑排序结果：&quot;</span>, order)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>Kahn 算法的核心逻辑</strong>：</p>
<ul>
<li>每次只处理入度为 0 的节点，即“无依赖”的任务。</li>
<li>处理后从图中移除该节点影响（即更新其邻接节点的入度）。</li>
<li>保证每个节点的依赖都先被处理。</li>
</ul>
</li>
<li><p><strong>为什么 Kahn 算法只适用于 DAG？</strong></p>
<ul>
<li>如果存在环，某些节点将永远无法变为入度 0，导致无法完成排序。</li>
<li>若排序结果节点数 &lt; 总节点数，说明图中存在环。</li>
</ul>
</li>
</ul>
<p>✅ <strong>因此：Kahn 算法不仅能进行拓扑排序，还能用于判断图中是否存在环。</strong></p>
<ul>
<li><strong>Kahn 算法实质上是 BFS 的变种</strong>，关注“入度为 0”的节点而不是“邻接点”。</li>
</ul>
<h3 id="Kahn-算法-vs-广度优先搜索（BFS）"><a href="#Kahn-算法-vs-广度优先搜索（BFS）" class="headerlink" title="Kahn 算法 vs 广度优先搜索（BFS）"></a>Kahn 算法 vs 广度优先搜索（BFS）</h3><table>
<thead>
<tr>
<th>项目</th>
<th>Kahn 算法（拓扑排序）</th>
<th>广度优先搜索（BFS）</th>
</tr>
</thead>
<tbody><tr>
<td>遍历方式</td>
<td>一层一层，按入度为 0 的点</td>
<td>一层一层，按邻接点</td>
</tr>
<tr>
<td>使用数据结构</td>
<td>队列（Queue）</td>
<td>队列（Queue）</td>
</tr>
<tr>
<td>访问顺序</td>
<td>所有无依赖的点先访问</td>
<td>当前点的所有邻居先访问</td>
</tr>
<tr>
<td>主要用途</td>
<td>拓扑排序 &#x2F; 检测环</td>
<td>遍历所有可达节点</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>Kahn 算法 &#x3D; BFS 的拓扑排序版本</strong>，核心是基于“入度为 0”的节点层层推进，保证拓扑顺序合法。</p>
</blockquote>
<hr>
<h2 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h2><ol>
<li><p><code>for lower &lt;= upper</code> —— <strong>闭区间版本 <code>[lower, upper]</code></strong></p>
<ul>
<li><p><code>mid = (lower + upper) / 2</code>（向下取整）</p>
<ul>
<li>如果 <code>mid</code> 满足条件（要往左找更小或更左的）：<code>upper = mid - 1</code></li>
<li>如果不满足条件（要往右找）：<code>lower = mid + 1</code></li>
</ul>
</li>
<li><p><strong>是否跳过了 mid？</strong></p>
<ul>
<li>表面上看，<code>upper = mid - 1</code> 似乎跳过了 <code>mid</code></li>
<li>实际上，<code>mid</code> 已经被判断过，<code>lower</code> 没变，下一轮中 <code>lower == mid</code></li>
<li>循环仍会继续执行，直到 <code>lower &gt; upper</code> 时退出</li>
</ul>
</li>
<li><p><strong>示例分析：</strong></p>
<ul>
<li>在数组 <code>[3, 4, 5]</code> 中查找“第一个大于等于 4 的数”</li>
<li>初始区间为 <code>[3, 5]</code>，<code>mid = 4</code></li>
<li><code>mid = 4</code> 满足条件 → <code>upper = 3</code></li>
<li>下一轮区间为 <code>[3, 3]</code>，<code>mid = 3</code></li>
<li><code>mid = 3</code> 不满足条件 → <code>lower = 4</code></li>
<li>区间变为 <code>[4, 3]</code>，循环结束</li>
<li>返回 <code>lower = 4</code>，即最小满足条件的值</li>
</ul>
</li>
</ul>
</li>
<li><p><code>for lower &lt; upper</code> —— <strong>半开区间版本 <code>[lower, upper)</code></strong></p>
<ul>
<li>如果 <code>mid</code> 满足条件（要往左找）：<code>upper = mid</code></li>
<li>如果不满足条件：<code>lower = mid + 1</code></li>
<li>循环结束时 <code>lower == upper</code>，即为最小满足条件的位置</li>
</ul>
</li>
</ol>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><h2 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h2><ul>
<li>相邻元素两两比较并交换，使用双重循环；</li>
<li>若某次遍历中未发生任何交换，说明数组已有序，可提前结束；</li>
<li>代码示例：</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">bubbleSort</span><span class="params">(arr []<span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    n := <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">if</span> n &lt;= <span class="number">1</span> &#123;</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">        unChanged := <span class="literal">true</span></span><br><span class="line">        <span class="keyword">for</span> j := <span class="number">0</span>; j &lt; n-i<span class="number">-1</span>; j++ &#123;</span><br><span class="line">            <span class="keyword">if</span> arr[j] &gt; arr[j+<span class="number">1</span>] &#123;</span><br><span class="line">                arr[j], arr[j+<span class="number">1</span>] = arr[j+<span class="number">1</span>], arr[j]</span><br><span class="line">                unChanged = <span class="literal">false</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> unChanged &#123;</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h2><ul>
<li><p>通过一趟排序将序列划分为左右两个子区间，其中左边的元素都小于右边的元素，再分别对左右区间递归排序，从而实现整体有序。</p>
</li>
<li><p>分区逻辑说明（采用首元素为基准）：</p>
<ul>
<li>交替比较并交换元素值，最终确定基准值的位置；</li>
<li>每步都需判断 <code>low &lt; high</code>，不要遗漏；</li>
<li><code>high--</code> 与 <code>low++</code> 的条件是与 <code>temp</code>（基准值）进行比较。</li>
</ul>
</li>
<li><p>TopK 剪枝优化（用于只需前K个元素的场景）：</p>
<ul>
<li>若 <code>mid &gt; k</code>，递归处理左边；</li>
<li>若 <code>mid &lt; k</code>，递归处理右边。</li>
</ul>
</li>
<li><p>分区函数定义模板：</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">partition</span><span class="params">(arr []<span class="type">int</span>, low, high <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    <span class="comment">// 首先从 high 开始比较，循环 high--，跳出后赋值；</span></span><br><span class="line">    <span class="comment">// 然后从 low 开始比较，同理；</span></span><br><span class="line">    <span class="comment">// 每步都要判断 low &lt; high；</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>快速排序递归模板：</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> quick <span class="function"><span class="keyword">func</span><span class="params">(arr []<span class="type">int</span>, start, end <span class="type">int</span>)</span></span></span><br><span class="line">quick = <span class="function"><span class="keyword">func</span><span class="params">(arr []<span class="type">int</span>, start, end <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>代码示例：</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 升序快速排序</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">quickSort</span><span class="params">(arr []<span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> quick <span class="function"><span class="keyword">func</span><span class="params">(arr []<span class="type">int</span>, start, end <span class="type">int</span>)</span></span></span><br><span class="line">    quick = <span class="function"><span class="keyword">func</span><span class="params">(arr []<span class="type">int</span>, start, end <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> start &gt;= end &#123;</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        mid := partition(arr, start, end)</span><br><span class="line">        quick(arr, start, mid)</span><br><span class="line">        quick(arr, mid+<span class="number">1</span>, end)</span><br><span class="line">    &#125;</span><br><span class="line">    quick(arr, <span class="number">0</span>, <span class="built_in">len</span>(arr)<span class="number">-1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分区函数，low &lt; high 判断不要漏！</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">partition</span><span class="params">(arr []<span class="type">int</span>, low, high <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    temp := arr[low]</span><br><span class="line">    <span class="keyword">for</span> low &lt; high &#123;</span><br><span class="line">        <span class="keyword">for</span> low &lt; high &amp;&amp; arr[high] &gt;= temp &#123;</span><br><span class="line">            high--</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> low &lt; high &#123;</span><br><span class="line">            arr[low] = arr[high]</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> low &lt; high &amp;&amp; arr[low] &lt; temp &#123;</span><br><span class="line">            low++</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> low &lt; high &#123;</span><br><span class="line">            arr[high] = arr[low]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    arr[low] = temp</span><br><span class="line">    <span class="keyword">return</span> low</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 前K个最小值</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">quickSortTopK</span><span class="params">(arr []<span class="type">int</span>, k <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> quick <span class="function"><span class="keyword">func</span><span class="params">(arr []<span class="type">int</span>, start, end, k <span class="type">int</span>)</span></span></span><br><span class="line">    quick = <span class="function"><span class="keyword">func</span><span class="params">(arr []<span class="type">int</span>, start, end, k <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> start &gt;= end &#123;</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        mid := partition(arr, start, end)</span><br><span class="line">        <span class="keyword">if</span> mid &gt; k &#123;</span><br><span class="line">            quick(arr, start, mid, k)</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> mid &lt; k &#123;</span><br><span class="line">            quick(arr, mid+<span class="number">1</span>, end, k)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    quick(arr, <span class="number">0</span>, <span class="built_in">len</span>(arr)<span class="number">-1</span>, k)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h2><ol>
<li>堆是一种<strong>完全二叉树结构</strong>；</li>
<li><strong>最大堆</strong>：父节点 ≥ 子节点；<strong>最小堆</strong>：父节点 ≤ 子节点；</li>
</ol>
<ul>
<li><p><strong>实现步骤</strong>：</p>
<ol>
<li><p><strong>调整堆（自上而下）</strong>：</p>
<ul>
<li>函数签名：<code>adjust(nums []int, root int, length int)</code></li>
<li>从当前根节点开始，比较左右子节点，找出较大者与根交换，递归向下直到无需调整。</li>
</ul>
</li>
<li><p><strong>初始化堆</strong>：</p>
<ul>
<li>从最后一个非叶子节点（<code>length/2</code>）开始，依次向上调整；</li>
</ul>
</li>
<li><p><strong>堆排序过程</strong>：</p>
<ul>
<li>每次将堆顶元素与末尾交换，再对堆顶进行调整；</li>
<li>排序范围逐步缩小，直到全部有序。</li>
</ul>
</li>
</ol>
</li>
<li><p><strong>最大堆调整函数</strong>：</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">adjust</span><span class="params">(nums []<span class="type">int</span>, root, length <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    child := root*<span class="number">2</span> + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> child &lt; length &#123;</span><br><span class="line">        <span class="keyword">if</span> child+<span class="number">1</span> &lt; length &amp;&amp; nums[child+<span class="number">1</span>] &gt; nums[child] &#123;</span><br><span class="line">            child++</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> nums[child] &lt;= nums[root] &#123;</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        nums[child], nums[root] = nums[root], nums[child]</span><br><span class="line">        root = child</span><br><span class="line">        child = root*<span class="number">2</span> + <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>代码示例：</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">heapSort</span><span class="params">(nums []<span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 初始化堆（自底向上）</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="built_in">len</span>(nums) / <span class="number">2</span>; i &gt;= <span class="number">0</span>; i-- &#123;</span><br><span class="line">        adjust(nums, i, <span class="built_in">len</span>(nums))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 排序过程</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="built_in">len</span>(nums) - <span class="number">1</span>; i &gt; <span class="number">0</span>; i-- &#123;</span><br><span class="line">        nums[i], nums[<span class="number">0</span>] = nums[<span class="number">0</span>], nums[i]</span><br><span class="line">        adjust(nums, <span class="number">0</span>, i)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** 最大堆取 TopK（前K大）且有序 */</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">heapSortTopK</span><span class="params">(nums []<span class="type">int</span>, k <span class="type">int</span>)</span></span> []<span class="type">int</span> &#123;</span><br><span class="line">    <span class="comment">// 初始化最大堆</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="built_in">len</span>(nums) / <span class="number">2</span>; i &gt;= <span class="number">0</span>; i-- &#123;</span><br><span class="line">        adjust(nums, i, <span class="built_in">len</span>(nums))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 取出前K大元素</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="built_in">len</span>(nums) - <span class="number">1</span>; i &gt; <span class="built_in">len</span>(nums)<span class="number">-1</span>-k; i-- &#123;</span><br><span class="line">        nums[i], nums[<span class="number">0</span>] = nums[<span class="number">0</span>], nums[i]</span><br><span class="line">        adjust(nums, <span class="number">0</span>, i)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nums[<span class="built_in">len</span>(nums)-k:]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>⚠️注意事项：</p>
<ul>
<li>初始化堆：自底向上遍历构建，但每个节点的调整是自上而下；</li>
<li>排序时：堆顶与尾部交换，再调整堆顶；</li>
<li><code>adjust</code> 函数中需确保越界处理、优先选择较大子节点交换；</li>
</ul>
</blockquote>
<h1 id="贪心算法（Greedy）"><a href="#贪心算法（Greedy）" class="headerlink" title="贪心算法（Greedy）"></a>贪心算法（Greedy）</h1><ul>
<li><p><strong>贪心算法：通过局部最优解实现全局最优</strong></p>
</li>
<li><p><a href="https://leetcode.cn/problems/jump-game/description/">55. 跳跃游戏</a></p>
<ul>
<li>给定一个非负整数数组 <code>nums</code>，你最初位于数组的第一个下标。数组中的每个元素代表你在该位置可以跳跃的最大长度。</li>
<li>判断你是否能够到达最后一个下标</li>
</ul>
</li>
<li><p>遍历数组，并实时维护「最远可以到达的位置」</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">canJump</span><span class="params">(nums []<span class="type">int</span>)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">    mostIndex := <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(nums); i++ &#123;</span><br><span class="line">        <span class="keyword">if</span> i &lt;= mostIndex &#123;</span><br><span class="line">            mostIndex = max(mostIndex, i+nums[i])</span><br><span class="line">            <span class="keyword">if</span> mostIndex &gt;= <span class="built_in">len</span>(nums)<span class="number">-1</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><a href="https://leetcode.cn/problems/jump-game-ii/description/">45. 跳跃游戏 II</a></p>
<ul>
<li>计算到达最后一个位置的最小跳跃次数</li>
</ul>
</li>
<li><p><strong>贪心 + 正向查找「可达的最远位置」</strong></p>
<ul>
<li>每次在当前跳跃的范围内，选择可以跳得最远的位置，作为下一跳的终点</li>
</ul>
</li>
<li><p><strong>贪心策略的正确性：</strong></p>
<ul>
<li>在当前跳跃范围内尽量跳得远，可以最大化下一跳的「选择空间」</li>
<li>避免走回头路或多跳一次的情况</li>
</ul>
</li>
<li><p><strong>为什么不遍历到最后一个元素？</strong></p>
<ul>
<li><p>跳到最后一个位置时，必然是在前一步完成跳跃</p>
</li>
<li><p>如果访问 <code>i == len(nums) - 1</code>，可能导致「多跳一步」</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">jump</span><span class="params">(nums []<span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    end, farthest := <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    steps := <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(nums)<span class="number">-1</span>; i++ &#123;</span><br><span class="line">        farthest = max(farthest, i+nums[i])</span><br><span class="line">        <span class="keyword">if</span> i == end &#123;</span><br><span class="line">            steps++</span><br><span class="line">            end = farthest</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> steps</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">max</span><span class="params">(a, b <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> a &gt; b &#123;</span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h1 id="动态规划（Dynamic-Programming）"><a href="#动态规划（Dynamic-Programming）" class="headerlink" title="动态规划（Dynamic Programming）"></a>动态规划（Dynamic Programming）</h1><ul>
<li><p><strong>动态规划的本质</strong>：通过<strong>穷举所有可能解法</strong>来寻找最优解。</p>
<ul>
<li>常见的穷举方式有两种：<strong>回溯算法</strong>和<strong>动态规划</strong>。回溯是暴力尝试每种可能，动态规划则利用<strong>状态转移方程</strong>推导各个状态。</li>
<li>动态规划相比暴力穷举更高效，其核心优势在于：<strong>利用状态转移 + 记忆</strong>，<strong>消除重复计算的子问题（重叠子问题）</strong>。</li>
</ul>
</li>
<li><p>动态规划问题通常具有大量<strong>重叠子问题</strong>，直接穷举效率极低，因此需借助以下两种优化方式：</p>
<ul>
<li>使用 <strong>备忘录（记忆化递归）</strong> 或 <strong>DP table（递推表格）</strong> 来<strong>避免重复计算</strong>；</li>
<li>其中，<strong>记忆化递归为自顶向下</strong>，<strong>DP table 为自底向上</strong>。</li>
</ul>
</li>
<li><p><strong>动态规划 &#x3D; 穷举 + 剪枝</strong></p>
</li>
<li><p>动态规划的标准解题流程：</p>
<ol>
<li>明确“<strong>状态</strong>”和“<strong>选择</strong>”；</li>
<li>定义 <code>dp</code> 数组或函数的含义；</li>
<li>写出<strong>状态转移方程（递推关系）</strong>。</li>
</ol>
</li>
<li><p>常通过<strong>状态压缩</strong>优化空间复杂度，例如将 <code>O(N^2)</code> 降为 <code>O(N)</code>。</p>
</li>
</ul>
<h2 id="背包问题（Knapsack）"><a href="#背包问题（Knapsack）" class="headerlink" title="背包问题（Knapsack）"></a>背包问题（Knapsack）</h2><h3 id="✅-分类依据：每个物品的使用次数是否受限"><a href="#✅-分类依据：每个物品的使用次数是否受限" class="headerlink" title="✅ 分类依据：每个物品的使用次数是否受限"></a>✅ 分类依据：<strong>每个物品的使用次数是否受限</strong></h3><table>
<thead>
<tr>
<th>问题类型</th>
<th>每种物品使用次数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0-1 背包问题</strong></td>
<td>最多使用一次</td>
<td>每件物品要么选，要么不选，不能重复使用。</td>
</tr>
<tr>
<td><strong>子集和问题</strong></td>
<td>最多使用一次</td>
<td>0-1 背包的特例：目标是恰好凑出某个和，而非最大价值。</td>
</tr>
<tr>
<td><strong>完全背包问题</strong></td>
<td>可无限次使用</td>
<td>每种物品可选多次，适用于硬币兑换、无限供给的资源选择等场景。</td>
</tr>
</tbody></table>
<h3 id="🎯-拓展理解："><a href="#🎯-拓展理解：" class="headerlink" title="🎯 拓展理解："></a>🎯 拓展理解：</h3><ul>
<li><strong>0-1 背包</strong> &#x3D; 最经典模型，用于资源受限问题。</li>
<li><strong>子集和问题</strong> &#x3D; 判断“是否可以凑出某个值”，不关心价值。</li>
<li><strong>完全背包</strong> &#x3D; 每种物品无限可选，常见于无限物品、找零等问题。</li>
</ul>
<h3 id="0-1-背包问题"><a href="#0-1-背包问题" class="headerlink" title="0-1 背包问题"></a>0-1 背包问题</h3><ul>
<li><p><strong>题目描述</strong></p>
<ul>
<li>给定一个容量为 <code>W</code> 的背包，以及 <code>N</code> 个物品，每个物品有：重量 <code>wt[i]</code> 和价值 <code>val[i]</code></li>
<li>每种物品只能选择一次，求在不超过总容量 <code>W</code> 的前提下，最大可获得的总价值。</li>
</ul>
</li>
<li><p><strong>解题思路</strong></p>
<ul>
<li><p>状态定义：<code>dp[i][w]</code> 表示前 <code>i</code> 个物品中，容量为 <code>w</code> 的背包所能达到的最大价值。</p>
</li>
<li><p>状态转移：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> w &lt; wt[i<span class="number">-1</span>]:</span><br><span class="line">    dp[i][w] = dp[i<span class="number">-1</span>][w]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    dp[i][w] = max(dp[i<span class="number">-1</span>][w], dp[i<span class="number">-1</span>][w - wt[i<span class="number">-1</span>]] + val[i<span class="number">-1</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>初始化：</p>
<ul>
<li><code>dp[0][..] = 0</code>：没有物品可选，价值为 0；</li>
<li><code>dp[..][0] = 0</code>：背包容量为 0，价值也为 0。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>代码实现</strong></p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">knapsack</span><span class="params">(W <span class="type">int</span>, wt, val []<span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    N := <span class="built_in">len</span>(wt)</span><br><span class="line">    dp := <span class="built_in">make</span>([][]<span class="type">int</span>, N+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="keyword">range</span> dp &#123;</span><br><span class="line">        dp[i] = <span class="built_in">make</span>([]<span class="type">int</span>, W+<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= N; i++ &#123;</span><br><span class="line">        <span class="keyword">for</span> w := <span class="number">1</span>; w &lt;= W; w++ &#123;</span><br><span class="line">            <span class="keyword">if</span> w &lt; wt[i<span class="number">-1</span>] &#123;</span><br><span class="line">                dp[i][w] = dp[i<span class="number">-1</span>][w]</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                dp[i][w] = max(dp[i<span class="number">-1</span>][w], dp[i<span class="number">-1</span>][w - wt[i<span class="number">-1</span>]] + val[i<span class="number">-1</span>])</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[N][W]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">max</span><span class="params">(a, b <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> a &gt; b &#123;</span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="子集背包问题（Subset-Sum）"><a href="#子集背包问题（Subset-Sum）" class="headerlink" title="子集背包问题（Subset Sum）"></a>子集背包问题（Subset Sum）</h3><ul>
<li><p><strong>Leetcode 416. <a href="https://leetcode.cn/problems/partition-equal-subset-sum/description/">分割等和子集</a></strong></p>
<ul>
<li>给定一个只包含正整数的非空数组 <code>nums</code>，判断是否可以将其分割为两个子集，且两个子集的元素和相等。</li>
<li>转换为背包问题：给一个容量为 <code>sum / 2</code> 的背包，判断是否可以从数组中选出若干数字恰好装满它。</li>
</ul>
</li>
<li><p><strong>解题思路</strong></p>
<ul>
<li>状态定义：<code>dp[i][j]</code> 表示前 <code>i</code> 个数中，是否存在子集和为 <code>j</code>。</li>
<li>状态转移：</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> j &lt; nums[i]:</span><br><span class="line">    dp[i][j] = dp[i<span class="number">-1</span>][j]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    dp[i][j] = dp[i<span class="number">-1</span>][j] || dp[i<span class="number">-1</span>][j - nums[i]]</span><br></pre></td></tr></table></figure>

<ul>
<li><p>初始化：</p>
<ul>
<li><code>dp[..][0] = true</code>：背包容量为 0，总能装满；</li>
<li><code>dp[0][nums[0]] = true</code>：只有一个数且恰好等于容量；</li>
</ul>
</li>
<li><p>剪枝条件：</p>
<ul>
<li>若 <code>sum</code> 为奇数，直接返回 <code>false</code>；</li>
<li>若某元素大于 <code>sum / 2</code>，可提前跳过。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>二维数组实现</strong></p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">canPartition</span><span class="params">(nums []<span class="type">int</span>)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">    sum := <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _, num := <span class="keyword">range</span> nums &#123;</span><br><span class="line">        sum += num</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> sum%<span class="number">2</span> != <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">    target := sum / <span class="number">2</span></span><br><span class="line">    N := <span class="built_in">len</span>(nums)</span><br><span class="line"></span><br><span class="line">    dp := <span class="built_in">make</span>([][]<span class="type">bool</span>, N)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="keyword">range</span> dp &#123;</span><br><span class="line">        dp[i] = <span class="built_in">make</span>([]<span class="type">bool</span>, target+<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; N; i++ &#123;</span><br><span class="line">        dp[i][<span class="number">0</span>] = <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> nums[<span class="number">0</span>] &lt;= target &#123;</span><br><span class="line">        dp[<span class="number">0</span>][nums[<span class="number">0</span>]] = <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">1</span>; i &lt; N; i++ &#123;</span><br><span class="line">        <span class="keyword">for</span> j := <span class="number">1</span>; j &lt;= target; j++ &#123;</span><br><span class="line">            <span class="keyword">if</span> j &lt; nums[i] &#123;</span><br><span class="line">                dp[i][j] = dp[i<span class="number">-1</span>][j]</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                dp[i][j] = dp[i<span class="number">-1</span>][j] || dp[i<span class="number">-1</span>][j - nums[i]]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[N<span class="number">-1</span>][target]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>状态压缩：一维优化版本（倒序）</strong></li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">canPartition</span><span class="params">(nums []<span class="type">int</span>)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">    sum := <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _, num := <span class="keyword">range</span> nums &#123;</span><br><span class="line">        sum += num</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> sum%<span class="number">2</span> != <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">    target := sum / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    dp := <span class="built_in">make</span>([]<span class="type">bool</span>, target+<span class="number">1</span>)</span><br><span class="line">    dp[<span class="number">0</span>] = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _, num := <span class="keyword">range</span> nums &#123;</span><br><span class="line">        <span class="keyword">for</span> j := target; j &gt;= num; j-- &#123;</span><br><span class="line">            dp[j] = dp[j] || dp[j - num]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[target]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="完全背包问题（Unbounded-Knapsack）"><a href="#完全背包问题（Unbounded-Knapsack）" class="headerlink" title="完全背包问题（Unbounded Knapsack）"></a>完全背包问题（Unbounded Knapsack）</h3><ul>
<li><p><strong>Leetcode 518. <a href="https://leetcode.cn/problems/coin-change-ii/description/">零钱兑换 II</a></strong></p>
<ul>
<li>给定一个背包容量为 <code>amount</code>，以及一个物品数组 <code>coins</code>（可重复使用），求有多少种不同的方法可以凑出该金额。</li>
</ul>
</li>
<li><p><strong>解题思路</strong></p>
<ul>
<li><p>状态定义：<code>dp[i][j]</code> 表示使用前 <code>i</code> 种硬币，凑出金额 <code>j</code> 的方法数。</p>
</li>
<li><p>状态转移：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> j &lt; coins[i<span class="number">-1</span>]:</span><br><span class="line">    dp[i][j] = dp[i<span class="number">-1</span>][j]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    dp[i][j] = dp[i<span class="number">-1</span>][j] + dp[i][j - coins[i<span class="number">-1</span>]]</span><br></pre></td></tr></table></figure></li>
<li><p>初始化：</p>
<ul>
<li><code>dp[0][..] = 0</code>：没有硬币无法组成正金额；</li>
<li><code>dp[..][0] = 1</code>：金额为 0，只有 1 种凑法（什么都不选）。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>二维数组实现</strong></p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">change</span><span class="params">(amount <span class="type">int</span>, coins []<span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    n := <span class="built_in">len</span>(coins)</span><br><span class="line">    dp := <span class="built_in">make</span>([][]<span class="type">int</span>, n+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="keyword">range</span> dp &#123;</span><br><span class="line">        dp[i] = <span class="built_in">make</span>([]<span class="type">int</span>, amount+<span class="number">1</span>)</span><br><span class="line">        dp[i][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= n; i++ &#123;</span><br><span class="line">        <span class="keyword">for</span> j := <span class="number">0</span>; j &lt;= amount; j++ &#123;</span><br><span class="line">            <span class="keyword">if</span> j &lt; coins[i<span class="number">-1</span>] &#123;</span><br><span class="line">                dp[i][j] = dp[i<span class="number">-1</span>][j]</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                dp[i][j] = dp[i<span class="number">-1</span>][j] + dp[i][j - coins[i<span class="number">-1</span>]]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[n][amount]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>一维数组优化（正序遍历）</strong></li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">change</span><span class="params">(amount <span class="type">int</span>, coins []<span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    dp := <span class="built_in">make</span>([]<span class="type">int</span>, amount+<span class="number">1</span>)</span><br><span class="line">    dp[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _, coin := <span class="keyword">range</span> coins &#123;</span><br><span class="line">        <span class="keyword">for</span> j := coin; j &lt;= amount; j++ &#123;</span><br><span class="line">            dp[j] += dp[j - coin]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[amount]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="回溯"><a href="#回溯" class="headerlink" title="回溯"></a>回溯</h1><ul>
<li>适用于排列、组合、子集等构造类枚举问题</li>
</ul>
<h3 id="通用回溯模板总结"><a href="#通用回溯模板总结" class="headerlink" title="通用回溯模板总结"></a>通用回溯模板总结</h3><table>
<thead>
<tr>
<th>题型</th>
<th>递归参数</th>
<th>关键点</th>
<th>重复处理策略</th>
<th>代码模板示例（Go 伪码简化）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>排列（Permutation）</strong></td>
<td>无需起点</td>
<td>需要标记已使用元素 <code>used[]</code></td>
<td>排序 + <code>used</code> + 跳过相邻重复元素</td>
<td>见 <em>排列 II</em> 模板</td>
</tr>
<tr>
<td><strong>组合 &#x2F; 子集（Combination &#x2F; Subset）</strong></td>
<td>需要起点</td>
<td>控制遍历起点，防止重复使用前面元素</td>
<td>排序 + 跳过同层相邻重复元素</td>
<td>见 <em>组合 II &#x2F; 子集 II</em> 模板</td>
</tr>
</tbody></table>
<h2 id="1-排列（Permutation）"><a href="#1-排列（Permutation）" class="headerlink" title="1. 排列（Permutation）"></a>1. 排列（Permutation）</h2><h3 id="1-1-无重复元素-—-基础排列（46-全排列）"><a href="#1-1-无重复元素-—-基础排列（46-全排列）" class="headerlink" title="1.1 无重复元素 — 基础排列（46. 全排列）"></a>1.1 无重复元素 — 基础排列（<a href="https://leetcode.cn/problems/permutations/description/">46. 全排列</a>）</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">permute</span><span class="params">(nums []<span class="type">int</span>)</span></span> [][]<span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> res [][]<span class="type">int</span></span><br><span class="line">    <span class="keyword">var</span> path []<span class="type">int</span></span><br><span class="line">    used := <span class="built_in">make</span>([]<span class="type">bool</span>, <span class="built_in">len</span>(nums))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> dfs <span class="function"><span class="keyword">func</span><span class="params">()</span></span></span><br><span class="line">    dfs = <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(path) == <span class="built_in">len</span>(nums) &#123;</span><br><span class="line">            res = <span class="built_in">append</span>(res, <span class="built_in">append</span>([]<span class="type">int</span>(<span class="literal">nil</span>), path...))</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(nums); i++ &#123;</span><br><span class="line">            <span class="keyword">if</span> used[i] &#123;</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            &#125;</span><br><span class="line">            used[i] = <span class="literal">true</span></span><br><span class="line">            path = <span class="built_in">append</span>(path, nums[i])</span><br><span class="line">            dfs()</span><br><span class="line">            path = path[:<span class="built_in">len</span>(path)<span class="number">-1</span>]</span><br><span class="line">            used[i] = <span class="literal">false</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dfs()</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="1-2-有重复元素-—-排列-II（47-全排列-II）"><a href="#1-2-有重复元素-—-排列-II（47-全排列-II）" class="headerlink" title="1.2 有重复元素 — 排列 II（47. 全排列 II）"></a>1.2 有重复元素 — 排列 II（<a href="https://leetcode.cn/problems/permutations-ii/">47. 全排列 II</a>）</h3><ul>
<li><p>相较于 46，需增加：</p>
<ul>
<li>排序以便判断相邻重复</li>
<li>重复剪枝：跳过已访问前一个相同元素</li>
</ul>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">permuteUnique</span><span class="params">(nums []<span class="type">int</span>)</span></span> [][]<span class="type">int</span> &#123;</span><br><span class="line">    sort.Ints(nums)</span><br><span class="line">    <span class="keyword">var</span> res [][]<span class="type">int</span></span><br><span class="line">    <span class="keyword">var</span> path []<span class="type">int</span></span><br><span class="line">    used := <span class="built_in">make</span>([]<span class="type">bool</span>, <span class="built_in">len</span>(nums))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> dfs <span class="function"><span class="keyword">func</span><span class="params">()</span></span></span><br><span class="line">    dfs = <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(path) == <span class="built_in">len</span>(nums) &#123;</span><br><span class="line">            res = <span class="built_in">append</span>(res, <span class="built_in">append</span>([]<span class="type">int</span>(<span class="literal">nil</span>), path...))</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(nums); i++ &#123;</span><br><span class="line">            <span class="keyword">if</span> used[i] &#123;</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//只能先用同一组重复数字的“第一个”，不能先用后面的。</span></span><br><span class="line">			<span class="comment">//如果现在选择了后一个重复元素，就会导致重复排列。</span></span><br><span class="line">			<span class="comment">//!used[i-1]表明前一个相同的还没用，所以你这边就别先用了</span></span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span> &amp;&amp; nums[i] == nums[i<span class="number">-1</span>] &amp;&amp; !used[i<span class="number">-1</span>] &#123;</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            &#125;</span><br><span class="line">            used[i] = <span class="literal">true</span></span><br><span class="line">            path = <span class="built_in">append</span>(path, nums[i])</span><br><span class="line">            dfs()</span><br><span class="line">            path = path[:<span class="built_in">len</span>(path)<span class="number">-1</span>]</span><br><span class="line">            used[i] = <span class="literal">false</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dfs()</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-组合-x2F-子集（Combination-x2F-Subset）"><a href="#2-组合-x2F-子集（Combination-x2F-Subset）" class="headerlink" title="2. 组合 &#x2F; 子集（Combination &#x2F; Subset）"></a>2. 组合 &#x2F; 子集（Combination &#x2F; Subset）</h2><blockquote>
<p>本质都是选取元素的子集，区别主要在题意和输出要求。</p>
</blockquote>
<h3 id="2-1-无重复元素-—-子集-I（78-子集）"><a href="#2-1-无重复元素-—-子集-I（78-子集）" class="headerlink" title="2.1 无重复元素 — 子集 I（78. 子集）"></a>2.1 无重复元素 — 子集 I（<a href="https://leetcode.cn/problems/subsets/">78. 子集</a>）</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">subsets</span><span class="params">(nums []<span class="type">int</span>)</span></span> [][]<span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> res [][]<span class="type">int</span></span><br><span class="line">    <span class="keyword">var</span> path []<span class="type">int</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> dfs <span class="function"><span class="keyword">func</span><span class="params">(start <span class="type">int</span>)</span></span></span><br><span class="line">    dfs = <span class="function"><span class="keyword">func</span><span class="params">(start <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        res = <span class="built_in">append</span>(res, <span class="built_in">append</span>([]<span class="type">int</span>(<span class="literal">nil</span>), path...))</span><br><span class="line">        <span class="keyword">for</span> i := start; i &lt; <span class="built_in">len</span>(nums); i++ &#123;</span><br><span class="line">            path = <span class="built_in">append</span>(path, nums[i])</span><br><span class="line">            dfs(i + <span class="number">1</span>)</span><br><span class="line">            path = path[:<span class="built_in">len</span>(path)<span class="number">-1</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dfs(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="2-2-有重复元素-—-子集-II（90-子集-II）"><a href="#2-2-有重复元素-—-子集-II（90-子集-II）" class="headerlink" title="2.2 有重复元素 — 子集 II（90. 子集 II）"></a>2.2 有重复元素 — 子集 II（<a href="https://leetcode.cn/problems/subsets-ii/">90. 子集 II</a>）</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">subsetsWithDup</span><span class="params">(nums []<span class="type">int</span>)</span></span> [][]<span class="type">int</span> &#123;</span><br><span class="line">    sort.Ints(nums)</span><br><span class="line">    <span class="keyword">var</span> res [][]<span class="type">int</span></span><br><span class="line">    <span class="keyword">var</span> path []<span class="type">int</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> dfs <span class="function"><span class="keyword">func</span><span class="params">(start <span class="type">int</span>)</span></span></span><br><span class="line">    dfs = <span class="function"><span class="keyword">func</span><span class="params">(start <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        res = <span class="built_in">append</span>(res, <span class="built_in">append</span>([]<span class="type">int</span>(<span class="literal">nil</span>), path...))</span><br><span class="line">        <span class="keyword">for</span> i := start; i &lt; <span class="built_in">len</span>(nums); i++ &#123;</span><br><span class="line">            <span class="keyword">if</span> i &gt; start &amp;&amp; nums[i] == nums[i<span class="number">-1</span>] &#123;</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            &#125;</span><br><span class="line">            path = <span class="built_in">append</span>(path, nums[i])</span><br><span class="line">            dfs(i + <span class="number">1</span>)</span><br><span class="line">            path = path[:<span class="built_in">len</span>(path)<span class="number">-1</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dfs(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="子集的另一种方式：不使用-for-循环（显式选与不选）"><a href="#子集的另一种方式：不使用-for-循环（显式选与不选）" class="headerlink" title="子集的另一种方式：不使用 for 循环（显式选与不选）"></a>子集的另一种方式：不使用 for 循环（显式选与不选）</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">subsetsDfs</span><span class="params">(nums []<span class="type">int</span>)</span></span> [][]<span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> res [][]<span class="type">int</span></span><br><span class="line">    <span class="keyword">var</span> set []<span class="type">int</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> dfs <span class="function"><span class="keyword">func</span><span class="params">(<span class="type">int</span>)</span></span></span><br><span class="line">    dfs = <span class="function"><span class="keyword">func</span><span class="params">(cur <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> cur == <span class="built_in">len</span>(nums) &#123;</span><br><span class="line">            res = <span class="built_in">append</span>(res, <span class="built_in">append</span>([]<span class="type">int</span>(<span class="literal">nil</span>), set...))</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 选择当前</span></span><br><span class="line">        set = <span class="built_in">append</span>(set, nums[cur])</span><br><span class="line">        dfs(cur + <span class="number">1</span>)</span><br><span class="line">        <span class="comment">// 撤销选择</span></span><br><span class="line">        set = set[:<span class="built_in">len</span>(set)<span class="number">-1</span>]</span><br><span class="line">        <span class="comment">// 不选择当前</span></span><br><span class="line">        dfs(cur + <span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    dfs(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="总结要点"><a href="#总结要点" class="headerlink" title="总结要点"></a>总结要点</h2><table>
<thead>
<tr>
<th>特征</th>
<th>排列（Permutation）</th>
<th>组合 &#x2F; 子集（Combination &#x2F; Subset）</th>
</tr>
</thead>
<tbody><tr>
<td>是否用 <code>used</code></td>
<td>是</td>
<td>否（一般）</td>
</tr>
<tr>
<td>是否排序</td>
<td>有重复元素时必须排序</td>
<td>同左</td>
</tr>
<tr>
<td>是否有起点参数</td>
<td>无需（但可选）</td>
<td>必须有，通常为 <code>start</code></td>
</tr>
<tr>
<td>去重策略</td>
<td><code>i &gt; 0 &amp;&amp; nums[i]==nums[i-1] &amp;&amp; !used[i-1]</code></td>
<td><code>i &gt; start &amp;&amp; nums[i]==nums[i-1]</code> 跳过</td>
</tr>
<tr>
<td>递归形式</td>
<td><code>dfs()</code> &#x2F; <code>dfs(index)</code></td>
<td><code>dfs(start int)</code></td>
</tr>
</tbody></table>
<h2 id="扩展说明"><a href="#扩展说明" class="headerlink" title="扩展说明"></a>扩展说明</h2><ul>
<li><p><strong>全局变量 vs 参数传递：</strong></p>
<ul>
<li>全局变量：书写更简洁，多个函数共享更方便。</li>
<li>参数传递：封装更清晰，递归状态更独立，减少副作用。</li>
</ul>
</li>
<li><p><strong>for 循环的角色：</strong></p>
<ul>
<li>回溯中 for 循环用于枚举“选项”。</li>
<li>不要在 for 中处理“不选”的逻辑，不然会重复或乱序。</li>
</ul>
</li>
</ul>
<h2 id="举例：组合总和（39-Combination-Sum）"><a href="#举例：组合总和（39-Combination-Sum）" class="headerlink" title="举例：组合总和（39. Combination Sum）"></a>举例：组合总和（<a href="https://leetcode.cn/problems/combination-sum/">39. Combination Sum</a>）</h2><ul>
<li>元素可重复使用，需遍历所有可行组合</li>
</ul>
<h4 id="✅-推荐写法：for-中只做“选”的动作"><a href="#✅-推荐写法：for-中只做“选”的动作" class="headerlink" title="✅ 推荐写法：for 中只做“选”的动作"></a>✅ 推荐写法：for 中只做“选”的动作</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">combinationSum</span><span class="params">(candidates []<span class="type">int</span>, target <span class="type">int</span>)</span></span> [][]<span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> res [][]<span class="type">int</span></span><br><span class="line">    <span class="keyword">var</span> path []<span class="type">int</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> dfs <span class="function"><span class="keyword">func</span><span class="params">(start, target <span class="type">int</span>)</span></span></span><br><span class="line">    dfs = <span class="function"><span class="keyword">func</span><span class="params">(start, target <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> target == <span class="number">0</span> &#123;</span><br><span class="line">            res = <span class="built_in">append</span>(res, <span class="built_in">append</span>([]<span class="type">int</span>(<span class="literal">nil</span>), path...))</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> i := start; i &lt; <span class="built_in">len</span>(candidates); i++ &#123;</span><br><span class="line">            <span class="keyword">if</span> target &gt;= candidates[i] &#123;</span><br><span class="line">                path = <span class="built_in">append</span>(path, candidates[i])</span><br><span class="line">                dfs(i, target - candidates[i])</span><br><span class="line">                path = path[:<span class="built_in">len</span>(path)<span class="number">-1</span>]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dfs(<span class="number">0</span>, target)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="🚫-不推荐写法：用“选-x2F-不选”逻辑递归（逻辑复杂，易错）"><a href="#🚫-不推荐写法：用“选-x2F-不选”逻辑递归（逻辑复杂，易错）" class="headerlink" title="🚫 不推荐写法：用“选&#x2F;不选”逻辑递归（逻辑复杂，易错）"></a>🚫 不推荐写法：用“选&#x2F;不选”逻辑递归（逻辑复杂，易错）</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">combinationSum</span><span class="params">(candidates []<span class="type">int</span>, target <span class="type">int</span>)</span></span> [][]<span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> res [][]<span class="type">int</span></span><br><span class="line">    <span class="keyword">var</span> path []<span class="type">int</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> dfs <span class="function"><span class="keyword">func</span><span class="params">(index, target <span class="type">int</span>)</span></span></span><br><span class="line">    dfs = <span class="function"><span class="keyword">func</span><span class="params">(index, target <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> target == <span class="number">0</span> &#123;</span><br><span class="line">            res = <span class="built_in">append</span>(res, <span class="built_in">append</span>([]<span class="type">int</span>(<span class="literal">nil</span>), path...))</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> index == <span class="built_in">len</span>(candidates) || target &lt; <span class="number">0</span> &#123;</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 选当前</span></span><br><span class="line">        path = <span class="built_in">append</span>(path, candidates[index])</span><br><span class="line">        dfs(index, target - candidates[index])</span><br><span class="line">        path = path[:<span class="built_in">len</span>(path)<span class="number">-1</span>]</span><br><span class="line">        <span class="comment">// 不选当前</span></span><br><span class="line">        dfs(index + <span class="number">1</span>, target)</span><br><span class="line">    &#125;</span><br><span class="line">    dfs(<span class="number">0</span>, target)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DFS-模板的两种核心模式"><a href="#DFS-模板的两种核心模式" class="headerlink" title="DFS 模板的两种核心模式"></a>DFS 模板的两种核心模式</h2><h3 id="模式一：组合型问题（需-for-循环）"><a href="#模式一：组合型问题（需-for-循环）" class="headerlink" title="模式一：组合型问题（需 for 循环）"></a>模式一：<strong>组合型问题（需 for 循环）</strong></h3><ul>
<li>子集、组合、排列等</li>
<li>每一步从当前位置开始向后枚举选项</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i := start; i &lt; <span class="built_in">len</span>(nums); i++ &#123;</span><br><span class="line">    path = <span class="built_in">append</span>(path, nums[i])</span><br><span class="line">    dfs(i + <span class="number">1</span>)</span><br><span class="line">    path = path[:<span class="built_in">len</span>(path)<span class="number">-1</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="模式二：构造型问题（不需-for-循环）"><a href="#模式二：构造型问题（不需-for-循环）" class="headerlink" title="模式二：构造型问题（不需 for 循环）"></a>模式二：<strong>构造型问题（不需 for 循环）</strong></h3><ul>
<li>例如：电话号码字母组合、迷宫路径、树遍历等</li>
<li>每层只能处理一个“位置”的合法选项，当前层不枚举后面</li>
</ul>
<h4 id="示例：17-电话号码的字母组合"><a href="#示例：17-电话号码的字母组合" class="headerlink" title="示例：17. 电话号码的字母组合"></a>示例：<a href="https://leetcode.cn/problems/letter-combinations-of-a-phone-number/">17. 电话号码的字母组合</a></h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">letterCombinations</span><span class="params">(digits <span class="type">string</span>)</span></span> []<span class="type">string</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(digits) == <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> []<span class="type">string</span>&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    phoneMap := <span class="keyword">map</span>[<span class="type">rune</span>]<span class="type">string</span>&#123;</span><br><span class="line">        <span class="string">&#x27;2&#x27;</span>: <span class="string">&quot;abc&quot;</span>, <span class="string">&#x27;3&#x27;</span>: <span class="string">&quot;def&quot;</span>, <span class="string">&#x27;4&#x27;</span>: <span class="string">&quot;ghi&quot;</span>, <span class="string">&#x27;5&#x27;</span>: <span class="string">&quot;jkl&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;6&#x27;</span>: <span class="string">&quot;mno&quot;</span>, <span class="string">&#x27;7&#x27;</span>: <span class="string">&quot;pqrs&quot;</span>, <span class="string">&#x27;8&#x27;</span>: <span class="string">&quot;tuv&quot;</span>, <span class="string">&#x27;9&#x27;</span>: <span class="string">&quot;wxyz&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">var</span> res []<span class="type">string</span></span><br><span class="line">    <span class="keyword">var</span> dfs <span class="function"><span class="keyword">func</span><span class="params">(index <span class="type">int</span>, str <span class="type">string</span>)</span></span></span><br><span class="line">    dfs = <span class="function"><span class="keyword">func</span><span class="params">(index <span class="type">int</span>, str <span class="type">string</span>)</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> index == <span class="built_in">len</span>(digits) &#123;</span><br><span class="line">            res = <span class="built_in">append</span>(res, str)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> _, ch := <span class="keyword">range</span> phoneMap[<span class="type">rune</span>(digits[index])] &#123;</span><br><span class="line">            dfs(index + <span class="number">1</span>, str + <span class="type">string</span>(ch))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dfs(<span class="number">0</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="总结结构图"><a href="#总结结构图" class="headerlink" title="总结结构图"></a>总结结构图</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">回溯问题分类</span><br><span class="line">├── 排列类：顺序重要，used + path</span><br><span class="line">├── 组合类：顺序不重要，start 起点控制，元素不可重复</span><br><span class="line">├── 子集类：所有组合（选 or 不选）</span><br><span class="line">└── 构造类：必须填满所有位置，如数字组合/字符串构造等</span><br></pre></td></tr></table></figure>

<blockquote>
<p>✅ 判断是否需要 for：是否在当前层“枚举选项”</p>
<ul>
<li>有枚举（子集&#x2F;组合&#x2F;排列）：需要 <code>for</code></li>
<li>无枚举（构造型）：不需要 <code>for</code></li>
</ul>
</blockquote>
<hr>
<h1 id="典型问题"><a href="#典型问题" class="headerlink" title="典型问题"></a>典型问题</h1><h2 id="TopK"><a href="#TopK" class="headerlink" title="TopK"></a>TopK</h2><ul>
<li><p><strong>不要求有序</strong>：使用快速选择算法（基于快速排序思想）；也可以使用堆结构</p>
</li>
<li><p><strong>要求有序</strong>：使用堆</p>
<ul>
<li>最大堆：用于求前 K 个最大值</li>
<li>最小堆：用于求前 K 个最小值</li>
</ul>
</li>
</ul>
<h2 id="快慢指针"><a href="#快慢指针" class="headerlink" title="快慢指针"></a>快慢指针</h2><ul>
<li><strong>19. 删除链表的倒数第 N 个节点</strong><br>快指针先走 N 步，然后快慢指针一起前进，快指针到达末尾时，慢指针刚好指向待删除节点的前一个节点</li>
<li><strong>141. 环形链表</strong><br>快慢指针，快指针每次走两步，慢指针每次走一步；若存在环，两者最终会相遇</li>
<li><strong>142. 环形链表 II</strong><br>快慢指针相遇后，快指针从头开始，慢指针继续前进；再次相遇点即为入环点</li>
<li><strong>234. 回文链表</strong><br>快慢指针找到链表中点，同时将前半部分链表原地反转；再从中点与反转后的链表逐一比较，判断是否回文</li>
<li><strong>287. 寻找重复数</strong><br>使用 Floyd 判圈算法，将数组视为链表结构；第一次快慢指针相遇后，将其中一个指针重新指向起点，两个指针再次相遇时即为重复数字（环的入口）</li>
</ul>
<h2 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h2><ul>
<li><strong>160. 相交链表</strong><br>两指针分别从两个链表头出发，走到末尾后切换至对方链表头继续走；若相交，则最终会在交点相遇；若无交点，则会同时为 <code>null</code> 结束</li>
</ul>
<hr>
<h1 id="经典题目"><a href="#经典题目" class="headerlink" title="经典题目"></a>经典题目</h1><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><ul>
<li><p><strong>146. LRU 缓存</strong>（<code>HashMap + 双向链表</code>）</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> LRUCache <span class="keyword">struct</span> &#123;</span><br><span class="line">    data     <span class="keyword">map</span>[<span class="type">int</span>]*LinkedNode</span><br><span class="line">    head     *LinkedNode</span><br><span class="line">    tail     *LinkedNode</span><br><span class="line">    count    <span class="type">int</span></span><br><span class="line">    capacity <span class="type">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> LinkedNode <span class="keyword">struct</span> &#123;</span><br><span class="line">    key  <span class="type">int</span></span><br><span class="line">    val  <span class="type">int</span></span><br><span class="line">    pre  *LinkedNode</span><br><span class="line">    next *LinkedNode</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>data</code>: 使用 HashMap 存储 key 与节点指针的映射</li>
<li><code>双向链表</code>: 头部表示最近访问节点，新加入或访问的节点会被移动到头部，尾部为最久未使用节点，便于淘汰</li>
</ul>
</li>
<li><p><strong>460. LFU 缓存</strong>（<code>双 Hash + 双向链表</code>）</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> LFUCache <span class="keyword">struct</span> &#123;</span><br><span class="line">    keyToValFreq   <span class="keyword">map</span>[<span class="type">int</span>]*LFUNode</span><br><span class="line">    freqToKeysHead <span class="keyword">map</span>[<span class="type">int</span>]*LFUNode</span><br><span class="line">    freqToKeysTail <span class="keyword">map</span>[<span class="type">int</span>]*LFUNode</span><br><span class="line">    minFreq        <span class="type">int</span></span><br><span class="line">    capacity       <span class="type">int</span></span><br><span class="line">    size           <span class="type">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> LFUNode <span class="keyword">struct</span> &#123;</span><br><span class="line">    key  <span class="type">int</span></span><br><span class="line">    val  <span class="type">int</span></span><br><span class="line">    freq <span class="type">int</span></span><br><span class="line">    pre  *LFUNode</span><br><span class="line">    next *LFUNode</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>keyToValFreq</code>: 记录每个 key 的值和频率</li>
<li><code>freqToKeys</code>: 按照频率映射到对应频率的链表（内部按 LRU 顺序）</li>
<li><code>minFreq</code>: 当前缓存中的最小访问频率</li>
<li>注意 <code>put</code> 操作中若 key 已存在，需要更新其值和频率！</li>
</ul>
</li>
</ul>
<h2 id="打家劫舍"><a href="#打家劫舍" class="headerlink" title="打家劫舍"></a>打家劫舍</h2><ul>
<li><p><strong>198. 打家劫舍</strong>（相邻房屋不能偷）</p>
<ul>
<li>动态规划</li>
<li><code>dp[i]</code> 表示前 <code>i</code> 间房屋能偷到的最大金额</li>
<li>状态转移方程：<code>dp[i] = max(dp[i-2] + nums[i], dp[i-1])</code></li>
</ul>
</li>
<li><p><strong>213. 打家劫舍 II</strong>（房屋围成一圈）</p>
<ul>
<li>环状结构，首尾不能同时选择</li>
<li>拆分为两种情况：<code>(0, n-2)</code> 和 <code>(1, n-1)</code>，分别计算最大值，取较大者</li>
</ul>
</li>
<li><p><strong>2560. 打家劫舍 IV</strong>（给定偷 <code>k</code> 间房的条件，求最小窃取能力）</p>
<ul>
<li>题考的是：在不能偷相邻房子的条件下，选择至少 k 个房子，求所有方案中「最大金额最小」的那种偷法的最大单间金额（即窃取能力）的最小值。  </li>
<li>二分 + 贪心</li>
<li>在 <code>[min(nums), max(nums)]</code> 范围内二分 <code>x</code>，判断是否存在方案在不相邻的前提下偷到 <code>k</code> 间房且每间 ≤ <code>x</code></li>
<li>最小可行的 <code>x</code> 即为答案</li>
</ul>
</li>
<li><p><strong>337. 打家劫舍 III</strong>（树形结构）</p>
<ul>
<li>二叉树结构，不能偷父子节点</li>
<li>返回两个值：偷当前节点与不偷当前节点的最大值</li>
<li>后序遍历递归实现</li>
</ul>
</li>
</ul>
<h2 id="课程表"><a href="#课程表" class="headerlink" title="课程表"></a>课程表</h2><ul>
<li><p><strong>207. 课程表</strong></p>
<ul>
<li>判断有向图是否存在环</li>
<li>使用拓扑排序（Kahn 算法）</li>
<li>若排序后的节点数 <code>== numCourses</code>，说明可完成全部课程</li>
</ul>
</li>
</ul>
<h2 id="会议室"><a href="#会议室" class="headerlink" title="会议室"></a>会议室</h2><ul>
<li><p><strong>253. 会议室 II</strong>（计算最少需要多少间会议室）</p>
<ul>
<li>将所有会议按开始时间排序</li>
<li>使用最小堆记录正在进行的会议的结束时间</li>
<li>遇到新的会议时，检查是否能复用已结束的会议室</li>
<li>最后堆的大小即为最少会议室数</li>
</ul>
</li>
<li><p><strong>2402. 会议室 III</strong>（找出被安排次数最多的会议室编号）（如果没有可用的会议室，会议将会延期，直到存在空闲的会议室。延期会议的持续时间和原会议持续时间 相同 ）</p>
<ul>
<li><p>所有会议按开始时间排序</p>
</li>
<li><p>构造两个最小堆：</p>
<ul>
<li>空闲会议室（按编号）</li>
<li>占用会议室（按结束时间 + 编号）</li>
</ul>
</li>
<li><p>每轮会议安排时：</p>
<ul>
<li>如果无空闲会议室，则延期</li>
<li>记录每个会议室的使用次数</li>
</ul>
</li>
<li><p>最终返回使用次数最多的会议室中编号最小者</p>
</li>
</ul>
</li>
</ul>
<h2 id="买卖股票"><a href="#买卖股票" class="headerlink" title="买卖股票"></a>买卖股票</h2><ul>
<li><strong>309. 最佳买卖股票时机含冷冻期</strong><ul>
<li><p>卖出股票后，你无法在第二天买入股票 (即冷冻期为 1 天)。</p>
</li>
<li><p>三种状态转移：</p>
<ul>
<li><code>f[i][0]</code>: 第 i 天持有股票</li>
<li><code>f[i][1]</code>: 第 i 天卖出股票（进入冷冻期）</li>
<li><code>f[i][2]</code>: 第 i 天未持股（非冷冻期）</li>
</ul>
</li>
<li><p>状态转移方程：</p>
<ul>
<li><code>f[i][0] = max(f[i-1][0], f[i-1][2] - prices[i])</code></li>
<li><code>f[i][1] = f[i-1][0] + prices[i]</code></li>
<li><code>f[i][2] = max(f[i-1][1], f[i-1][2])</code></li>
</ul>
</li>
<li><p>最终答案：<code>max(f[n-1][1], f[n-1][2])</code></p>
</li>
</ul>
</li>
</ul>
<h2 id="高楼扔鸡蛋"><a href="#高楼扔鸡蛋" class="headerlink" title="高楼扔鸡蛋"></a>高楼扔鸡蛋</h2><ul>
<li><p><strong>887. 鸡蛋掉落</strong></p>
<ul>
<li><p>给定 <code>k</code> 个鸡蛋和 <code>n</code> 层楼，找出确定临界楼层所需的最少操作次数（最坏情况下）</p>
</li>
<li><p>定义：<code>f(t, k)</code> 表示在最多尝试 <code>t</code> 次、拥有 <code>k</code> 个鸡蛋的情况下，最多能测试的楼层数</p>
<ul>
<li>转移方程：<code>f(t, k) = 1 + f(t-1, k-1) + f(t-1, k)</code></li>
</ul>
</li>
<li><p>最终寻找最小的 <code>t</code>，使得 <code>f(t, k) &gt;= n</code></p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">superEggDrop</span><span class="params">(k <span class="type">int</span>, n <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    ans := math.MaxInt32</span><br><span class="line">    dp := <span class="built_in">make</span>([][]<span class="type">int</span>, n+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= n; i++ &#123;</span><br><span class="line">        dp[i] = <span class="built_in">make</span>([]<span class="type">int</span>, k+<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">1</span>; i &lt;= n; i++ &#123;</span><br><span class="line">        dp[i][<span class="number">1</span>] = i</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> j := <span class="number">1</span>; j &lt;= k; j++ &#123;</span><br><span class="line">        dp[<span class="number">1</span>][j] = <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">1</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    i := <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i &lt;= n &#123;</span><br><span class="line">        <span class="keyword">for</span> j := <span class="number">1</span>; j &lt;= k; j++ &#123;</span><br><span class="line">            dp[i][j] = <span class="number">1</span> + dp[i<span class="number">-1</span>][j<span class="number">-1</span>] + dp[i<span class="number">-1</span>][j]</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> dp[i][k] &gt;= n &#123;</span><br><span class="line">            ans = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        &#125;</span><br><span class="line">        i++</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ans</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><ul>
<li>学习总被寄予理解的希望，现实却常逼我们回归重复与记忆的路径。掌握技巧、熟悉模板，也许并不光鲜，却是应对复杂世界最有效的方式之一。</li>
<li>然而熟练，何尝不是另一种形式的“背”呢。</li>
</ul>
]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>算法</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>QuicKit：高效并发任务管理工具库详解</title>
    <url>/2025/07/16/20250716-quickit-gao-xiao-bing-fa-ren-wu-guan-li-gong-ju-ku-xiang-jie/</url>
    <content><![CDATA[<p>在现代软件开发中，高效的任务管理与并发处理是提升系统性能的关键。<strong>QuicKit</strong> 是一个基于 Java 的工具库，专注于并发任务调度、执行控制、重试机制等通用能力的封装。本文将深入介绍 QuicKit 的核心功能及其实现原理。</p>
<hr>
<h2 id="1-延迟任务调度：DelayQueueUtils"><a href="#1-延迟任务调度：DelayQueueUtils" class="headerlink" title="1. 延迟任务调度：DelayQueueUtils"></a>1. 延迟任务调度：<code>DelayQueueUtils</code></h2><p><code>DelayQueueUtils</code> 使用 <strong>HashedWheelTimer</strong> 实现延迟任务的高效调度。</p>
<h3 id="实现原理："><a href="#实现原理：" class="headerlink" title="实现原理："></a>实现原理：</h3><ul>
<li><strong>时间轮机制</strong>：将时间划分为多个槽（slots），类似时钟的刻度。</li>
<li><strong>任务分配</strong>：任务根据设定的延迟时间分配至对应槽中。</li>
<li><strong>槽激活</strong>：时间轮旋转，当指针指向某个槽时，执行该槽内的所有任务。</li>
</ul>
<blockquote>
<p>✅ 优势：极大减少内存消耗和调度开销，适合高频延迟任务场景。</p>
</blockquote>
<hr>
<h2 id="2-执行频率控制：ExecutionFrequencyUtils"><a href="#2-执行频率控制：ExecutionFrequencyUtils" class="headerlink" title="2. 执行频率控制：ExecutionFrequencyUtils"></a>2. 执行频率控制：<code>ExecutionFrequencyUtils</code></h2><p>用于<strong>控制任务执行频率</strong>，防止系统被大量任务压垮。</p>
<h3 id="实现原理：-1"><a href="#实现原理：-1" class="headerlink" title="实现原理："></a>实现原理：</h3><ul>
<li><strong>任务分片</strong>：将任务列表切分为多个子任务，每批任务在一定时间间隔内执行。</li>
<li><strong>频率限制</strong>：可配置每秒允许执行的任务数量，避免突发任务过载系统。</li>
</ul>
<blockquote>
<p>✅ 应用场景：接口限流、批量处理限速、系统保护。</p>
</blockquote>
<hr>
<h2 id="3-并行任务处理：ParallelTask"><a href="#3-并行任务处理：ParallelTask" class="headerlink" title="3. 并行任务处理：ParallelTask"></a>3. 并行任务处理：<code>ParallelTask</code></h2><p>提供简洁高效的<strong>并行处理能力</strong>，充分利用多核 CPU 性能。</p>
<h3 id="实现原理：-2"><a href="#实现原理：-2" class="headerlink" title="实现原理："></a>实现原理：</h3><ul>
<li><strong>并行流</strong>：基于 Java 8 的 <code>parallelStream()</code> 并行处理任务。</li>
<li><strong>线程池管理</strong>：使用 <code>ExecutorService</code> 管理线程，降低线程创建销毁开销。</li>
</ul>
<blockquote>
<p>✅ 适用场景：批量任务处理、并发计算、数据转换等。</p>
</blockquote>
<hr>
<h2 id="4-重试机制：RetryUtils"><a href="#4-重试机制：RetryUtils" class="headerlink" title="4. 重试机制：RetryUtils"></a>4. 重试机制：<code>RetryUtils</code></h2><p>内置灵活的<strong>重试机制</strong>，应对任务失败后的自动恢复。</p>
<h3 id="实现原理：-3"><a href="#实现原理：-3" class="headerlink" title="实现原理："></a>实现原理：</h3><ul>
<li><strong>重试策略配置</strong>：通过 <code>RetryerBuilder</code> 设置重试次数、间隔、终止条件等。</li>
<li><strong>异常捕获与处理</strong>：根据异常类型与策略自动判断是否重试。</li>
</ul>
<blockquote>
<p>✅ 典型用途：数据库重试、远程服务调用、临时异常容忍。</p>
</blockquote>
<hr>
<h2 id="5-读写锁封装：ReadWriteLockWrapper"><a href="#5-读写锁封装：ReadWriteLockWrapper" class="headerlink" title="5. 读写锁封装：ReadWriteLockWrapper"></a>5. 读写锁封装：<code>ReadWriteLockWrapper</code></h2><p>封装 Java 原生 <code>ReentrantReadWriteLock</code>，简化并发数据访问控制。</p>
<h3 id="实现原理：-4"><a href="#实现原理：-4" class="headerlink" title="实现原理："></a>实现原理：</h3><ul>
<li><strong>读写分离</strong>：多个线程可同时读，写需独占。</li>
<li><strong>锁降级支持</strong>：支持写锁降级为读锁，提升吞吐性能。</li>
</ul>
<blockquote>
<p>✅ 适用场景：缓存读取、配置中心、共享资源管理等。</p>
</blockquote>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>QuicKit</strong> 通过提供一系列高性能并发工具，极大简化了任务调度、线程管理与错误恢复的复杂性。无论你在构建分布式系统、服务中间件，还是日常业务逻辑开发，QuicKit 都是一个值得使用的并发基础组件库。</p>
<hr>
<p>📦 <strong>项目地址</strong>：<br>👉 <a href="https://github.com/Kingson4Wu/QuicKit">https://github.com/Kingson4Wu/QuicKit</a></p>
<p>📚 <strong>文档地址</strong>：<br>👉 <a href="https://deepwiki.com/Kingson4Wu/QuicKit">https://deepwiki.com/Kingson4Wu/QuicKit</a></p>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>延迟队列</tag>
        <tag>频率控制</tag>
        <tag>失败重试</tag>
        <tag>读写锁</tag>
      </tags>
  </entry>
  <entry>
    <title>quick_worker 项目分析：基于 Channel 的高效异步批处理与 CPU 空转问题解析</title>
    <url>/2025/07/17/20250717-quick-worker-xiang-mu-fen-xi-ji-yu-channel-de-gao-xiao-yi-bu-pi-chu-li-yu-cpu-kong-zhuan-wen-ti-jie-xi/</url>
    <content><![CDATA[<p><a href="https://github.com/Kingson4Wu/quick_worker"><code>quick_worker</code></a> 是一个用 Go 实现的轻量级异步批处理框架。它通过 channel 和 goroutine 构建了一个高效的生产者-消费者模型，支持按批量大小或超时触发数据处理，适合高并发、吞吐敏感的场景。</p>
<p>本文将围绕其核心并发模型进行分析，重点讨论：</p>
<ul>
<li>是否存在 CPU 空转（Busy Waiting）问题</li>
<li><code>select</code> 和 channel 的阻塞特性</li>
<li>在什么情况下应考虑使用 <code>sync.Cond</code> 替代主动轮询</li>
</ul>
<hr>
<h3 id="一、项目核心架构概览"><a href="#一、项目核心架构概览" class="headerlink" title="一、项目核心架构概览"></a>一、项目核心架构概览</h3><p><code>quick_worker</code> 的核心工作流程：</p>
<ol>
<li><strong>数据投递</strong>：调用方通过 <code>Produce</code> 方法投递任务数据。</li>
<li><strong>缓冲通道</strong>：数据进入内部 <code>dataChan</code> 缓冲通道。</li>
<li><strong>消费者循环</strong>：独立的消费者 goroutine 执行 <code>consume</code> 方法，负责从通道中取出数据并批量处理。</li>
<li><strong>触发机制</strong>：处理可以由达到最大批量（maxBatchSize）或等待超时（maxWaitDuration）触发。</li>
<li><strong>退出控制</strong>：通过 <code>doneChan</code> 通知消费者优雅退出。</li>
</ol>
<p>这一模型兼具性能与可靠性，典型用于日志聚合、异步队列、延迟任务聚合等场景。</p>
<hr>
<h3 id="二、关于-CPU-空转（Busy-Waiting）问题的分析"><a href="#二、关于-CPU-空转（Busy-Waiting）问题的分析" class="headerlink" title="二、关于 CPU 空转（Busy Waiting）问题的分析"></a>二、关于 CPU 空转（Busy Waiting）问题的分析</h3><h4 id="1-消费者循环是否会导致空转？"><a href="#1-消费者循环是否会导致空转？" class="headerlink" title="1. 消费者循环是否会导致空转？"></a>1. 消费者循环是否会导致空转？</h4><p><code>core/worker.go</code> 中的主循环如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> data, ok := &lt;-w.dataChan:</span><br><span class="line">        <span class="comment">// 接收并处理数据</span></span><br><span class="line">    <span class="keyword">case</span> &lt;-timer.C:</span><br><span class="line">        <span class="comment">// 超时触发处理</span></span><br><span class="line">    <span class="keyword">case</span> &lt;-w.doneChan:</span><br><span class="line">        <span class="comment">// 接收到退出信号</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该循环具有以下特性：</p>
<ul>
<li><strong>select 是阻塞式的</strong>：当所有分支都不满足时，<code>select</code> 会自动挂起，不占用 CPU。</li>
<li>只要 <code>dataChan</code> 中没有数据、<code>timer</code> 没有到期、<code>doneChan</code> 没有信号，该 goroutine 会自然休眠。</li>
<li><strong>结论：这段代码不会导致 CPU 空转，是标准的 Go 并发写法。</strong></li>
</ul>
<h4 id="2-生产者逻辑是否安全？"><a href="#2-生产者逻辑是否安全？" class="headerlink" title="2. 生产者逻辑是否安全？"></a>2. 生产者逻辑是否安全？</h4><p>生产者调用 <code>Produce</code> 方法将数据投递进通道时，使用了非阻塞的 <code>select</code>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> w.dataChan &lt;- data:</span><br><span class="line">    <span class="comment">// 投递成功</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">    <span class="comment">// 通道已满，放弃投递</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这避免了阻塞与死循环，也没有任何 busy loop 行为。</p>
<h4 id="3-可能导致空转的场景分析"><a href="#3-可能导致空转的场景分析" class="headerlink" title="3. 可能导致空转的场景分析"></a>3. 可能导致空转的场景分析</h4><table>
<thead>
<tr>
<th>场景</th>
<th>quick_worker 中是否存在</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>for &#123;&#125;</code> 死循环</td>
<td>❌</td>
<td>无此代码</td>
</tr>
<tr>
<td><code>for &#123; select &#123;&#125; &#125;</code> 且无阻塞分支</td>
<td>❌</td>
<td>每个 select 都含有阻塞通道</td>
</tr>
<tr>
<td>定时器设置过小，频繁唤醒</td>
<td>⚠️</td>
<td>频繁 wakeup 但不构成空转</td>
</tr>
<tr>
<td>通道满后生产者死循环 retry</td>
<td>❌</td>
<td>当前实现非阻塞，未重试</td>
</tr>
</tbody></table>
<h4 id="✅-总结结论："><a href="#✅-总结结论：" class="headerlink" title="✅ 总结结论："></a>✅ 总结结论：</h4><ul>
<li><code>quick_worker</code> 中的核心并发逻辑是以阻塞式 channel + timer 驱动的。</li>
<li>消费者 goroutine 不存在任何 busy waiting。</li>
<li>项目天然避免了 CPU 空转问题，性能开销可控。</li>
</ul>
<hr>
<h3 id="三、sync-Cond：在什么情况下必须使用它来避免-CPU-空转？"><a href="#三、sync-Cond：在什么情况下必须使用它来避免-CPU-空转？" class="headerlink" title="三、sync.Cond：在什么情况下必须使用它来避免 CPU 空转？"></a>三、sync.Cond：在什么情况下必须使用它来避免 CPU 空转？</h3><p>虽然 <code>quick_worker</code> 本身没有使用 <code>sync.Cond</code>，但了解它的用途对于设计其他复杂同步场景非常重要。</p>
<h4 id="1-什么是-CPU-空转？"><a href="#1-什么是-CPU-空转？" class="headerlink" title="1. 什么是 CPU 空转？"></a>1. 什么是 CPU 空转？</h4><p>CPU 空转（Busy Waiting）是指：<strong>线程在等待某个条件成立时，不阻塞、不 sleep，而是反复检查条件的状态，导致 CPU 被无意义地占用</strong>。</p>
<p>例如：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> !ready &#123;</span><br><span class="line">    <span class="comment">// 空转：一直检查条件，浪费 CPU</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码没有任何阻塞操作，会让 CPU 持续忙碌。</p>
<h4 id="2-如何使用-sync-Cond-避免空转？"><a href="#2-如何使用-sync-Cond-避免空转？" class="headerlink" title="2. 如何使用 sync.Cond 避免空转？"></a>2. 如何使用 sync.Cond 避免空转？</h4><p><code>sync.Cond</code> 提供了条件变量机制，允许我们在等待某个条件时挂起 goroutine，直到条件成立被显式唤醒。</p>
<p>示例：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> mu sync.Mutex</span><br><span class="line"><span class="keyword">var</span> cond = sync.NewCond(&amp;mu)</span><br><span class="line"><span class="keyword">var</span> ready <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 等待方（消费者）</span></span><br><span class="line">mu.Lock()</span><br><span class="line"><span class="keyword">for</span> !ready &#123;</span><br><span class="line">    cond.Wait() <span class="comment">// 阻塞等待，自动释放锁，避免空转</span></span><br><span class="line">&#125;</span><br><span class="line">mu.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通知方（生产者）</span></span><br><span class="line">mu.Lock()</span><br><span class="line">ready = <span class="literal">true</span></span><br><span class="line">cond.Signal() <span class="comment">// 或 cond.Broadcast()</span></span><br><span class="line">mu.Unlock()</span><br></pre></td></tr></table></figure>

<p>优点：</p>
<ul>
<li><code>Wait()</code> 会阻塞 goroutine，而不是让它空转。</li>
<li><code>Signal()</code> 只唤醒一个等待者，<code>Broadcast()</code> 唤醒所有等待者。</li>
</ul>
<h4 id="3-使用-sync-Cond-的典型场景"><a href="#3-使用-sync-Cond-的典型场景" class="headerlink" title="3. 使用 sync.Cond 的典型场景"></a>3. 使用 sync.Cond 的典型场景</h4><table>
<thead>
<tr>
<th>适用场景</th>
<th>原因</th>
</tr>
</thead>
<tbody><tr>
<td>缓存读取等待写入</td>
<td>等待数据可用，不适合用 channel 表达</td>
</tr>
<tr>
<td>对象池等待资源释放</td>
<td>条件复杂或需共享状态，channel 难以表达</td>
</tr>
<tr>
<td>多线程 barrier 同步</td>
<td>等待多个条件成立后同时唤醒</td>
</tr>
<tr>
<td>控制 goroutine 启停</td>
<td>管理状态而不是数据流</td>
</tr>
</tbody></table>
<h4 id="4-channel-和-sync-Cond-的选择建议"><a href="#4-channel-和-sync-Cond-的选择建议" class="headerlink" title="4. channel 和 sync.Cond 的选择建议"></a>4. channel 和 sync.Cond 的选择建议</h4><table>
<thead>
<tr>
<th>特性</th>
<th>channel</th>
<th>sync.Cond</th>
</tr>
</thead>
<tbody><tr>
<td>数据流驱动</td>
<td>✅（首选）</td>
<td>❌（不适合）</td>
</tr>
<tr>
<td>条件状态驱动</td>
<td>❌（难表达）</td>
<td>✅（适合表达条件判断）</td>
</tr>
<tr>
<td>是否易用</td>
<td>简单直观</td>
<td>需要配合锁、小心竞态</td>
</tr>
<tr>
<td>是否阻塞</td>
<td>✅（天然阻塞）</td>
<td>✅（Wait 手动阻塞）</td>
</tr>
</tbody></table>
<p><strong>结论：</strong></p>
<blockquote>
<p>如果你在等待某个“条件”而非“数据”，又无法用 channel 表达，那么使用 <code>sync.Cond</code> 可以有效避免 busy loop。</p>
</blockquote>
<hr>
<h3 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h3><ul>
<li><code>quick_worker</code> 项目使用阻塞式 select 循环，无 busy loop 行为，不存在 CPU 空转问题。</li>
<li>Go 的 channel 和 timer 本身就是高效的阻塞机制，只要 select 内有阻塞分支，goroutine 就不会占用 CPU。</li>
<li>只有在使用 <code>for + 条件判断</code> 等原始自旋方式等待状态时，才需要引入 <code>sync.Cond</code>。</li>
<li><code>sync.Cond</code> 更适合资源池、复杂状态条件协作等无法使用 channel 描述的场景。</li>
</ul>
]]></content>
      <tags>
        <tag>Go</tag>
        <tag>CPU</tag>
        <tag>批处理任务</tag>
      </tags>
  </entry>
  <entry>
    <title>三种学习法核心精髓</title>
    <url>/2025/08/04/20250804-san-chong-xue-xi-fa-he-xin-jing-sui/</url>
    <content><![CDATA[<h2 id="🧠-一、费曼学习法（Feynman-Technique）"><a href="#🧠-一、费曼学习法（Feynman-Technique）" class="headerlink" title="🧠 一、费曼学习法（Feynman Technique）"></a>🧠 一、费曼学习法（Feynman Technique）</h2><p><strong>核心理念：用教别人的方式来教自己。</strong></p>
<h3 id="📌-关键步骤："><a href="#📌-关键步骤：" class="headerlink" title="📌 关键步骤："></a>📌 关键步骤：</h3><ol>
<li><strong>选择概念</strong>：挑选你想学的知识点。  </li>
<li><strong>解释给小白听</strong>：用简单、口语化的语言讲解，好像在教一个完全不懂的人（比如小学生）。  </li>
<li><strong>找出盲点</strong>：当你卡住或讲不清楚，说明你还没真正理解。  </li>
<li><strong>回顾补全</strong>：回到原材料查漏补缺，搞清楚所有细节。  </li>
<li><strong>重新讲解 &amp; 简化</strong>：再次讲解，并尽量用更简单的语言表达。</li>
</ol>
<p>✅ <strong>核心关键：</strong>  </p>
<blockquote>
<p>“能讲清楚，才算真正学懂。”</p>
</blockquote>
<hr>
<h2 id="🧩-二、西蒙学习法（Herbert-Simon-Learning-Strategy）"><a href="#🧩-二、西蒙学习法（Herbert-Simon-Learning-Strategy）" class="headerlink" title="🧩 二、西蒙学习法（Herbert Simon Learning Strategy）"></a>🧩 二、西蒙学习法（Herbert Simon Learning Strategy）</h2><p>（又称“问题解决导向学习”Problem-Solving Learning）</p>
<h3 id="📌-关键特点："><a href="#📌-关键特点：" class="headerlink" title="📌 关键特点："></a>📌 关键特点：</h3><ol>
<li><strong>以问题为驱动</strong>：学习过程围绕真实问题展开，而不是被动接收知识。  </li>
<li><strong>建立知识结构</strong>：通过已有的知识和逻辑推理解决新问题。  </li>
<li><strong>重视反思与优化</strong>：每一次问题解决都伴随着策略的反思和迭代。</li>
</ol>
<p>✅ <strong>核心关键：</strong>  </p>
<blockquote>
<p>“用解决问题的方式构建知识体系。”</p>
</blockquote>
<hr>
<h2 id="📝-三、康奈尔学习法（Cornell-Note-taking-System）"><a href="#📝-三、康奈尔学习法（Cornell-Note-taking-System）" class="headerlink" title="📝 三、康奈尔学习法（Cornell Note-taking System）"></a>📝 三、康奈尔学习法（Cornell Note-taking System）</h2><p><strong>核心理念：结构化笔记提升理解与记忆。</strong></p>
<h3 id="📌-五大步骤："><a href="#📌-五大步骤：" class="headerlink" title="📌 五大步骤："></a>📌 五大步骤：</h3><ol>
<li><strong>笔记区（右侧大块）</strong>：上课或阅读时记下主要内容。  </li>
<li><strong>提问区（左侧小块）</strong>：课后写下问题、关键词或提示语，用于复习时自测。  </li>
<li><strong>总结区（底部）</strong>：用自己的话总结整页笔记的核心。  </li>
<li><strong>回顾复习</strong>：定期回看并测试自己，强化记忆。  </li>
<li><strong>联结思考</strong>：不断将新知识与旧知识联系起来。</li>
</ol>
<p>✅ <strong>核心关键：</strong>  </p>
<blockquote>
<p>“记笔记不是为了记录，而是为了思考和复习。”</p>
</blockquote>
<hr>
<h2 id="🔍-总结对比表"><a href="#🔍-总结对比表" class="headerlink" title="🔍 总结对比表"></a>🔍 总结对比表</h2><table>
<thead>
<tr>
<th>学习法</th>
<th>核心关键</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>费曼学习法</td>
<td>教别人来检验理解深度</td>
<td>理论知识、概念型内容</td>
</tr>
<tr>
<td>西蒙学习法</td>
<td>以解决问题构建知识结构</td>
<td>数理逻辑、编程、工程类内容</td>
</tr>
<tr>
<td>康奈尔学习法</td>
<td>结构化笔记促进理解与回顾</td>
<td>听课、读书、考试复习</td>
</tr>
</tbody></table>
]]></content>
      <tags>
        <tag>学习法</tag>
      </tags>
  </entry>
  <entry>
    <title>多语言大模型如何处理不同语言？是翻译成英语后再推理的吗？</title>
    <url>/2025/08/07/20250807-duo-yu-yan-da-mo-xing-ru-he-chu-li-bu-tong-yu-yan-shi-fan-yi-cheng-ying-yu-hou-zai-tui-li-de-ma/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>以下文章有ChatGPT生成</p>
</blockquote>
</blockquote>
<p>多语言大模型（Multilingual LLM）越来越普及，但一个常见的问题是：<strong>模型处理非英语语言时，是直接在原语言上推理，还是先翻译成英语再处理？</strong></p>
<p>简短回答：<strong>大多数主流模型并不会将输入翻译为英语后再推理，而是直接在原语言上进行理解与生成。</strong></p>
<p>以下是详细解释。</p>
<hr>
<h2 id="1-训练方式：直接多语言训练"><a href="#1-训练方式：直接多语言训练" class="headerlink" title="1. 训练方式：直接多语言训练"></a>1. 训练方式：直接多语言训练</h2><p>当前主流大模型（如 GPT、Claude、Gemini、Mistral、LLaMA、BLOOM 等）在训练时使用了多语种语料，模型在训练阶段就学会了多语言的语法、词汇和语义表达：</p>
<ul>
<li>不会将所有语料翻译成英语；</li>
<li>而是在训练过程中构建出一个“跨语言的共享语义空间”，在这个空间中不同语言的同义句会靠得很近；</li>
<li>因此，模型具备了直接理解和生成多语言的能力。</li>
</ul>
<hr>
<h2 id="2-英语的优势与“隐性中心化”"><a href="#2-英语的优势与“隐性中心化”" class="headerlink" title="2. 英语的优势与“隐性中心化”"></a>2. 英语的优势与“隐性中心化”</h2><p>虽然模型支持多语言，但英语仍然是“最强语言”，原因包括：</p>
<ul>
<li>英语在训练数据中占比通常高达 60%~90%；</li>
<li>模型参数对英语有更强的优化效果；</li>
<li>英语可能隐性地作为“锚点”来对齐其他语言的语义表示。</li>
</ul>
<p>这种语义对齐并不是翻译行为，而是一种深层语义空间的统一。</p>
<hr>
<h2 id="3-推理流程：不会翻译成英语再处理"><a href="#3-推理流程：不会翻译成英语再处理" class="headerlink" title="3. 推理流程：不会翻译成英语再处理"></a>3. 推理流程：不会翻译成英语再处理</h2><p>当你用中文或其他语言提问时，模型不会走「中文 → 英文 → 推理 → 翻译成中文」这一路径，而是：</p>
<ul>
<li>直接在中文语境中理解问题；</li>
<li>在语义空间中执行推理；</li>
<li>直接生成中文结果。</li>
</ul>
<p>当然，部分三方插件可能人为引入翻译步骤，但这不是模型本身的机制。</p>
<hr>
<h2 id="4-支持机制的实验证据"><a href="#4-支持机制的实验证据" class="headerlink" title="4. 支持机制的实验证据"></a>4. 支持机制的实验证据</h2><ul>
<li><strong>对比实验</strong>：模型处理法语、德语等非英语输入时，直接完成推理与生成，无中转行为。</li>
<li><strong>语义嵌入对齐</strong>：多语言句子在语义空间中具有高度重合性。</li>
<li><strong>激活层分析</strong>：输入非英语语言时，中间激活状态未显示出“语言切换”迹象。</li>
</ul>
<hr>
<h2 id="5-用英语输入表现是否更好？"><a href="#5-用英语输入表现是否更好？" class="headerlink" title="5. 用英语输入表现是否更好？"></a>5. 用英语输入表现是否更好？</h2><p>是的。虽然模型支持多语言，但用英语输入通常效果最佳，尤其体现在知识完整性、表达清晰度、推理深度等方面：</p>
<h3 id="为什么英语效果更好："><a href="#为什么英语效果更好：" class="headerlink" title="为什么英语效果更好："></a>为什么英语效果更好：</h3><table>
<thead>
<tr>
<th>因素</th>
<th>原因说明</th>
</tr>
</thead>
<tbody><tr>
<td>数据占比高</td>
<td>英语语料远多于其他语言，覆盖面更广，细节更丰富</td>
</tr>
<tr>
<td>表达优化充分</td>
<td>模型在英语上训练迭代次数更多，结构化表达能力更强</td>
</tr>
<tr>
<td>知识密度高</td>
<td>很多细节知识只出现在英文语料（如 Reddit、Wikipedia、新闻、论文等）中</td>
</tr>
<tr>
<td>推理能力领先</td>
<td>英文任务训练量大，模型更善于处理多步推理、复杂逻辑问题</td>
</tr>
</tbody></table>
<hr>
<h3 id="对比示例："><a href="#对比示例：" class="headerlink" title="对比示例："></a>对比示例：</h3><table>
<thead>
<tr>
<th>输入语言</th>
<th>问题</th>
<th>模型响应风格与质量</th>
</tr>
</thead>
<tbody><tr>
<td>英语</td>
<td>Why did the Roman Empire fall?</td>
<td>内容结构清晰，信息丰富，逻辑严密</td>
</tr>
<tr>
<td>中文</td>
<td>罗马帝国为何衰亡？</td>
<td>内容相似，但用词偏模板化，论证略显单薄</td>
</tr>
<tr>
<td>阿拉伯语</td>
<td>لماذا سقطت الإمبراطورية الرومانية؟</td>
<td>回答趋于泛泛，具体细节缺失</td>
</tr>
</tbody></table>
<hr>
<h2 id="6-Prompt-编写建议"><a href="#6-Prompt-编写建议" class="headerlink" title="6. Prompt 编写建议"></a>6. Prompt 编写建议</h2><table>
<thead>
<tr>
<th>使用场景</th>
<th>推荐策略</th>
</tr>
</thead>
<tbody><tr>
<td>复杂推理&#x2F;创作</td>
<td>使用英文 Prompt，提升准确性和内容质量</td>
</tr>
<tr>
<td>中文对话&#x2F;问答</td>
<td>可直接用中文，响应速度快，语义易控</td>
</tr>
<tr>
<td>翻译任务</td>
<td>直接使用目标语言作为输入&#x2F;输出，模型对翻译任务表现良好</td>
</tr>
<tr>
<td>多语言兼容输出</td>
<td>英文 Prompt + 指令 <code>Please answer in Chinese.</code> 等，结果可控</td>
</tr>
</tbody></table>
<hr>
<h2 id="7-实用技巧：英文-Prompt-中文输出"><a href="#7-实用技巧：英文-Prompt-中文输出" class="headerlink" title="7. 实用技巧：英文 Prompt + 中文输出"></a>7. 实用技巧：英文 Prompt + 中文输出</h2><h3 id="模板："><a href="#模板：" class="headerlink" title="模板："></a>模板：</h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">[Your task in English]</span><br><span class="line">Please answer in Chinese.</span><br></pre></td></tr></table></figure>

<h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">Write a short argumentative essay about how artificial intelligence is impacting the future of employment. Focus on both the opportunities and challenges it presents. Use logical reasoning and real-world examples.</span><br><span class="line">Please answer in Chinese.</span><br></pre></td></tr></table></figure>

<h3 id="输出（模型生成中文）："><a href="#输出（模型生成中文）：" class="headerlink" title="输出（模型生成中文）："></a>输出（模型生成中文）：</h3><blockquote>
<p>人工智能正在以惊人的速度改变就业的未来……（略）</p>
</blockquote>
<hr>
<h2 id="8-进阶策略：先生成英文，再翻译"><a href="#8-进阶策略：先生成英文，再翻译" class="headerlink" title="8. 进阶策略：先生成英文，再翻译"></a>8. 进阶策略：先生成英文，再翻译</h2><p>对于需要最大限度保持内容质量的应用，可以：</p>
<ol>
<li>使用英文 Prompt；</li>
<li>得到英文结果后，用模型翻译为中文；</li>
</ol>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">Translate the following text into Chinese:</span><br><span class="line">[英文生成内容]</span><br></pre></td></tr></table></figure>

<p>适合精细控制内容质量的生产环境。</p>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table>
<thead>
<tr>
<th>问题</th>
<th>答案</th>
</tr>
</thead>
<tbody><tr>
<td>大模型是否将非英语输入翻译为英语再推理？</td>
<td>否，直接在原语言上推理</td>
</tr>
<tr>
<td>英语输入是否效果更好？</td>
<td>是，表现更强、内容更准确、表达更自然</td>
</tr>
<tr>
<td>多语言之间是否共享知识？</td>
<td>共享语义空间，但知识覆盖仍取决于训练数据分布</td>
</tr>
<tr>
<td>推荐的 Prompt 编写方式？</td>
<td>英文 Prompt + 中文输出 或 英文生成 + 翻译为中文</td>
</tr>
</tbody></table>
<hr>
<h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ul>
<li><a href="https://arxiv.org/abs/2010.11934">Massively Multilingual Models (mT5)</a></li>
<li><a href="https://huggingface.co/bigscience/bloom">BLOOM: a 176B Multilingual LLM</a></li>
<li><a href="https://arxiv.org/abs/2201.10005">XGLM: Multilingual Autoregressive Language Model</a></li>
<li><a href="https://openai.com/research/multilingual">OpenAI: Language models as multilingual translators</a></li>
</ul>
]]></content>
      <tags>
        <tag>AI</tag>
        <tag>LLM</tag>
        <tag>大模型</tag>
        <tag>多语言</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解正向代理与反向代理：HTTP 报文与 TCP 连接的区别</title>
    <url>/2025/08/17/20250817-shen-ru-li-jie-zheng-xiang-dai-li-yu-fan-xiang-dai-li-http-bao-wen-yu-tcp-lian-jie-de-qu-bie/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>发现之前的理解有一点小偏差，重新整理一下<br>以下内容由AI生成，本人审阅</p>
</blockquote>
</blockquote>
<p>在日常开发和运维中，“正向代理（Forward Proxy）”和“反向代理（Reverse Proxy）”是两个高频概念。但很多人容易混淆两者的请求格式和工作机制。本文将从 <strong>HTTP 报文格式、TCP 连接目标、历史规范</strong> 等角度，系统梳理这两种代理的差别与本质。</p>
<hr>
<h2 id="1-正向代理（Forward-Proxy）"><a href="#1-正向代理（Forward-Proxy）" class="headerlink" title="1. 正向代理（Forward Proxy）"></a>1. 正向代理（Forward Proxy）</h2><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>客户端无法直接访问目标网站（如跨境访问、内网限制），于是先把请求交给代理服务器，由代理转发给目标站点。</p>
<h3 id="请求示例"><a href="#请求示例" class="headerlink" title="请求示例"></a>请求示例</h3><p>客户端请求发送给代理时，<strong>请求行必须带完整 URL</strong>：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">http://www.example.com/index.html</span> <span class="meta">HTTP/1.1</span></span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>www.example.com</span><br></pre></td></tr></table></figure>

<ul>
<li>TCP 连接目标：代理服务器（如 <code>proxy.mycorp.com:8080</code>）</li>
<li>请求行：完整 URL（<code>http://host/path</code>）</li>
<li>Host：目标站点域名（<code>www.example.com</code>）</li>
</ul>
<p>👉 代理根据 URL 或 Host，建立新连接去访问目标网站，再返回结果。</p>
<hr>
<h2 id="2-反向代理（Reverse-Proxy）"><a href="#2-反向代理（Reverse-Proxy）" class="headerlink" title="2. 反向代理（Reverse Proxy）"></a>2. 反向代理（Reverse Proxy）</h2><h3 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h3><p>客户端以为自己访问的是目标站点，其实连到的是反向代理（常见如 Nginx、Apache）。代理再根据配置，把请求分发给后端不同的服务。</p>
<h3 id="请求示例-1"><a href="#请求示例-1" class="headerlink" title="请求示例"></a>请求示例</h3><p>客户端对代理并不知情，请求格式与直连一致：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/index.html</span> <span class="meta">HTTP/1.1</span></span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>www.example.com</span><br></pre></td></tr></table></figure>

<ul>
<li>TCP 连接目标：反向代理（如 <code>nginx</code>）</li>
<li>请求行：相对路径 <code>/path</code></li>
<li>Host：目标站点域名（用于路由转发）</li>
</ul>
<p>👉 对客户端而言，看起来就是访问了目标站点。</p>
<hr>
<h2 id="3-请求报文差异总结"><a href="#3-请求报文差异总结" class="headerlink" title="3. 请求报文差异总结"></a>3. 请求报文差异总结</h2><table>
<thead>
<tr>
<th>特性</th>
<th>正向代理</th>
<th>反向代理 &#x2F; 直连</th>
</tr>
</thead>
<tbody><tr>
<td>TCP 连接目标</td>
<td>代理服务器</td>
<td>目标服务器 &#x2F; 反向代理</td>
</tr>
<tr>
<td>请求行</td>
<td><strong>完整 URL</strong> (<code>http://host/path</code>)</td>
<td><strong>相对路径</strong> (<code>/path</code>)</td>
</tr>
<tr>
<td>Host 头</td>
<td>目标域名（如 <code>www.example.com</code>）</td>
<td>目标域名（同上）</td>
</tr>
<tr>
<td>客户端感知</td>
<td><strong>知道在用代理</strong></td>
<td><strong>不知道有代理</strong></td>
</tr>
</tbody></table>
<hr>
<h2 id="4-为什么正向代理要写完整-URL？"><a href="#4-为什么正向代理要写完整-URL？" class="headerlink" title="4. 为什么正向代理要写完整 URL？"></a>4. 为什么正向代理要写完整 URL？</h2><p>这源于 <strong>HTTP&#x2F;1.0 的历史限制</strong>：</p>
<ul>
<li><p><strong>早期（HTTP&#x2F;1.0）</strong>：请求行只有路径，如 <code>GET /index.html HTTP/1.0</code>。<br>当时一个 IP 对应一个网站，直连场景没问题；但如果连的是代理，代理无法得知目标域名。<br>👉 解决方案：<strong>在代理模式下，强制请求行写完整 URL</strong>。</p>
</li>
<li><p><strong>HTTP&#x2F;1.1</strong>：引入 <code>Host</code> 头，直连时可区分虚拟主机。<br>但 <strong>代理模式依旧保留完整 URL 规则</strong>，原因有两点：</p>
<ol>
<li>向后兼容旧代理。</li>
<li>代理可直接用 URL 做缓存键、写日志，逻辑更清晰。</li>
</ol>
</li>
</ul>
<p>因此，虽然代理理论上可以只靠 <code>Host</code> 判断目标，但规范要求写完整 URL。</p>
<hr>
<h2 id="5-TCP-连接层与应用层的分工"><a href="#5-TCP-连接层与应用层的分工" class="headerlink" title="5. TCP 连接层与应用层的分工"></a>5. TCP 连接层与应用层的分工</h2><p>这里的核心区别在于 <strong>TCP 与 HTTP 的分工</strong>：</p>
<ul>
<li><p><strong>TCP 层</strong>：只管“连哪个 IP:Port”。</p>
<ul>
<li>直连：连 <code>www.example.com:80</code></li>
<li>正向代理：连 <code>proxy.mycorp.com:8080</code></li>
</ul>
</li>
<li><p><strong>HTTP 层</strong>：报文里体现目标站点信息。</p>
<ul>
<li>直连&#x2F;反向代理：请求行 <code>/path</code> + Host</li>
<li>正向代理：请求行 <code>http://host/path</code> + Host</li>
</ul>
</li>
</ul>
<p>👉 换句话说，<strong>TCP 根本不知道什么是代理</strong>，它只负责传字节流；代理语义完全由 HTTP 层和客户端实现决定。</p>
<hr>
<h2 id="6-为什么客户端在代理模式下，TCP-连接建到代理服务器？"><a href="#6-为什么客户端在代理模式下，TCP-连接建到代理服务器？" class="headerlink" title="6. 为什么客户端在代理模式下，TCP 连接建到代理服务器？"></a>6. 为什么客户端在代理模式下，TCP 连接建到代理服务器？</h2><p>👉 因为这是 <strong>客户端实现决定的</strong>，不是 HTTP 协议强制的。</p>
<h3 id="1-普通直连模式"><a href="#1-普通直连模式" class="headerlink" title="1. 普通直连模式"></a>1. 普通直连模式</h3><p>浏览器要访问 <code>http://www.example.com/index.html</code>：</p>
<ul>
<li><p>DNS 解析 <code>www.example.com</code> → 得到 IP</p>
</li>
<li><p>建立 TCP 连接 <code>www.example.com:80</code></p>
</li>
<li><p>发请求：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/index.html</span> <span class="meta">HTTP/1.1</span></span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>www.example.com</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h3 id="2-配置了正向代理模式"><a href="#2-配置了正向代理模式" class="headerlink" title="2. 配置了正向代理模式"></a>2. 配置了正向代理模式</h3><p>当浏览器或系统配置了代理地址，例如：</p>
<ul>
<li>代理地址：<code>proxy.mycorp.com</code></li>
<li>端口：<code>8080</code></li>
</ul>
<p>此时客户端行为改变：</p>
<ul>
<li><p>DNS 不再解析 <code>www.example.com</code></p>
</li>
<li><p>TCP 连接目标改为 <code>proxy.mycorp.com:8080</code></p>
</li>
<li><p>发请求：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">http://www.example.com/index.html</span> <span class="meta">HTTP/1.1</span></span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>www.example.com</span><br></pre></td></tr></table></figure></li>
</ul>
<p>👉 代理收到报文后，根据 Host 或 URL 确定目标网站，再去转发。</p>
<hr>
<h3 id="3-为什么这是客户端逻辑？"><a href="#3-为什么这是客户端逻辑？" class="headerlink" title="3. 为什么这是客户端逻辑？"></a>3. 为什么这是客户端逻辑？</h3><ul>
<li><p>HTTP 协议只规定“请求报文格式”</p>
</li>
<li><p>TCP 连接目标是由客户端实现决定的</p>
</li>
<li><p>浏览器配置代理的含义就是：</p>
<blockquote>
<p>“以后别直连目标网站，把请求先交给代理。”</p>
</blockquote>
</li>
</ul>
<p>因此：<br>✔ 直连模式 → TCP 连目标站点<br>✔ 代理模式 → TCP 连代理服务器<br>✔ 完全是客户端的选择和实现逻辑</p>
<hr>
<h3 id="4-特别注意：HTTPS-代理"><a href="#4-特别注意：HTTPS-代理" class="headerlink" title="4. 特别注意：HTTPS + 代理"></a>4. 特别注意：HTTPS + 代理</h3><p>当访问 HTTPS 时，客户端会先向代理发送 <strong>CONNECT 方法</strong>：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CONNECT</span> <span class="string">www.example.com:443</span> <span class="meta">HTTP/1.1</span></span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>www.example.com:443</span><br></pre></td></tr></table></figure>

<p>代理收到后，建立一条 TCP 隧道；TLS 握手和加密流量在隧道中传输，代理无法解密。<br>👉 这同样完全是客户端的实现逻辑。</p>
<hr>
<p>✅ <strong>结论</strong><br>正向代理模式下，客户端确实是 <strong>主动选择连代理服务器</strong>，而不是目标站点。<br>这是因为客户端知道自己在用代理，所以构造了“特殊的请求行 + 代理 TCP 目标”。</p>
<p>其实从客户端角度看，即使请求行写得像直连模式，效果也常常一样，因为多数代理会兼容：</p>
<ul>
<li>如果请求行缺少完整 URL</li>
<li>代理也能 fallback 到用 Host 提取目标域名</li>
</ul>
<p>因此对用户体验影响不大，差别更多是 <strong>规范要求 vs 代理实现的便利性</strong>。</p>
<hr>
<h2 id="7-正向代理的本质"><a href="#7-正向代理的本质" class="headerlink" title="7. 正向代理的本质"></a>7. 正向代理的本质</h2><p>从不同角度来看，正向代理的核心本质可以归纳为三层：</p>
<ul>
<li><p><strong>从 TCP 角度</strong><br>客户端只是在“建 TCP 连接”这一步，选择连代理服务器的 IP:Port，而不是目标服务器的 IP:Port。<br>👉 对 TCP 来说，这没有什么“特殊”，就是连了另一台机器而已。</p>
</li>
<li><p><strong>从 HTTP 角度</strong><br>客户端在请求报文里写的是绝对 URI（<code>http://host/path</code>），这样代理才能知道目标是谁。<br>👉 这就是“请求行会有完整路径”的原因。</p>
</li>
<li><p><strong>从代理实现角度</strong><br>代理要支持解析这种“带绝对 URI 的请求行”，并根据 Host&#x2F;URI 再去发起一个新的 TCP 连接转发给目标。<br>👉 这就是“代理服务器要有支持转发的逻辑”。</p>
</li>
</ul>
<hr>
<h2 id="8-实际实现-vs-规范要求"><a href="#8-实际实现-vs-规范要求" class="headerlink" title="8. 实际实现 vs 规范要求"></a>8. 实际实现 vs 规范要求</h2><table>
<thead>
<tr>
<th>维度</th>
<th>规范要求</th>
<th>实际实现兼容性</th>
</tr>
</thead>
<tbody><tr>
<td>正向代理请求行</td>
<td>必须写完整 URL</td>
<td>大部分代理也容忍只写 <code>/path</code>，会用 Host 拼接</td>
</tr>
<tr>
<td>Host 头</td>
<td>必须携带</td>
<td>必须携带</td>
</tr>
<tr>
<td>缓存&#x2F;日志</td>
<td>直接用 URL 做键，简单高效</td>
<td>如果缺 URL，代理需额外拼接 Host</td>
</tr>
</tbody></table>
<hr>
<h2 id="9-HTTPS-与正向代理的特殊性"><a href="#9-HTTPS-与正向代理的特殊性" class="headerlink" title="9. HTTPS 与正向代理的特殊性"></a>9. HTTPS 与正向代理的特殊性</h2><p>当通过正向代理访问 HTTPS 站点时，客户端先发起 <strong>CONNECT 隧道请求</strong>：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CONNECT</span> <span class="string">www.example.com:443</span> <span class="meta">HTTP/1.1</span></span><br><span class="line"><span class="attribute">Host</span><span class="punctuation">: </span>www.example.com:443</span><br></pre></td></tr></table></figure>

<p>代理建立 TCP 隧道后，客户端在隧道内直接跑 TLS 握手，代理无法看到明文。<br>👉 这同样由客户端的代理配置决定，TCP 本身并不区分。</p>
<hr>
<h2 id="10-结论"><a href="#10-结论" class="headerlink" title="10. 结论"></a>10. 结论</h2><ol>
<li><p><strong>正向代理</strong>：</p>
<ul>
<li>TCP 连代理服务器</li>
<li>HTTP 请求行写完整 URL</li>
<li>客户端知道自己在用代理</li>
</ul>
</li>
<li><p><strong>反向代理</strong>：</p>
<ul>
<li>TCP 连反向代理（表面看似目标站点）</li>
<li>HTTP 请求行写路径，Host 提供目标域名</li>
<li>客户端无感知</li>
</ul>
</li>
<li><p><strong>核心差别</strong>：</p>
<ul>
<li>正向代理：服务于客户端，帮助突破访问限制</li>
<li>反向代理：服务于服务器，做负载均衡、缓存、安全隔离</li>
</ul>
</li>
</ol>
<hr>
<p>📌 总结一句话：<br><strong>正向代理是客户端主动配置的中转站，反向代理是服务端架构中的门面。区别的本质在于 TCP 建链目标和 HTTP 请求行格式。</strong></p>
]]></content>
      <tags>
        <tag>TCP</tag>
        <tag>HTTP</tag>
        <tag>正向代理</tag>
        <tag>反向代理</tag>
      </tags>
  </entry>
  <entry>
    <title>家庭宽带中的公网与内网 IP 分配机制解析</title>
    <url>/2025/08/17/20250817-jia-ting-kuan-dai-zhong-de-gong-wang-yu-nei-wang-ip-fen-pei-ji-zhi-jie-xi/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>以下内容由AI生成</p>
</blockquote>
</blockquote>
<p>在日常使用家庭宽带时，很多人会遇到“到底我家有没有独立公网 IP”的问题。这不仅关系到能否顺利访问外网，更影响到是否可以在家中搭建服务器、使用 P2P 应用等。本文将系统梳理家庭宽带 IP 的分配方式、运营商 NAT 的机制以及其对用户的实际影响。</p>
<hr>
<h2 id="1-家庭宽带的几种典型-IP-分配方式"><a href="#1-家庭宽带的几种典型-IP-分配方式" class="headerlink" title="1. 家庭宽带的几种典型 IP 分配方式"></a>1. 家庭宽带的几种典型 IP 分配方式</h2><h3 id="（1）独立公网-IP"><a href="#（1）独立公网-IP" class="headerlink" title="（1）独立公网 IP"></a>（1）独立公网 IP</h3><ul>
<li>家庭路由器的 <strong>WAN 口直接获取公网 IPv4 地址</strong>（或独立 IPv6 前缀）。</li>
<li>此时家庭就是一个独立的外网节点，可直接与互联网通信（除非被防火墙限制）。</li>
<li><strong>典型场景</strong>：早期 ADSL 宽带、当前部分电信&#x2F;联通&#x2F;移动的 IPv6 分配。</li>
</ul>
<p><strong>优势</strong>：可开放端口、搭建服务器，外网可直接访问家庭设备。</p>
<hr>
<h3 id="（2）共享公网-IP（运营商-NAT-x2F-CGNAT）"><a href="#（2）共享公网-IP（运营商-NAT-x2F-CGNAT）" class="headerlink" title="（2）共享公网 IP（运营商 NAT &#x2F; CGNAT）"></a>（2）共享公网 IP（运营商 NAT &#x2F; CGNAT）</h3><ul>
<li><p>由于 IPv4 地址紧张，很多家庭宽带 WAN 口拿到的并不是公网地址，而是内网地址：</p>
<ul>
<li><code>100.64.x.x</code>（CGNAT 专用）、<code>10.x.x.x</code>、<code>172.16–31.x.x</code>、<code>192.168.x.x</code> 等。</li>
</ul>
</li>
<li><p>运营商在核心网部署 NAT，把成百上千家庭流量映射到同一个公网 IP 上。</p>
</li>
</ul>
<p><strong>特点与问题</strong>：</p>
<ul>
<li>家庭没有独立公网出口，而是和他人“拼”一个公网 IP。</li>
<li><strong>限制</strong>：端口映射困难甚至不可能 → 无法轻易搭建对外服务。</li>
</ul>
<hr>
<h3 id="（3）混合模式（IPv6-公网-IPv4-NAT）"><a href="#（3）混合模式（IPv6-公网-IPv4-NAT）" class="headerlink" title="（3）混合模式（IPv6 公网 + IPv4 NAT）"></a>（3）混合模式（IPv6 公网 + IPv4 NAT）</h3><ul>
<li>家庭可获得独立的 <strong>IPv6 前缀</strong>（相当于独立公网地址）。</li>
<li>IPv4 依旧通过 NAT，共享公网 IP。</li>
<li>这种情况在目前逐渐普及，算是“半独立外网”。</li>
</ul>
<hr>
<h2 id="2-内网与外网的关系"><a href="#2-内网与外网的关系" class="headerlink" title="2. 内网与外网的关系"></a>2. 内网与外网的关系</h2><ul>
<li><strong>LAN 内网 IP</strong>：路由器分配给家庭设备的地址（如 192.168.x.x），可支持上百台设备。</li>
<li><strong>WAN IP</strong>：路由器外网口的地址，可能是真公网，也可能是运营商 NAT 内网（如 100.64.x.x）。</li>
</ul>
<p><strong>关键点</strong>：</p>
<ul>
<li><p>家庭可分配的内网 IP 数量不受共享公网限制，理论上仍可支持数百设备。</p>
</li>
<li><p>共享公网真正的限制在于：</p>
<ul>
<li>端口映射受阻</li>
<li>P2P 软件连接困难</li>
<li>搭建家庭服务器几乎不可能</li>
</ul>
</li>
</ul>
<hr>
<h2 id="3-CGNAT-的工作机制"><a href="#3-CGNAT-的工作机制" class="headerlink" title="3. CGNAT 的工作机制"></a>3. CGNAT 的工作机制</h2><p>CGNAT 的核心是 <strong>端口映射表</strong>。</p>
<ol>
<li>家庭路由器将内网设备请求 NAT 成 <strong>WAN IP + 端口</strong>。</li>
<li>运营商 CGNAT 再将 WAN IP + 端口转换为 <strong>公网 IP + 唯一端口</strong>。</li>
<li>返回数据时，CGNAT 通过映射表查找，精准把数据包发回正确的家庭。</li>
</ol>
<p><strong>要点</strong>：</p>
<ul>
<li>即使不同家庭设备端口相同，CGNAT 会分配不同的公网端口 → 不会冲突。</li>
<li>每个家庭必须有唯一的 WAN IP（即便是私有地址），否则映射表无法区分连接。</li>
</ul>
<hr>
<h2 id="4-特殊地址段：100-64-x-x"><a href="#4-特殊地址段：100-64-x-x" class="headerlink" title="4. 特殊地址段：100.64.x.x"></a>4. 特殊地址段：100.64.x.x</h2><ul>
<li><p><strong>定义</strong>：RFC 6598 规定 <code>100.64.0.0/10</code> 专用于 <strong>运营商级 NAT</strong>。</p>
</li>
<li><p><strong>特性</strong>：</p>
<ul>
<li>不是公网 IP（外网无法直达）。</li>
<li>不是家庭 LAN 内网（192.168&#x2F;10.x&#x2F;172.16–31），而是运营商内部“二级内网”。</li>
</ul>
</li>
<li><p><strong>工作方式</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">家庭设备 192.168.1.2</span><br><span class="line">    ↓ 家庭路由器 NAT</span><br><span class="line">WAN: 100.64.1.2  ← 运营商私有地址</span><br><span class="line">    ↓ 运营商 CGNAT</span><br><span class="line">公网 IP: 1.2.3.4</span><br><span class="line">    ↓ Internet</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>注意</strong>：家庭网络不应使用 100.64.x.x 作为 LAN 地址，否则会和运营商 CGNAT 冲突，导致公网无法访问。</p>
<hr>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><ol>
<li><strong>独立公网 IP</strong>：可直接对外通信，最自由。</li>
<li><strong>共享公网 IP（CGNAT）</strong>：常见于 IPv4，无法轻易开放端口，但家庭内网不受影响。</li>
<li><strong>IPv6 普及下的混合模式</strong>：IPv6 独立公网，IPv4 仍共享。</li>
<li><strong>100.64.x.x 是运营商内网地址</strong>，不是公网 IP。</li>
<li><strong>核心差异</strong>：家庭内网数量不受限制，但共享公网时外网访问受阻。</li>
</ol>
<hr>
<p>📌 <strong>一句话总结</strong>：<br>大多数家庭宽带并没有独立公网 IPv4，而是通过 CGNAT 与他人共享出口。要想获得真正独立的公网地址，需要向运营商申请“公网 IP 服务”或使用企业宽带。</p>
]]></content>
      <tags>
        <tag>家庭网络</tag>
        <tag>公网IP</tag>
      </tags>
  </entry>
  <entry>
    <title>VPN 与正向代理的原理与差异分析</title>
    <url>/2025/08/17/20250817-vpn-yu-zheng-xiang-dai-li-de-yuan-li-yu-chai-yi-fen-xi/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>以下内容由AI生成，本人审阅</p>
</blockquote>
</blockquote>
<h2 id="一、VPN-的基本原理"><a href="#一、VPN-的基本原理" class="headerlink" title="一、VPN 的基本原理"></a>一、VPN 的基本原理</h2><p>**VPN（Virtual Private Network，虚拟专用网络）**的核心思想是在 <strong>公网上（Internet）</strong> 建立一条 <strong>加密隧道</strong>，使用户的数据能够像在同一局域网中一样安全传输。其关键机制包括：</p>
<ol>
<li><p><strong>隧道封装（Tunneling）</strong></p>
<ul>
<li>将原始 IP 包或 TCP&#x2F;UDP 流量再次封装后发送至 VPN 服务器。</li>
<li>VPN 服务器解封装后再转发至目标网站或服务。</li>
<li>常见协议包括 PPTP、L2TP、IPSec、OpenVPN（基于 TLS&#x2F;SSL）、WireGuard 等。</li>
</ul>
</li>
<li><p><strong>数据加密（Encryption）</strong></p>
<ul>
<li>VPN 的核心能力之一就是加密，例如 AES、ChaCha20。</li>
<li>运营商或中间路由器看到的只是加密数据流，而无法识别内容。</li>
</ul>
</li>
<li><p><strong>虚拟网卡（Virtual NIC）</strong></p>
<ul>
<li>客户端安装 VPN 时会创建虚拟网卡。</li>
<li>系统将原始流量交给虚拟网卡，由 VPN 客户端进行加密与封装，再传输至服务器。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="二、正向代理的基本原理"><a href="#二、正向代理的基本原理" class="headerlink" title="二、正向代理的基本原理"></a>二、正向代理的基本原理</h2><p><strong>正向代理（Forward Proxy）</strong> 是一种由客户端主动指定的代理模式：</p>
<ul>
<li>客户端 → <strong>代理服务器</strong> → 目标网站</li>
<li>代理服务器替代客户端访问网站。</li>
</ul>
<p>常见类型包括：</p>
<ul>
<li><strong>HTTP Proxy</strong>：仅代理网页流量。</li>
<li><strong>SOCKS5 Proxy</strong>：支持 TCP&#x2F;UDP，更通用。</li>
</ul>
<p>👉 如果在正向代理的基础上增加加密，就得到 <strong>加密正向代理</strong>，例如：</p>
<ul>
<li><strong>Shadowsocks</strong>（基于 SOCKS5 + 加密）</li>
<li><strong>V2Ray、Trojan</strong>（自定义协议 + 加密）</li>
</ul>
<hr>
<h2 id="三、VPN-与正向代理的关系"><a href="#三、VPN-与正向代理的关系" class="headerlink" title="三、VPN 与正向代理的关系"></a>三、VPN 与正向代理的关系</h2><ol>
<li><p><strong>共性</strong></p>
<ul>
<li>都是正向代理的广义形式，用户请求最终都由中间服务器转发。</li>
<li>都可以实现数据加密、突破访问限制、保护隐私。</li>
</ul>
</li>
<li><p><strong>差异</strong></p>
<ul>
<li><strong>VPN</strong>：工作在 <strong>网络层</strong>，接管整个系统的所有流量，不需要应用单独配置。</li>
<li><strong>加密代理（Shadowsocks&#x2F;V2Ray&#x2F;Trojan 等）</strong>：工作在 <strong>传输层&#x2F;应用层</strong>，更灵活，可以选择性分流。</li>
</ul>
</li>
</ol>
<p>✅ 准确的表述是：</p>
<blockquote>
<p><strong>VPN 是一种在网络层实现的“全流量加密隧道代理”；而机场协议（如 Shadowsocks&#x2F;V2Ray&#x2F;Trojan）是工作在传输层或应用层的“加密正向代理”。</strong></p>
</blockquote>
<hr>
<h2 id="四、为什么“机场代理”常被叫做-VPN"><a href="#四、为什么“机场代理”常被叫做-VPN" class="headerlink" title="四、为什么“机场代理”常被叫做 VPN"></a>四、为什么“机场代理”常被叫做 VPN</h2><ul>
<li>手机或电脑端的 Shadowsocks&#x2F;V2Ray 客户端通常会申请系统的 <strong>VPN 权限（VPNService）</strong>，创建虚拟网卡，将流量导入代理。</li>
<li>在用户体验上，表现为“一键开启，所有流量都出国”，与 VPN 相似。</li>
<li>但协议层面，它们并非传统 VPN，而是 <strong>加密正向代理 + VPN 伪装</strong> 的结合体。</li>
</ul>
<hr>
<h2 id="五、效果、效率与使用体验差异"><a href="#五、效果、效率与使用体验差异" class="headerlink" title="五、效果、效率与使用体验差异"></a>五、效果、效率与使用体验差异</h2><h3 id="1-效果层面"><a href="#1-效果层面" class="headerlink" title="1. 效果层面"></a>1. 效果层面</h3><ul>
<li><strong>VPN</strong>：全流量隧道，统一加密转发。</li>
<li><strong>机场代理</strong>：通过加密代理转发流量，用户体验上几乎无差别。</li>
</ul>
<h3 id="2-效率与性能"><a href="#2-效率与性能" class="headerlink" title="2. 效率与性能"></a>2. 效率与性能</h3><ul>
<li><strong>VPN</strong>：底层封装，效率较高（WireGuard 延迟小、速度快）。</li>
<li><strong>代理</strong>：协议转换可能增加开销，但现代实现已高度优化。</li>
</ul>
<h3 id="3-使用体验"><a href="#3-使用体验" class="headerlink" title="3. 使用体验"></a>3. 使用体验</h3><ul>
<li><strong>VPN</strong>：系统级全局接管，适合企业远程办公、统一管控。</li>
<li><strong>机场代理</strong>：支持灵活分流（国际流量走代理、国内直连），更适合个人日常使用。</li>
</ul>
<hr>
<h2 id="六、典型场景对比"><a href="#六、典型场景对比" class="headerlink" title="六、典型场景对比"></a>六、典型场景对比</h2><ol>
<li><p><strong>公司 VPN</strong></p>
<ul>
<li>常见模式是 <strong>全隧道（Full Tunnel）</strong>，所有流量经由公司出口，安全统一但效率偏低。</li>
<li>有些公司支持 <strong>分隧道（Split Tunnel）</strong>，仅内网走 VPN，外网直连，但安全性存在隐患。</li>
</ul>
</li>
<li><p><strong>机场代理</strong></p>
<ul>
<li>可选择 <strong>全局代理</strong>，模拟 VPN 效果。</li>
<li>或使用 <strong>规则分流</strong>（PAC 模式），国际流量走代理，国内直连，更高效。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a>七、总结</h2><ul>
<li><strong>VPN</strong>：本质是 <strong>网络层的加密隧道代理</strong>，接管系统所有流量。</li>
<li><strong>机场协议（Shadowsocks、V2Ray、Trojan）</strong>：本质是 <strong>传输层&#x2F;应用层的加密正向代理</strong>，通过虚拟网卡实现“伪装成 VPN”的体验。</li>
<li><strong>共同点</strong>：都加密、都代理、都能突破限制。</li>
<li><strong>差异点</strong>：VPN 更底层、统一接管；机场代理更灵活、支持分流。</li>
</ul>
<p>👉 一句话概括：<br><strong>VPN 与机场协议都是“加密正向代理”，区别只在于工作层级和使用方式。</strong></p>
]]></content>
      <tags>
        <tag>正向代理</tag>
        <tag>VPN</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解 SOCKS5 正向代理原理</title>
    <url>/2025/08/17/20250817-shen-ru-li-jie-socks5-zheng-xiang-dai-li-yuan-li/</url>
    <content><![CDATA[<blockquote>
<blockquote>
<p>以下内容由AI生成，本人审阅</p>
</blockquote>
</blockquote>
<p>在网络代理领域，<strong>SOCKS5</strong> 是一种常用的正向代理协议。它不同于传统的 HTTP 代理，能够为各种应用层协议提供通用的转发支持。本文将从概念、协议机制、工作流程和应用场景几个层次，系统梳理 SOCKS5 的技术原理。</p>
<hr>
<h2 id="1-正向代理的基本概念"><a href="#1-正向代理的基本概念" class="headerlink" title="1. 正向代理的基本概念"></a>1. 正向代理的基本概念</h2><p><strong>正向代理</strong>是指客户端主动使用代理服务器，把请求先发给代理，再由代理去访问目标服务器，并把结果返回客户端。</p>
<p><strong>主要作用</strong>：</p>
<ul>
<li>隐藏客户端真实 IP</li>
<li>绕过访问限制（如内网封锁、跨境访问）</li>
<li>统一出口流量，便于管理和审计</li>
</ul>
<hr>
<h2 id="2-SOCKS-协议简介"><a href="#2-SOCKS-协议简介" class="headerlink" title="2. SOCKS 协议简介"></a>2. SOCKS 协议简介</h2><p><strong>SOCKS (Socket Secure)</strong> 是一种通用的代理协议，不依赖特定的应用层协议。</p>
<ul>
<li><p><strong>SOCKS5</strong> 是该协议的第 5 版，支持更多功能：</p>
<ul>
<li>TCP 与 UDP 转发</li>
<li>用户认证（无认证、用户名&#x2F;密码等）</li>
<li>IPv4 &#x2F; IPv6 &#x2F; 域名解析</li>
</ul>
</li>
</ul>
<p>👉 与 HTTP 代理相比，SOCKS5 并不解析上层应用协议，只做数据字节的透明转发，因此适用范围更广。</p>
<hr>
<h2 id="3-SOCKS5-的工作流程"><a href="#3-SOCKS5-的工作流程" class="headerlink" title="3. SOCKS5 的工作流程"></a>3. SOCKS5 的工作流程</h2><p>假设客户端配置了一个 SOCKS5 代理，整个交互过程如下：</p>
<h3 id="1）客户端与代理握手"><a href="#1）客户端与代理握手" class="headerlink" title="1）客户端与代理握手"></a>1）客户端与代理握手</h3><ul>
<li>客户端告知代理：“我支持哪些认证方式（无认证 &#x2F; 用户名密码 &#x2F; …）”</li>
<li>代理回应：“我要求用某种认证方式”</li>
<li>若需认证，客户端提交凭证，通过后进入下一阶段</li>
</ul>
<h3 id="2）客户端请求目标地址"><a href="#2）客户端请求目标地址" class="headerlink" title="2）客户端请求目标地址"></a>2）客户端请求目标地址</h3><ul>
<li>客户端通过代理的 TCP 连接，发送目标地址和端口，例如：<code>example.com:80</code></li>
<li>代理尝试与目标服务器建立连接</li>
</ul>
<h3 id="3）代理回应结果"><a href="#3）代理回应结果" class="headerlink" title="3）代理回应结果"></a>3）代理回应结果</h3><ul>
<li>连接成功：返回成功报文，允许数据传输</li>
<li>连接失败：返回错误码（如目标不可达、连接被拒绝等）</li>
</ul>
<h3 id="4）数据转发"><a href="#4）数据转发" class="headerlink" title="4）数据转发"></a>4）数据转发</h3><ul>
<li>客户端与目标服务器的所有数据均通过代理中转</li>
<li>代理只做字节转发，不理解应用层协议内容</li>
<li>这使得 SOCKS5 成为一种非常通用的代理机制</li>
</ul>
<hr>
<h2 id="4-TCP-与-UDP-的支持"><a href="#4-TCP-与-UDP-的支持" class="headerlink" title="4. TCP 与 UDP 的支持"></a>4. TCP 与 UDP 的支持</h2><p>SOCKS5 协议既能代理 <strong>TCP</strong>，也能代理 <strong>UDP</strong>：</p>
<ul>
<li><p><strong>TCP CONNECT</strong></p>
<ul>
<li>客户端请求代理建立到目标服务器的 TCP 连接</li>
<li>数据传输过程中，代理双向转发 TCP 流量</li>
<li>应用场景：网页浏览、SSH、邮件收发等</li>
</ul>
</li>
<li><p><strong>UDP ASSOCIATE</strong></p>
<ul>
<li>客户端先通过 TCP 控制通道告诉代理要进行 UDP 转发</li>
<li>代理返回一个专用的 UDP 端口</li>
<li>客户端将 UDP 数据包（带 SOCKS5 UDP 头）发送到该端口，代理再转发到目标服务器</li>
<li>应用场景：DNS 查询、在线游戏、视频流</li>
</ul>
</li>
</ul>
<hr>
<h2 id="5-TCP-与-UDP-的关系"><a href="#5-TCP-与-UDP-的关系" class="headerlink" title="5. TCP 与 UDP 的关系"></a>5. TCP 与 UDP 的关系</h2><p>需要特别注意：</p>
<ol>
<li><p><strong>控制信道：必然是 TCP</strong></p>
<ul>
<li>无论最终转发 TCP 还是 UDP，客户端和代理之间都要先建立一条 TCP 连接</li>
<li>握手、认证、UDP 转发上下文都依赖该 TCP 控制信道</li>
</ul>
</li>
<li><p><strong>数据通道：因请求而异</strong></p>
<ul>
<li><strong>CONNECT 命令</strong> → 代理 TCP 流量</li>
<li><strong>UDP ASSOCIATE 命令</strong> → 代理 UDP 数据包</li>
</ul>
</li>
</ol>
<p>👉 简单比喻：</p>
<ul>
<li>TCP 就像一条“电话线”，你先打电话告诉代理你要去哪</li>
<li>如果是 TCP 业务，代理帮你中继对话</li>
<li>如果是 UDP 业务，代理给你一个“邮局地址”，你把信件（UDP 包）寄过去，它帮你转发</li>
</ul>
<hr>
<h2 id="6-为什么-SOCKS5-常用"><a href="#6-为什么-SOCKS5-常用" class="headerlink" title="6. 为什么 SOCKS5 常用"></a>6. 为什么 SOCKS5 常用</h2><p>SOCKS5 在现代网络应用中被广泛使用，原因在于：</p>
<ul>
<li><strong>协议层次低</strong>：位于 TCP&#x2F;UDP 之上，应用层之下，对上层协议透明</li>
<li><strong>适用性广</strong>：能代理任意应用层协议，不仅限于 HTTP</li>
<li><strong>支持 UDP 转发</strong>：满足实时性要求高的业务场景</li>
<li><strong>支持身份认证与 IPv6</strong>：更安全，适应新网络环境</li>
<li><strong>比 HTTP 代理更灵活</strong>：不做解析，只做转发</li>
</ul>
<hr>
<h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>一句话概括：<br><strong>SOCKS5 正向代理的原理是——客户端和代理建立 TCP 会话，告诉代理要访问的目标地址，代理再代表客户端发起连接，并负责转发所有 TCP&#x2F;UDP 数据。代理本身不理解应用层协议，只是透明转发。</strong></p>
<hr>
<p>⚡关键点回顾：</p>
<ul>
<li>SOCKS5 协议本身基于 TCP</li>
<li>可代理 TCP 与 UDP 流量</li>
<li>UDP 转发依赖 TCP 控制信道维持会话</li>
<li>对应用层协议透明，通用性极强</li>
</ul>
]]></content>
      <tags>
        <tag>正向代理</tag>
        <tag>SOCKS5</tag>
      </tags>
  </entry>
  <entry>
    <title>VS Code + Dev Container：打造丝滑的 Linux 开发调试体验</title>
    <url>/2025/08/25/20250825-vs-code-dev-container-da-zao-si-hua-de-linux-kai-fa-diao-shi-ti-yan/</url>
    <content><![CDATA[<p>最近在重新学习 Linux C++ 的过程中，发现了一种优雅的方式：借助 <strong>Docker + VS Code Dev Container</strong> 在任何系统上轻松获得一致的 Linux 开发调试环境。作为长期在 macOS 和 Windows 上开发的人，这种体验让我感受到前所未有的丝滑，真有点“相逢恨晚”。</p>
<p>从此，无论是 C++、Python、Go，还是其他需要 Linux 环境的项目，都可以通过 Dev Container 轻松构建一致的开发调试环境。以下是相关的整理和总结。</p>
<hr>
<h2 id="1-Dev-Container-的核心优势"><a href="#1-Dev-Container-的核心优势" class="headerlink" title="1. Dev Container 的核心优势"></a>1. Dev Container 的核心优势</h2><ul>
<li><strong>统一环境</strong>：项目环境配置集中管理，避免“环境配置地狱”。</li>
<li><strong>真实 Linux 环境</strong>：Mac&#x2F;Windows 上可获得接近原生 Linux 的开发体验。</li>
<li><strong>环境隔离</strong>：每个项目独立运行，避免宿主机污染。</li>
<li><strong>一键上手</strong>：新人无需安装复杂依赖，直接启动容器即用。</li>
<li><strong>跨平台一致性</strong>：团队成员无论使用何种操作系统，都能保持开发环境完全一致。</li>
</ul>
<hr>
<h2 id="2-调试工作原理"><a href="#2-调试工作原理" class="headerlink" title="2. 调试工作原理"></a>2. 调试工作原理</h2><ul>
<li><strong>VS Code 前端</strong>：仅负责界面展示和用户交互。</li>
<li><strong>容器内调试器后端</strong>：断点、变量跟踪等逻辑均在容器中执行。</li>
<li><strong>Docker 通信</strong>：通过端口映射或内置通道实现容器与宿主机的连接。</li>
<li><strong>DAP 协议</strong>：调试适配器协议（Debug Adapter Protocol）统一了调试接口，支持多语言插件。</li>
<li><strong>无缝体验</strong>：Dev Container 自动部署 VS Code Server，调试如同本地运行。</li>
</ul>
<hr>
<h2 id="3-跨架构开发（Mac-ARM-跑-x86-容器）"><a href="#3-跨架构开发（Mac-ARM-跑-x86-容器）" class="headerlink" title="3. 跨架构开发（Mac ARM 跑 x86 容器）"></a>3. 跨架构开发（Mac ARM 跑 x86 容器）</h2><ul>
<li><strong>QEMU 仿真</strong>：通过指令翻译运行 x86 ELF 程序。</li>
<li><strong>binfmt_misc</strong>：自动识别并调度不同架构的可执行文件。</li>
<li><strong>优势</strong>：可兼容仅支持 x86 的旧软件或镜像。</li>
<li><strong>不足</strong>：性能有损耗，不适合重度计算任务或长期运行。</li>
</ul>
<hr>
<h2 id="4-微服务项目的容器化策略"><a href="#4-微服务项目的容器化策略" class="headerlink" title="4. 微服务项目的容器化策略"></a>4. 微服务项目的容器化策略</h2><ol>
<li><p><strong>共享开发环境容器</strong><br>单一容器作为开发机，挂载多个项目，减少容器启动和切换成本。</p>
</li>
<li><p><strong>多服务合一容器</strong><br>借助 <code>supervisord</code> 管理多个进程，将多个微服务打包到同一个容器中运行。</p>
</li>
<li><p><strong>docker-compose 管理公共依赖</strong><br>数据库、缓存等共享服务通过 <code>docker-compose</code> 集中管理，避免重复维护。</p>
</li>
<li><p><strong>多项目 Dev Container 配置</strong></p>
<ul>
<li>利用 <code>workspaceMount</code> 挂载多个项目目录；</li>
<li><code>.devcontainer/</code> 建议放在仓库或 monorepo 顶层，便于团队协作。</li>
</ul>
</li>
</ol>
<h4 id="方法1-vs-方法4-对比表"><a href="#方法1-vs-方法4-对比表" class="headerlink" title="方法1 vs 方法4 对比表"></a>方法1 vs 方法4 对比表</h4><table>
<thead>
<tr>
<th>特性</th>
<th>方法1：单容器开发机</th>
<th>方法4：多项目 Dev Container</th>
</tr>
</thead>
<tbody><tr>
<td>容器构建</td>
<td>手动构建镜像</td>
<td>自动构建</td>
</tr>
<tr>
<td>配置文件位置</td>
<td>可选，不依赖 <code>.devcontainer</code></td>
<td>必须在仓库最外层目录</td>
</tr>
<tr>
<td>多项目管理</td>
<td>手动挂载路径</td>
<td>自动 <code>workspaceMount</code></td>
</tr>
<tr>
<td>团队协作</td>
<td>偏向个人开发</td>
<td>团队友好</td>
</tr>
<tr>
<td>启动方式</td>
<td>手动 Attach</td>
<td>一键 <code>Reopen in Container</code></td>
</tr>
</tbody></table>
<blockquote>
<p>对于大型项目或多团队协作，可以考虑 Kubernetes 或云端 Codespaces 来简化开发环境管理。</p>
</blockquote>
<hr>
<h2 id="5-总结与趋势"><a href="#5-总结与趋势" class="headerlink" title="5. 总结与趋势"></a>5. 总结与趋势</h2><ul>
<li><strong>容器化开发环境已成趋势</strong>：开发环境可以像代码一样被版本化、迁移、复刻。</li>
<li><strong>适用场景广泛</strong>：不仅适合现代项目，对老旧技术栈（如 PHP 项目）同样友好。</li>
<li><strong>开发体验升级</strong>：只需一次配置，团队成员无需手动搭建环境，即可专注业务开发。</li>
</ul>
<hr>
<p>这样一套方案，让跨平台、跨语言、跨架构的开发调试都像在本地一样丝滑高效。</p>
<hr>
<h2 id="参考例子"><a href="#参考例子" class="headerlink" title="参考例子"></a>参考例子</h2><ul>
<li><a href="https://github.com/Kingson4Wu/cpp-linux-playground">https://github.com/Kingson4Wu/cpp-linux-playground</a></li>
</ul>
]]></content>
      <tags>
        <tag>vscode</tag>
        <tag>DevContainer</tag>
        <tag>linux</tag>
        <tag>CPP</tag>
      </tags>
  </entry>
  <entry>
    <title>用 tmux + 内网穿透，让出门也能指导编程任务</title>
    <url>/2025/08/28/20250828-yong-tmux-nei-wang-chuan-tou-rang-chu-men-ye-neng-zhi-dao-bian-cheng-ren-wu/</url>
    <content><![CDATA[<p>以前写代码是个挺“重”的事情：开一堆 IDE、文档、调试窗口，在桌面环境里来回切换。要是人在外面，就算能远程登录，也常常因为手机输入不方便、网络不稳定而放弃。</p>
<p>但现在情况不一样了。很多时候，你并不需要全套开发环境。只要能接上家里的机器，就能让零碎时间发挥点价值：不管是写点脚手架代码，跑几个命令，还是做些前期准备工作，都可以在外面先处理掉。等回到电脑前，再做深度开发和调试，就顺畅很多。</p>
<h2 id="实际效果"><a href="#实际效果" class="headerlink" title="实际效果"></a>实际效果</h2><p><img src="/2025/08/28/20250828-yong-tmux-nei-wang-chuan-tou-rang-chu-men-ye-neng-zhi-dao-bian-cheng-ren-wu/Chrome_Remote_Desktop.PNG"></p>
<p><img src="/2025/08/28/20250828-yong-tmux-nei-wang-chuan-tou-rang-chu-men-ye-neng-zhi-dao-bian-cheng-ren-wu/tmux.PNG"></p>
<hr>
<h2 id="思路很简单"><a href="#思路很简单" class="headerlink" title="思路很简单"></a>思路很简单</h2><p>其实只要搞定两件事，就能让“人在外面也能继续编程”变得靠谱：</p>
<h3 id="1-远程连上家里的环境"><a href="#1-远程连上家里的环境" class="headerlink" title="1. 远程连上家里的环境"></a>1. 远程连上家里的环境</h3><p>最简单的方式是用 <strong>Chrome Remote Desktop</strong> 直接把桌面搬到手机上。<br>但如果你更喜欢命令行的简洁，可以在 Mac 上开好 <strong>SSH + tmux</strong>，再配合 <strong>内网穿透工具</strong>（比如 Cloudflare Tunnel、frp、zerotier），这样就能在手机终端里直连家里的 tmux 会话。</p>
<h3 id="2-保持会话不中断"><a href="#2-保持会话不中断" class="headerlink" title="2. 保持会话不中断"></a>2. 保持会话不中断</h3><p>这里的关键是 <code>tmux</code>：</p>
<ul>
<li>它能把会话挂在后台，不会因为你断开 SSH 就消失。</li>
<li>下次连上去，只要 <code>tmux attach</code> 就能回到之前的窗口，继续干活，丝毫不影响节奏。</li>
</ul>
<hr>
<h2 id="这种方式的好处"><a href="#这种方式的好处" class="headerlink" title="这种方式的好处"></a>这种方式的好处</h2><ul>
<li><strong>轻量</strong>：不用开完整远程桌面，命令行就够了。</li>
<li><strong>连续性强</strong>：断线没关系，tmux 会帮你“记住现场”。</li>
<li><strong>利用碎片时间</strong>：比如地铁上、咖啡店里，掏出手机就能跑些小任务。</li>
</ul>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>tmux + 内网穿透，说白了就是给自己搭了条随时可用的远程工作通道。<br>出门在外，你可以用手机连上去，把一些零碎的准备工作先做掉；回到家，再用大屏幕和 IDE 把任务完善。</p>
]]></content>
      <tags>
        <tag>tmux</tag>
        <tag>内网穿透</tag>
        <tag>AI编程</tag>
        <tag>Chrome Remote Desktop</tag>
      </tags>
  </entry>
  <entry>
    <title>用脚本+AI CLI半自动写代码：实践经验分享</title>
    <url>/2025/09/02/20250902-yong-jiao-ben-ai-cli-ban-zi-dong-xie-dai-ma-shi-jian-jing-yan-fen-xiang/</url>
    <content><![CDATA[<p>最近在折腾一个“半自动编程”项目，目标是让 AI 工具在一个相对可控的框架下持续编码，帮我实现一个个明确的开发任务。这里分享整个过程、思路和实践套路，算是一次探索性的工程笔记。</p>
<h2 id="为什么要搞半自动"><a href="#为什么要搞半自动" class="headerlink" title="为什么要搞半自动"></a>为什么要搞半自动</h2><p>市面上的 AI 编程工具越来越多，比如：Claude Code、Gemini CLI、QWEN CODE 以及其他支持 CLI 模式的 AI 工具。<br>它们都能帮我们提高开发效率，但如果只是一次次手动问问题，效率还是不够高。我的想法是：</p>
<ol>
<li>用脚本封装和调度这些 AI 工具；</li>
<li>利用 <code>tmux</code> 维持 AI CLI 的会话状态；</li>
<li>自动给 AI 下发任务、收集结果，让 AI 一直“干活”，直到任务完成。</li>
</ol>
<p>这就像有个“虚拟小弟”24小时帮你写代码，而你更多做架构和技术方案的管理。</p>
<hr>
<h2 id="总体套路"><a href="#总体套路" class="headerlink" title="总体套路"></a>总体套路</h2><p>我总结下来整个流程可以分成四步，每一步都强调<strong>人工 review</strong>，避免“AI乱写”导致项目失控。</p>
<h3 id="1-初始化项目：立规范、搭框架"><a href="#1-初始化项目：立规范、搭框架" class="headerlink" title="1. 初始化项目：立规范、搭框架"></a>1. 初始化项目：立规范、搭框架</h3><p>项目开始前先搞定<strong>规范和架构</strong>，这是整个半自动化的基础。</p>
<ul>
<li><p>新建 GitHub 仓库，初始化代码框架：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:Kingson4Wu/ts-playground.git</span><br></pre></td></tr></table></figure></li>
<li><p>参考已有项目文档，比如我用的 <a href="https://github.com/Kingson4Wu/cpp-linux-playground/blob/main/PROJECT.md">cpp-linux-playground</a>，根据 TypeScript 项目的需求，改写成自己的 <code>PROJECT.md</code>。</p>
</li>
<li><p>规划好：</p>
<ul>
<li>技术栈（语言、工具链、标准）</li>
<li>测试和任务验收标准</li>
<li>静态分析工具</li>
<li>项目目录结构</li>
<li>Git 提交规范</li>
</ul>
</li>
</ul>
<blockquote>
<p>小建议：把 <code>docs/</code> 改成更专门的目录名（比如 <code>specifications/</code>），避免混乱。</p>
</blockquote>
<p>这一阶段主要是人工定规则、搭骨架，AI可以辅助起草文档，但最终必须你拍板。</p>
<hr>
<h3 id="2-细化任务实现方案"><a href="#2-细化任务实现方案" class="headerlink" title="2. 细化任务实现方案"></a>2. 细化任务实现方案</h3><p>所有任务先出详细的实现和测试方案，放在 <code>@specifications/task_specs/</code> 下。<br>原则：</p>
<ul>
<li><p><strong>不直接写代码</strong>，先写详细设计；</p>
</li>
<li><p>每个任务的设计经过人工审查和修改；</p>
</li>
<li><p>任务设计文件需要明确：</p>
<ul>
<li>功能描述</li>
<li>实现逻辑</li>
<li>输入输出</li>
<li>单元测试方案</li>
<li>潜在问题或风险点</li>
</ul>
</li>
</ul>
<p>这样做的好处是：AI有明确的执行指南，写出的代码更可控，后续修改成本也低。</p>
<hr>
<h3 id="3-半自动化驱动编码"><a href="#3-半自动化驱动编码" class="headerlink" title="3. 半自动化驱动编码"></a>3. 半自动化驱动编码</h3><p>有了规范和任务设计，就可以开始半自动写代码了。<br>我的方案是：</p>
<ul>
<li><p>用 Python 脚本驱动 AI CLI 工具；</p>
</li>
<li><p>通过 <code>tmux</code> 维持 AI 会话，避免中断；</p>
</li>
<li><p>每个任务循环：</p>
<ol>
<li>给 AI 发实现方案；</li>
<li>要求它按方案写代码，但<strong>不要自动提交代码</strong>；</li>
<li>人工检查后再提交到 Git。</li>
</ol>
</li>
</ul>
<p>脚本和逻辑可以参考 <a href="https://github.com/Kingson4Wu/ForgeFlow">ForgeFlow</a>，里面有完整的交互逻辑示例。</p>
<blockquote>
<p>小技巧：</p>
<ul>
<li>每个 Prompt 末尾强调“不要自动提交代码”；</li>
<li>如果任务超时超过1小时，自动触发检查机制；</li>
<li>项目进度同步到 <code>TODO.md</code>，并在 <code>PROJECT.md</code> 中引用。</li>
</ul>
</blockquote>
<hr>
<h3 id="4-定义“完成”的标准"><a href="#4-定义“完成”的标准" class="headerlink" title="4. 定义“完成”的标准"></a>4. 定义“完成”的标准</h3><p>一个任务完成的定义：</p>
<ol>
<li>按实现方案完成代码；</li>
<li>单元测试全部通过；</li>
<li>脚本和 Prompt 更新到位；</li>
<li>构建和测试无异常；</li>
<li>Git 提交所有改动；</li>
<li>进入下一个任务。</li>
</ol>
<p>最终目标是：</p>
<blockquote>
<p>输出所有方案 -&gt; 自动实现 -&gt; 所有项目任务完成后，AI只返回“完成”两个字。</p>
</blockquote>
<hr>
<h2 id="实战项目参考"><a href="#实战项目参考" class="headerlink" title="实战项目参考"></a>实战项目参考</h2><p>示例项目：<a href="https://github.com/Kingson4Wu/ts-playground">ts-playground</a><br>这是我搭的一个 TypeScript 学习和实验环境：</p>
<ul>
<li>CI&#x2F;CD 流程完整；</li>
<li>用于系统掌握 TypeScript 类型系统；</li>
<li>可以复用于后端服务、CLI 工具开发。</li>
</ul>
<p>这个项目就是通过“人机协作+半自动化”方式落地的。</p>
<hr>
<h2 id="半自动-vs-全自动"><a href="#半自动-vs-全自动" class="headerlink" title="半自动 vs 全自动"></a>半自动 vs 全自动</h2><p>目前这种方案是“半自动”，而不是“全自动”。原因：</p>
<ul>
<li><strong>设计和规范必须人工介入</strong>：AI生成的规范往往不够完善；</li>
<li><strong>脚本和Prompt需要不断打磨</strong>：无法覆盖所有场景；</li>
<li><strong>代码质量还需人工检查</strong>：AI的水平不总是稳定。</li>
</ul>
<p>换句话说，这是一个低成本、可控、复用性强的探索阶段方案。<br>全自动化？有点远，尤其是多Agent复杂度太高，难以管理上下文和控制风险。</p>
<hr>
<h2 id="上下文管理的核心"><a href="#上下文管理的核心" class="headerlink" title="上下文管理的核心"></a>上下文管理的核心</h2><p>要想让AI持续有效地工作，项目上下文必须有序管理：</p>
<ol>
<li>规范文件分类清晰，按模块分目录；</li>
<li>方案文档结构化，方便AI快速索引；</li>
<li>自动化脚本根据任务调度上下文，让AI“看得懂项目”。</li>
</ol>
<p>这才是真正的“AI编程助手”关键所在。</p>
<hr>
<h2 id="一点哲学思考"><a href="#一点哲学思考" class="headerlink" title="一点哲学思考"></a>一点哲学思考</h2><p>这套方案的本质是把开发人员角色分层：</p>
<ul>
<li>AI是“码农+助理”，帮你实现具体功能；</li>
<li>你是“开发经理”，负责设计、审查、控制质量；</li>
<li>团队协作依旧重要，人类仍然是决策核心。</li>
</ul>
<p>AI工具不是真正的替代，而是推动开发人员往更高的抽象层次发展。<br>从这个角度看，AI是个强大的加速器，而不是终点。</p>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>整个实践路线：</p>
<ol>
<li>项目初始化，搭规范和骨架；</li>
<li>细化任务方案，人工Review；</li>
<li>用脚本驱动AI半自动写代码；</li>
<li>明确完成标准，逐步推进。</li>
</ol>
<p>这是目前我能找到的最可控、最实用的“AI编程”方式。<br>它既降低了成本，又不至于乱套，非常适合小团队或者个人工程师快速起项目。</p>
]]></content>
      <tags>
        <tag>tmux</tag>
        <tag>AI编程</tag>
        <tag>自动化开发</tag>
        <tag>Prompt工程</tag>
        <tag>Python</tag>
      </tags>
  </entry>
</search>
