---
title: 关于大模型的Prompt
date: 2025-02-25 21:48:37
tags: [AI, Prompt, LLM]
---

>> 网上资料摘要
>> 一些个人理解

# 大模型交互的核心：提示词工程
>> 以下基于个人理解，并通过claude优化（2025-02-26）
+ 提示词（Prompt）是大模型的输入，也是调用大模型能力的接口，用以激发或引导大模型生成特定类型的回答。
+ 提示词工程的目的是尽量把任务说清楚，让大模型能充分理解我们的意图，以按照正确的方向回答问题。  
+ 在不微调大模型的情况下，外部与大模型交互的唯一途径就是提示工程。即便是已经微调过的大模型，后续与其沟通的唯一途径仍是通过提供提示词，尽管微调可能改变模型对提示词的响应方式。
+ 所谓的RAG、短期记忆（对话历史）、长期记忆等功能，都是基于提示工程这一与大模型交互的路径作为切入点，建立的其他优化策略和架构。


# ICIO框架（Prompt包含的要素）
+ [从原理出发 - 提示词如何影响大模型的输出](https://mp.weixin.qq.com/s/xYC6saH3PU6nJc9mzV5alw)
+ 核心思想，是通过明确定义任务的各个方面，来提高AI响应时的效率和准确性。
+ 在ICIO的框架的设计中，Prompt可能包含四要素：
    - Instruction（指令）：这是最重要的部分，它直接告诉模型需要执行的具体任务。
    - Context（上下文/背景）：上下文提供了任务执行所需的背景信息，帮助模型理解任务的情景和环境。
    - Input Data（输入数据）：输入数据是模型需要处理的具体信息。
    - Output Indicator（输出指示器）：输出指示器告诉模型用户期望的输出类型或格式。
+ 其中除了指令以外，其他要素都是可选的，说明指令对于大模型来说是最重要的，其他要素都是对指令的补充。
+ 优质的Prompt，可以清晰地传达用户的意图

# Prompt五大框架
+ [大模型Prompt技巧全解析](https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A)    
+ RTF框架 
    - R-Role(角色)、R-Role(角色)、F-Format(格式)
+ 思考链模式 
    - 适合一些复杂的任务处理
    - 要使用这种模式，只需要在末尾添加”让我们逐步思考”即可
+ RISEN框架
    - R-Role:大模型扮演的角色
    - I-Instructions: 指示命令，和Task-任务差不多
    - S-Steps: 步骤
    - E-End Goal: 最终目标
    - N-Narrowing(Constraints): 缩小范围(约束条件)，和RTF框架中的Format有异曲同工之妙
    - 该框架主要适合
        - 撰写具有特定约束的任务(例如博客文章)
        - 有明确指导方针的任务（例如商业计划）
+ RODES框架
    - R-Role: 角色、O - Objective: 目标、D - Details: 详细的细节、E - Examples: 示例、S - Sense Check: 感官检查
+ 密度链模式
    - 使用递归来创建越来越好的输出的提示，与普通提示生成的 GPT-4 摘要相比，它生成的摘要更加密集且更适合人们理解
    - 适合：总结、改进您最喜欢的提示、通过递归生成可用的长格式内容

# 打造高效Prompt的两大核心原则
+ [大模型Prompt技巧全解析](https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A) 
+ 原则一：编写明确和具体的指令
    - 策略1：使用分隔符清晰界定输入部分
    - 策略2：要求结构化输出
    - 策略3：要求模型检查条件是否满足
    - 策略4：Few-shot prompting（少样本提示）
+ 原则二：给予模型充足的思考时间
    - 策略1：明确完成任务所需的步骤
    - 策略2：引导模型在得出结论前充分思考方案

# Prompt技术剖析与应用
+ [大模型Prompt技巧全解析](https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A) 
+ 一、零样本提示（Zero-Shot Prompting）
+ 二、少样本提示（Few-Shot Prompting）
    - 在零样本提示效果不佳时发挥作用
+ 三、思维链提示（Chain-of-Thought Prompting）
    - 与少样本提示结合，增强效果，尤其适用于算术、常识推理等任务，帮助模型更有条理地处理问题
+ 四、自我一致性（Self-Consistency）   
    - 主要用于优化思维链提示中的推理路径选择
    - 核心思想是通过提供多个少样本推理示例，让模型从多样的推理结果中筛选出最一致的答案，增强模型在算术和常识推理任务中的可靠性
+ 五、生成知识提示（Generated Knowledge Prompting）
    - 主要用于解决模型在处理需要额外知识的任务时出现的局限性   
    - 个人理解：一种特殊的RAG罢了
+ 六、链式提示（Prompt Chaining）
    - 将复杂任务拆解为多个子任务，通过逐个子任务生成提示并传递结果的方式来实现复杂任务的有序处理
+ 七、思维树（ToT）
    - 为了帮助模型应对复杂的探索性任务而设计
    - 通过维护一棵思维树，让模型在解决问题时能够生成和评估中间思维步骤，并结合搜索算法进行系统性探索
+ 八、检索增强生成（RAG）
    - 将信息检索与文本生成相结合，专门用于处理知识密集型任务
    - 通过检索相关文档来为模型提供额外的知识支持，从而缓解模型的“幻觉”问题
+ 九、自动推理并使用工具（ART）
    - 使模型能够自动生成包含推理步骤的程序，并在需要时调用外部工具
+ 十、自动提示工程师（APE）
    - 自动生成和筛选任务指令
    - 利用大型语言模型生成指令候选项，再依据评估分数选择最佳指令，从而提升提示生成的效率与效果
+ 十一、Active-Prompt
    - 用于解决思维链示例有效性的问题
    - 通过先查询模型生成多个答案，计算不确定度后挑选最不确定的问题由人类注释示例，再用新示例推断其他问题，从而优化模型对不同任务的适应性
+ 十二、方向性刺激提示（Directional Stimulus Prompting）
    - 通过训练策略 LM 生成引导提示，增强对模型生成结果的掌控力。例如文本摘要任务
+ 十三、PAL（程序辅助语言模型）
    - 让模型生成程序来解决问题，借助编程运行时提升解决复杂问题的能力
+ 十四、ReAct 框架
    - ReAct 框架使模型交错生成推理轨迹和操作，提升答案的可靠性与可解释性
+ 十五、自我反思（Reflexion）
    - 包含参与者、评估者和自我反思三个模型，旨在帮助模型从错误中学习并提升性能


# Reference
+ [从原理出发 - 提示词如何影响大模型的输出](https://mp.weixin.qq.com/s/xYC6saH3PU6nJc9mzV5alw)
    - 大模型如何理解Prompt
        + 基于Transformer的解码器的大模型
        + 最核心的两层
            - 掩码多头自注意力层（Masked Multi Self Attention Layers，对应Transformer的Masked Multi-Head Attention，简称MHA）
            - 前置反馈网络层（Feed Forward Networks Layers，简称FFN）
        + Prompt会影响自注意力层对上下文信息的捕捉
        + 自注意力机制
            - 它的核心思想是模仿人类的注意力，即在处理大量信息时，能够聚焦于当前任务最相关的部分，而忽略其他不太重要的信息
+ [大模型Prompt技巧全解析](https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A)            
+ [LLM相关技术简单了解](https://kingson4wu.github.io/2024/12/26/20241226-llm-xiang-guan-ji-zhu-jian-dan-liao-jie/)
+ [大型语言模型的提示注入](https://mp.weixin.qq.com/s/q2iMW0t5456btmIPS1ba6Q)
    - 三种防范此类漏洞的方法
        - 可以在提示中添加指令
        - 使用对抗性探测器添加第二层保护
        - 对模型进行微调，使其更符合用户需求，同时提供最高级别的保护，防止提示注入和窃取


