---
title: 用脚本+AI CLI半自动写代码：实践经验分享
date: 2025-09-02 21:44:21
tags: [tmux, AI编程, 自动化开发, Prompt工程, Python]
---

最近在折腾一个“半自动编程”项目，目标是让 AI 工具在一个相对可控的框架下持续编码，帮我实现一个个明确的开发任务。这里分享整个过程、思路和实践套路，算是一次探索性的工程笔记。

## 为什么要搞半自动

市面上的 AI 编程工具越来越多，比如：Claude Code、Gemini CLI、QWEN CODE 以及其他支持 CLI 模式的 AI 工具。
它们都能帮我们提高开发效率，但如果只是一次次手动问问题，效率还是不够高。我的想法是：

1. 用脚本封装和调度这些 AI 工具；
2. 利用 `tmux` 维持 AI CLI 的会话状态；
3. 自动给 AI 下发任务、收集结果，让 AI 一直“干活”，直到任务完成。

这就像有个“虚拟小弟”24小时帮你写代码，而你更多做架构和技术方案的管理。

---

## 总体套路

我总结下来整个流程可以分成四步，每一步都强调**人工 review**，避免“AI乱写”导致项目失控。

### 1. 初始化项目：立规范、搭框架

项目开始前先搞定**规范和架构**，这是整个半自动化的基础。

* 新建 GitHub 仓库，初始化代码框架：

  ```bash
  git clone git@github.com:Kingson4Wu/ts-playground.git
  ```
* 参考已有项目文档，比如我用的 [cpp-linux-playground](https://github.com/Kingson4Wu/cpp-linux-playground/blob/main/PROJECT.md)，根据 TypeScript 项目的需求，改写成自己的 `PROJECT.md`。
* 规划好：

  * 技术栈（语言、工具链、标准）
  * 测试和任务验收标准
  * 静态分析工具
  * 项目目录结构
  * Git 提交规范

> 小建议：把 `docs/` 改成更专门的目录名（比如 `specifications/`），避免混乱。

这一阶段主要是人工定规则、搭骨架，AI可以辅助起草文档，但最终必须你拍板。

---

### 2. 细化任务实现方案

所有任务先出详细的实现和测试方案，放在 `@specifications/task_specs/` 下。
原则：

* **不直接写代码**，先写详细设计；
* 每个任务的设计经过人工审查和修改；
* 任务设计文件需要明确：

  * 功能描述
  * 实现逻辑
  * 输入输出
  * 单元测试方案
  * 潜在问题或风险点

这样做的好处是：AI有明确的执行指南，写出的代码更可控，后续修改成本也低。

---

### 3. 半自动化驱动编码

有了规范和任务设计，就可以开始半自动写代码了。
我的方案是：

* 用 Python 脚本驱动 AI CLI 工具；
* 通过 `tmux` 维持 AI 会话，避免中断；
* 每个任务循环：

  1. 给 AI 发实现方案；
  2. 要求它按方案写代码，但**不要自动提交代码**；
  3. 人工检查后再提交到 Git。

脚本和逻辑可以参考 [ForgeFlow](https://github.com/Kingson4Wu/ForgeFlow)，里面有完整的交互逻辑示例。

> 小技巧：
>
> * 每个 Prompt 末尾强调“不要自动提交代码”；
> * 如果任务超时超过1小时，自动触发检查机制；
> * 项目进度同步到 `TODO.md`，并在 `PROJECT.md` 中引用。

---

### 4. 定义“完成”的标准

一个任务完成的定义：

1. 按实现方案完成代码；
2. 单元测试全部通过；
3. 脚本和 Prompt 更新到位；
4. 构建和测试无异常；
5. Git 提交所有改动；
6. 进入下一个任务。

最终目标是：

> 输出所有方案 -> 自动实现 -> 所有项目任务完成后，AI只返回“完成”两个字。

---

## 实战项目参考

示例项目：[ts-playground](https://github.com/Kingson4Wu/ts-playground)
这是我搭的一个 TypeScript 学习和实验环境：

* CI/CD 流程完整；
* 用于系统掌握 TypeScript 类型系统；
* 可以复用于后端服务、CLI 工具开发。

这个项目就是通过“人机协作+半自动化”方式落地的。

---

## 半自动 vs 全自动

目前这种方案是“半自动”，而不是“全自动”。原因：

* **设计和规范必须人工介入**：AI生成的规范往往不够完善；
* **脚本和Prompt需要不断打磨**：无法覆盖所有场景；
* **代码质量还需人工检查**：AI的水平不总是稳定。

换句话说，这是一个低成本、可控、复用性强的探索阶段方案。
全自动化？有点远，尤其是多Agent复杂度太高，难以管理上下文和控制风险。

---

## 上下文管理的核心

要想让AI持续有效地工作，项目上下文必须有序管理：

1. 规范文件分类清晰，按模块分目录；
2. 方案文档结构化，方便AI快速索引；
3. 自动化脚本根据任务调度上下文，让AI“看得懂项目”。

这才是真正的“AI编程助手”关键所在。

---

## 一点哲学思考

这套方案的本质是把开发人员角色分层：

* AI是“码农+助理”，帮你实现具体功能；
* 你是“开发经理”，负责设计、审查、控制质量；
* 团队协作依旧重要，人类仍然是决策核心。

AI工具不是真正的替代，而是推动开发人员往更高的抽象层次发展。
从这个角度看，AI是个强大的加速器，而不是终点。

---

## 总结

整个实践路线：

1. 项目初始化，搭规范和骨架；
2. 细化任务方案，人工Review；
3. 用脚本驱动AI半自动写代码；
4. 明确完成标准，逐步推进。

这是目前我能找到的最可控、最实用的“AI编程”方式。
它既降低了成本，又不至于乱套，非常适合小团队或者个人工程师快速起项目。

## 扩展
+ 细化任务方案，可以参考https://github.com/github/spec-kit的套路
