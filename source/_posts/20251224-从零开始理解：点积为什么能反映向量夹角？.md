---
title: 从零开始理解：点积为什么能反映向量夹角？
date: 2025-12-24 17:18:33
tags: [LLM, Math, 数学, 线性代数, AI]
---

当我们谈到词向量相似度时，总会用到"余弦相似度"这个概念。但你有没有想过：**为什么两个向量的点积能反映它们的夹角？这背后的数学原理是什么？**

## 一、从投影说起：最直观的理解

### 投影的几何意义

看这个图：

```
      a
     /|
    / |
   /  | |a|cos(θ)
  /   |
 /_)θ |
b————————————→
```

**a 在 b 方向上的投影长度 = |a|cos(θ)**

### 为什么投影能反映相似度？

想象两个向量代表不同的方向：

**情况1：方向完全一致（θ=0°）**
```
你  →→→→→
    →→→→→
```
投影 = 全部长度，cos(0°) = 1，投影最大

**情况2：方向垂直（θ=90°）**
```
你  ↑↑↑
    →→→
```
投影 = 0，cos(90°) = 0，没有共同分量

**情况3：方向相反（θ=180°）**
```
你  ←←←←←
    →→→→→
```
投影为负，cos(180°) = -1，完全相反

**关键洞察**：
- **夹角越小** → cos(θ) 越大 → **投影越长** → 两个方向越一致
- **夹角为90°** → cos(90°) = 0 → **投影为0** → 两个方向完全无关
- **夹角为180°** → cos(180°) = -1 → **投影为负** → 两个方向完全相反

这就是为什么 cos(θ) 能反映方向相似性。

### cos函数的性质

在 [0°, 180°] 范围内：

```
θ = 0°   → cos(0°) = 1      (完全同向)
θ = 45°  → cos(45°) ≈ 0.707
θ = 90°  → cos(90°) = 0     (垂直)
θ = 135° → cos(135°) ≈ -0.707
θ = 180° → cos(180°) = -1   (完全反向)
```

cos(θ) 随夹角单调递减，这是余弦函数的基本性质。

用图像理解：
```
  cos(θ)
    1 |     ●
      |    /  
    0 |___/__________ θ
      |  /
   -1 | ●
      0°  90°  180°
```

夹角越小 → cos值越大 → 点积越大（向量长度相同时）

## 二、点积的定义和几何意义

### 点积的代数定义

点积的原始定义（代数形式）：

**a · b = a₁b₁ + a₂b₂ + ... + aₙbₙ**

就是对应坐标相乘再求和。

### 点积的几何意义

点积还有一个几何解释：

**a · b = |b| × (|a|cos(θ))**  
= b的长度 × a在b方向上的投影

或反过来：

**a · b = |a| × (|b|cos(θ))**  
= a的长度 × b在a方向上的投影

### 为什么投影还要乘以b的长度？

**举个例子**：
```
a = [3, 4]  
b = [2, 0]  (纯x方向，长度为2)

点积 = 3×2 + 4×0 = 6
```

这个6怎么来的？
- a 在 x 方向的分量是 3
- b 在 x 方向的分量是 2（包含了 b 的长度）
- 两者相乘：3 × 2 = 6

**如果 b 是单位向量呢？**
```
b' = [1, 0]  (长度为1)

点积 = 3×1 + 4×0 = 3
```

这时候点积恰好等于 a 的投影！

**本质原因：坐标分量的乘积**

点积的每一项是 **aᵢbᵢ**，不是 **aᵢ × 1**。

```
a = [a₁, a₂]
b = [b₁, b₂]

点积 = a₁b₁ + a₂b₂
```

b₁ 和 b₂ 本身就包含了 b 的长度信息。

用极坐标看更清楚：
```
b₁ = |b|cos(β)  ← 包含了|b|
b₂ = |b|sin(β)  ← 包含了|b|

点积 = a₁(|b|cos(β)) + a₂(|b|sin(β))
     = |b|(a₁cos(β) + a₂sin(β))
     ↑
     这就是|b|的来源
```

**结论**：
- 如果 b 是**单位向量**（|b|=1），点积 = a 的投影
- 如果 b 不是单位向量，点积 = a 的投影 × |b|

### 如果只想要投影怎么办？

如果你只想要"a 在 b 方向上的投影"，需要：

**投影 = (a · b) / |b|**

或者先把 b 变成单位向量：

**b̂ = b / |b|**  (单位向量)

**投影 = a · b̂ = (a · b) / |b|**

余弦相似度就是这样做的——同时除以两个向量的长度。

## 三、为什么点积公式天然就能算出夹角？

### 坐标分量的乘积求和

让我们看看点积 **a₁b₁ + a₂b₂** 在做什么：

**假设**：
```
a = [3, 4]
b = [5, 0]  (纯x方向)

点积 = 3×5 + 4×0 = 15
```

这在算什么？

b 是纯 x 方向，所以点积只保留了 a 在 x 方向的分量：
- a 的 x 分量是 3
- b 的长度是 5
- 结果 = 3×5 = 15

**本质**：点积的每一项 **aᵢbᵢ** 都在计算"两个向量在第 i 个坐标轴上的分量的乘积"，求和后就得到了"总的共同分量"。

### 再看两个例子

**例子1**：
```
a = [1, 1]    // 指向45°方向
b = [1, 0]    // 指向0°方向
θ = 45°

点积 = 1×1 + 1×0 = 1
|a| = √2
|b| = 1

公式验证：|a||b|cos(45°) = √2 × 1 × 0.707 ≈ 1 ✓
```

**例子2**：
```
a = [0, 1]    // 指向90°方向
b = [1, 0]    // 指向0°方向  
θ = 90°

点积 = 0×1 + 1×0 = 0

验证：|a||b|cos(90°) = 1 × 1 × 0 = 0 ✓
```

## 四、数学推导：点积 = |a||b|cos(θ)

现在严格推导，证明点积的代数定义和几何定义是等价的。

### 方法一：从二维开始（最直观）

**第一步：用极坐标表示向量**

假设两个二维向量：
```
a = [a₁, a₂]
b = [b₁, b₂]
```

用极坐标表示：
```
a = [|a|cos(α), |a|sin(α)]  // α是a与x轴的夹角
b = [|b|cos(β), |b|sin(β)]  // β是b与x轴的夹角
```

其中 **θ = β - α** 是两个向量之间的夹角。

**第二步：计算点积**

```
a · b = a₁b₁ + a₂b₂
     = |a|cos(α) × |b|cos(β) + |a|sin(α) × |b|sin(β)
     = |a||b| [cos(α)cos(β) + sin(α)sin(β)]
```

**第三步：使用三角恒等式**

关键的三角恒等式：

**cos(α)cos(β) + sin(α)sin(β) = cos(β - α) = cos(θ)**

所以：

**a · b = |a||b|cos(θ)**

这不是定义，是推导出来的结论！

### 方法二：用余弦定理（适用于任意维度）

考虑由原点O、向量a的终点A、向量b的终点B构成的三角形：

```
      A (向量a的终点)
     /|
    / |
   /  |θ
  /   |
 O————|————B (向量b的终点)
```

三条边的长度：
- OA = |a|
- OB = |b|
- AB = |a - b|

**余弦定理**：

**|a - b|² = |a|² + |b|² - 2|a||b|cos(θ)**

**展开左边**：

```
|a - b|² = (a - b)·(a - b)
         = a·a - 2a·b + b·b
         = |a|² - 2a·b + |b|²
```

**两式相等**：

```
|a|² - 2a·b + |b|² = |a|² + |b|² - 2|a||b|cos(θ)

⇒ -2a·b = -2|a||b|cos(θ)

⇒ a·b = |a||b|cos(θ)
```

这个证明对任意维度都成立！

### 三维和高维推广

**三维**：用球坐标表示向量，通过更复杂的三角恒等式，同样可以得到：

**a · b = |a||b|cos(θ)**

**高维**：用余弦定理的方法，对**任意 n 维向量**都有：

**a · b = |a||b|cos(θ)**

因此余弦相似度在任意维度都适用！

## 五、余弦相似度：剥离长度，只看方向

### 推导余弦相似度公式

现在我们知道了：

**a · b = |a| |b| cos(θ)**

两边同时除以 **|a||b|**：

**cos(θ) = (a · b) / (|a| × |b|)**

这就是余弦相似度公式！

### 完整推导链条

```
1. 向量用极坐标表示：a = |a|[cos(α), sin(α)]

2. 计算点积：a·b = |a||b|[cos(α)cos(β) + sin(α)sin(β)]

3. 三角恒等式：cos(α)cos(β) + sin(α)sin(β) = cos(β-α) = cos(θ)

4. 得到：a·b = |a||b|cos(θ)

5. 移项：cos(θ) = (a·b)/(|a||b|)
```

### 验证：用具体数字

**例子1：两个向量夹角45°**
```
a = [1, 0]     // 在x轴上，α = 0°
b = [1, 1]     // 在45°方向，β = 45°
θ = 45°

计算：
|a| = √(1² + 0²) = 1
|b| = √(1² + 1²) = √2
a · b = 1×1 + 0×1 = 1

余弦相似度 = 1 / (1 × √2) = 1/√2 ≈ 0.707

验证：cos(45°) = √2/2 ≈ 0.707 ✓
```

**例子2：两个向量垂直**
```
a = [1, 0]     // x轴
b = [0, 1]     // y轴
θ = 90°

计算：
|a| = 1
|b| = 1
a · b = 1×0 + 0×1 = 0

余弦相似度 = 0 / (1 × 1) = 0

验证：cos(90°) = 0 ✓
```

**例子3：两个向量同向但长度不同**
```
a = [3, 4]     // 长度5
b = [6, 8]     // 长度10，方向相同
θ = 0°

计算：
|a| = √(3² + 4²) = 5
|b| = √(6² + 8²) = 10
a · b = 3×6 + 4×8 = 18 + 32 = 50

余弦相似度 = 50 / (5 × 10) = 1

验证：cos(0°) = 1 ✓
```

### 为什么要用余弦相似度？

在语义分析中，我们只关心方向（语义），不关心长度（词频）。

**例如**：
```
"国王" = [0.2, 0.5, 0.8, ...]  长度可能是1.2
"王后" = [0.3, 0.6, 0.9, ...]  长度可能是1.5
```

这两个词向量方向一致，语义应该相似：
- **原始点积**：会受长度影响
- **余弦相似度**：消除长度影响，只看方向

### 余弦相似度的标准化范围

**-1 ≤ cos(θ) ≤ 1**

- **cos(θ) = 1**：完全同向（θ = 0°）
- **cos(θ) = 0**：垂直（θ = 90°），语义无关
- **cos(θ) = -1**：完全反向（θ = 180°）

## 六、核心总结

### 为什么点积能反映夹角？

**1. 数学本质**

点积的代数定义（坐标分量乘积求和）和几何定义（长度×夹角余弦）是数学上等价的，这是通过三角恒等式严格推导出来的。

**2. 直观理解**

- **投影视角**：点积 = 一个向量长度 × 另一个向量在其上的投影
- **分量视角**：点积 = 各坐标轴上"共同分量"的总和
- **夹角视角**：cos(θ)天然单调递减，完美编码了方向差异

**3. 为什么夹角越小，点积越大？**

因为：
- 点积 = |a||b|cos(θ)
- cos函数在[0°,180°]单调递减
- θ小 → cos(θ)大 → 点积大（长度不变时）

这不是人为设计，而是数学结构的必然结果。

### 余弦相似度的意义

**cos(θ) = (a · b) / (|a| × |b|)**

- **消除了向量长度的影响**：同时除以两个向量的长度
- **只保留纯粹的方向信息**：结果只依赖夹角 θ
- **标准化范围 [-1, 1]**：便于比较和解释
- **完美适用于语义相似度**：在NLP中，我们只关心语义方向，不关心词频

所以点积用来衡量"方向一致性"是非常自然的，因为它的数学定义天然就包含了夹角信息。词向量技术只是巧妙地利用了这个数学事实。

---

### 扩展：余弦相似度的几何特性与 Transformer 实战

在深度学习中，余弦相似度（Cosine Similarity）是最常用的度量手段，但其背后的几何逻辑与实际工程应用存在关键差异。

#### 1. 核心矛盾：方向一致性  语义完全等价

* **数学逻辑**：若两个向量共线（同方向），其余弦相似度为 1。
* **物理现实**：在 Embedding 空间中，即使是同义词（如“苹果”与“Apple”）也很难完全共线。模型会利用微小的夹角和向量长度来区分语境、词频或语法特征。
* **结论**：余弦相似度衡量的是“**主题相关性**”，而非绝对的“**语义等同**”。

#### 2. 余弦相似度的“盲区”

余弦相似度最大的特点是**模长无关性**。

* **几何直觉**：它只能分辨向量“指向哪里”，无法分辨向量“走了多远”。对于处于同一条射线上的两个点，余弦相似度认为它们是完全一样的。
* **局限性**：这会导致它无法捕捉语义的“强度”。例如，“好”和“非常好”在方向上可能一致，但后者在向量长度（能量）上通常更强。

#### 3. Transformer 是只用余弦相似度吗？

这是一个常见的误解。事实上，模型在不同阶段对“长度”的态度完全不同：

* **训练阶段（内部机理）**：
Transformer 核心的 **Attention 机制使用点积（Dot Product）**而非余弦相似度。向量长度会被保留并参与运算，用以调节注意力的权重分布。**此时，长度是重要的信号。**
* **检索阶段（工程应用）**：
在向量数据库检索时，通常会先对 Embedding 进行 **L2 归一化**。归一化后的点积计算在数学上等价于余弦相似度。**此时，长度被视为噪声而被抹除。**

#### 本节要点

* **余弦相似度**擅长比较“是什么”，但在区分“程度有多深”上存在天然弱点。
* **模型内部**利用长度来建模重要性，**模型外部**利用方向来保证检索的稳定性。

